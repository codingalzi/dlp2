{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(ch:getting_started_with_neural_networks)=\n",
    "# 신경망 활용 처음부터 끝까지: 분류와 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**감사의 글**\n",
    "\n",
    "아래 내용은 프랑소와 숄레의 \n",
    "[Deep Learning with Python(2판)](https://github.com/fchollet/deep-learning-with-python-notebooks)의 \n",
    "소스코드 내용을 참고해서 작성되었습니다.\n",
    "자료를 공개한 저자에게 진심어린 감사를 전합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스코드**\n",
    "\n",
    "여기서 언급되는 코드를\n",
    "[(구글 코랩) 신경망 활용 처음부터 끝까지: 분류와 회귀](https://colab.research.google.com/github/codingalzi/dlp2/blob/master/notebooks/NB-getting_started_with_neural_networks.ipynb)에서 \n",
    "직접 실행할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**슬라이드**\n",
    "\n",
    "본문 내용을 요약한 [슬라이드](https://github.com/codingalzi/dlp2/raw/master/slides/slides-getting_started_with_neural_networks.pdf)를 다운로드할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**주요 내용**\n",
    "\n",
    "세 종류의 문제를 해결하는 모델을 실전 데이터셋을 이용하여 훈련시키는 방법을 소개한다.\n",
    "\n",
    "- 이진 분류 신경망 모델: 영화 후기 분류\n",
    "- 다중 클래스 분류 신경망 모델: 뉴스 기사 분류\n",
    "- 회귀 신경망 모델: 주택 가격 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**머신러닝 주요 용어**\n",
    "\n",
    "아래 용어의 정의를 명확히 알아야 한다.\n",
    "\n",
    "| 한글 | 영어 | 뜻 |\n",
    "| :--- | :--- | :--- |\n",
    "| 샘플, 입력값 | sample, input | 모델 훈련에 사용되는 데이터 |\n",
    "| 예측값, 출력값 | prediction, output | 모델이 계산한 예측값 |\n",
    "| 타깃 | target | 모델이 맞춰야 하는 값 |\n",
    "| 손실값, 비용, 예측 오차 | loss value | 타깃과 예측값 사이의 오차. 문제 유형에 따라 측정법 다름. |\n",
    "| 손실 함수, 비용 함수| loss function | 손실값(비용)을 계산하는 함수. |\n",
    "| 클래스 | class | 분류 모델에서 각각의 샘플이 속하는 범주(클래스) |\n",
    "| 라벨 | label | 분류 모델에서 타깃 대신 사용하는 표현 |\n",
    "| 이진 분류 | binary classification | 양성/음성, 긍정/부정 등 샘플을 두 개의 클래스로 분류. |\n",
    "| 다중 클래스 분류 | multiclass classification | 샘플을 세 개 이상의 클래스로 분류. 손글씨 숫자 분류 등. |\n",
    "| 다중 라벨 분류 | multilabel classification | 샘플에 대해 두 종류 이상의 라벨을 지정하는 분류. 한 장의 사진에 강아지, 고양이, 토끼 등 여러 종의 포함 여부 확인. 각각의 종에 대해 범부를 맞춰야 함. |\n",
    "| (스칼라) 회귀 | (scalar) regression | 샘플 별로 하나의 값만 예측하기. 주택 가격 예측 등. |\n",
    "| 벡터 회귀 | vector regression | 샘플 별로 두 종류 이상의 값 예측하기. 네모 상자의 좌표 등. |\n",
    "| 배치 | batch | 보통 16, 32, 64, 128 등의 개수의 샘플로 구성된 묶음(배치). 훈련 루프의 스텝에 사용되는 훈련셋. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "(sec:imdb)=\n",
    "## 영화 후기: 이진 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영화 후기의 긍정/부정 여부를 판단하는 이진 분류 모델을 구성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 데이터 준비: IMDB 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "긍정 후기와 부정 후기 각각 25,000개씩 총 50,000개의 영화 후기 샘플로 구성되었으며\n",
    "[IMDB(Internet Moview Database)](https://www.imdb.com/) 영화 후기 사이트에서\n",
    "구한 데이터셋이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스의 `imdb` 모듈의 `load_data()` 함수로 불러올 수 있는 IMDB 데이터셋은\n",
    "이미 훈련셋과 테스트셋으로 구분되어 있다.\n",
    "\n",
    "- `train_data`: 훈련용 입력 데이터셋. 25,000개의 리스트로 구성된 1차원 어레이.\n",
    "- `train_labels`: 훈련용 타깃 데이터셋. 0과 1로 구성된 길이가 25,000인 1차원 어레이.\n",
    "- `test_data`: 테스트용 입력 데이터셋. 25,000개의 리스트로 구성된 1차원 어레이.\n",
    "- `test_labels`: 테스트용 타깃 데이터셋. 0과 1로 구성된 길이가 25,000인 1차원 어레이.\n",
    "\n",
    "```python\n",
    ">>> from tensorflow.keras.datasets import imdb\n",
    ">>> (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "```\n",
    "\n",
    "후기 데이터셋 전체에서 원래 총 88,585개의 단어가 최소 한 번 이상 사용되지만 가장 많이 사용되는\n",
    "10,000개 단어 이외에는 사용 빈도가 너무 낮다.\n",
    "그런 단어는 클래스 분류 훈련에 별 도움이 되지 않거나 오히려 악형향을 끼치기도 한다.\n",
    "따라서 그런 단어들은 무시하는 것이 좋다.\n",
    "`imdb.load_data()` 함수의 `num_words=10000` 키워드 인자는\n",
    "가장 많이 사용되는 10,000개의 이외의 단어는 특정 숫자로 처리하여\n",
    "신경망 모델을 훈련시킬 때 무시되도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 케라스 제공 데이터셋\n",
    ":class: note\n",
    "\n",
    "[`tf.keras.datasets` 모듈](https://keras.io/api/datasets/)이 몇 개의 연습용 데이터셋을 제공한다.\n",
    "\n",
    "- MNIST 손글씨 숫자 분류 데이터셋\n",
    "- CIFAR10 작은 이미지 분류 데이터셋\n",
    "- CIFAR100 작은 이미지 분류 데이터셋\n",
    "- IMDB 영화 후기 감성 분류 데이터셋\n",
    "- Reuters 단문 기사 주제 분류 데이터셋\n",
    "- 패션 MNIST(Fashion MNIST) dataset\n",
    "- 보스턴 주택 가격(Boston Housing price) 회귀 데이터셋\n",
    "\n",
    "각 데이터셋을 담고 있는 객체의 `load_data()` 메서드를 이용하여 미리 구분된 훈련셋과 테스트셋을 넘파이 어레이로 불러올 수 있다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터 살펴보기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "후기 샘플 각각에 사용되는 단어의 수는 일정하지 않다. \n",
    "즉 각 후기 문장의 길이가 일정하지 않다.\n",
    "예를 들어, 훈련셋의 첫째 후기 문장은 218개의 단어로,\n",
    "둘째 후기 문장은 189개의 단어로 구성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> len(train_data[0])\n",
    "218\n",
    ">>> len(train_data[1])\n",
    "189\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각의 입력 샘플은 정수로 구성된 벡터, 즉 1차원 텐서다.\n",
    "각각의 정수는 특정 단어를 가리킨다.\n",
    "예를 들어, 530은 영화 후기에서 530번째로 많이 사용되는 어떤 단어를 가리킨다.\n",
    "\n",
    "훈련셋의 0번 입력 샘플의 처음 10개 값은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> train_data[0][:10]\n",
    "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 샘플의 라벨은 0(부정) 또는 1(긍정)이다.\n",
    "예를 들어, 훈련셋 0번 샘플은 긍정 후기를 가리킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> train_labels[0]\n",
    "1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    ":::{admonition} 영화 후기 내용\n",
    ":class: tip\n",
    "\n",
    "**모델 훈련을 위해 반드시 필요한 사항은 아니지만**\n",
    "필요한 경우 단어와 정수(빈도) 사이의 관계를 담은 사전을 이용하여\n",
    "후기 내용을 확인할 수 있다.\n",
    "\n",
    "```python\n",
    ">>> word_index = imdb.get_word_index()\n",
    "```\n",
    "\n",
    "`word_index`에 포함된 10개 항목을 확인하면 다음과 같다.\n",
    "\n",
    "```python\n",
    ">>> list(word_index.items()[:10]\n",
    "('fawn', 34701)\n",
    "('tsukino', 52006)\n",
    "('nunnery', 52007)\n",
    "('sonja', 16816)\n",
    "('vani', 63951)\n",
    "('woods', 1408)\n",
    "('spiders', 16115)\n",
    "('hanging', 2345)\n",
    "('woody', 2289)\n",
    "('trawling', 52008)\n",
    "```\n",
    "\n",
    "아래 코드는 첫째 후기의 내용을 확인한다.\n",
    "단어 인덱스에서 3을 빼야 함에 주의하라.\n",
    "이유는 인덱스 0, 1, 2는 아래의 의미로 지정되었기 때문이다.\n",
    "\n",
    "- 0: 여백\n",
    "- 1: 문장의 시작\n",
    "- 2: 불분명\n",
    "\n",
    "앞서 10,000개의 가장 많이 사용되는 단어만을 대상으로 하였기에\n",
    "그 이외의 단어는 모두 2로 처리된다.\n",
    "\n",
    "```python\n",
    ">>> reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    ">>> first_review = train_data[0]\n",
    ">>> decoded_review = \" \".join([reverse_word_index.get(i-3, \"?\") for i in first_review])\n",
    "```\n",
    "\n",
    "첫째 후기 내용은 다음과 같다.\n",
    "\n",
    "```python\n",
    ">>> decoded_review\n",
    "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\"\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리: 벡터화와 멀티-핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정수들의 리스트, 그것도 길이가 다른 여러 개의 리스트로 구성된 데이터셋은\n",
    "신경망의 입력값으로 사용할 수 없다. \n",
    "이 문제를 해결하기 위해 일반적으로 아래 두 방식중에 하나를 적용한다.\n",
    "\n",
    "- **벡터화**<font size='2'>vectorization</font>\n",
    "    - 가장 긴 길이의 샘플에 맞춰 모든 샘플을 확장한다.\n",
    "    - 확장에 사용되는 값은 기존 샘플에 사용되지 않은 값을 사용한다.\n",
    "    - 예를 들어 여백을 의미하는 0을 사용할 수 있다.\n",
    "- **멀티-핫 인코딩**<font size='2'>multi-hot encoding</font>\n",
    "    - 0과 1로만 이루어진 일정한 길이의 벡터(1차원 어레이)로 변환한다.\n",
    "    - 벡터의 길이는 사용된 단어의 총 수, 예를 들어 10,000을 사용한다.\n",
    "    \n",
    "여기서는 멀티-핫 인코딩 방식을 사용한다. \n",
    "벡터화 방식은 {numref}`%s장 자연어 처리<ch:nlp>`에서 `Embedding` 층을 사용할 때 자세히 설명한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "후기 리스트에 사용된 숫자들은 0부터 9999 사이의 값이다.\n",
    "이 정보를 이용하여 후기 샘플을 길이가 10,000인 벡터(1차원 어레이)로 변환한다.\n",
    "\n",
    "- 어레이 길이: 10,000\n",
    "- 항목: 0 또는 1\n",
    "- 후기 샘플에 포함된 정수에 해당하는 인덱스의 항목만 1로 지정\n",
    "\n",
    "예를 들어, `[1, 5, 9998]`은 길이가 10,000인 1차원 어레이(벡터)로 변환되는데\n",
    "1번, 5번, 13번 인덱스의 항목만 1이고 나머지는 0으로 채워진다.\n",
    "\n",
    "```\n",
    "멀티-핫-인코딩([1, 5, 9998]) => [0, 1, 0, 0, 0, 1, 0, ..., 0, 0, 1, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 `vectorize_sequences()` 함수는 앞서 설명한 멀티-핫 인코딩을 \n",
    "모든 주어진 샘플에 대해 실행하여 최종적으로\n",
    "데이터셋을 표현하는 넘파이 어레이를 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    \n",
    "    for i, seq in enumerate(sequences):    # 모든 샘플에 대한 멀티-핫 인코딩\n",
    "        for j in seq:\n",
    "            results[i, j] = 1.\n",
    "    return results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 훈련셋과 테스트셋을 벡터화한다.\n",
    "자료형은 `float32`로 고정한다. 그렇지 않으면 `float64`로 지정되기에\n",
    "메모리 효율성을 떨어뜨린다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> x_train = vectorize_sequences(train_data).astype(\"float32\")\n",
    ">>> x_test = vectorize_sequences(test_data).astype(\"float32\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫째 훈련 샘플의 변환 결과는 다음과 같다.\n",
    "결과를 보면 원래의 첫째 훈련 샘플에 0은 포함되지 않았지만 1과 2는 사용되었음을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> x_train[0]\n",
    "array([0., 1., 1., ..., 0., 0., 0.], dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라벨은 멀티-핫 인코딩을 적용하지 않는다.\n",
    "다만 `float32` 자료형으로 변환해서 훈련 샘플의 자료형과 일치시킬 필요는 있다.\n",
    "그래야 손실값을 계산하기 위해 예측값과 라벨을 서로 비교할 수 있기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> y_train = np.asarray(train_labels).astype(\"float32\")\n",
    ">>> y_train\n",
    "array([1., 0., 0., ..., 0., 1., 0.], dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 구성과 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**모델 구성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 샘플의 특성이 벡터(1차원 어레이)로 주어지고 \n",
    "라벨이 스칼라(하나의 숫자)로 주어졌을 때 \n",
    "밀집층<font size='2'>densely-connected layer</font>인 `Dense` 층과\n",
    "`Sequential` 모델을 이용한 모델 구성을 추천한다.\n",
    "\n",
    "이진 분류 신경망 모델에 사용되는 활성화 함수는 일반적으로 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 은닉층의 활성화 함수: 음수를 제거하는 `relu()` 함수\n",
    "\n",
    "    ```python\n",
    "    def relu(x):\n",
    "        if x > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return 0\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이진 분류 모델의 최상위 출력층의 활성화 함수: 0과 1사이의 확률값을 계삲하는 `sigmoid()` 함수\n",
    "\n",
    "    ```python\n",
    "    def sigmoid(x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp/master/slides/images/relu_sigmoid.png\" style=\"width:600px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 활성화 함수\n",
    ":class: hint\n",
    "\n",
    "은닉층의 활성화 함수로 `relu()` 함수와 유사한 함수들이 사용된다.\n",
    "대표적으로 `prelu()`, `elu()`, `tanh()` 등이 많이 활용된다.\n",
    "하지만 여기서는 기본적으로 `relu()` 함수만 사용한다.\n",
    "기타 활성화 함수에 대한 활용과 설명은 \n",
    "오렐리앙 제롱의 [핸즈온 머신러닝 (3판)](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/) 11장을 참고하면 좋다.\n",
    "\n",
    "마지막 출력층의 활성화 함수는 모델의 종류에 따라 결정된다.\n",
    "회귀 모델의 경우 일반적으로 활성화 함수를 사용하지 않으며,\n",
    "이진 분류 모델은 `sigmoid()` 함수를\n",
    "다중 클래스 분류 모델은 `softmax()` 함수를 사용한다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dense` 층으로 신경망을 구성할 때 다음 두 가지를 정해야 한다.\n",
    "\n",
    "- 몇 개의 층을 사용하는가?\n",
    "- 각 층마다 몇 개의 유닛<font size='2'>unit</font>을 사용하는가?\n",
    "\n",
    "위 두 질문에 대한 체계적인 답은\n",
    "{numref}`%s장 머신러닝 핵심 이슈<ch:fundamentals_of_ml>`에서 다룬다.\n",
    "여기서는 일단 아래 구성을 사용한다.\n",
    "\n",
    "- 세 개의 밀집층\n",
    "- 은닉층: 각각 16개의 유닛 사용. 활성화 함수는 `relu()` 함수\n",
    "- 출력층: 1개의 유닛 사용. 활성화 함수는 `sigmoid()` 함수\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이진 분류 모델의 최상위 층은 긍정과 부정 중의 하나, \n",
    "양성과 음성 중의 하나를 결정하는 데에 사용될 \n",
    "하나의 값, 즉 스칼라를 계산해서 출력해야 하기에 \n",
    "보통 하나의 유닛을 사용하는 `Dense` 밀집층을 사용한다. \n",
    "\n",
    "또한 활성화 함수로 0과 1사이의 확률값을 계산하는 `sigmoid()`를 활성화 함수로 사용한다.\n",
    "그러면 [사이킷런의 로지스틱 회귀<font size='2'>logistic regression</font> 모델](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)처럼 작동하는 신경망 모델을 얻게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 모델을 시각화하면 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/04-01.png\" style=\"width:200px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**이진 분류 모델 컴파일**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련에 필요한 옵티마이저, 손실 함수, 평가지표를 다음과 같이 지정한다.\n",
    "\n",
    "- `optimizer=\"rmsprop\"`: 일반적으로 추천되는 옵티마이저.\n",
    "- `loss=\"binary_crossentropy\"`: 이진 분류 모델의 확률 예측값의 오차에 해당하는 로그 손실 계산.\n",
    "- `metrics=\"accuracy\"`: 정확도가 분류 모델의 일반적인 평가지표로 사용됨.\n",
    "\n",
    "```python\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"]\n",
    "             )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 훈련과 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 중인 모델을 에포크마다 검증하기 위해 검증셋을 따로 지정한다.\n",
    "여기서는 `x_train`에서 10,000개의 샘플을 검증셋으로 활용한다.\n",
    "즉, 실제 훈련에 사용되는 데이터는 15,000개로 줄어든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "x_val = x_train[:10000]            # 검증용\n",
    "partial_x_train = x_train[10000:]  # 훈련용\n",
    "y_val = y_train[:10000]            # 검증용 타깃셋\n",
    "partial_y_train = y_train[10000:]  # 훈련용 타깃셋\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val) # 검증 데이터셋 지정\n",
    "                   )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`fit()` 메서드 반환값: `History` 객체**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fit()` 메서드는 훈련과정 중에 계산된 다양한 정보를 저장한 `History` 클래스의 객체를\n",
    "반환한다.\n",
    "`History` 클래스는 `Callback` 클래스를 상속하는데\n",
    "신경망 모델의 훈련 과정중에 생성되는 다양한 정보를 기록하도록 설계되었다.\n",
    "\n",
    "콜백(`Callback`) 클래스의 다양한 활용법에 대해서는 \n",
    "{numref}`%s장 케라스 모델 고급 활용법<ch:working_with_keras>`에서 자세히 살펴볼 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어, \n",
    "`History` 객체에 포함된 `history` 속성은 훈련중에 에포크 단위로 측정된 손실값과 평가지표를 사전으로 저장한다.\n",
    "아래 코드는 훈련 과정중에 기록된 \n",
    "훈련셋과 검증셋에 대한 에포크별 손실값과 정확도가\n",
    "저장되어 있음을 보여준다.\n",
    "\n",
    "```python\n",
    ">>> history_dict = history.history\n",
    ">>> history_dict.keys()\n",
    "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**손실값의 변화**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`history` 속성에 저장된 훈련셋과 검증 세트에 대한 에포크별 손실값의 변화를 보면\n",
    "훈련셋에 대해서는 손실값이 계속 감소하지만 \n",
    "검증셋에 대해서는 4번째 에포크 다음부터 오히려 상승한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/04-04.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**정확도의 변화**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`history` 속성에 저장된 훈련셋과 검증셋에 대한 에포크별 정확도의 경우엔\n",
    "훈련셋에 대해서는 정확도가 계속 증가하지만,\n",
    "검증셋에 대해서는 역시 4번째 에포크 다음부터 조금씩 감소한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/04-05.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**과대적합 방지**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**과대적합**<font size='2'>overfitting</font>은 모델이 훈련셋에 익숙해져서\n",
    "처음 보는 데이터에 대해서 성능이 더 이상 좋아지지 않거나 떨어지는 현상을 가리킨다.\n",
    "따라서 앞서 살펴본 모델도 4번째 에포크 이후로 과대적합 현상을 겪기 시작했다.\n",
    "이는 4번의 에포크만 훈련 반복을 진행하면 과대적합되지 \n",
    "않은 모델이 훈련됨을 의미한다.\n",
    "\n",
    "여기서는 과대적합되지 않는 모델을 얻기위해 모델을 재훈련시킨다. \n",
    "모델을 재훈련 시키려면 \n",
    "모델 구성부터, 컴파일, 훈련을 모두 처음부터 다시 시작해야 한다.\n",
    "그래야 가중치와 편향이 초기화된 상태로 훈련이 시작되기 때문이다.\n",
    "그렇지 않으면 이전 훈련 결과를 이어 받아 훈련된다.\n",
    "\n",
    "{numref}`%s장 머신러닝 모델 훈련 기법<ch:fundamentals_of_ml>`에서\n",
    "과대적합을 방지하기 위한 기타 다양한 기법을 소개한다.\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**훈련 결과 테스트**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 결과를 테스트하기 위해 훈련에 전혀 사용되지 않은 테스트셋을 이용하여\n",
    "정확도를 계산한다.\n",
    "이를 훈련된 모델의 `evaluate()` 메서드를 이용한다.\n",
    "\n",
    "```python\n",
    ">>> results = model.evaluate(x_test, y_test)\n",
    ">>> results\n",
    "[0.3139097988605499, 0.8770800232887268]\n",
    "```\n",
    "\n",
    "테스트셋에 대한 성능은 아래와 같이 88% 정도의 정확도를 보인다. 모델의 손실값은 0.31 정도.\n",
    "앞으로 보다 좋은 성능의 모델을 살펴볼 것이며, \n",
    "현존하는 가장 좋은 모델의 정확도는 95% 정도로 알려져 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 활용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "훈련된 모델을 활용하려면 `predict()` 메서드를 이용한다.\n",
    "그러면 큰 데이터셋에 대해서도 지정된 배치 단위로 예측값을 계산한다.\n",
    "\n",
    "이진 분류 모델이고 출력층에 `sigmoid()` 함수를 사용하였기에\n",
    "예측값이 부정 샘플에 대해서는 0을, 긍정 샘플에 대해서는 1에 가까울 수록\n",
    "신경망 모델이 자신의 예측값에 대한 확신이 높다고 할 수 있다.\n",
    "\n",
    "앞서 훈련셋의 `dtype`을 `float32`로 지정하였기에 예측값도 동일한 자료형으로\n",
    "계산되었음을 확인할 수 있다.\n",
    "\n",
    "```python\n",
    ">>> model.predict(x_test, batch_size=512)\n",
    "array([[0.25440323],\n",
    "       [0.9999424 ],\n",
    "       [0.95840394],\n",
    "       ...,\n",
    "       [0.17153329],\n",
    "       [0.10725482],\n",
    "       [0.6672551 ]], dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 뉴스 기사: 다중 클래스 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 데이터 준비: 로이터 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로이터<font size='2'>Reuter</font> 통신사가 1986년에 작성한 단문 기사 모음집이다.\n",
    "총 11,228개의 단문 기사로 구성되었으며 훈련셋과 테스트셋으로 이미 구분되어 있다.\n",
    "\n",
    "- 훈련셋 크기: 8,982\n",
    "- 테스트셋 크기: 2,246\n",
    "\n",
    "기사에서 다루는 주제는 총 46 개로 구분되며, 각각의 기사는 하나의 주제와 연관된다.\n",
    "여기서 훈련시키는 모델은 각각의 기사에 대해 46개 중의 하나의 주제를 예측하는\n",
    "분류 모델이다.\n",
    "라벨의 범주(클래스)가 3개 이상이기에 \n",
    "**다중 클래스 분류**<font size='2'>multiclass classification</font> 모델이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스의 `reuters` 모듈의 `load_data()` 함수로 데이터셋을 불러올 수 있다.\n",
    "불러올 때 영화 후기의 경우처럼 단어 사용빈도에서 상위 10,000등 이내의 단어만 대상으로 한다.\n",
    "그렇지 않은 단어는 모두 특정 숫자로 대체된다.\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.datasets import reuters\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터 살펴보기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 샘플은 정수들의 리스트이다.\n",
    "\n",
    "```python\n",
    ">>> train_data[10]\n",
    "[1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979,\n",
    "3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 샘플에 대한 라벨은 0부터 45까지의 정수로 표현된다.\n",
    "예를 들어, 10번 기사의 주제는 3이다. \n",
    "\n",
    "```python\n",
    ">>> train_labels[10]\n",
    "3\n",
    "```\n",
    "\n",
    "3번 주제는 소득(earn)을 가리킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 로이터 기사 주제\n",
    ":class: tip\n",
    "\n",
    "언급된 46개의 주제와 번호 사이의 관계는\n",
    "[GitHub: Where can I find topics of reuters dataset #12072](https://github.com/keras-team/keras/issues/12072)에서 확인할 수 있다.\n",
    "\n",
    "| 번호 | 주제 | 번호 | 주제 | 번호 | 주제 | 번호 | 주제 |\n",
    "| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| 0 | cocoa | 1 | grain| 2 | veg-oil | 3 | earn |\n",
    "| 4 | acq | 5 | wheat | 6 | copper | 7 | housing |\n",
    "| 8 | money-supply | 9 | coffee | 10 | sugar | 11 | trade |\n",
    "| 12 | reserves | 13 | ship | 14 | cotton | 15 | carcass |\n",
    "| 16 | crude | 17 | nat-gas | 18 | cpi | 19 | money-fx |\n",
    "| 20 | interest | 21 | gnp | 22 | meal-feed | 23 | alum |\n",
    "| 24 | oilseed | 25 | gold | 26 | tin | 27 | strategic-metal |\n",
    "| 28 | livestock | 29 | retail | 30 | ipi | 31 | iron-steel |\n",
    "| 32 | rubber | 33 | heat | 34 | jobs | 35 | lei |\n",
    "| 36 | bop | 37 | zinc | 38 | orange | 39 | pet-chem |\n",
    "| 40 | dlr | 41 | gas | 42 | silver | 43 | wpi |\n",
    "| 44 | hog | 45 | lead | | | | |\n",
    "\n",
    "실제로 10번 기사 내용을 확인해보면 소득(earn)과 관련되어 있어 보인다.\n",
    "데이터를 해독(decoding)하는 방법은 IMDB 데이터셋의 경우와 동일하다.\n",
    "\n",
    "```python\n",
    ">>> word_index = reuters.get_word_index()\n",
    ">>> reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    ">>> decoded_newswire = \" \".join([reverse_word_index.get(i - 3, \"?\") for i in train_data[10]])\n",
    ">>> decoded_newswire\n",
    "? period ended december 31 shr profit 11 cts vs loss 24 cts net profit 224 271 vs loss 511 349 revs 7 258 688 vs 7 200 349 reuter 3\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 데이터 전처리: 원-핫 인코딩, 멀티-핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**입력 데이터셋 멀티-핫 인코딩**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "사용빈도가 10,000 미만인 단어만 사용하도록 하였기에\n",
    "IMDB의 경우와 동일한 방식으로 모든 기사 샘플을 길이가 10,000인 멀티-핫 인코딩 한다.\n",
    "\n",
    "```python\n",
    ">>> x_train = vectorize_sequences(train_data)\n",
    ">>> x_test = vectorize_sequences(test_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**라벨 데이터셋 원-핫 인코딩**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라벨은 0부터 45 사이의 값이다.\n",
    "이런 경우 정수로 구성된 텐서를 사용하기 보다는\n",
    "**원-핫 인코딩**<font size='2'>one-hot encoding</font>\n",
    "기법을 적용하는 게 좋다.\n",
    "\n",
    "원-핫 인코딩은 멀티-핫 인코딩 기법과 유사하다.\n",
    "원-핫 인코딩으로 생성된 벡터 (1차원 텐서, 여기서는 1차원 어레이)는 \n",
    "한 곳에서만 1이고 나머지 인덱스에서는 모두 0을 항목으로 갖는다.\n",
    "예를 들어, 정수 3은 길이가 46인 벡터로 변환되는데\n",
    "3번 인덱스에서만 1이고 나머지 항목은 모두 0이다.\n",
    "\n",
    "```python\n",
    "3 => [0, 0, 0, 1, 0, 0, ...., 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스의 `to_categorical()` 함수가 원-핫 인코딩을 지원한다.\n",
    "원-핫 벡터의 길이는 사용된 라벨의 최댓값에 1을 더한 값이다.\n",
    "\n",
    "```python\n",
    ">>> from tensorflow.keras.utils import to_categorical\n",
    ">>> y_train = to_categorical(train_labels)\n",
    ">>> y_test = to_categorical(test_labels)\n",
    ">>> y_train[0]\n",
    "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 원-핫 인코딩 함수\n",
    ":class: note\n",
    "\n",
    "케라스의 `to_categorical()` 함수를 아래 `to_ont_hot()` 함수로 직접 구현할 수 있다.\n",
    "`dimension`은 원-핫 벡터의 길이를 지정하며, 사용된 라벨의 최댓값보다 1 크게 잡는다.\n",
    "\n",
    "```python\n",
    "def to_one_hot(labels):\n",
    "    dimension = max(labels) + 1\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "```\n",
    "또한 원-핫 인코딩, 멀티-핫 인코딩 등 정수를 사용하는 데이터를 범주형 데이터로 변환하는 \n",
    "전처리 과정을 지원하는 층<font size='2'>layer</font>도 있다.\n",
    "예를 들어 [tf.keras.layers.CategoryEncoding](https://keras.io/api/layers/preprocessing_layers/categorical/category_encoding/)은 \n",
    "원-핫 인코딩과 멀티-핫 인코딩을 지원한다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구성과 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 구성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "IMDB 데이터셋의 경우와는 달리 3 개 이상의 클래스(범주)로 분류하는 \n",
    "**다중 클래스 분류** 모델을 구성하고 훈련시킨다.\n",
    "\n",
    "여기서 사용하는 층의 구성은 다음과 같다.\n",
    "\n",
    "- 은닉층은 긍정/부정의 이진 분류 모델 보다 훨씬 많은 64개의 \n",
    "    유닛을 사용하도록 한다.\n",
    "    이유는 이진 분류보다 훨씬 많은 46개의 클래스로 분류하려면\n",
    "    보다 많은 정보를 각 층에서 다룰 수 있어야 하기 때문이다.\n",
    "    층에 사용되는 유닛이 많을 수록 보다 많은 정보를 계산한다.\n",
    "\n",
    "- 다중 클래스 분류 모델의 출력층은 클래스 수 만큼의 값으로 구성된 벡터를 출력하도록 \n",
    "    여러 개의 유닛을 사용하는 `Dense` 밀집층을 사용한다. \n",
    "    또한 활성화 함수로 모든 유닛에 대한 확률값의 합이 1이 되도록 하는 `softmax()`를 활성화 함수로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\")\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    ":::{admonition} softmax 활성화 함수\n",
    ":class: info\n",
    "\n",
    "`softmax()` 함수는 다음과 같이 정의된다.\n",
    "\n",
    "```python\n",
    "def softmax(vector):\n",
    "    e = np.exp(vector)\n",
    "    return e / e.sum()\n",
    "```\n",
    "\n",
    "`softmax()` 활성화 함수는 유닛별로 아핀변환된 값들을 종합하여\n",
    "최종적으로 각 유닛이 대변하는 클래스에 속할 확률을 계산한다.\n",
    "클래스별 확률을 합치면 1이 되며, 가장 높은 확률을 갖는 클래스를 \n",
    "모델의 최종 예측값으로 사용한다.\n",
    "보다 자세한 설명은 [핸즈온 머신러닝 4장](https://codingalzi.github.io/handson-ml3/training_models.html)을 참고한다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 컴파일**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "다중 클래스 분류 모델의 손실함수는 `categorical_crossentropy`로 지정한다. \n",
    "`categorical_crossentropy`는 클래스의 실제 분포와 예측 클래스의 분포 사이의 \n",
    "오차를 측정하며, 보다 자세한 설명은\n",
    "[핸즈온 머신러닝(3판)의 소프트맥스 회귀의 비용 함수](https://codingalzi.github.io/handson-ml3/training_models.html#sec-softmax-regression)를 참고한다.\n",
    "\n",
    "```python\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    ":::{admonition} 정수 라벨과 sparse_categorical_crossentropy\n",
    ":class: hint\n",
    "\n",
    "분류할 범주의 수가 많을 경우 정수 라벨을 원-핫 인코딩하지 않고 바로 사용하는 게 보다 메모리 효율적이다.\n",
    "그런데 정수 텐서 라벨(타깃)을 이용하여 훈련하려면 모델을 컴파일할 때 손실함수로 \n",
    "`sparse_categorical_crossentropy`를 사용해야 한다.\n",
    "\n",
    "```python\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 훈련과 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "훈련 방식은 영화 후기 이진 분류 모델의 경우와 동일하다.\n",
    "대신에 검증셋의 크기를 1,000으로 지정한다.\n",
    "참고로, 검증셋의 크기는 훈련셋의 크기에 비례해서 적절하게 정한다.\n",
    "\n",
    "```python\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "y_val = y_train[:1000]\n",
    "partial_y_train = y_train[1000:]\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**손실값의 변화**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9번째 에포크 이후로 검증셋에 대한 손실값이 올라간다.\n",
    "즉, 그때부터 과대적합이 발생하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/04-06.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**정확도의 변화**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도 역시 9번째 에포크 이후로 조금씩 떨어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/04-07.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 재훈련**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "9번 에포크를 지나면서 과대적합이 발생하기에\n",
    "에포크 수를 9로 줄이고 처음부터 다시 훈련시킨다.\n",
    "IMDB 데이터셋 이진 분류에서 설명한 대로 \n",
    "모델 구성부터, 컴파일, 훈련을 모두 다시 시작한다.\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트셋에 대한 성능은 아래와 같이 80% 정도의 정확도를 보인다.\n",
    "모델의 손실값은 0.96 정도로 계산된다.\n",
    "\n",
    "```python\n",
    ">>> results = model.evaluate(x_test, y_test)\n",
    ">>> results\n",
    "[0.9565213431445807, 0.79697239536954589]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80%의 정확도가 얼마나 좋은지/나쁜지를 판단하려면 무작위로 찍을 때의 정확도를 계산해봐야 한다.\n",
    "실제로 로이터 데이터셋을 이용하여 무작위로 찍을 때의 정확도는 19% 정도 나온다.\n",
    "따라서 80% 정도의 정확도는 상당히 좋은 편이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 활용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련된 모델의 `predict()` 메서드는 각 입력 샘플에 대해\n",
    "마지막 층에 사용된 유닛의 개수 만큼의 길이로 구성된 벡터 텐서를 반환한다.\n",
    "여기서는 소프트맥스 함수에 의해 46개 클래스에 속할 확률로 구성된 길이가 46인 벡터 텐서가 반환되며\n",
    "각 확률값의 합은 1이다.\n",
    "\n",
    "```python\n",
    ">>> predictions = model.predict(x_test)\n",
    ">>> predictions[0].shape\n",
    "(46,)\n",
    ">>> np.sum(predictions[0])\n",
    "1.0\n",
    "```\n",
    "\n",
    "이중에 가장 높은 확률값이 위치한 인덱스를 모델의 최종 예측값으로 사용하면 된다.\n",
    "이를 위해 `np.argmax()` 함수를 이용한다.\n",
    "예를 들어, 테스트셋의 첫째 샘플에 대한 예측값은 3이다.\n",
    "\n",
    "```python\n",
    ">>> np.argmax(predictions[0])\n",
    "3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 정보 병목 현상\n",
    ":class: tip\n",
    "\n",
    "층에 사용되는 유닛의 수를 지정할 때 병목 현상<font size='2'>bottleneck</font>이 발생하지 않도록 조심해야 한다.\n",
    "각 층은 이전 층에서 넘겨진 값만 활용할 수 있기에 이전 층이 너무 적은 수의 유닛을\n",
    "사용하면 그만큼 전달되는 정보의 양도 적다.\n",
    "따라서 이후에 아무리 많은 유닛을 사용하더라도 새로운 정보를 생성하기는 어렵다.\n",
    "이를 정보 병목 현상이라 부르며 이런 일이 발생하지 않도록\n",
    "층을 구성해야 한다.\n",
    "\n",
    "예를 들어 은닉층에 사용되는 유닛은 마지막 층의 유닛보다 많아야 한다.\n",
    "그렇지 않으면 정보전달 과정에 병목 현상이 발생할 수 있다.\n",
    "아래 코드의 둘째 은닉층은 4 개의 유닛만을 사용하는데 \n",
    "훈련된 모델의 성능이 많이 저하된다.\n",
    "실제로 테스트셋에 대한 정확도가 80% 정도에서 65% 정도로 낮아진다.\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\")\n",
    "])\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 주택가격: 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이진 분류와 다중 클래스 분류는\n",
    "몇 개의 클래스를 가리키는 숫자들 중에 하나를 예측하는 문제다.\n",
    "반면에 임의의 실수를 예측하는 문제는 **회귀**<font size='2'>regression</font>라 부른다. \n",
    "예를 들어 온도 예측, 가격 예측을 하는 머신러닝 모델이 회귀 모델이다.\n",
    "\n",
    "여기서는 미국 보스턴<font size='2'>Boston</font> 시의 1970년대 중반의 \n",
    "주택가격을 예측하는 회귀 문제를 예제로 다룬다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 로지스틱 회귀\n",
    ":class: warning\n",
    "\n",
    "로지스틱 회귀<font size='2'>logistic regression</font> 알고리즘는 분류 모델임에 주의하라.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 데이터 준비: 보스턴 주택가격 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용하는 데이터셋은\n",
    "1970년대 중반의 미국 보스턴 시 외곽의 총 506개 지역에서 수집된 통계 자료를 담고 있다.\n",
    "통계는  지역별 중간 주택가격과 함께 다음 13가지 내용을 조사했다.\n",
    "\n",
    "| 특성 | 의미 |\n",
    "|:------|:---------|\n",
    "| <font color=\"#FF0000\">CRIM</font>  | <font color=\"#FF0000\">구역별 1인당 범죄율</font> |\n",
    "| ZN    | 25,000 평방 피트 이상의 주거 구역 비율 |\n",
    "| INDUS | 구역별 비 소매 사업 면적(에이커) 비율 |\n",
    "| CHAS  | Charles River 경계 접촉 여부 |\n",
    "| NOX   | 산화 질소 농도 |\n",
    "| RM    | 주택 당 평균 방 수 |\n",
    "| AGE   | 1940년 이전에 지어졌으면서 소유주가 살고 있는 주택 비율 |\n",
    "| DIS   | 보스턴 고용 센터 다섯 곳 까지의 가중(weighted) 거리 |\n",
    "| RAD   | 방사형 고속도로 접근성 지수 |\n",
    "| TAX   | 1만달러당 재산세율 |\n",
    "| PTRATIO | 구역별 학생-교사 비율 |\n",
    "| <font color=\"#FF0000\">B</font>     | <font color=\"#FF0000\">1000(Bk - 0.63)^2 (Bk는구역별 흑인 비율)</font> |\n",
    "| <font color=\"#FF0000\">LSTAT</font> | <font color=\"#FF0000\">구역별 하위 계층 인구 비율</font> |\n",
    "\n",
    "언급된 13가지 데이터가 주어졌을 때 해당 구역의 중간 주택가격을 예측하는 회귀 모델을\n",
    "훈련시켜야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 보스턴 데이터셋의 윤리 문제\n",
    ":class: hint\n",
    "\n",
    "구역별로 조사된 자료 중에서 범죄율, 흑인 비율, 하위 계층 비율 등을 포함한다.\n",
    "특히 흑인 비율을 사용하는 `B` 특성이 윤리적 논쟁을 일으킨다.\n",
    "구역의 집값과 흑인 비율의 연관성을 암시하는 이런 통계 조사는\n",
    "1970년대 미국에서 인종 차별이 여전히 주요 쟁점이었음을 단편적으로 보여준다.\n",
    "여기서는 단순히 데이터 활용 차원에서만 보스턴 데이터셋을 이용할 뿐 다른 어떤 의도도 없음을 밝힌다.\n",
    "또한 `B` 특성을 제거하더라도 좋은 성능의 회귀 모델을 훈련시킬 수 있음을 보인다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스 `boston_housing` 모듈의 `load_data()` 함수로 보스턴 데이터셋을 불러올 수 있다.\n",
    "데이터셋이 이미 404개 샘플로 구성된 훈련셋과 102개 샘플로 구성된 테스트셋으로 구분되어 있다.\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타깃은 구역별 중앙 주택가격이며 부동소수점을 사용한다.\n",
    "\n",
    "```python\n",
    ">>> train_targets\n",
    "[ 15.2,  42.3,  50. ...  19.4,  19.4,  29.1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 데이터 전처리: 표준화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성에 따라 사용되는 값들의 크기 정도<font size='2'>scale</font>가 다르다. \n",
    "어떤 특성은 0과 1사이의 값을, 다른 특성은 100단위의 값을 포함하기도 한다.\n",
    "그런데 머신러닝 모델은 기본적으로 모든 특성이 동일한 크기 정도의 \n",
    "값으로 구성될 때 보다 잘 훈련된다.\n",
    "이런 이유로 여기서는 평균은 0, 표준편차는 1이 되도록 변환하는\n",
    "**표준화**<font size='2'>standardization</font>를 적용해서\n",
    "훈련셋과 테스트셋을 전처리한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "표준화는 다음 식으로 계산된다. \n",
    "\n",
    "$$\n",
    "\\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "$x$는 샘플의 특성값을, $\\mu$와 $\\sigma$는 특성별 평균값과 표준편차를 가리킨다.\n",
    "넘파이 어레이를 이용하면 전체 훈련셋에 대해 다음처럼 한 번에 표준화를 진행할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 훈련셋의 특성별 평균값/표준편차\n",
    "mean = train_data.mean(axis=0)\n",
    "std = train_data.std(axis=0)\n",
    "\n",
    "# 훈련셋 표준화\n",
    "train_data -= mean\n",
    "train_data /= std\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트셋의 표준화도 훈련셋의 평균값과 표준편차를 이용한다.\n",
    "이유는 테스트셋에 대한 어떤 정보도 미리 알 수 없다는 전제가 실현되야 하기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 테스트셋 표준화: 훈련셋의 평균값과 표준편차 활용\n",
    "test_data -= mean\n",
    "test_data /= std\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 구성과 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋이 작으므로 출력층을 제외하고 두 개 층만 사용한다.\n",
    "머신러닝 모델은 훈련셋이 작을 수록 과대적합을 보다 잘하기 때문이\n",
    "이를 방지하기 위해 보다 단순한 모델을 사용한다.\n",
    "\n",
    "마지막 층을 제외한 나머지 층은 64개의 유닛과 함께 `relu()` 활성화 함수를 사용한다.\n",
    "회귀 모델의 마지막 층은 기본적으로 활성화 함수 없이 1개의 유닛만 사용한다.\n",
    "이유는 하나의 값을 예측하되 그 값의 크기를 제한하지 않아야 하기 때문이다.\n",
    "\n",
    "모델 컴파일에 필요한 손실 함수와 평가지표는 다음과 같다.\n",
    "\n",
    "- 손실함수: **평균제곱오차**<font size='2'>mean squared error</font>(mse). \n",
    "    타깃과 예측값 사이의 오차의 제곱의 평균값. 회귀 모델의 일반적인 손실 함수.\n",
    "- 평가지표: **평균절대오차**<font size='2'>mean absolute error</font>(mae).\n",
    "    타깃과 예측값 사이의 오차의 평균값. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동일한 모델을 앞으로도 반복해서 사용할 예정이기에\n",
    "여기서는 모델 구성과 컴파일을 동시에 진행하는 \n",
    "하나의 함수를 선언한다.\n",
    "\n",
    "```python\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "    return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련과 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋이 작기에 훈련 중에 사용할 검증 세트를 따로 분리하는 것은 훈련의 효율성을 떨어뜨린다.\n",
    "대신에 **K-겹 교차검증**<font size='2'>K-fold cross-validation</font>을 사용한다.\n",
    "아래 이미지는 3-겹 교차검증을 사용할 때 훈련 중에 사용되는 훈련셋과 검증셋의 사용법을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/3-fold-cross-validation.png\" style=\"width:600px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "아래 코드는 3-겹 교차검증을 구현한다.\n",
    "\n",
    "훈련셋을 3등분 한 다음에 폴드별로 차례대로 검증셋으로 활용하여 모델을 3번 훈련시킨다.\n",
    "훈련되는 모델은 앞서 `build_model()` 함수로 선언된 모델이며\n",
    "폴드가 정해지면 매번 새롭게 선언된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "# 폴드 수\n",
    "k = 3\n",
    "# 검증 폴드의 크기\n",
    "num_val_samples = len(train_data) // k\n",
    "# 모델 훈련 에포크 수\n",
    "num_epochs = 500\n",
    "# 폴드별 평가지표 저장\n",
    "all_mae_histories = []\n",
    "\n",
    "# k-겹 교차검증\n",
    "for i in range(k):\n",
    "    print(f\"{i+1}번 째 폴드(fold) 훈련 시작\")\n",
    "    # 검증 폴드 지정\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    # 훈련셋과 훈련 타깃 지정: 검증 폴드 이외 나머지 3개의 폴드\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    # 모델 지정\n",
    "    model = build_model()\n",
    "    # 모델 훈련\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=16, verbose=0)\n",
    "    # 폴드별 평가지표 저장\n",
    "    mae_history = history.history[\"val_mae\"]\n",
    "    all_mae_histories.append(mae_history)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "3개의 폴드에 대해 매번 다른 폴드를 검증셋으로 지정하고 \n",
    "모델 훈련을 500번 에포크 동안 진행하였다.\n",
    "에포크별로 검증셋을 대상으로하는 평균절대오차(MAE)의 평균값을 계산하면\n",
    "에포크별 MAE의 변화를 그래프로 확인할 수 있다.\n",
    "\n",
    "```python\n",
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
    "```\n",
    "\n",
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch04-overfitting02.png\" style=\"width:600px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{prf:example} 사이킷런의 `KFold` 클래스\n",
    ":label: exp-k-fold\n",
    "\n",
    "사이킷런의 `KFold` 클래스를 이용하면 봅다 간단하게 K-겹 교차검증을 진행할 수 있다.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k = 3\n",
    "num_epochs = 500\n",
    "\n",
    "kf = KFold(n_splits=k)\n",
    "all_mae_histories = []\n",
    "\n",
    "for train_index, val_index in kf.split(train_data, train_targets):\n",
    "    \n",
    "    val_data, val_targets = train_data[val_index], train_targets[val_index]\n",
    "    partial_train_data, partial_train_targets = train_data[train_index], train_targets[train_index]\n",
    "    \n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=16, verbose=0)\n",
    "\n",
    "    mae_history = history.history[\"val_mae\"]    \n",
    "    all_mae_histories.append(mae_history)\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 재훈련**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "대략 200번 째 에포크를 전후로 과대적합이 발생함을 확인할 수 있다.\n",
    "정확한 에포크 수는 아래와 같이 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 최소의 mae가 위치한 인덱스 확인\n",
    ">>> overfitting_epoch = np.argmin(average_mae_history)\n",
    ">>> overfitting_epoch\n",
    "196\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "과대적합이 발생하기 이전까지의 에포크만 이용해서 모델을 처음부터 재훈련한다.\n",
    "\n",
    "```python\n",
    ">>> model = build_model()\n",
    ">>> model.fit(train_data, train_targets,\n",
    "...           epochs=overfitting_epoch, batch_size=16, verbose=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "재훈련된 모델의 테스트셋에 대한 성능을 평가하면 \n",
    "주택가격 예측에 있어서 평균적으로 2.39, 즉 2,390달러 정도의 차이를 갖는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    ">>> test_mae_score\n",
    "2.3917253017425537\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 활용**\n",
    "\n",
    "새로운 데이터에 대한 예측은 `predict()` 메서드를 활용한다.\n",
    "집갑을 예측하는 모델이기에 하나의 수가 예측된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> predictions = model.predict(test_data)\n",
    ">>> predictions[0]\n",
    "array([9.530529], dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성 `B` 제외 후 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`B` 특성을 제거하고 동일한 방식으로 모델을 훈련시킨 결과를 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch04-overfitting03.png\" style=\"width:600px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재훈련된 모델의 테스트셋에 대한 성능을 평가하면 \n",
    "주택가격 예측에 있어서 평균적으로 2.60, 즉 2,600달러 정도의 차이를 가지면\n",
    "특성 `B`를 추가했을 때보다 성능이 조금 떨어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 12.2827 - mae: 2.6088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.608802080154419"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "test_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `B` 특성 제거 2부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`B` 특성을 제거한 다음에 모델 훈련 방식을 조금 수정한다.\n",
    "여기서는 3겹 교차검증 대신에 4차 교차검증을 이용하여 모델의 성능을 조금 향상시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch04-overfitting04.png\" style=\"width:600px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재훈련된 모델의 테스트셋에 대한 성능이 조금 좋아졌다. \n",
    "주택가격 예측에 있어서 평균적으로 2.47, 즉 2,470달러 정도의 차이를 가진다.\n",
    "하지만 특성 `B`를 추가했을 때보다 성능이 조금 떨어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 16.2812 - mae: 2.4741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4740915298461914"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "test_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `B` 특성 제거 3부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`B` 특성을 제거한 다음에 데이터 전처리를 다르게 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**전처리: 범주형 특성 원-핫 인코딩**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성 `'CHAS'`는 찰스강<font size='2'>Charles River</font>과의 인접성 여부를 판단하는\n",
    "범주형 데이터다.\n",
    "따라서 이들을 모두 원-핫 인코딩할 필요가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['CHAS'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터프레임의 일부 특성을 원-핫 인코딩하기 위해 `pd.get_dummies()` 함수를 이용한다.\n",
    "참고로 더미<font size='2'>dummy</font>는 부가적으로 추가된 요소를 의미한다.\n",
    "\n",
    "- `data`: 변환 대상 데이터프레임 지정\n",
    "- `columns`: 원-핫 인코딩 대상 특성들의 리스트 지정\n",
    "- `prefix`: 새롭게 생성되는 더미 특성들의 이름에 사용될 접두사 지정\n",
    "- `dtype`: 새롭게 생성되는 값들의 자료형 지정\n",
    "\n",
    "원-핫 인코딩 대상으로 지정된 특성들은 삭제되고 대신 새로운 더미 특성들이 추가된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_dummy = pd.get_dummies(data= train_df,\n",
    "                               columns=['CHAS'],\n",
    "                               prefix=['CHAS'],\n",
    "                               dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>CHAS_0.0</th>\n",
       "      <th>CHAS_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.23247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.142</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3.9769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02177</td>\n",
       "      <td>82.5</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.415</td>\n",
       "      <td>7.610</td>\n",
       "      <td>15.7</td>\n",
       "      <td>6.2700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.89822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.631</td>\n",
       "      <td>4.970</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.3325</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.19</td>\n",
       "      <td>0.515</td>\n",
       "      <td>6.037</td>\n",
       "      <td>34.5</td>\n",
       "      <td>5.9853</td>\n",
       "      <td>5.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>8.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.69311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.376</td>\n",
       "      <td>88.4</td>\n",
       "      <td>2.5671</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>14.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS    NOX     RM    AGE     DIS   RAD    TAX  PTRATIO  \\\n",
       "0  1.23247   0.0   8.14  0.538  6.142   91.7  3.9769   4.0  307.0     21.0   \n",
       "1  0.02177  82.5   2.03  0.415  7.610   15.7  6.2700   2.0  348.0     14.7   \n",
       "2  4.89822   0.0  18.10  0.631  4.970  100.0  1.3325  24.0  666.0     20.2   \n",
       "3  0.03961   0.0   5.19  0.515  6.037   34.5  5.9853   5.0  224.0     20.2   \n",
       "4  3.69311   0.0  18.10  0.713  6.376   88.4  2.5671  24.0  666.0     20.2   \n",
       "\n",
       "   LSTAT  CHAS_0.0  CHAS_1.0  \n",
       "0  18.72       1.0       0.0  \n",
       "1   3.11       1.0       0.0  \n",
       "2   3.26       1.0       0.0  \n",
       "3   8.01       1.0       0.0  \n",
       "4  14.65       1.0       0.0  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트셋에 대해서도 동일하게 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_dummy = pd.get_dummies(data= test_df,\n",
    "                               columns=['CHAS'],\n",
    "                               prefix=['CHAS'],\n",
    "                               dtype='float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**모델 훈련**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "*예제: 4-겹 교차검증*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "truncated_mae_history = average_mae_history[10:]\n",
    "\n",
    "plt.plot(range(1, len(truncated_mae_history) + 1), truncated_mae_history)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation MAE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재훈련된 모델의 테스트셋에 대한 성능을 평가하면 \n",
    "주택가격 예측에 있어서 평균적으로 2.26, 즉 2,260달러 정도의 차이를 가지면\n",
    "특성 `B`를 추가했을 때보다 성능이 많이 좋아진다.\n",
    "\n",
    "앞서 확인한대로 이는 과대적합이 보다 늦게 발생하기 때문이다.\n",
    "즉, 과대적합 없이 오랫동안 훈련한 모델일 수록 성능이 좋아진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 11.8552 - mae: 2.2617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2616639137268066"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "test_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [(실습) 신경망 활용 처음부터 끝까지: 분류와 회귀](https://colab.research.google.com/github/codingalzi/dlp2/blob/master/excs/exc-getting_started_with_neural_networks.ipynb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dlp04-started_with_neural_networks",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
