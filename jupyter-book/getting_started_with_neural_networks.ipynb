{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(ch:getting_started_with_neural_networks)=\n",
    "# 신경망 활용 처음부터 끝까지: 분류와 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**감사의 글**\n",
    "\n",
    "아래 내용은 프랑소와 숄레의 \n",
    "[Deep Learning with Python(2판)](https://github.com/fchollet/deep-learning-with-python-notebooks)의 \n",
    "소스코드 내용을 참고해서 작성되었습니다.\n",
    "자료를 공개한 저자에게 진심어린 감사를 전합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스코드**\n",
    "\n",
    "여기서 언급되는 코드를\n",
    "[(구글 코랩) 신경망 활용 처음부터 끝까지: 분류와 회귀](https://colab.research.google.com/github/codingalzi/dlp2/blob/master/notebooks/NB-getting_started_with_neural_networks.ipynb)에서 \n",
    "직접 실행할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**주요 내용**\n",
    "\n",
    "간단한 실전 예제을 이용하여 신경망 모델을 \n",
    "이진 분류, 다중 클래스 분류, 회귀 문제에 적용하는 방법을 소개한다.\n",
    "\n",
    "- 이진 분류: 영화 후기 분류\n",
    "- 다중 클래스 분류: 뉴스 기사 분류\n",
    "- 회귀: 주택 가격 예측\n",
    "\n",
    "이를 통해 데이터 전처리, 모델 구조 설계, 모델 평가의 딥러닝 모델 훈련의\n",
    "전체 과정을 자세히 살펴본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**머신러닝 주요 용어**\n",
    "\n",
    "아래 용어의 정의를 명확히 알아야 한다.\n",
    "\n",
    "| 한글 | 영어 | 뜻 |\n",
    "| :--- | :--- | :--- |\n",
    "| 샘플, 입력값 | sample, input | 모델 훈련에 사용되는 데이터 |\n",
    "| 예측값, 출력값 | prediction, output | 모델이 계산한 결과 |\n",
    "| 타깃 | target | 예측해야 하는 값 |\n",
    "| 예측 오류, 손실값, 비용 | prediction error, loss value | 타깃과 예측값 사이의 거리 측정값. 측정 방식에 의존함.|\n",
    "| 손실 함수, 비용 함수| loss function | 손실값(비용)을 계산하는 함수 |\n",
    "| 클래스 | class | 분류 문제에서 샘플이 속하는 범주 |\n",
    "| 레이블 | label | 분류 문제에서 타깃 대신 사용 |\n",
    "| 실제의/정답의 | ground-truth | 실제 조사 결과와 관련된 |\n",
    "| 이진 분류 | binary classification | 샘플을 두 개의 클래스로 분류. 양성/음성, 긍정/부정 등. |\n",
    "| 다중 클래스 분류 | multiclass classification | 샘플을 세 개 이상의 클래스로 분류. 손글씨 숫자 등. |\n",
    "| 다중 레이블 분류 | multilabel classification | 샘플에 두 종류 이상의 레이블을 지정하는 분류.사진 속 여러 마리 동물 등. |\n",
    "| 스칼라 회귀 | scalar regression | 샘플 별로 하나의 실숫값 예측하기. 주택 가격 예측 등. |\n",
    "| 벡터 회귀 | vector regression | 샘플 별로 두 개 이상의 실숫값 예측하기. 네모 상자의 좌표 등. |\n",
    "| 미니배치 | mini-batch | 보통 8개에서 128개의 샘플로 구성된 묶음(배치). 훈련 루프의 스텝 지정에 활용됨. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 영화 후기: 이진 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영화 후기가 긍정적인지 부정적인지를 판단하는 이진 분류 모델을 구성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**IMDB 데이터셋**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "긍정 후기와 부정 후기 각각 25,000개씩 총 50,000개의 영화 후기 샘플로 구성된 데이터셋이며,\n",
    "[IMDB(Internet Moview Database)](https://www.imdb.com/) 영화 후기 사이트에서\n",
    "추출된 데이터로 케라스가 자체적으로 제공한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스의 `imdb` 모듈의 `load_data()` 함수로 데이터를 불러온다.\n",
    "데이터셋이 훈련셋과 테스트셋으로 이미 구분되어 있다.\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "```\n",
    "\n",
    "`num_words=10000` 키워드 인자는\n",
    "가장 많이 사용되는 10,000개의 단어로만 구성된 후기를 불러오도록 지정한다.\n",
    "10,000개의 단어에 포함되지 않는 단어는 무시한다.\n",
    "\n",
    "후기 전체에서 원래 총 88,585개의 단어가 최소 한 번 이상 사용되지만 가장 많이 사용되는\n",
    "10,000개 단어 이외는 사용 빈도가 너무 낮아서 클래스 분류에 거의 도움되지 않는다.\n",
    "따라서 그런 단어들은 무시하는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플들의 크기는 서로 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> len(train_data[0])\n",
    "218\n",
    ">>> len(train_data[1])\n",
    "189\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0번 샘플의 처음 10개 값은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> train_data[0][:10]\n",
    "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 샘플의 레이블은 0(부정) 또는 1(긍정)이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> train_labels[0]\n",
    "1\n",
    ">>> test_labels[0]\n",
    "0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    ":::{admonition} 영화 후기 내용\n",
    ":class: tip\n",
    "\n",
    "**모델 훈련을 위해 반드시 필요한 사항은 아니지만**\n",
    "정수와 단어 사이의 관계를 담은 사전을 이용하여\n",
    "원하면 후기 내용을 확인할 수 있다.\n",
    "\n",
    "```python\n",
    ">>> word_index = imdb.get_word_index()\n",
    "```\n",
    "\n",
    "`word_index`에 포함된 10개 항목을 확인하면 다음과 같다.\n",
    "\n",
    "```python\n",
    ">>> list(word_index.items()[:10]\n",
    "('fawn', 34701)\n",
    "('tsukino', 52006)\n",
    "('nunnery', 52007)\n",
    "('sonja', 16816)\n",
    "('vani', 63951)\n",
    "('woods', 1408)\n",
    "('spiders', 16115)\n",
    "('hanging', 2345)\n",
    "('woody', 2289)\n",
    "('trawling', 52008)\n",
    "```\n",
    "\n",
    "아래 코드는 첫째 후기의 내용을 확인한다.\n",
    "단어 인덱스에서 3을 빼야 함에 주의하라.\n",
    "이유는 인덱스 0, 1, 2는 각각 여백, 문장 시작, 불분명을 의미하기 때문이다.\n",
    "앞서 10,000개의 가장 많이 사용되는 단어만을 대상으로 하였기에\n",
    "그 이외의 단어는 모두 2로 처리된다.\n",
    "\n",
    "```python\n",
    ">>> reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    ">>> first_review = train_data[0]\n",
    ">>> decoded_review = \" \".join([reverse_word_index.get(i-3, \"?\") for i in first_review])\n",
    "```\n",
    "\n",
    "첫째 후기 내용은 다음과 같다.\n",
    "\n",
    "```python\n",
    ">>> decoded_review\n",
    "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\"\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터 전처리: 벡터화, 멀티-핫-인코딩**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정수들의 리스트, 그것도 길이가 다른 여러 개의 리스트를 신경망의 입력값으로 사용할 수 없다. \n",
    "따라서 각 샘플을 지정된 크기의 1차원 어레이로 변환하는 \n",
    "**벡터화**<font size='2'>vectorization</font>를 먼저 실행해야 한다.\n",
    "\n",
    "그런데 서로 길이가 다른 정수들의 리스트의 길이를 통일시킨다 하더라도 \n",
    "정수들의 리스트를 직접 신경망 모델의 입력값으로 사용하는 일은 가급적 피한다.\n",
    "여기서는 대신에 **멀티-핫-인코딩**을 이용하여 정수들의 리스트를\n",
    "0과 1로만 이루어진 일정한 길이의 벡터(1차원 어레이)로 변환한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "후기 리스트에 사용된 숫자들은 0부터 9999 사이의 값이다.\n",
    "이 정보를 이용하여 후기 샘플을 길이가 10,000인 벡터(1차원 어레이)로 변환할 수 있다.\n",
    "\n",
    "- 어레이 길이: 10,000\n",
    "- 항목: 0 또는 1\n",
    "- 후기 샘플에 포함된 정수에 해당하는 인덱스의 항목만 1로 지정\n",
    "\n",
    "예를 들어, `[1, 18, 13]`은 길이가 10,000인 1차원 어레이(벡터)로 변환되는데\n",
    "1번, 18번, 13번 인덱스의 항목만 1이고 나머지는 0으로 채워진다.\n",
    "이러한 변환을 **멀티-핫-인코딩**<font size='2'>multi-hot-encoding</font>이라 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 `vectorize_sequences()` 함수는 앞서 설명한 멀티-핫-인코딩을 \n",
    "모든 주어진 샘플에 대해 실행하여 최종적으로\n",
    "데이터셋을 표현하는 넘파이 어레이를 반환한다.\n",
    "\n",
    "```python\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    \n",
    "    for i, sequence in enumerate(sequences):    # 모든 샘플에 대한 멀티-핫-인코딩\n",
    "        for j in sequence:\n",
    "            results[i, j] = 1.\n",
    "    return results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{prf:example} 훈련셋 벡터화\n",
    ":label: exp-vectorization\n",
    "\n",
    "이제 훈련셋와 테스트셋를 벡터화한다.\n",
    "자료형은 `float32`로 고정한다. 그렇지 않으면 `float64`로 지정되기에\n",
    "메모리 효율성을 떨어뜨린다.\n",
    "\n",
    "```python\n",
    ">>> x_train = vectorize_sequences(train_data).astype(\"float32\")\n",
    ">>> x_test = vectorize_sequences(test_data).astype(\"float32\")\n",
    "```\n",
    "\n",
    "첫째 훈련 샘플의 변환 결과는 다음과 같다.\n",
    "\n",
    "```python\n",
    ">>> x_train[0]\n",
    "array([0., 1., 1., ..., 0., 0., 0.], dtype=float32)\n",
    "```\n",
    "\n",
    "레이블 또한 정수 자료형에서 `float32` 자료형으로 변환해서 자료형을 일치시킨다.\n",
    "\n",
    "```python\n",
    ">>> y_train = np.asarray(train_labels).astype(\"float32\")\n",
    ">>> y_train\n",
    "array([1., 0., 0., ..., 0., 1., 0.], dtype=float32)\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 구성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 샘플의 특성이 벡터(1차원 어레이)로 주어지고 \n",
    "레이블이 스칼라(하나의 숫자)로 주어졌을 때 \n",
    "밀집층<font size='2'>densely-connected layer</font>인 `Dense` 층을 이용하는\n",
    "`Sequential` 모델을 추천한다.\n",
    "이때 사용하는 활성화 함수는 일반적으로 다음과 같다.\n",
    "\n",
    "- 은닉층의 활성화 함수: 음수를 제거하는 `relu()` 함수\n",
    "- 이진 분류 모델의 최상위 층의 활성화 함수: 0과 1사이의 확률값을 계삲하는 `sigmoid()` 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp/master/slides/images/relu_sigmoid.png\" style=\"width:600px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dense` 층을 이용할 때의 핵심은 두 가지다.\n",
    "\n",
    "- 몇 개의 층을 사용하는가?\n",
    "- 각 층마다 몇 개의 유닛<font size='2'>unit</unit>을 사용하는가?\n",
    "\n",
    "위 두 질문에 대한 체계적인 답은\n",
    "{numref}`%s장 머신러닝 핵심 이슈<ch:fundamentals_of_ml>`에서 다룬다.\n",
    "여기서는 일단 아래 구성을 사용한다.\n",
    "\n",
    "- 두 개의 연속된 밀집층\n",
    "- 각각 16개의 유닛\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "```\n",
    "\n",
    "`Dense` 층의 유닛이 많을 수록 입력값에 내재된 보다 많은 특성을 찾아내어 보다 복잡한\n",
    "모델을 학습한다. 하지만 유닛수가 많을 수록 모델 훈련에 필요한 비용(시간과 메모리)이\n",
    "늘어난다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} `relu()` 활성화 함수\n",
    ":class: hint\n",
    "\n",
    "마지막 층을 제외한 모든 층에서 `relu()` 활성화 함수를 사용한다.\n",
    "이유는 그렇게 하지 않으면 기본적으로 선형 분류 모델이 생성되기 때문이며\n",
    "비선형 분류 문제는 해결하지 못하기 때문이다.\n",
    "\n",
    "`relu()`, `prelu()`, `elu()`, `tanh()` 등 다양한 종류의 활성화 함수가 경우에 따라 사용된다.\n",
    "하지만 여기서는 기본적으로 `relu()`를 사용한다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 모델을 시각화하면 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/04-01.png\" style=\"width:200px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 사이킷런의 로지스틱 회귀 모델\n",
    ":class: info\n",
    "\n",
    "이진 분류 모델의 최상위 층은 스칼라 값을 출력하도록 하나의 유닛을 사용하는 \n",
    "`Dense` 밀집층을 사용한다. \n",
    "또한 활성화 함수로 0과 1사이의 확률값을 계산하는 `sigmoid()`를 활성화 함수로 사용한다.\n",
    "그러면 [사이킷런의 로지스틱 회귀<font size='2'>logistic regression</font> 모델](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)처럼 작동한다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 컴파일**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 훈련시키기 전에 컴파일한다. \n",
    "사용되는 옵티마이저, 손실 함수, 평가지표는 다음과 같다.\n",
    "\n",
    "- `optimizer=\"rmsprop\"`: 일반적으로 추천되는 옵티마이저.\n",
    "- `loss=\"binary_crossentropy\"`: 이진 분류 모델에서 확률 결과에 대한 오차 계산 용도로 최선임. \n",
    "    로그 손실이라고도 불림.\n",
    "- `metrics=\"accuracy\"`: 정확도가 분류 모델의 기본적인 평가지표로 사용됨.\n",
    "\n",
    "```python\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 훈련**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 중인 모델을 에포크마다 검증하기 위해 검증셋을 따로 지정한다.\n",
    "여기서는 10,000개의 샘플을 검증셋으로 활용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`History` 객체 활용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fit()` 메서드가 반환하는 객체는 `Callback` 클래스를 상속하는\n",
    "`History` 클래스의 객체이며 모델 훈련과정 중에 계산되는 다양한 정보를 저장한다.\n",
    "콜백(`Callback`) 클래스에 대해서는 {numref}`%s장 <ch:working_with_keras>`에서 자세히 살펴본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`History` 객체의 속성 중에서 `history` 속성이 가장 많이 활용된다.\n",
    "`history` 속성은 훈련중 에포크 단위로 측정된 손실값과 평가지표를 사전으로 저장한다.\n",
    "\n",
    "```python\n",
    ">>> history_dict = history.history\n",
    ">>> history_dict.keys()\n",
    "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어, `history` 속성에 저장된 정보를 이용하여 \n",
    "훈련셋과 검증셋에 대한 에포크별 손실값과 정확도의 변화를 그래프로 그릴 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*손실값의 변화*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋와 검증 세트에 대한 에포크별 손실값의 변화를 보면\n",
    "훈련셋에 대해서는 손실값이 계속 감소하지만 \n",
    "검증셋에 대해서는 9번째 에포크 전후 정체하다가 상승한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/04-04.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*정확도의 변화*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋과 검증셋에 대한 에포크별 정확도의 경우엔\n",
    "훈련셋에 대해서는 정확도 계속 증가한다.\n",
    "반면에 검증셋에 대해서는 역시 9번째 에포크 전후 정체하다가 감소한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/04-05.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**과대적합**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과대적합<font size='2'>overfitting</font>은 모델이 훈련셋에 익숙해진다는 의미이다.\n",
    "반면에 처음 보는 데이터에 대해서는 성능이 떨어진다.\n",
    "에포크가 진행될 수록 훈련셋에 대한 성능은 계속해서 좋아지지만\n",
    "검증셋에 대한 성능이 4번째 에포크 이후에 오히려 나빠진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 재훈련**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과대적합을 방지하기 위한 다양한 기법은 \n",
    "{numref}`%s장 <ch:fundamentals_of_ml>`에서 다룬다.\n",
    "위 문제의 경우 4번의 에포크만 훈련 반복을 진행하면 된다.\n",
    "\n",
    "모델 구성부터, 컴파일, 훈련을 모두 다시 시작해야 \n",
    "가중치와 편향이 초기화된 상태서 훈련을 시작한다.\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트셋에 대한 성능은 아래와 같이 88% 정도의 정확도를 보인다. 모델의 손실값은 0.31 정도.\n",
    "앞으로 보다 좋은 성능의 모델을 살펴볼 것이며, 현존하는 가장 좋은 모델의 정확도는 95% 정도이다.\n",
    "\n",
    "```python\n",
    ">>> results = model.evaluate(x_test, y_test)\n",
    ">>> results\n",
    "[0.3139097988605499, 0.8770800232887268]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 활용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "훈련된 모델을 활용하려면 `predict()` 메서드를 이용한다.\n",
    "큰 데이터셋에 대해 미니배치 단위로 예측할 수 있다. \n",
    "\n",
    "- 0,99 이상 또는 0.01 이하의 경우: 매우 확실한 예측\n",
    "- 0.4 ~ 0.6: 불확실한 예측\n",
    "\n",
    "```python\n",
    ">>> model.predict(x_test, batch_size=512)\n",
    "array([[0.25440323],\n",
    "       [0.9999424 ],\n",
    "       [0.95840394],\n",
    "       ...,\n",
    "       [0.17153329],\n",
    "       [0.10725482],\n",
    "       [0.6672551 ]], dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 뉴스 기사: 다중 클래스 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**로이터 데이터셋**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로이터<font size='2'>Reuter</font> 통신사가 1986년에 작성한 짧은 기사 모음집이다.\n",
    "총 11,228개의 기사로 구성되었으며 훈련셋과 테스트셋으로 이미 구분되어 있다.\n",
    "\n",
    "- 훈련셋 크기: 8,982\n",
    "- 테스트셋 크기: 2,246\n",
    "\n",
    "기사의 주제는 46개로 구분되며, 각각의 기사에 하나의 주제가 할당되어 있다.\n",
    "여기서 훈련시키는 모델은 기사별로 46개 중의 하나의 주제를 예측해는\n",
    "분류 모델이며, 클래스가 3개 이상이기에 \n",
    "**다중 클래스 분류**<font size='2'>multiclass classification</font> 모델이라 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스의 `reuters` 모듈의 `load_data()` 함수로 데이터셋을 불러올 수 있다.\n",
    "영화 후기의 경우처럼 사용 빈도가 상위 10,000등 이내의 단어만 사용하도록 한다.\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.datasets import reuters\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 샘플은 정수들의 리스트이다.\n",
    "\n",
    "```python\n",
    ">>> train_data[10]\n",
    "[1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979,\n",
    "3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 샘플에 대한 레이블은 0부터 45까지의 정수로 표현된다.\n",
    "예를 들어, 10번 기사의 주제는 3이다. \n",
    "\n",
    "```python\n",
    ">>> train_labels[10]\n",
    "3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 로이터 기사 주제\n",
    ":class: tip\n",
    "\n",
    "기사 주제 3은 'earn'(수익)과 연관된다.\n",
    "언급된 46개의 주제와 번호 사이의 관계는\n",
    "[GitHub: Where can I find topics of reuters dataset #12072](https://github.com/keras-team/keras/issues/12072)에서 확인할 수 있다.\n",
    "\n",
    "```\n",
    "{'cocoa': 0,\n",
    "'grain': 1,\n",
    "'veg-oil': 2,\n",
    "'earn': 3,\n",
    "'acq': 4,\n",
    "'wheat': 5,\n",
    "'copper': 6,\n",
    "'housing': 7,\n",
    "'money-supply': 8,\n",
    "'coffee': 9,\n",
    "'sugar': 10,\n",
    "'trade': 11,\n",
    "'reserves': 12,\n",
    "'ship': 13,\n",
    "'cotton': 14,\n",
    "'carcass': 15,\n",
    "'crude': 16,\n",
    "'nat-gas': 17,\n",
    "'cpi': 18,\n",
    "'money-fx': 19,\n",
    "'interest': 20,\n",
    "'gnp': 21,\n",
    "'meal-feed': 22,\n",
    "'alum': 23,\n",
    "'oilseed': 24,\n",
    "'gold': 25,\n",
    "'tin': 26,\n",
    "'strategic-metal': 27,\n",
    "'livestock': 28,\n",
    "'retail': 29,\n",
    "'ipi': 30,\n",
    "'iron-steel': 31,\n",
    "'rubber': 32,\n",
    "'heat': 33,\n",
    "'jobs': 34,\n",
    "'lei': 35,\n",
    "'bop': 36,\n",
    "'zinc': 37,\n",
    "'orange': 38,\n",
    "'pet-chem': 39,\n",
    "'dlr': 40,\n",
    "'gas': 41,\n",
    "'silver': 42,\n",
    "'wpi': 43,\n",
    "'hog': 44,\n",
    "'lead': 45}\n",
    "```\n",
    "\n",
    "실제로 10번 기사 내용을 확인해보면 'earn'과 관련되어 있어 보인다.\n",
    "데이터를 해독(decoding)하는 방법은 IMDB 데이터셋의 경우와 동일하다.\n",
    "\n",
    "```python\n",
    ">>> word_index = reuters.get_word_index()\n",
    ">>> reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    ">>> decoded_newswire = \" \".join([reverse_word_index.get(i - 3, \"?\") for i in train_data[10]])\n",
    ">>> decoded_newswire\n",
    "'? period ended december 31 shr profit 11 cts vs loss 24 cts net profit 224 271 vs loss 511 349 revs 7 258 688 vs 7 200 349 reuter 3'\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**데이터 전처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*입력 데이터셋 벡터화: 멀티-핫-인코딩*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "IMDB의 경우와 동일하게 모든 샘플을 길이가 10,000인 벡터로 변환한다.\n",
    "\n",
    "```python\n",
    ">>> x_train = vectorize_sequences(train_data)\n",
    ">>> x_test = vectorize_sequences(test_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "*레이블 데이터셋 벡터화: 원-핫-인코딩*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블은 0부터 45 사이의 값이다.\n",
    "이런 경우 정수로 구성된 텐서를 사용하기 보다는\n",
    "**원-핫-인코딩**<font size='2'>one-hot-encoding</font>\n",
    "기법을 적용하는 게 좋다.\n",
    "\n",
    "원-핫-인코딩은 멀티-핫-인코딩 기법과 유사하다.\n",
    "원-핫-인코딩으로 생성된 텐서는 한 곳만을 제외한 모든 항목이 0이다.\n",
    "예를 들어, 정수 3은 길이가 46인 벡터로 변환되는데\n",
    "3번 인덱스에서만 1이고 나머지 항목은 모두 0이다.\n",
    "\n",
    "아래 함수는 정수들의 어레이로 주어진 레이블 데이터셋을\n",
    "원-핫-인코딩된 원-핫-벡터로 구성된 2차원 텐서로 변환한다.\n",
    "각 원-핫-벡터의 길이(차원)는 46이다.\n",
    "\n",
    "```python\n",
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`to_categorical()` 함수*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스의 `to_categorical()` 함수가 원-핫-인코딩을 지원한다.\n",
    "원-핫-벡터의 길이는 사용된 레이블의 최댓값에 1을 더한 값이다.\n",
    "\n",
    "```python\n",
    ">>> from tensorflow.keras.utils import to_categorical\n",
    ">>> y_train = to_categorical(train_labels)\n",
    ">>> y_test = to_categorical(test_labels)\n",
    ">>> y_train[0]\n",
    "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} `CategoryEncoding` 층\n",
    ":class: info\n",
    "\n",
    "원-핫-인코딩, 멀티-핫-인코딩 등 정수를 사용하는 데이터를 범주형 데이터로 변환하는 \n",
    "전처리 과정을 지원하는 층<font size='2'>layer</font>이 있다.\n",
    "예를 들어 [tf.keras.layers.CategoryEncoding](https://keras.io/api/layers/preprocessing_layers/categorical/category_encoding/)은 \n",
    "원-핫-인코딩과 멀티-핫-인코딩을 지원한다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 구성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "IMDB 데이터셋의 경우와는 달리 3 개 이상의 클래스로 분류하는 \n",
    "**다중 클래스 분류** 모델의 최종 층은 \n",
    "분류해야 하는 클래스의 수 만큼의 유닛과 함께\n",
    "각 클래스에 속할 확률을 계산하는 \n",
    "`softmax` 활성화 함수를 이용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    ":::{admonition} softmax 활성화 함수\n",
    ":class: info\n",
    "\n",
    "여기서 사용하는 모델의 마지막 층은 46개의 유닛을 사용하며,\n",
    "46개 클래스 각각에 속할 확률이 유닛별로 계산되어야 한다.\n",
    "`softmax()` 활성화 함수는 유닛별로 아핀변환된 값들을 종합하여\n",
    "최종적으로 각 유닛이 대변하는 클래스에 속할 확률을 계산한다.\n",
    "클래스별 확률을 합치면 1이 되며, 가장 높은 확률을 갖는 클래스를 \n",
    "모델의 최종 예측값으로 사용한다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "마지막 층을 제외한 나머지 층은 긍정/부정의 이진 분류 모델 보다 훨씬 많은 64개의 \n",
    "유닛을 사용하도록 한다.\n",
    "이유는 이진 분류보다 훨씬 많은 46개의 클래스로 분류하려면\n",
    "보다 많은 정보를 각 층에서 다룰 수 있어야 하기 때문이다.\n",
    "층에 사용되는 유닛이 많을 수록 보다 많은 정보를 계산한다.\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\")\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 정보 병목현상\n",
    ":class: tip\n",
    "\n",
    "층에 사용되는 유닛의 수를 지정할 때 병목현상이 발생하지 않도록 조심해야 한다.\n",
    "각 층은 이전 층에서 넘겨진 값만 활용할 수 있기에 이전 층이 너무 적은 수의 유닛을\n",
    "사용하면 그만큼 전달되는 정보의 양도 적다.\n",
    "따라서 아무리 많은 유닛을 사용하더라도 새로운 정보를 생성하기는 어렵다.\n",
    "이를 정보 병목현상이라 부르며 이런 일이 발생하지 않도록\n",
    "층을 구성해야 한다.\n",
    "앞으로 다양한 모델을 통해 다양한 방식의 구조의 층을 살펴볼 것이다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 사이킷런의 소프트맥스 회귀 모델\n",
    ":class: info\n",
    "\n",
    "다중 클래스 분류 모델의 최상위 층은 클래스 수 만큼의 값으로 구성된 벡터를 출력하도록 \n",
    "여러 개의 유닛을 사용하는 `Dense` 밀집층을 사용한다. \n",
    "또한 활성화 함수로 모든 유닛에 대한 확률값의 합이 1이 되도록 하는 `softmax()`를 활성화 함수로 사용한다.\n",
    "그러면 [사이킷런의 로지스틱 회귀<font size='2'>logistic regression</font> 모델](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)에서\n",
    "`multi_class='multinomial'` 옵션이 사용되는 경우처럼 작동한다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 컴파일**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "다중 클래스 분류 모델의 손실함수는 `categorical_crossentropy`을 사용한다. \n",
    "`categorical_crossentropy`는 클래스의 실제 분포와 예측 클래스의 분포 사이의 \n",
    "오차를 측정하며, 보다 자세한 설명은\n",
    "[핸즈온 머신러닝(3판)의 소프트맥스 회귀의 비용 함수](https://codingalzi.github.io/handson-ml3/training_models.html#sec-softmax-regression)를 참고한다.\n",
    "\n",
    "```python\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    ":::{admonition} 정수 레이블과 sparse_categorical_crossentropy\n",
    ":class: hint\n",
    "\n",
    "클래스 수가 많을 경우 정수 레이블을 사용하는 게 메모리 효율적이다.\n",
    "그런데 정수 텐서 레이블(타깃)을 이용하여 훈련하려면 모델을 컴파일할 때 손실함수로 \n",
    "`sparse_categorical_crossentropy`를 사용해야 한다.\n",
    "\n",
    "```python\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 훈련**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "훈련 방식은 영화 후기 이진 분류 모델의 경우와 동일하다.\n",
    "다만 검증셋의 크기를 1,000으로 정한다.\n",
    "\n",
    "```python\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "y_val = y_train[:1000]\n",
    "partial_y_train = y_train[1000:]\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`History` 객체 활용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번엔 9번째 에포크 이후에 과대적합이 발생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*손실값의 변화*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/04-06.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "*정확도의 변화*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/04-07.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 재훈련**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "9번 에포크를 지나면서 과대적합이 발생하기에\n",
    "에포크 수를 9로 줄이고 처음부터 다시 훈련시킨다.\n",
    "모델 구성부터, 컴파일, 훈련을 모두 다시 시작해야 \n",
    "가중치와 편향이 초기화된 상태서 훈련을 시작한다.\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트셋에 대한 성능은 아래와 같이 80% 정도의 정확도를 보인다.\n",
    "모델의 손실값은 0.96 정도.\n",
    "\n",
    "```python\n",
    ">>> results = model.evaluate(x_test, y_test)\n",
    ">>> results\n",
    "[0.9565213431445807, 0.79697239536954589]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80%의 정확도가 얼마나 좋은지/나쁜지를 판단하려면 무작위로 찍을 때의 정확도를 계산해봐야 한다.\n",
    "실제로 로이터 데이터셋을 이용하여 무작위로 찍을 때의 정확도는 19% 정도 나온다.\n",
    "따라서 80% 정도의 정확도는 상당히 좋은 편이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 활용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련된 모델의 `predict()` 메서드는 각 입력 샘플에 대해\n",
    "마지막 층에 사용된 유닛의 개수 만큼의 길이로 구성된 벡터 텐서를 반환한다.\n",
    "따라서 여기서는 46개 클래스에 솏할 확률로 구성된 길이가 46인 벡터 텐서가 반환되며\n",
    "각 확률값의 합은 1이다.\n",
    "이중에 가장 높은 확률값이 위치한 위치가 모델의 최종 예측값으로 사용된다.\n",
    "\n",
    "예를 들어, 테스트셋의 첫째 샘플에 대한 예측값은 4다.\n",
    "\n",
    "```python\n",
    ">>> predictions = model.predict(x_test)\n",
    ">>> predictions[0].shape\n",
    "(46,)\n",
    ">>> np.sum(predictions[0])\n",
    "1.0\n",
    ">>> np.argmax(predictions[0])\n",
    "4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 주택가격 예측: 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이진 분류, 다중 클래스 분류 모델은 지정된 숫자들로 이루어진 특정 클래스의 번호 하나를 예측한다.\n",
    "반면에 임의의 수를 예측하는 문제는 **회귀**(regression)이라 부른다. \n",
    "예를 들어 온도 예측, 가격 예측 등을 다루는 것이 회귀 문제이다. \n",
    "여기서는 보스턴 시의 주택가격을 예측하는 회귀 문제를 예제로 다룬다.\n",
    "\n",
    "**주의사항**: '로지스틱 회귀'(logistic regression) 알고리즘는 분류 모델임에 주의하라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 보스턴 주택가격 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용하는 데이터셋은 다음과 같다.\n",
    "\n",
    "- 1970년대 중반의 미국 보스턴 시내와 외곽의 총 506개 지역별 중간 주택가격.\n",
    "    즉, 매우 적은 수의 데이터셋임.\n",
    "- 케라스의 `boston_housing` 모듈의 `load_data()` 함수로 데이터 적재\n",
    "    - 훈련셋와 테스트셋로 분류됨.\n",
    "- 지역별 샘플\n",
    "    - 특성: 총 13 개. 지역별 범죄율, 토지 비율, 재산세율, 학생 대 교사 비율 등.\n",
    "    - 타깃: 주택가격\n",
    "- 참고: [위키독스: 보스턴 주택가격 데이터셋 소개](https://wikidocs.net/49966)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**보스턴 주택가격 데이터셋 적재**\n",
    "\n",
    "- 데이터셋 크기: 506\n",
    "    - 훈련셋: 404\n",
    "    - 테스트셋: 102\n",
    "- 샘플 특성 수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋 샘플의 타깃은 아래처럼 범위가 지정되지 않은 부동소수점 값이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성에 따라 사용되는 값들의 크기가 다르다. \n",
    "어떤 특성은 0과 1사이, 다른 특성은 한 자리리부터 세 자리의 수를 갖기도 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.745111</td>\n",
       "      <td>11.480198</td>\n",
       "      <td>11.104431</td>\n",
       "      <td>0.061881</td>\n",
       "      <td>0.557356</td>\n",
       "      <td>6.267082</td>\n",
       "      <td>69.010644</td>\n",
       "      <td>3.740271</td>\n",
       "      <td>9.440594</td>\n",
       "      <td>405.898515</td>\n",
       "      <td>18.475990</td>\n",
       "      <td>354.783168</td>\n",
       "      <td>12.740817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.240734</td>\n",
       "      <td>23.767711</td>\n",
       "      <td>6.811308</td>\n",
       "      <td>0.241238</td>\n",
       "      <td>0.117293</td>\n",
       "      <td>0.709788</td>\n",
       "      <td>27.940665</td>\n",
       "      <td>2.030215</td>\n",
       "      <td>8.698360</td>\n",
       "      <td>166.374543</td>\n",
       "      <td>2.200382</td>\n",
       "      <td>94.111148</td>\n",
       "      <td>7.254545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.081437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>5.874750</td>\n",
       "      <td>45.475000</td>\n",
       "      <td>2.077100</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.225000</td>\n",
       "      <td>374.672500</td>\n",
       "      <td>6.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.268880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.198500</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>3.142300</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>11.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.674808</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>6.609000</td>\n",
       "      <td>94.100000</td>\n",
       "      <td>5.118000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.157500</td>\n",
       "      <td>17.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.725000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.710300</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean     3.745111   11.480198   11.104431    0.061881    0.557356    6.267082   \n",
       "std      9.240734   23.767711    6.811308    0.241238    0.117293    0.709788   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.081437    0.000000    5.130000    0.000000    0.453000    5.874750   \n",
       "50%      0.268880    0.000000    9.690000    0.000000    0.538000    6.198500   \n",
       "75%      3.674808   12.500000   18.100000    0.000000    0.631000    6.609000   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.725000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean    69.010644    3.740271    9.440594  405.898515   18.475990  354.783168   \n",
       "std     27.940665    2.030215    8.698360  166.374543    2.200382   94.111148   \n",
       "min      2.900000    1.129600    1.000000  188.000000   12.600000    0.320000   \n",
       "25%     45.475000    2.077100    4.000000  279.000000   17.225000  374.672500   \n",
       "50%     78.500000    3.142300    5.000000  330.000000   19.100000  391.250000   \n",
       "75%     94.100000    5.118000   24.000000  666.000000   20.200000  396.157500   \n",
       "max    100.000000   10.710300   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "               12  \n",
       "count  404.000000  \n",
       "mean    12.740817  \n",
       "std      7.254545  \n",
       "min      1.730000  \n",
       "25%      6.890000  \n",
       "50%     11.395000  \n",
       "75%     17.092500  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as df\n",
    "\n",
    "df.DataFrame(train_data).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**데이터 정규화**\n",
    "\n",
    "따라서 모든 특성의 값을 **정규화** 해주어야 모델 훈련이 더 잘된다.\n",
    "모든 특성값들을 특성별로 표준 정규분포를 따르도록 한다. \n",
    "즉, 평균값 0, 표준편차 1이 되도록 특성값을 특성별로 변환한다.\n",
    "\n",
    "**주의사항**: 테스트셋의 정규화는 훈련셋의 평균값과 표준편차를 이용해야 한다.\n",
    "이유는 테스트셋의 정보는 모델 훈련에 절대로 사용되지 않아야 하기 때문이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# 훈련셋의 평균값\n",
    "mean = train_data.mean(axis=0)\n",
    "\n",
    "# 훈련셋 정규화\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "# 테스트셋 정규화: 훈련셋의 평균값과 표준편차 활용\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 정의**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전과는 달리 모델 구성과 컴파일을 동시에 진행하는 함수를 이용한다.\n",
    "\n",
    "- 은닉층: 데이터셋이 작으므로 두 개만 사용.\n",
    "- 각 은닉층의 유닛 수: 인자로 받도록 함. 아래 예제에서는 64 사용.\n",
    "- 마지막 층: 활성화 함수 없음. 회귀 모델이기 때문임.\n",
    "- 손실함수: **평균제곱오차**(mse). 회귀 모델의 일반적인 손실함수\n",
    "- 평가지표: **평균절대오차**(mae, mean absolute error)\n",
    "\n",
    "**참고**: 데이터셋이 클 수록 보다 많은 층과 보다 많은 유닛 사용하는 것이 일반적임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### K-겹 교차검증 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋이 작기에 훈련 중에 사용할 검증 세트를 따로 분리하는 것은 훈련의 효율성을 떨어뜨린다.\n",
    "대신에 **K-겹 교차검증**을(K-fold cross-validation) 사용한다.\n",
    "아래 이미지는 3-겹 교차검증을 사용할 때 훈련 중에 사용되는 훈련셋과 검증셋의 사용법을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/3-fold-cross-validation.png\" style=\"width:600px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**예제: 4-겹 교차검증**\n",
    "\n",
    "- 에포크 수: 500\n",
    "- `validation_data` 옵션 인자 활용\n",
    "    - 교차검증과 에포크마다 평가지표 저장됨.\n",
    "- `verbose=0`: 손실값과 평가지표를 출력하지 않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 째 폴드(fold) 훈련 시작\n",
      "2번 째 폴드(fold) 훈련 시작\n",
      "3번 째 폴드(fold) 훈련 시작\n",
      "4번 째 폴드(fold) 훈련 시작\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "\n",
    "num_epochs = 500\n",
    "all_mae_histories = []   # 모든 에포크에 대한 평균절대오차 저장\n",
    "\n",
    "for i in range(k):       # 교차 검증\n",
    "    \n",
    "    print(f\"{i+1}번 째 폴드(fold) 훈련 시작\")\n",
    "\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    \n",
    "    model = build_model()    # 유닛 수: 64\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=16, verbose=0)\n",
    "    \n",
    "    mae_history = history.history[\"val_mae\"]\n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**K-겹 교차검증 훈련 과정 그래프: 평가지표 기준**\n",
    "\n",
    "500번의 에포크마다 4 번의 교차 검증을 진행하였기에\n",
    "에포크 별로 검증세트를 대상으로하는 평균절대오차의 평균값을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "에포크별 평균절대오차의 평균값의 변화를 그래프로 그리면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation MAE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "첫 10개의 에포크의 성능이 매우 나쁘기에 그 부분을 제외하고 그래프를 그리면 보다 정확하게 \n",
    "변환 과정을 파악할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "truncated_mae_history = average_mae_history[10:]\n",
    "\n",
    "plt.plot(range(1, len(truncated_mae_history) + 1), truncated_mae_history)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation MAE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**재훈련**\n",
    "\n",
    "- 130번 째 에포크를 전후로 과대적합 발생함.\n",
    "- 130번의 에포크만 사용해서 모델 재훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cf386a5670>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(train_data, train_targets,\n",
    "          epochs=130, batch_size=16, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재훈련된 모델의 테스트셋에 대한 성능을 평가하면 \n",
    "주택가격 예측에 있어서 평균적으로 2,500달러 정도의 차이를 갖는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 0s/step - loss: 15.9659 - mae: 2.5950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.5949742794036865"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "test_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 활용\n",
    "\n",
    "- 새로운 데이터에 대한 예측은 `predict()` 메서드를 활용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.091597], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_data)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런의 `KFold`를 이용하면 봅다 간단하게 K-겹 교차검증을 진행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k = 4\n",
    "num_epochs = 500\n",
    "\n",
    "kf = KFold(n_splits=k)\n",
    "all_mae_histories = []\n",
    "\n",
    "for train_index, val_index in kf.split(train_data, train_targets):\n",
    "    \n",
    "    val_data, val_targets = train_data[val_index], train_targets[val_index]\n",
    "    partial_train_data, partial_train_targets = train_data[train_index], train_targets[train_index]\n",
    "    \n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=16, verbose=0)\n",
    "\n",
    "    mae_history = history.history[\"val_mae\"]    \n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 0s/step - loss: 15.7864 - mae: 2.7254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.725350856781006"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "test_mae_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 영화 후기 이진 분류\n",
    "    1. 두 개의 은닉층 대신 1 개 또는 3 개의 은닉층을 사용할 때 \n",
    "        검증셋와 테스트셋에 대한 평가지표의 변화를 확인하라.\n",
    "    1. 각 은닉층에 사용된 유닛의 수를 8, 32, 64 등으로 변화시킨 후 \n",
    "        검증셋과 테스트셋에 대한 평가지표의 변화를 확인하라.\n",
    "    1. `binary_crossentropy` 대신 `mse`를 손실함수로 지정한 후 \n",
    "        검증셋과 테스트셋에 대한 평가지표의 변화를 확인하라.\n",
    "    1. `relu()` 함수 대신 이전에 많이 사용됐었던 `tanh()` 함수를 손실함수로 지정한 후 \n",
    "        검증셋과 테스트셋에 대한 평가지표의 변화를 확인하라.\n",
    "1. 뉴스 기사 다중 클래스 분류\n",
    "    1. 아래 모델을 사용하염 정보 병목현상이 발생함을 성능 테스트를 통해 보여라.\n",
    "        ```python\n",
    "        model = keras.Sequential([\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dense(4, activation=\"relu\"),\n",
    "            layers.Dense(46, activation=\"softmax\")\n",
    "        ])\n",
    "        ```\n",
    "    1. 은닉층의 유닛의 수를 32, 128 등 여러 값으로 실험해 보아라.\n",
    "    1. 은닉층의 수를 1개 또는 3개로 바꿔 보아라."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dlp04-started_with_neural_networks",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
