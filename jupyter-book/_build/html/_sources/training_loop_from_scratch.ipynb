{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daf323e33b84"
      },
      "source": [
        "# 훈련 루프 들여다보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "신경망 모델의 훈련과 평가 과정을 보다 깊이 이해하기 위해 `fit()` 메서드를 실행할 때 \n",
        "텐서플로우 내부에서 훈련 루프가 처리되는 과정을 자세히 들여다본다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 모델 지정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "설명을 위해 다시 한 번 간단한 MNIST 모델을 이용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = keras.Sequential([layers.Dense(64, activation=\"relu\"),\n",
        "                          layers.Dense(64, activation=\"relu\"),\n",
        "                          layers.Dense(10, activation=\"softmax\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 옵티마이저, 손실 함수, 평가지표 지정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "모델 훈련에 필요한 요소인 옵티마이저, 손실 함수, 평가지표를 지정하기 위해\n",
        "일반적으로 모델의 `compile()` 메서드를 다음과 같이 실행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "하지만 여기서는 모델의 훈련 루프를 직접 구현하려 하기에\n",
        "`compile()` 메서드를 실행하는 대신 컴파일 과정에 필요한 API를 직접 선언한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**옵티마이저 API 선언**\n",
        "\n",
        "아래코드는 모델 컴파일에 사용된 문자열 `'rmsprop'`에 해당한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.RMSprop(learning_rate=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**손실 함수 API 선언**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " 0, 1, 2, 3 등 정수 형식의 타깃(레이블)을 예측하는 다중 클래스 분류 모델을 훈련시키는 경우\n",
        "보통 `SparseCategoricalCrossentropy` 클래스를 이용한다.\n",
        "아래코드는 모델 컴파일에 사용된 문자열 `'sparse_categorical_crossentropy'`에 해당한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**평가지표 API 선언**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " 0, 1, 2, 3 등 정수 형식의 타깃(레이블)을 예측하는 다중 클래스 분류 모델을 훈련시키는 경우\n",
        "평가지표는 `SparseCategoricalAccuracy` 클래스를 이용한다.\n",
        "아래코드는 모델 컴파일에 사용된 문자열 `'accuracy'`에 해당한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_acc_metric = keras.metrics.SparseCategoricalAccuracy() # 훈련셋 대상 평가\n",
        "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()   # 검증셋 대상 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 데이터셋 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "훈련과 평가에 사용된 데이터를 준비한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**훈련셋, 검증셋, 테스트셋 지정**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# 훈련셋과 테스트셋 가져오기\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = np.reshape(x_train, (-1, 784))\n",
        "x_test = np.reshape(x_test, (-1, 784))\n",
        "\n",
        "# 훈련셋의 일부를 검증셋으로 지정\n",
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**배치 묶음 `Dataset` 객체 지정**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "훈련셋과 검증셋을 대상으로 배치 묶음으로 구성된 모음 자료형 객체를 지정한다.\n",
        "이를 위해 텐서플로우의 `Dataset` 클래스를 이용한다.\n",
        "`tf.data.Dataset` 머신러닝 모델 훈련에 사용되는 대용량 데이터의 효율적인 처리를\n",
        "지원하는 모음 자료형이다.\n",
        "배치 크기는 64로 지정한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 훈련용 `Dataset` 객체 지정\n",
        "    - 훈련셋 어레이와 훈련셋 타깃 어레이로부터 `Dataset` 생성 후 배치로 묶은 `Dataset`으로 변환.\n",
        "    - `shuffle()` 메서드를 이용하여 데이터 무작위 섞기 실행 후 배치 묶음 생성\n",
        "- 검증용 `Dataset` 객체 지정\n",
        "    - 검증셋 어레이와 검증셋 타깃 어레이로부터 `Dataset` 생성 후 배치로 묶은 `Dataset`으로 변환."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 배치크기: 64\n",
        "batch_size = 64\n",
        "\n",
        "# 훈련용 Dataset 객체\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "# 검증용 Dataset 객체\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 훈련 루프"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "학습 및 평가를 진행하는 훈련 루프는 다음과 같다.\n",
        "\n",
        "- 지정된 에포크 수만큼 에포크를 반복하는 `for` 반복문 실행\n",
        "- 각 에포크에 대해 배치 단위로 스텝을 진행하는 `for` 반복문 실행\n",
        "    - 각 배치에 대해 `GradientTape()` 영역 지정\n",
        "        - 이 영역 내에서 순전파 실행 후 손실값 계산\n",
        "    - 영역 외부에서 손실값에 대한 모델 가중치의 그래디언트 계산\n",
        "    - 옵티마이저를 사용하여 모델의 가중치 업데이트\n",
        "- 평가지표를 확인하면서 에포크 마무리\n",
        "    - 훈련셋 대상 정확도 계산: 매 스텝을 통해 업데이트된 정확도 최종 결과 확인\n",
        "    - 검증셋 대상 정확도 계산: 지정된 배치 단위로 검증셋 정확도 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "평가지표 API는 다음과 같이 활용한다.\n",
        "\n",
        "- 매 스텝마다 훈련셋 평가지표 계산, 즉 `update_state()` 메서드 호출\n",
        "- 검증셋에 대한 평가지표 계산은 스텝 훈련이 끝난후 지정된 배치 단위로 진행.\n",
        "- 에포크를 마무리하면서 끝날 때마다 훈련셋과 검증셋의 평가지표 API 초기화:  `reset_state()` 메서드 호출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 0.5018\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 0.3227\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.3646\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 1.2174\n",
            "Seen so far: 38464 samples\n",
            "Training acc over epoch: 0.9342\n",
            "Validation acc: 0.9256\n",
            "Time taken: 8.39s\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 0.2016\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 0.3699\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.0628\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 0.1414\n",
            "Seen so far: 38464 samples\n",
            "Training acc over epoch: 0.9463\n",
            "Validation acc: 0.9501\n",
            "Time taken: 7.97s\n",
            "\n",
            "Start of epoch 2\n",
            "Training loss (for one batch) at step 0: 0.2433\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 0.2498\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.2782\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 0.2418\n",
            "Seen so far: 38464 samples\n",
            "Training acc over epoch: 0.9541\n",
            "Validation acc: 0.9520\n",
            "Time taken: 8.22s\n",
            "\n",
            "Start of epoch 3\n",
            "Training loss (for one batch) at step 0: 0.0207\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 0.4361\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.2838\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 0.0622\n",
            "Seen so far: 38464 samples\n",
            "Training acc over epoch: 0.9609\n",
            "Validation acc: 0.9507\n",
            "Time taken: 9.96s\n",
            "\n",
            "Start of epoch 4\n",
            "Training loss (for one batch) at step 0: 0.3596\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 0.0695\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.2535\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 0.0451\n",
            "Seen so far: 38464 samples\n",
            "Training acc over epoch: 0.9641\n",
            "Validation acc: 0.9543\n",
            "Time taken: 10.11s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(x_batch_train, training=True)\n",
        "            loss_value = loss_fn(y_batch_train, logits)\n",
        "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "        # Update training metric.\n",
        "        train_acc_metric.update_state(y_batch_train, logits)\n",
        "\n",
        "        # Log every 200 batches.\n",
        "        if step % 200 == 0:\n",
        "            print(\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                % (step, float(loss_value))\n",
        "            )\n",
        "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
        "\n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_state()\n",
        "\n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        val_logits = model(x_batch_val, training=False)\n",
        "        # Update val metrics\n",
        "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_acc_metric.reset_state()\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c9a16c21790"
      },
      "source": [
        "## `tf.function` 데코레이터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "TensorFlow 2의 기본 런타임은 [즉시 실행](https://www.tensorflow.org/guide/eager)입니다. 따라서 위의 훈련 루프는 즉시 실행됩니다.\n",
        "\n",
        "이것은 디버깅에 매우 유용하지만 그래프 컴파일이 확실한 성능에 이점이 있습니다. 계산을 정적 그래프로 설명하면 프레임워크로 전역 성능 최적화를 적용할 수 있습니다. 이것은 프레임워크가 다음에 무엇이 올지 알지 못한 상태로 탐욕적으로 하나의 작업을 차례로 실행하도록 제한되어 있을 때에는 불가능합니다.\n",
        "\n",
        "텐서를 입력으로 사용하는 모든 함수를 정적 그래프로 컴파일할 수 있습니다. 다음과 같이 `@tf.function` 데코레이터를 추가하기만 하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fdacc2d48ade"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(x, training=True)\n",
        "        loss_value = loss_fn(y, logits)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    train_acc_metric.update_state(y, logits)\n",
        "    return loss_value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab61b0bf3126"
      },
      "source": [
        "평가 단계에서도 동일하게 수행해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "da4828fd8ef7"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    val_logits = model(x, training=False)\n",
        "    val_acc_metric.update_state(y, val_logits)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d552377968f1"
      },
      "source": [
        "이제 이 컴파일된 학습 단계로 학습 루프를 다시 실행해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d69d73c94e44",
        "outputId": "c3e903cd-ffbc-469c-a146-08528982f3f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 0.1266\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 0.1668\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.2674\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 0.2795\n",
            "Seen so far: 38464 samples\n",
            "Training acc over epoch: 0.9685\n",
            "Validation acc: 0.9535\n",
            "Time taken: 2.72s\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 0.3350\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 0.0694\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.0694\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 0.2801\n",
            "Seen so far: 38464 samples\n",
            "Training acc over epoch: 0.9689\n",
            "Validation acc: 0.9566\n",
            "Time taken: 1.20s\n",
            "\n",
            "Start of epoch 2\n",
            "Training loss (for one batch) at step 0: 0.0226\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 0.0107\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.2391\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 0.0985\n",
            "Seen so far: 38464 samples\n",
            "Training acc over epoch: 0.9717\n",
            "Validation acc: 0.9574\n",
            "Time taken: 1.24s\n",
            "\n",
            "Start of epoch 3\n",
            "Training loss (for one batch) at step 0: 0.0103\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 0.0982\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.4373\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 0.2368\n",
            "Seen so far: 38464 samples\n",
            "Training acc over epoch: 0.9725\n",
            "Validation acc: 0.9545\n",
            "Time taken: 1.20s\n",
            "\n",
            "Start of epoch 4\n",
            "Training loss (for one batch) at step 0: 0.0172\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 0.1743\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.0733\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 0.0430\n",
            "Seen so far: 38464 samples\n",
            "Training acc over epoch: 0.9735\n",
            "Validation acc: 0.9569\n",
            "Time taken: 1.22s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        loss_value = train_step(x_batch_train, y_batch_train)\n",
        "\n",
        "        # Log every 200 batches.\n",
        "        if step % 200 == 0:\n",
        "            print(\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                % (step, float(loss_value))\n",
        "            )\n",
        "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
        "\n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_state()\n",
        "\n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        test_step(x_batch_val, y_batch_val)\n",
        "\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_acc_metric.reset_state()\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8977d77a8095"
      },
      "source": [
        "6배 정도 빠르게 훈련된다.\n",
        "하지만 `tf.function` 데코레이터를 사용한다 해서 모델 훈련 속도가 항상 빨라지는 것은 아님에 주의한다."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
