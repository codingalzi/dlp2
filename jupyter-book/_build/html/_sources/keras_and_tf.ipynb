{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(ch:keras-tf)=\n",
    "# 케라스와 텐서플로우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**감사의 글**\n",
    "\n",
    "아래 내용은 프랑소와 숄레의 \n",
    "[Deep Learning with Python(2판)](https://github.com/fchollet/deep-learning-with-python-notebooks)의 \n",
    "소스코드 내용을 참고해서 작성되었습니다.\n",
    "자료를 공개한 저자에게 진심어린 감사를 전합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스코드**\n",
    "\n",
    "여기서 언급되는 코드를\n",
    "[(구글 코랩) 케라스와 텐서플로우](https://colab.research.google.com/github/codingalzi/dlp2/blob/master/notebooks/NB-keras_and_tf.ipynb)에서 \n",
    "직접 실행할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**주요 내용**\n",
    "\n",
    "케라스와 텐서플로우를 이용한 딥러닝의 활용법을 소개한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 텐서플로우 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "텐서플로우는 파이썬 기본 머신러닝 플랫폼이며,\n",
    "머신러닝 모델의 훈련에 필요한 계산에 필요한 텐서 연산을 지원한다.\n",
    "넘파이(Numpy) 패키지와 유사하지만 보다 많은 기능을 제공한다. \n",
    "\n",
    "- 그레이디언트 자동 계산\n",
    "- GPU, TPU 등 고성능 병렬 하드웨어 가속기 활용 가능\n",
    "- 여러 대의 컴퓨터 또는 클라우드 컴퓨팅 서비스 활용 가능\n",
    "- C++(게임), 자바스크립트(웹브라우저), TFLite(모바일 장치) 등 다른 언어가 선호되는 \n",
    "    도메인 특화 프로그램에 쉽게 이식 가능\n",
    "\n",
    "텐서플로우는 또한 단순한 패키지 기능을 넘어서는 머신러닝 플랫폼 역할도 수행한다.\n",
    "- TF-Agents: 강화학습 연구 지원\n",
    "- TFX: 머신러닝 프로젝트 운영 지원\n",
    "- TensorFlow-Hub: 사전 훈련된 머신러닝 모델 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 케라스 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "딥러닝 모델 구성 및 훈련에 단순하지만 활용성이 높은 다양한 수준의 API를 제공한다.\n",
    "원래 텐서플로우와 독립적으로 개발되었지만 텐서플로우 2.0부터 텐서플로우 라이브러리의 최상위 프레임워크(framework)로 포함됐다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/keras_and_tf.png\" style=\"width:600px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 딥러닝 주요 라이브러리 약력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 2007년: 씨아노(Theano) 공개. 텐서를 이용한 계산 그래프, 미분 자동화 등을 최초로 지원한 딥러닝 라이브러리.\n",
    "- 2015년 3월: 케라스 라이브러리 공개. Theano를 백앤드로 사용하는 고수준 패키지.\n",
    "- 2015년 11월: 텐서플로우 라이브러리 공개.\n",
    "- 2016년: 텐서플로우가 케라스의 기본 백엔드로 지정됨.\n",
    "- 2016년 9월: 페이스북이 개발한 PyTorch 공개.\n",
    "- 2017년: Theano, 텐서플로우, CNTK(마이크로소프트), MXNet(아마존)이 케라스의 백엔드로 지원됨.\n",
    "    현재 Theano, CNTK 등은 더 이상 개발되지 않으며, MXNet은 아마존에서만 주로 사용됨.\n",
    "- 2018년 3월: PyTorch와 Caffe2를 합친 PyTorch 출시(페이스북과 마이크로소프트의 협업)\n",
    "- 2019년 9월: 텐서플로우 2.0부터 케라스가 텐서플로우의 최상위 프레임워크로 지정됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 텐서플로우 대 파이토치\n",
    ":class: info\n",
    "\n",
    "파이토치<font size='2'>PyTorch</font> 또한 텐서 연산을 지원하는 딥러닝 라이브러리다.\n",
    "텐서플로우와 케라스의 조합이 강력하지만 신경망의 보다 섬세한 조정은 약하다는 지적을 많이 받는 반면에\n",
    "파이토치는 상대적으로 보다 자유롭게 신경망을 구성할 수 있다는 장점이 많이 언급된다.\n",
    "텐서플로우와 케라스의 조합이 여전히 보다 많이 사용되지만 파이토치의 비중 또한 점점 늘고 있다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 딥러닝 개발환경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "딥러닝 신경망 모델의 훈련을 위해서 GPU를 활용할 것을 강력히 추천한다.\n",
    "GPU를 사용하지 않으면 모델의 훈련이 너무 느려 제대로 활용할 수 없을 것이다.\n",
    "[구글 코랩](https://colab.research.google.com/?hl=ko)을 이용하면\n",
    "특별한 준비가 필요 없이 바로 신경망 모델을 GPU와 함께 훈련시킬 수 있다.\n",
    "구글 코랩은 주피터 노트북을 사용하는데, 주피터 노트북 사용법과\n",
    "구글 코랩에서 GPU를 이용하는 방법을 여기서는 설명하지 않는다.\n",
    "필요한 경우 인터넷에서 쉽게 관련 내용을 찾아볼 수 있다.\n",
    "\n",
    "하지만 딥러닝 모델 훈련을 많이 시키려면 NVIDIA 그래픽카드가 장착된 \n",
    "개인용 컴퓨터를 활용하는 것이 좋다.\n",
    "운영체제는 [Ubuntu](https://ubuntu.com/download/desktop) 또는 [WSL 2(Windows Subsystem for Linux 2)](https://docs.microsoft.com/ko-kr/windows/wsl/install) 사용할 것을 추천한다.\n",
    "\n",
    "윈도우 10/11에서 GPU를 지원하는 텐서플로우를 설치하는 가장 간단한 방식은\n",
    "[conda를 활용한 gpu 지원 tensorflow 설치 요령](https://github.com/ageron/handson-ml3/issues/21#issuecomment-1177864010)과\n",
    "[Anaconda와 conda 환경 활용](https://github.com/ageron/handson-ml3/blob/main/INSTALL.md)을 참고한다.\n",
    "\n",
    "보다 전문적인 딥러닝 연구를 위해 대용량의 메모리와 고성능의 CPU, GPU가 필요한 경우\n",
    "비용이 들기는 하지만\n",
    "[구글 클라우드 플랫폼](https://cloud.google.com/) 또는 \n",
    "[아마존 웹서비스(AWS EC2)](https://aws.amazon.com/ko/?nc2=h_lg)를\n",
    "단기간동안 고성능 컴퓨터를 활용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 순수 텐서플로우 사용법 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스를 전혀 이용하지 않으면서 신경망 모델을 지정하고 훈련시킬 수 있다.\n",
    "하지만 다음 개념, 기능, 도구를 모두 직접 구현해야 한다.\n",
    "\n",
    "- 가중치, 편향 등을 저장할 텐서 지정\n",
    "- 덧셈, 행렬 곱, `relu()` 함수 등 정의\n",
    "- 역전파 실행\n",
    "- 층과 모델\n",
    "- 손실 함수\n",
    "- 옵티마이저\n",
    "- 평가지표\n",
    "- 훈련 루프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 상수 텐서와 변수 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "텐서플로우 자체로 두 종류의 텐서 자료형을 지원한다.\n",
    "사용법은 기본적으로 넘파이 어레이와 유사하지만 GPU 연산과 그레이디언트 자동계산 등\n",
    "신경망 모델 훈련에 최적화된 기능을 제공한다.\n",
    "\n",
    "- `tf.Tensor` 자료형\n",
    "    - 상수 텐서\n",
    "    - 입출력 데이터 등 변하지 않는 텐서로 사용. \n",
    "    - 불변 자료형\n",
    "- `tf.Variable` 자료형\n",
    "    - 변수 텐서\n",
    "    - 모델의 가중치, 편향 등 업데이트가 되는 텐서로 사용. \n",
    "    - 가변 자료형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 텐서 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "덧셈, relu, 점곱 등 텐서 연산은 기본적으로 넘파이 어레이 연산과 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### `GradientTape` 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "넘파이 어레이와의 가장 큰 차이점은 \n",
    "그레이디언트 테이프 기능을 이용하여 변수 텐서에 의존하는 미분가능한 \n",
    "함수의 그레이디언트 자동 계산이다. \n",
    "예를 들어 아래 코드는 제곱 함수의 $x = 3$에서의 미분값인 6을 계산한다.\n",
    "\n",
    "$$\n",
    "f(x) = x^2 \\quad \\Longrightarrow \\quad \\nabla f(x) = \\frac{df(x)}{dx} = 2x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> input_var = tf.Variable(initial_value=3.)\n",
    ">>> with tf.GradientTape() as tape:\n",
    ">>>     result = tf.square(input_var)\n",
    ">>> gradient = tape.gradient(result, input_var)\n",
    ">>> print(gradient)\n",
    "tf.Tensor(6.0, shape=(), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그레이디언트 테이프 기능을 이용하여 신경망 모델 훈련 중에\n",
    "손실 함수의 그레이디언트를 계산한다.\n",
    "\n",
    "```python\n",
    "gradient = tape.gradient(loss, weights)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    ":::{admonition} 상수 텐서와 그레이디언트 테이프\n",
    ":class: info\n",
    "\n",
    "상수 텐서에 대해 그레이디언트 테이프를 이용하려면 `tape.watch()` 메서드로 감싸야 한다.\n",
    "\n",
    "```python\n",
    "input_const = tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(input_const)\n",
    "    result = tf.square(input_const)\n",
    "gradient = tape.gradient(result, input_const)\n",
    "```\n",
    "\n",
    "이유는 모델의 가중치와 편향 등 모델 훈련에 중요한 텐서들에 대해 미분 연산을\n",
    "집중하기 위해서이다. 그렇지 않으면 너무 많은 계산을 해야 한다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순수 텐서플로우로 선형 분류기 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스를 전혀 사용하지 않으면서 간단한 선형 분류기를 구현하는 과정을 통해\n",
    "텐서플로우 API의 기본 기능을 살펴 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터셋 생성**\n",
    "\n",
    "아래 사진 모양처럼 양성(노랑색)과 음성(보라색)으로 구분되는 훈련셋을 생성한다.\n",
    "훈련셋은 다변량 정규분포를 따르도록 하며 각각 1,000개의 샘플로 구성된 양성과 음성 데이터셋의 \n",
    "공분산은 동일하고 평균값만 다르도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/03-07.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "num_samples_per_class = 1000\n",
    "\n",
    "# 음성 데이터셋\n",
    "negative_samples = np.random.multivariate_normal(\n",
    "    mean=[0, 3], cov=[[1, 0.5],[0.5, 1]], size=num_samples_per_class)\n",
    "\n",
    "# 양성 데이터셋\n",
    "positive_samples = np.random.multivariate_normal(\n",
    "    mean=[3, 0], cov=[[1, 0.5],[0.5, 1]], size=num_samples_per_class)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "두 데이터셋을 합쳐서 훈련셋, 즉, 모델의 입력값으로 지정한다.\n",
    "자료형을 `np.float32`로 지정함에 주의하라.\n",
    "그렇게 하지 않으면 `np.float64`로 지정되어 보다 많은 메모리와 실행시간을 요구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "inputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "음성 샘플의 레이블은 0, 양성 샘플의 레이블은 1로 지정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "targets = np.vstack((np.zeros((num_samples_per_class, 1), dtype=\"float32\"),\n",
    "                     np.ones((num_samples_per_class, 1), dtype=\"float32\")))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**선형 회귀 모델 훈련에 필요한 가중치와 편향 변수 텐서 생성**\n",
    "\n",
    "모델 학습에 사용될 가중치와 편향을 변수 텐서로 선언한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "input_dim = 2     # 입력 샘플의 특성이 2개\n",
    "output_dim = 1    # 하나의 값으로 출력\n",
    "\n",
    "# 가중치: 무작위 초기화\n",
    "W = tf.Variable(initial_value=tf.random.uniform(shape=(input_dim, output_dim)))\n",
    "\n",
    "# 편향: 0으로 초기화\n",
    "b = tf.Variable(initial_value=tf.zeros(shape=(output_dim,)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 선언: 포워드 패스**\n",
    "\n",
    "신경망 모델을 훈련할 때 입력값에 대한 예측값을 계산하는 과정인\n",
    "포워드 패스를 함수로 구현한다.\n",
    "간단한 모델 표현을 위해 활성화 함수는 사용하지 않는다.\n",
    "\n",
    "`tf.matmul()` 함수는 넘파이의 점 곱 함수처럼 작동하며 아래 코드에서는\n",
    "행렬의 곱을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "def model(inputs):\n",
    "    return tf.matmul(inputs, W) + b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**손실 함수: 평균 제곱 오차(MSE)**\n",
    "\n",
    "타깃과 예측값 사이의 평균 제곱 오차를 손실값으로 사용한다. \n",
    "아래 코드에서 `tf.reduce_mean()` 함수는 넘파이의 `np.mean()`처럼\n",
    "평균값을 계산하지만 텐서플로우의 텐서를 대상으로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "def square_loss(targets, predictions):\n",
    "    per_sample_losses = tf.square(targets - predictions)\n",
    "    return tf.reduce_mean(per_sample_losses)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**훈련 스텝: 백워드 패스와 역전파**\n",
    "\n",
    "하나의 배치에 대해 예측값을 계산한 후에 손실 함수의 그레이디언트를 \n",
    "계산한 후에 가중치와 편향을 업데이트하는 함수를 선언한다.\n",
    "그레이디언트 계산은 그레이디언트 테이프를 이용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "def training_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs)\n",
    "        loss = square_loss(targets, predictions)\n",
    "    grad_loss_wrt_W, grad_loss_wrt_b = tape.gradient(loss, [W, b])\n",
    "    W.assign_sub(grad_loss_wrt_W * learning_rate)\n",
    "    b.assign_sub(grad_loss_wrt_b * learning_rate)\n",
    "    return loss\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**훈련 루프**\n",
    "\n",
    "반복해서 훈련한 내용을 지정한다.\n",
    "여기서는 설명을 간단하게 하기 위해 미니 배치가 아닌 배치 훈련을 구현한다.\n",
    "전체 훈련셋을 총 40번 반복 학습할 때마다 손실값을 출력하도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "for step in range(40):\n",
    "    loss = training_step(inputs, targets)\n",
    "    print(f\"Loss at step {step}: {loss:.4f}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**결정경계 예측**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 예측값이 0.5보다 클 때 양성으로 판정하는 것이 좋은데\n",
    "이유는 샘플들의 레이블이 0 또는 1이기 때문이다.\n",
    "모델은 훈련과정 중에 음성 샘플은 최대한 0에, \n",
    "양성 샘플은 최대한 1에 가까운 값으로 예측하여 손실값을 최대한 줄여야 하는데\n",
    "옵티마이저가 그렇게 유도한다.\n",
    "따라서 예측값이 0과 1의 중간값인 0.5일 때를 결정경계로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결정경계를 직선으로 그리려면 아래 식을 이용한다.\n",
    "\n",
    "```python\n",
    "y = - W[0] /  W[1] * x + (0.5 - b) / W[1]\n",
    "```\n",
    "\n",
    "이유는 위 모델의 예측값이 다음과 같이 계산되며,\n",
    "\n",
    "```python\n",
    "W[0]*x + W[1]*y + b\n",
    "```\n",
    "\n",
    "위 예측값이 0.5보다 큰지 여부에 따라 음성, 양성이 판단되기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/HighResolutionFigures/figure_3-8.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.6 케스의 핵심 API  이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 신경망 모델 훈련 핵심 2\n",
    "\n",
    "1. 층(layer)과 모델: 층을 적절하게 쌓아 모델 구성\n",
    "1. 손실 함수(loss function): 학습 방향을 유도하는 피드백 역할 수행\n",
    "1. 옵티마이저(optimizer): 학습 방향을 정하는 기능 수행\n",
    "1. 메트릭(metric): 정확도 등 모델 성능 평가 용도\n",
    "1. 훈련 반복(training loop): 미니 배치 경사하강법 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 층(layer)의 역할\n",
    "\n",
    "- 모델의 상태(지식)로 사용되는 가중치(weight)와 편향(bias) 저장\n",
    "- 데이터 표현 변환(forwardd pass)\n",
    "- 케라스 활용 딥러닝 모델: 호환 가능한 층들의 적절한 연결"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 층의 종류와 처리 가능 텐서\n",
    "\n",
    "- `Dense` 클래스를 사용하는 밀집층(dense layer): \n",
    "    `(샘플수, 특성수)` 모양의 2D 텐서로 제공된 데이터셋\n",
    "- `LSTM` 클래스, `Conv1D` 클래스 등을 사용하는 순환층(recurrent layer): \n",
    "    `(샘플수, 타임스텝수, 특성수)` 모양의 3D 텐서로 제공된 순차 데이터셋\n",
    "- `Cons2D` 클래스 등을 사용하는 층: \n",
    "    `(샘플수, 가로, 세로, 채널수)` 모양의 4D 텐서로 제공된 이미지 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `Layer` 클래스와 `__call__()` 메서드\n",
    "\n",
    "- 케라스에서 사용되는 모든 층에 대한 부모 클래스\n",
    "- `__call__()` 메서드의 역할\n",
    "    - 가중치와 편향 벡터 생성 및 초기화\n",
    "    - 입력 데이터를 출력 데이터로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `__call__()` 메서드의 대략적 정의\n",
    "\n",
    "```python\n",
    "def __call__(self, inputs):\n",
    "    if not self.built:\n",
    "        self.build(inputs.shape)\n",
    "        self.built = True\n",
    "return self.call(inputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `self.built`: 가중치와 편향 벡터가 초기화가 되어 있는지 여부 기억\n",
    "- `self.build(inputs.shape)`: 입력 배치 데이터셋(`inputs`)의 모양(shape) 정보 이용\n",
    "    - 가중치 텐서 생성 및 무작위적으로 초기화\n",
    "    - 편향 텐서 생성 및 0벡터로 초기화\n",
    "- `self.call(inputs)`: 출력값 계산(forward pass)\n",
    "    - 아핀 변환 및 활성화 함수 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 층에서 모델로\n",
    "\n",
    "- 입렵값을 보고 바로 입력값의 모양 확인\n",
    "- MNIST 모델 사용된 `Dense` 클래스처럼 입력 데이터에 정보 미리 요구하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "```python\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.SimpleDense(512, activation=\"relu\"),\n",
    "    layers.SimpleDense(10, activation=\"softmax\")\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 딥러닝 모델\n",
    "\n",
    "- 층으로 구성된 그래프\n",
    "- 예제: `Sequential` 모델\n",
    "    - 층을 일렬로 쌓은 신경망 제공\n",
    "    - 아래 층에서 전달한 값을 받아 변환한 후 위 층으로 전달\n",
    "- 예제: 트랜스포머(Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/transformer0001.png\" style=\"width:400px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 망 구성방식과 가설 공간\n",
    "\n",
    "- 모델의 학습과정은 층을 어떻게 구성하였는가에 전적으로 의존함.\n",
    "- 여러 개의 `Dense` 층을 이용한 `Sequential` 모델\n",
    "    - 아핀 변환,`relu()` 등의 활성화 함수를 연속적으로 적용한 데이터 표현 변환\n",
    "- 다른 방식으로 구성된 모델: 다른 방식으로 텐서 표현 변환\n",
    "- 이렇듯 층을 구성하는 방식에 따라 텐서들이 가질 수 있는 표현들의 공간이 정해짐.\n",
    "- '**망 구성방식(network topology)에 따른 표현 가설 공간(hypothesis space)**'이 지정됨.\n",
    "- 신경망의 구성\n",
    "    - 주어진 데이터셋과 모델의 목적에 따라 결정됨.\n",
    "    - 특별한 규칙 또는 이론은 없음.\n",
    "    - 이론 보다는 많은 실습을 통한 경험에 의존"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 컴파일\n",
    "\n",
    "모델의 구조를 정의한 후에 아래 세 가지 설정을 추가로 지정해야 함.\n",
    "\n",
    "- 옵티마이저(optimizer): 모델의 성능을 향상시키는 방향으로 가중치를 업데이트하는 알고리즘\n",
    "- 손실함수(loss function): 훈련 중 모델의 성능 얼마 나쁜가를 측정하는 기준. \n",
    "    미분가능이어야 하며 옵티마이저가 경사하강법을 활용하여 손실함숫값을 줄이는 방향으로 작동함.\n",
    "- 평가지표(metrics):: 훈련과 테스트 과정을 모니터링 할 때 사용되는 모델 평가 지표. \n",
    "    옵티마이저 또는 손실함수와 일반적으로 상관 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `fit()` 메서드 작동법\n",
    "\n",
    "모델을 훈련시키려면 `fit()` 메서드를 적절한 인자들과 함께 호출해야 함.\n",
    "\n",
    "- 훈련 세트: 보통 넘파이 어레이 또는 텐서플로우의 `Dataset` 객체 사용\n",
    "- 에포크(`epochs`): 전체 훈련 세트를 몇 번 훈련할 지 지정\n",
    "- 배치 크기(`batch_size`): 배치 경사하강법에 적용될 배치(묶음) 크기 지정\n",
    "\n",
    "아래 코드는 앞서 넘파이 어레이로 생성한 (2000, 2) 모양의 양성, 음성 데이터셋을 대상으로 훈련한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 검증 세트 활용\n",
    "\n",
    "훈련된 모델이 완전히 새로운 데이터에 대해 예측을 잘하는지 여부를 판단하려면\n",
    "전체 데이터셋을 훈련 세트와 **검증 세트**로 구분해야 함.\n",
    "\n",
    "- 훈련 세트: 모델 훈련에 사용되는 데이터셋\n",
    "- 검증 세트: 훈련된 모델 평가에 사용되는 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model.fit(\n",
    "    training_inputs,\n",
    "    training_targets,\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    validation_data=(val_inputs, val_targets)\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter03_introduction-to-keras-and-tf.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
