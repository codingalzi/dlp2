

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>5. 머신러닝 모델 훈련 기법 &#8212; Deep Learning with Python(2판)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=c5ced968eda925caa686" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=c5ced968eda925caa686" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=c5ced968eda925caa686" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=c5ced968eda925caa686" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=c5ced968eda925caa686" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=c5ced968eda925caa686" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=c5ced968eda925caa686"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'fundamentals_of_ml';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="6. 머신러닝 작업 흐름 일반" href="unversal_workflow_of_ml.html" />
    <link rel="prev" title="4. 신경망 활용 처음부터 끝까지: 분류와 회귀" href="getting_started_with_neural_networks.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Deep Learning with Python(2판)</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="what_is_deep_learning.html">1. 딥러닝 소개</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="building_blocks_of_NN.html">2. 신경망 기본 구성 요소</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="tensor_intro.html">2.5. 부록: 텐서 소개</a></li>
<li class="toctree-l2"><a class="reference internal" href="tf_tensor.html">2.6. 부록: 텐서플로우 텐서</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="keras_and_tf.html">3. 케라스와 텐서플로우</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started_with_neural_networks.html">4. 신경망 활용 처음부터 끝까지: 분류와 회귀</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">5. 머신러닝 모델 훈련 기법</a></li>
<li class="toctree-l1"><a class="reference internal" href="unversal_workflow_of_ml.html">6. 머신러닝 작업 흐름 일반</a></li>
<li class="toctree-l1"><a class="reference internal" href="working_with_keras.html">7. 케라스 신경망 모델 활용법</a></li>
<li class="toctree-l1"><a class="reference internal" href="computer_vision_intro.html">8. 컴퓨터 비전 기초: 합성곱 신경망</a></li>
<li class="toctree-l1"><a class="reference internal" href="computer_vision_advanced.html">9. 고급 컴퓨터 비전</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl_for_timeseries.html">10. 시계열 분석</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl_for_text.html">11. 자연어 처리</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative_dl.html">12. 생성 모델</a></li>
<li class="toctree-l1"><a class="reference internal" href="best_practices.html">13. 딥러닝 실전 적용</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/codingalzi/dlp2" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/codingalzi/dlp2/issues/new?title=Issue%20on%20page%20%2Ffundamentals_of_ml.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/fundamentals_of_ml.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>머신러닝 모델 훈련 기법</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">5.1. 최적화, 일반화, 과대적합</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">5.1.1. 머신러닝 모델 훈련의 핵심: 최적화대 일반화</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">5.1.2. 과대적합 대 과소적합</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">5.1.3. 과대적합 발생 주요 요인</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">5.2. 다양체 가설과 일반화</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">5.2.1. 다양체 가설</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">5.2.2. 보간법과 일반화</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">5.3. 모델 평가</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">5.3.1. 훈련셋, 검증셋, 테스트셋</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">5.3.2. 검증셋 활용법</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">5.3.3. 모델 성능 평가의 기준선</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">5.4. 모델 훈련 최적화</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">5.5. 모델 일반화 성능 향상 기법</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">5.5.1. 조기 종료</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">5.5.2. 규제: 드롭아웃</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">5.6. 연습문제</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ch-fundamentals-of-ml">
<span id="id1"></span><h1><span class="section-number">5. </span>머신러닝 모델 훈련 기법<a class="headerlink" href="#ch-fundamentals-of-ml" title="Permalink to this heading">#</a></h1>
<p><strong>감사의 글</strong></p>
<p>아래 내용은 프랑소와 숄레의
<a class="reference external" href="https://github.com/fchollet/deep-learning-with-python-notebooks">Deep Learning with Python(2판)</a>의
소스코드 내용을 참고해서 작성되었습니다.
자료를 공개한 저자에게 진심어린 감사를 전합니다.</p>
<p><strong>소스코드</strong></p>
<p>여기서 언급되는 코드를
<a class="reference external" href="https://colab.research.google.com/github/codingalzi/dlp2/blob/master/notebooks/NB-fundamentals_of_ml.ipynb">(구글 코랩) 머신러닝 모델 훈련 기법</a>에서
직접 실행할 수 있다.</p>
<p><strong>슬라이드</strong></p>
<p>본문 내용을 요약한 <a class="reference external" href="https://github.com/codingalzi/dlp2/raw/master/slides/slides-fundamentals_of_ml.pdf">슬라이드</a>를 다운로드할 수 있다.</p>
<p><strong>주요 내용</strong></p>
<ul class="simple">
<li><p>최적화, 일반화, 과대적합</p></li>
<li><p>다양체 가설</p></li>
<li><p>모델 평가</p></li>
<li><p>모델 훈련 최적화</p></li>
<li><p>모델 일반화 성능 향상 기법</p></li>
</ul>
<section id="id2">
<h2><span class="section-number">5.1. </span>최적화, 일반화, 과대적합<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<section id="id3">
<h3><span class="section-number">5.1.1. </span>머신러닝 모델 훈련의 핵심: 최적화대 일반화<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<p>머신러닝 모델 훈련의 주요 과제는 모델 훈련의 <strong>최적화</strong><font size='2'>optimization</font>와
모델 <strong>일반화</strong><font size='2'>generalization</font> 사이의 적절한 관계 찾기이다.</p>
<ul class="simple">
<li><p><strong>최적화</strong>: 훈련셋에 대해 가장 좋은 성능 이끌어내기</p></li>
<li><p><strong>일반화</strong>: 훈련 과정에서 보지 못한 데이터를 처리하는 능력 향상시키기</p></li>
</ul>
<p>모델 훈련의 최적화는 데이터셋 전처리, 적절한 모델 구성과 모델의 하이퍼파라미터 설정 등을 통해 이루어진다.
반면에 모델 성능의 일반화는 훈련을 통해 조정할 수 있는 대상이 아니다.
하지만 모델 훈련의 최적화 과정에서 일부 설정을 조정하면 훈련된 모델의 일반화 성능을 끌어올릴 수 있다.</p>
<p>모델은 훈련을 많이 할 수록 일반적으로 훈련셋에 대해 보다 좋은 성능을 보인다.
즉, 최적화가 진행된다.
하지만 훈련을 많이 할 수록 새로운 데이터에 대한 성능인
일반화 성능은 점점 약해지는 과대적합 현상이 발생할 가능성이 높아지며
언젠가는 반드시 과대적합이 발생한다.
따라서 머신러닝 모델 훈련의 핵심은 과대적합 현상을 최대한 피하면서 최적화 훈련을 오래할 수 있는
모델 구성과 모델의 하이퍼파라미터 설정을 조정하는 일이다.</p>
</section>
<section id="id4">
<h3><span class="section-number">5.1.2. </span>과대적합 대 과소적합<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<p><strong>과대적합</strong><font size='2'>overfitting</font>은 모델이 훈련셋에 너무 적응해서 훈련셋의 속성에 민감하게 반응하는 현상을 가리킨다.
과대적합이 발생하면 훈련중에 경험하지 못한 데이터에 대해 제대로 반응하지 못한다.</p>
<p>반면에 <strong>과소적합</strong><font size='2'>underfitting</font>은 모델이 훈련셋의 속성을 아직 덜 파악한 상태를 의미한다.
보통 훈련 초반에 일어나는 현상이며, 모델이 훈련셋과 검증셋 모두에 대해 성능이 향상되는 과정에 해당한다.</p>
<p>또한 모델 설정이 잘못되어 모델 훈련이 전혀 진행되지 않는 경우도 과소적합에 해당한다.
예를 들어 언어 인식 등 매우 복잡한 문제를 단순한 선형회귀 모델로
훈련시키려 하면 당연히 모델이 절대로 좋은 성능을 내지 못하는 과소적합 현상이 발생한다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/typical_overfitting.png" style="width:600px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p></section>
<section id="id5">
<h3><span class="section-number">5.1.3. </span>과대적합 발생 주요 요인<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h3>
<p>과대적합을 발생시키는 요인은 크게 세 가지로 나뉜다.</p>
<p><strong>첫째, 훈련셋에 포함된 노이즈</strong></p>
<p>적절하지 않은 데이터 또는 잘못된 라벨을 갖는 데이터 등을 <strong>노이즈</strong><font size='2'>noise</font>라 부른다.</p>
<ul class="simple">
<li><p>적절하지 않은 데이터: 다음 MNNIST 이미지들처럼 불분명하면 특성 파악이 어렵다.</p></li>
</ul>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/fucked_up_mnist.png" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><ul class="simple">
<li><p>잘못된 라벨: 예를 들어, 잘못 분류된 1처럼 생긴 이미지를 7로 잘못 분류할 가능성이 높아진다.</p></li>
</ul>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/mislabeled_mnist.png" style="width:660px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>노이즈 등의 이상치<font size='2'>outlier</font>를 학습하면
아래 오른편 그림의 경우처럼 모델이 이상치의 특별한 특성을 학습하게 되어
새루운 데이터에 대한 예측 성능이 불안정해지게 된다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/outliers_and_overfitting.png" style="width:660px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>둘째, 애매한 특성</strong></p>
<p>노이즈 등의 이상치가 전혀 없다 하더라도 특정 특성 영역에 대한 예측값이 여러 개의 값을 가질 수 있다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/iris01.png" style="width:500px;"></div><p>예를 들어, 붓꽃 데이터셋의 경우 꽃잎의 길이와 너비만을 활용해서는
버시컬러<font size='2'>versicolor</font> 품종과
버지니카<font size='2'>virginica</font> 품종의 완벽한 구분이
애초에 불가능하다.</p>
<div align="center"><img src="https://codingalzi.github.io/handson-ml2/slides/images/ch05/homl05-03b.png" style="width:500px;"></div><p>하지만 훈련을 오래 시키면 각 샘플의 특성을 해당 라벨의 고유의 특성으로
간주하는 정도까지 모델이 훈련되어 아래 오른편 그림과 같이
샘플의 특성에 너무 민감하게 작동한다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/HighResolutionFigures/figure_5-5.png" style="width:660px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>셋째: 특성과 타깃 사이의 거짓 상관관계</strong></p>
<p>특성과 타깃 사이의 거짓 상관관계를 유발하는 여러 상황이 있다.</p>
<ul>
<li><p>매우 드문 특성을 사용하는 데이터셋으로 훈련하는 경우</p>
<p><a class="reference internal" href="getting_started_with_neural_networks.html#sec-imdb"><span class="std std-numref">4.1절</span></a>의 이진 분류 모델의 훈련에 사용된
IMDB 데이터셋에서 매우 낮은 빈도로 사용되는 단어를 훈련셋에서 포함시키는 경우
어쩌다 한 번 사용되는 특성으로 인해 잘못된 판단이 유발될 수 있다.</p>
<p>예를 들어, 에쿠아도르, 페루 등 안데스 산맥 지역에서 자라는 Cherimoya(체리모야) 라는
과일 이름이 들어간 영화 후기가 단 하나만 있으면서 마침 부정적이었다면,
분류 모델은 Cherimoya 단어가 들어간 영화 후기를 기본적으로 부정적으로 판단할 가능이 높아진다.</p>
  <div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/cherimoya.jpg" style="width:300px;"></div>
  <p><div style="text-align: center">체리모야 열매</div></p>
<p>이렇듯 매우 매우 드물게 사용되는 특성은 과대적합을 유발한다.
앞서 사용 빈도에서 10,000등 안에 드는 단어만으로 작성된 영화 후기만을 대상으로 훈련시킨 이유가
이런 가능성을 제한하기 위해서였다.</p>
</li>
</ul>
<ul>
<li><p>우연에 의한 경우</p>
<p>자주 발생하는 특성이라 하더라도 우연히 잘못된 편견을 훈련중인 모델에 심어줄 수 있다.
예를 들어, “너무” 라는 단어를 포함한 100개의 영화 후기 중에서 54%는 긍정,
나머지 46%는 부정이었다면 훈련중인 모델은 “너무”라는 단어를 긍정적으로 평가할 가능성을 높힌다.
하지만 “너무”라는 단어는 긍정적으로, 부정적으로 사용될 수 있기 때문에 이는 우연에 불과하다.</p>
</li>
</ul>
<ul>
<li><p>의미 없는 특성에 의한 경우</p>
<p>아래 이미지는 MNIST 데이터셋에 <strong>화이트 노이즈</strong><font size='2'>white noise</font>가 추가된 경우와
단순히 여백이 추가된 경우의 훈련 샘플을 보여준다.</p>
  <div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch05-mnist-noise.png" style="width:400px;"></div>
  <p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p>
<p>화이트 노이즈가 포함된 샘플들의 데이터셋으로 훈련시킨 모델과
단순한 여백이 추가된 샘플들의 데이터셋으로 훈련시킨 모델의 성능을 비교하면
화이트 노이즈가 포함된 훈련셋을 이용한 모델의 성능이 1% 정도 떨어진다.</p>
  <div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch05-mnist-noise03.png" style="width:400px;"></div>
<p>이유는 모델이 화이트 노이즈에 특별한 의미를 부여하기 때문이며, 이로 인해 과대적합이
보다 쉽게 발생한다.
따라서 보다 효율적인 훈련을 위해 화이트 노이즈 등 과대적합을 유발하는
특성을 미리 제거하여 모델에 유용한 특성만을 훈련에 사용해야 한다.
하지만 유용한 특성을 선택하는 일이 기본적으로 불가능하거나 매우 어렵다.</p>
</li>
</ul>
<div class="note admonition">
<p class="admonition-title">화이트 노이즈</p>
<p>프로그래밍 분야에서 화이트 노이즈<font size='2'>white noise</font>은
<strong>무작위적으로 생성되었지만 전 영역에 걸쳐 고르게 퍼진 데이터셋</strong>을 의미한다.
화이트 노이즈가 다른 데이터와 섞일 경우 화이트 노이즈를 분리하는 것은 원천적으로 불가능하다.</p>
</div>
</section>
</section>
<section id="id6">
<h2><span class="section-number">5.2. </span>다양체 가설과 일반화<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h2>
<p>딥러닝 모델은 어떤 무엇도 학습할 수 있다.
예를 들어 MNIST 모델을 임의로 섞은 라벨과 함께 훈련시키면
훈련셋에 대한 성능은 훈련하면서 계속 향상되어 결국
모델은 모든 답을 외워버리는 정도에 다달한다.
물론 검증셋에 성능은 매우 낮은 상태에서 전혀 향상되지 않는다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch05-mnist-shuffled.png" style="width:400px;"></div><p>이는 다음 네 가지를 의미한다.</p>
<p>첫째, 일반화는 모델 훈련 과정 중에 제어할 수 있는 대상이 아니다.</p>
<p>둘째, 모델 훈련을 통해 할 수 있는 것은 주어진 훈련 데이터셋에 모델이 잘 적응하도록 하는 것 뿐이다.</p>
<p>셋째, 딥러닝 모델은 어떤 데이터셋에도 적응할 수 있기에
너무 오래 훈련시키면 과대적합은 반드시 발생하고 일반화는 어려워진다.</p>
<p>넷째, 모델의 <strong>일반화</strong> 능력은 모델 자체보다는 <strong>훈련셋에 내재하는 정보의 구조</strong>와
보다 밀접히 관련된다.</p>
<section id="id7">
<h3><span class="section-number">5.2.1. </span>다양체 가설<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h3>
<p><strong>다양체 가설</strong><font size='2'>manifold hypothesis</font>은
데이터셋에 내재하는 정보의 구조에 대한 다음과 같은 가설이다.</p>
<blockquote>
<div><p>일반적인 데이터셋은 고차원상에 존재하는 (저차원의) 연속이며 미분가능한 다양체를 구성한다.</p>
</div></blockquote>
<p>다양체 가설을 인정하면 모델 훈련은 다양체 형식으로 훈련셋에 내재된 정보의 구조를
찾아가는 과정이 된다.
그리고 적절히 훈련된 모델이 완전히 새로운 데이터에 대해 적절한 예측을 할 수 있는 이유를
다음과 같이 설명할 수 있다.</p>
<blockquote>
<div><p>모델이 찾아낸 훈련셋에 내제된 정보의 구조가 부드러운 곡선을 갖는 다양체이기에 보간법을 적절히 적용할 수 있기 때문이다.</p>
</div></blockquote>
<p>모델의 훈련 과정에서 훈련셋에 내재된 다양체를 찾는 과정은
경사하강법을 이용하여 단계적으로 아주 천천히 진행된다.
따라서 훈련 진행 과정 중에 특정 단계에서 데이터셋에 내재된 다양체에
근접하고, 훈련이 더 진행될 수록 아래 그림에서처럼
찾아야 하는 다양체에서 점차 멀어지는 과대적합 단계로 접어든다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/05-10.png" style="width:600px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>따라서 모델의 훈련을 적절한 단계에서 멈추도록 하면 모델의 일반화 성능을 최대한
끌어 올릴 수 있다. 아래에서 모델의 훈련을 적절할 때에 조기종료하는 방법을 살펴볼 것이다.</p>
</section>
<section id="id8">
<h3><span class="section-number">5.2.2. </span>보간법과 일반화<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h3>
<p><strong>보간법</strong><font size='2'>interpolation</font>은
모델 훈련에 사용된 훈련셋의 데이터와 새로운 데이터를 연결하는
다양체 상의 경로를 이용하여 예측값을 결정하는 방법이다.
새로운 데이터에 대한 예측, 즉 모델의 일반화는
바로 이 보간법을 이용한다.</p>
<p>아래 그림은 훈련셋이 작은 경우와 큰 경우의 차이를 잘 보여준다.
훈련셋이 충분히 크지 않으면 모델이 찾아낸 다양체와 훈련셋에 내재된 실제 다양체 사이의
편차가 크기에 새로운 데이터에 대한 예측이 보다 부정확할 수밖에 없다.
반면에 양질의 훈련 데이터 샘플이 충분히 많다면 훈련을 통해 실제 다양체에 매우 근접하는 모델을
얻을 수 있게 된다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/dense_sampling.png" style="width:660px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>일반적으로 양질의 많은 데이터를 이용한 모델의 일반화 성능이 좋다.
하지만 <a class="reference external" href="https://codingalzi.github.io/handson-ml3/dimensionality_reduction.html"><strong>차원의 저주</strong></a>로 인해 충분한 크기의 훈련셋을 구하기가 일반적으로 불가능하거나 매우 어렵다.
충분히 큰 훈련셋을 준비하지 못하는 경우 <strong>규제</strong><font size='2'>regularization</font>를
이용해서 모델이 과대적합되는 것을 예방할 수 있다.
규제에 대해서 잠시 뒤에 자세히 다룬다.</p>
</section>
</section>
<section id="id9">
<h2><span class="section-number">5.3. </span>모델 평가<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h2>
<p>검증셋을 활용하여 모델의 일반화 능력을 평가하는 방법을 소개한다.</p>
<section id="id10">
<h3><span class="section-number">5.3.1. </span>훈련셋, 검증셋, 테스트셋<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h3>
<p>테스트셋은 모델 구성과 훈련에 전혀 관여하지 않아야 한다.
따라서 구성된 모델의 성능을 평가하려면 테스트셋을 제외한 다른 데이터셋이 필요한데
이를 위해 훈련셋의 일부를 검증셋으로 활용한다.</p>
<p><strong>모델 튜닝</strong></p>
<p>검증셋은 <strong>훈련 과정 중에 모델의 일반화 성능을 테스트</strong>하는 용도로 사용된다.
모델의 검증셋에 대한 성능 평가를 바탕으로
모델 구성과 모델의 <strong>하이퍼파라미터</strong><font size='2'>hyperparameter</font> 설정을 조정한다.
이처럼 검증셋을 활용하여 최적의 모델을 찾는 과정이 <strong>모델 튜닝</strong><font size='2'>model tuning</font>이다.</p>
<p><strong>정보 유출</strong></p>
<p>모델 튜닝도 모델의 좋은 하이퍼파라미터를 찾아가는 일종의 <strong>학습</strong>이다.
따라서 튜닝을 많이 하게되면 검증셋에 특화된 모델이 얻어질 가능성이 커진다.
즉, 검증셋에 과대적합된 모델이 훈련될 가능성이 높아진다.
이런 현상을 <strong>정보 유출</strong>이라 하는데,
이유는 튜닝을 하면 할 수록 검증셋에 대한 보다 많은 정보가 모델로 흘러 들어가기 때문이다.</p>
<div class="info admonition">
<p class="admonition-title">하이퍼파라미터 대 파라미터</p>
<p>하이퍼파라미터와 파라미터는 다르다.
파라미터는 모델 훈련 중에 학습되는 가중치, 편향 등을 가리킨다.</p>
</div>
<p><strong>모델 평가용 데이터셋 준비 관련 주의사항</strong></p>
<p>모델 훈련의 최적화를 위해 아래 세 가지 사항을 준수하면서 훈련셋, 검증셋, 테스트셋을 준비해야 한다.</p>
<ul class="simple">
<li><p><strong>대표성</strong>: 일반적으로 데이터셋을 무작위로 섞어 라벨이 적절한 비율로 섞인
훈련셋, 검증셋, 테스트셋을 구성해야 한다.</p></li>
<li><p><strong>순서 준수</strong>: 미래를 예측하는 모델을 훈련시킬 때, 테스트셋의 데이터는 훈련셋의 데이터보다
시간상 뒤쪽에 위치하도록 해야 한다. 그렇지 않으면 미래 정보가 모델에 유출된다.
즉, 데이터를 무작위로 섞어 훈련셋과 테스트셋으로 구분하는 일은 하지 않아야 한다.</p></li>
<li><p><strong>중복 데이터 제거</strong>: 훈련셋과 테스트셋에 동일한 데이터가 들어가지 않도록 중복 데이터를 제거해야 한다.
그렇지 않으면 중복된 데이터에 보다 민감하게 작동하는 공정하지 못한 모델 훈련이 발생할 수 있다.</p></li>
</ul>
</section>
<section id="id11">
<h3><span class="section-number">5.3.2. </span>검증셋 활용법<a class="headerlink" href="#id11" title="Permalink to this heading">#</a></h3>
<p>데이터셋을 훈련셋, 검증셋, 테스트셋으로 분류하여 모델 훈련을 진행하는
전형적인 방식 세 가지를 소개한다.</p>
<p><strong>홀드아웃<font size='2'>hold-out</font> 검증</strong></p>
<p>훈련셋의 일부를 검증셋으로 지정하고 모델 튜닝에 활용하는 가장 일반적인 방법이다.
반면에 테스트셋은 모델 훈련에 절대로 활용하지 않고 훈련이 끝난 다음
실전에 배치하기 이전에 미리 실전 활용도를 평가하는 용도로만 사용한다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/holdout_validation.png" style="width:350px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>K-겹 교차검증</strong></p>
<p>홀드아웃 검증은 하지만 데이터셋이 크지 않은 경우 사용하기 어렵다.
이유는 데이터셋 자체가 작기 때문에 훈련셋으로부터 검증셋을 분리하면 훈련셋이 더욱 작아져서
제대로된 훈련이 이뤄지기 어려울 수 있기 때문이다.
이런 경우 K-겹 교차검증이 권장된다.</p>
<p>K-겹 교차검증은
훈련셋을 K 개의 부분집합으로 분류한 다음에 한 개의 부분집합을 검증셋으로,
나머지늘 훈련셋으로 사용하는 방식을 K 번 반복하는 훈련법이다.
이때 검증셋으로 사용되는 부분집합은 매번 다르게 선택된다.</p>
<p>모델의 성능은 K개의 검증성능의 평균값으로 평가된다.
아래 그림은 3-겹 교차검증의 작동 과정을 보여준다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/k_fold_validation.png" style="width:650px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>필요에 따라 K-겹 교차검증을 반복 적용할 수 있다.
훈련셋의 크기가 너무 작거나 모델의 성능을 최대한 정확하게 평가하기 위해 사용된다.
대신 매번 훈련셋을 무작위로 섞은 뒤에 교차검증을 실행한다.
최종 결과는 각 교차검증의 평균값을 사용한다.
훈련 시간이 매우 오래 걸린다는 게 이 방법의 단점이다.
K-겹 교차 검증을 P번 반복하면 총 <code class="docutils literal notranslate"><span class="pre">P</span> <span class="pre">*</span> <span class="pre">K</span></code> 개의 모델을 훈련시키게 된다.</p>
</section>
<section id="id12">
<h3><span class="section-number">5.3.3. </span>모델 성능 평가의 기준선<a class="headerlink" href="#id12" title="Permalink to this heading">#</a></h3>
<p>모델 훈련이 시작되면 평가지표<font size='2'>metrics</font>를 지켜보는 일 이외에 할 수 있는 게 없다.
다만 훈련중에 검증셋에 대한 평가지표가 특정 기준선 이상으로 좋아지는지를 확인한다.</p>
<p>예를 들어 지금까지 살펴봤던 모델들의 기준선은 다음과 같다.</p>
<ul class="simple">
<li><p>MNIST 데이터셋: 10%의 정확도</p></li>
<li><p>IMDB 데이터셋: 50%의 정확도</p></li>
<li><p>로이터 통신 기사: 18-19%의 정확도. 기사들이 균등하게 분포되어 있지 않음.</p></li>
</ul>
<p>모델 훈련을 시작할 때의 기본 목표는 기준선을 넘기는 성능을 가진 모델 훈련에 둔다.
모델 훈련 동안 기준선을 넘기지 못한다면
무언가 잘못된 모델 구성과 설정을 사용하고 있을 가능성이 크다.</p>
</section>
</section>
<section id="id13">
<h2><span class="section-number">5.4. </span>모델 훈련 최적화<a class="headerlink" href="#id13" title="Permalink to this heading">#</a></h2>
<p>모델 훈련을 최적화하려면 모순적이게도 먼저 과대적합을 달성해야 한다.
이유는 과대적합이 나타나야만 과대적합의 경계를 알아내서 모델 훈련을
언제 멈추어야 하는지 알 수 있기 때문이다.
일단 과대적합의 경계를 찾은 다음에 일반화 성능 향상을 목표로 삼는다.</p>
<p>모델 훈련 중에 발생하는 문제는 일반적으로 다음 세 종류이다.</p>
<ul class="simple">
<li><p>첫째, 훈련셋의 손실값이 줄어들지 않아 훈련이 제대로 진행되지 않는 경우</p></li>
<li><p>둘째, 훈련셋의 손실값은 줄어들지만 검증셋의 성능은 평가 기준선을 넘지 못하는 경우</p></li>
<li><p>셋째, 훈련셋과 검증셋의 평가가 기준선을 넘어 계속 좋아지지만 과대적합이 발생하지 않아
계속해서 과소적합 상태로 머무는 경우</p></li>
</ul>
<p><strong>첫째 경우: 경사하강법 관련 파라미터 조정</strong></p>
<p>훈련셋의 손실값이 줄어들지 않거나 진동하는 등 훈련이 제대로 이루어지지 않는 경우는
기본적으로 경사하강법이 제대로 작동하지 않아서이다.
이럴 때는 보통 학습률과 배치 크기를 조정하면 해결된다.</p>
<p><em>학습률 조정</em></p>
<ul class="simple">
<li><p>매우 큰 학습률을 사용하는 경우: 모델이 제대로 학습되지 않는다.</p></li>
</ul>
<div align="center"><img src="https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-03.png" style="width:550px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://github.com/ageron/handson-ml2">핸즈온 머신러닝(2판), 4장</a>&gt;</div></p><ul class="simple">
<li><p>매우 작은 학습률을 사용하는 경우: 모델이 너무 느리게 학습된다.</p></li>
</ul>
<div align="center"><img src="https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-02.png" style="width:550px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://github.com/ageron/handson-ml2">핸즈온 머신러닝(2판), 4장</a>&gt;</div></p><ul class="simple">
<li><p>적절한 학습률을 사용하는 경우: 모델이 적절한 속도로 학습된다.</p></li>
</ul>
<div align="center"><img src="https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-01.png" style="width:550px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://github.com/ageron/handson-ml2">핸즈온 머신러닝(2판), 4장</a>&gt;</div></p><p><em>배치 크기 조정</em></p>
<p>학습률 이외에 배치크기를 키우면 보다 안정적으로 훈련이 된다.
단, 배치 크기를 너무 크게 지정하면 계산량이 많아져서 훈련 시간이 오래 걸릴 수 있다.
아래 그림은 배치 크기가 클 수록 보다 부드럽게
손실값이 보다 부드럽게 특정 값에 수렴하는 것, 즉 모델이 보다 일관되게 학습되는 것을 보여준다.</p>
<div align="center"><img src="https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-05.png" style="width:550px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://github.com/ageron/handson-ml2">핸즈온 머신러닝(2판), 4장</a>&gt;</div></p><p><strong>둘째 경우: 보다 적절한 모델 사용</strong></p>
<p>훈련은 잘 진행되는데 검증셋에 대한 성능이 좋아지지 않는다면 다음 두 가지 경우를 의심해 보아야 한다.</p>
<ul class="simple">
<li><p>훈련셋이 적절한지 않은 경우</p>
<ul>
<li><p>예제: 라벨이 무작위로 섞인 MNIST 데이터셋</p></li>
</ul>
</li>
<li><p>사용하는 모델이 적절하지 않은 경우</p>
<ul>
<li><p>예제: 선형 분류가 불가능한 데이터셋에 선형분류 모델을 적용하는 경우</p></li>
<li><p>예제: 시계열 데이터 분석에 앞서 살펴본 <code class="docutils literal notranslate"><span class="pre">Sequential</span></code> 모델을 사용하는 경우</p></li>
</ul>
</li>
</ul>
<p>문제 해결에 적절한 모델을 훈련시켜야 한다.
앞으로 주어진 문제에 따른 다양한 모델 구성과 훈련방법을 살펴볼 것이다.</p>
<p><strong>셋째 경우: 모델의 정보 저장 능력 조정</strong></p>
<p>모델의 훈련셋/검증셋의 평가지표가 계속 향상되지만 과대적합이 발생하지 않는 경우
기본적으로 모델의 정보 저장 능력을 키워야 한다.
즉, 신경망 모델의 은닉층 또는 층에 사용되는 유닛의 수를 증가시켜서
모델이 보다 많은 정보를 처리하여 보다 적절한 방식으로 값을 변환할 수 있도록 한다.</p>
</section>
<section id="id14">
<h2><span class="section-number">5.5. </span>모델 일반화 성능 향상 기법<a class="headerlink" href="#id14" title="Permalink to this heading">#</a></h2>
<p>모델 훈련이 어느 정도 잘 진행되어 일반화 성능이 향상되고 과대적합이 발생하기 시작하면
모델의 일반화 성능을 극대화하는 방법에 집중한다.
일반적으로 다음 두 가지 사항이 모델의 일반화 성능에 도움된다.</p>
<ul class="simple">
<li><p>조기 종료</p></li>
<li><p>규제</p></li>
</ul>
<section id="id15">
<h3><span class="section-number">5.5.1. </span>조기 종료<a class="headerlink" href="#id15" title="Permalink to this heading">#</a></h3>
<p>모델 훈련 중에 훈련셋에 대한 성능은 계속 좋아지지만
검증셋에 대한 성능이 더 이상 좋아지지 않는 순간에 모델 훈련을 멈추는 것이
<strong>조기 종료</strong>(early stopping)이다.
이를 위해 에포크마다 모델의 검증셋에 대한 성능을 측정하여 가장 좋은 성능의 모델을 기억해 두고,
더 이상 좋아지지 않으면 그때까지 기록된 최적의 모델을
최종 모델로 사용한다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch05-early-stopping.png" style="width:600px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>케라스의 경우 <code class="docutils literal notranslate"><span class="pre">EarlyStopping</span></code> 이라는
<strong>콜백</strong><font size='2'>callback</font> 기능을 이용하여 조기 종료 기능을 간단하게 지정할 수 있다.
다양한 콜백 기능에 대해서는 <a class="reference internal" href="working_with_keras.html#ch-working-with-keras"><span class="std std-numref">7장</span></a> 자세히 다룬다.</p>
</section>
<section id="id16">
<h3><span class="section-number">5.5.2. </span>규제: 드롭아웃<a class="headerlink" href="#id16" title="Permalink to this heading">#</a></h3>
<p>모델이 훈련셋에 너무 익숙해지지 않도록 방해하는 것을
규제라 부른다.
모델 규제를 위해 <strong>드롭아웃</strong><font size='2'>drop out</font> 기법이 많이 적용된다.
드롭아웃은 무작위로 선택된 일정한 비율의 유닛을 끄는 것을 의미하며,
해당 유닛에 저장된 값을 0으로 처리한다.</p>
<p>아래 그림은 50%의 드롭아웃을 층의 출력값에 적용하는 과정을 보여준다.
출력값의 50%를 0으로 처리한 다음에 출력 텐서를 0.5로 나눈다.
즉 2를 곱해준다.
이유는 드롭아웃 기능은 훈련에만 적용하며 실전에서는 사용되지 않기에
출력값의 최종 크기를 훈련일 때와 아닐 때 비슷하게 만들어주기 위해서이다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/05-20.png" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>케라스에서는 드롭아웃 적용을 위해 적절한 드롭아웃 비율을 답은 드롭아웃 층 <code class="docutils literal notranslate"><span class="pre">Dropout</span></code>을 활용한다.
아래 그래프는 IMDB 영화 후기 분류 모델 대상으로 50%의 드롭아웃을 적용하여 훈련하면
검증셋에 대한 손실값이 보다 천천히 증가함을 보여준다.
즉, 모델의 과대적합이 보다 늦게, 보다 약하게 발생한다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/original_model_vs_dropout_regularized_model_imdb.png" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p></section>
</section>
<section id="id17">
<h2><span class="section-number">5.6. </span>연습문제<a class="headerlink" href="#id17" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://colab.research.google.com/github/codingalzi/dlp2/blob/master/excs/exc-fundamentals_of_ml.ipynb">(실습) 머신러닝 모델 훈련 기법</a></p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="getting_started_with_neural_networks.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">4. </span>신경망 활용 처음부터 끝까지: 분류와 회귀</p>
      </div>
    </a>
    <a class="right-next"
       href="unversal_workflow_of_ml.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6. </span>머신러닝 작업 흐름 일반</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">5.1. 최적화, 일반화, 과대적합</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">5.1.1. 머신러닝 모델 훈련의 핵심: 최적화대 일반화</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">5.1.2. 과대적합 대 과소적합</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">5.1.3. 과대적합 발생 주요 요인</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">5.2. 다양체 가설과 일반화</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">5.2.1. 다양체 가설</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">5.2.2. 보간법과 일반화</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">5.3. 모델 평가</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">5.3.1. 훈련셋, 검증셋, 테스트셋</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">5.3.2. 검증셋 활용법</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">5.3.3. 모델 성능 평가의 기준선</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">5.4. 모델 훈련 최적화</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">5.5. 모델 일반화 성능 향상 기법</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">5.5.1. 조기 종료</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">5.5.2. 규제: 드롭아웃</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">5.6. 연습문제</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By 코딩알지
</p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=c5ced968eda925caa686"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=c5ced968eda925caa686"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>