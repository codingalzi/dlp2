{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(ch:keras-tf)=\n",
    "# 케라스와 텐서플로우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**감사의 글**\n",
    "\n",
    "아래 내용은 프랑소와 숄레의 \n",
    "[Deep Learning with Python(2판)](https://github.com/fchollet/deep-learning-with-python-notebooks)의 \n",
    "소스코드 내용을 참고해서 작성되었습니다.\n",
    "자료를 공개한 저자에게 진심어린 감사를 전합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스코드**\n",
    "\n",
    "여기서 언급되는 코드를\n",
    "[(구글 코랩) 케라스와 텐서플로우](https://colab.research.google.com/github/codingalzi/dlp2/blob/master/notebooks/NB-keras_and_tf.ipynb)에서 \n",
    "직접 실행할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**주요 내용**\n",
    "\n",
    "케라스와 텐서플로우를 이용한 딥러닝의 활용법을 소개한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 텐서플로우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "텐서플로우는 파이썬 기본 머신러닝 플랫폼이며,\n",
    "머신러닝 모델의 훈련에 필요한 텐서 연산을 지원한다.\n",
    "넘파이<font size='2'>Numpy</font> 패키지와 유사하지만 보다 많은 기능을 제공한다. \n",
    "\n",
    "- 그레이디언트 자동 계산\n",
    "- GPU, TPU 등 고성능 병렬 하드웨어 가속기 활용 가능\n",
    "- 여러 대의 컴퓨터 또는 클라우드 컴퓨팅 서비스 활용 가능\n",
    "- C++(게임), 자바스크립트(웹브라우저), TFLite(모바일 장치) 등 다른 언어가 선호되는\n",
    "    영역에서의 도메인 특화 프로그램과 호환 가능\n",
    "\n",
    "텐서플로우는 또한 단순한 패키지 기능을 넘어서는 머신러닝 플랫폼 역할도 수행한다.\n",
    "\n",
    "- TF-Agents: 강화학습 연구 지원\n",
    "- TFX: 머신러닝 프로젝트 운영 지원\n",
    "- TensorFlow-Hub: 사전 훈련된 머신러닝 모델 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 케라스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "딥러닝 모델 구성 및 훈련에 효율적으로 사용될 수 있는 다양한 수준의 API를 제공하며,\n",
    "텐서플로우의 프론트엔드<font size='2'>front end</font> 인터페이스 기능을 수행한다.\n",
    "원래 텐서플로우와 독립적으로 개발되었지만 텐서플로우 2.0부터 텐서플로우 라이브러리의 최상위 프레임워크<font size='2'>framework</font>로 포함됐다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/keras_and_tf.png\" style=\"width:600px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 모듈, 패키지, 라이브러리, 프레임워크\n",
    ":class: note\n",
    "\n",
    "한 번 구현한 파이썬 코드를 다른 파이썬 파일의 코드에서 공유해서 사용할 수 있도록 하기 위해 모듈<font size='2'>module</font>을 활용한다. \n",
    "파이썬 모듈은 간단하게 말하면 하나의 파이썬 소스코드 파일이며, 확장자로 .py 가 사용된다. 모듈에는 보통 서로 연관된 함수와 클래스 등을 저장한다.\n",
    "하나의 모듈이 독립적으로 제공되기도 하지만 다른 모듈과 함께 하나의 모음집으로 제공되기도 한다. \n",
    "모음집의 크기와 용도에 따라 패키지, 라이브러리, 프레임워크 등 다양한 이름으로 불린다.\n",
    "\n",
    "- 패키지<font size='2'>package</font>: 모듈을 모아놓은 디렉토리(폴더)\n",
    "- 라이브러리<font size='2'>library</font>: 모듈, 패키지 등 재사용이 가능한 코드의 모음집을 통칭헤서 부르는 이름\n",
    "- 프레임워크<font size='2'>framework</font>: 라이브러리 보다 포괄적인 개념. \n",
    "    라이브러리가 도구 모음집만 제공하는 반면에 프레임워크는 라이브러리와 함께 라이브러리를 쉽게 적용할 수 있는 \n",
    "    틀<font size='2'>frame</font>과 아키텍처<font size='2'>architecture</font> 함께 제공\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 딥러닝 주요 라이브러리 약력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 2007년: 씨아노<font size='2'>Theano</font> 공개. \n",
    "    텐서를 이용한 계산 그래프, 미분 자동화 등을 최초로 지원한 딥러닝 라이브러리.\n",
    "- 2015년 3월: 케라스 라이브러리 공개. Theano를 백앤드로 사용하는 고수준 패키지.\n",
    "- 2015년 11월: 텐서플로우 라이브러리 공개.\n",
    "- 2016년: 텐서플로우가 케라스의 기본 백엔드로 지정됨.\n",
    "- 2016년 9월: 페이스북이 개발한 파이토치<font size='2'>PyTorch</font> 공개.\n",
    "- 2017년: Theano, 텐서플로우, CNTK(마이크로소프트), MXNet(아마존)이 케라스의 백엔드로 지원됨.\n",
    "    현재 Theano, CNTK 등은 더 이상 개발되지 않으며, MXNet은 아마존에서만 주로 사용됨.\n",
    "- 2018년 3월: PyTorch와 Caffe2를 합친 PyTorch 출시(페이스북과 마이크로소프트의 협업)\n",
    "- 2019년 9월: 텐서플로우 2.0부터 케라스가 텐서플로우의 최상위 프레임워크로 지정됨.\n",
    "- 2023년 가을: Keras Core가 케라스 3.0으로 출시 예정. 텐서플로우, PyTorch, JAX의 프론트엔드 기능 지원."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Keras Core\n",
    ":class: note\n",
    "\n",
    "파이토치 또한 텐서 연산을 지원하는 딥러닝 라이브러리이다.\n",
    "텐서플로우와 케라스의 조합이 강력하지만 신경망의 보다 섬세한 조정은 약하다는 지적을 많이 받는 반면에\n",
    "파이토치는 상대적으로 보다 자유롭게 신경망을 구성할 수 있다고 평가된다.\n",
    "텐서플로우와 케라스의 조합이 여전히 보다 많이 사용되지만 딥러닝 연구에서 파이토치의 활용 또한 점점 늘고 있다.\n",
    "선호도에 대한 논쟁이 지난 몇 년간 있어 왔지만 곧 종식될 것으로 기대된다.\n",
    "이유는 케라스 3.0부터 텐서플로우뿐만 아니라 파이토치도 케라스의 지원을 받을 예정이기 때문이다.\n",
    "\n",
    "<div align=\"center\"><img src=\"https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch03-keras-core.png?raw=true\" style=\"width:500px;\"></div>\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 딥러닝 개발환경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "딥러닝 신경망 모델의 훈련을 위해서 GPU를 활용할 것을 강력히 추천한다.\n",
    "GPU를 사용하지 않으면 모델의 훈련이 너무 느려진다.\n",
    "[구글 코랩](https://colab.research.google.com/?hl=ko)을 이용하면\n",
    "특별한 준비 없이 바로 신경망 모델을 GPU와 함께 훈련시킬 수 있다.\n",
    "구글 코랩은 주피터 노트북을 사용하는데, 주피터 노트북 사용법과\n",
    "구글 코랩에서 GPU를 이용하는 방법은 검색을 통해 쉽게 확인할 수 있다.\n",
    "\n",
    "하지만 딥러닝 모델 훈련을 많이 시키려면 NVIDIA 그래픽카드가 장착된 \n",
    "개인용 컴퓨터를 활용하는 것이 좋다.\n",
    "운영체제는 [Ubuntu](https://ubuntu.com/download/desktop) 또는 윈도우 10 이상, 가능하면 윈도우 11을 추천한다.\n",
    "\n",
    "- 윈도우 10/11에서 GPU를 지원 텐서플로우 설치: [conda를 활용한 gpu 지원 tensorflow 설치 요령](https://github.com/codingalzi/dlp2) 참고\n",
    "\n",
    "- 우분투에서 GPU 지원하는 텐서플로우 설치: [Anaconda와 conda 환경 활용](https://github.com/ageron/handson-ml3/blob/main/INSTALL.md) 참고\n",
    "\n",
    "보다 전문적인 딥러닝 연구를 위해 대용량의 메모리와 고성능의 CPU, GPU가 필요한 경우\n",
    "[구글 클라우드 플랫폼](https://cloud.google.com/) 또는 \n",
    "[아마존 웹서비스(AWS EC2)](https://aws.amazon.com/ko/?nc2=h_lg) 등에서\n",
    "고성능 클라우드 컴퓨팅 서비스를 활용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 케라스 신경망 모델의 핵심 API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "신경망 모델은 층<font size='2'>layer</font>으로 구성된다.\n",
    "모델에 사용되는 층의 종류와 층을 쌓는 방식에 따라\n",
    "모델이 처리할 수 있는 데이터와 훈련 방식이 달라진다.\n",
    "모델과 훈련 방식이 정해지면 이후에 훈련을 어떻게 진행할 것인가를 정해야 한다.\n",
    "이또한 많은 선택이 필요하지만 케라스가\n",
    "쉽고 간단하게 활용할 수 있는 다양한 API를 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**층의 기능**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "층은 입력 데이터를 지정된 방식에 따라 다른 모양의 데이터로 변환하는 포워드 패스 기능을 담당하는 함수다.\n",
    "또한 데이터 변환에 사용되는 가중치<font size='2'>weight</font>와 편향<font size='2'>bias</font>을\n",
    "저장하는 부수효과 기능도 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**층의 종류**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "층은 사용되는 클래스에 따라 다양한 형식의 텐서를 취급한다.\n",
    "\n",
    "- `Dense` 클래스: 밀집층(dense layer)이며, `(샘플 수, 특성 수)` 모양의 2D 텐서 데이터셋 처리.\n",
    "- `LSTM` 또는 `Conv1D` 클래스: 순차 데이터 및 시계열 데이터 분석에 사용되는 순환층이며,\n",
    "    `(샘플 수, 타임스텝 수, 특성 수)` 모양의 3D 텐서로 제공된 순차 데이터셋 처리.\n",
    "- `Conv2D` 클래스: `(샘플 수, 가로, 세로, 채널 수)` 모양의 4D 텐서로 제공된 이미지 데이터셋 처리.\n",
    "    \n",
    "케라스를 활용하여 딥러닝 모델을 구성하는 것은 호환 가능한 층들을 적절하게 연결하여 층을 쌓는 것을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`tf.keras.layers.Layer` 클래스**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스에서 사용되는 모든 층 클래스는 `tf.keras.layers.Layer` 클래스를 상속하며,\n",
    "이를 통해 상속받는 `__call__()` 메서드가 \n",
    "가중치와 편향 텐서를 생성 및 초기화 하고 입력 데이터를 출력 데이터로 변환하는 \n",
    "포워드 패스를 수행한다.\n",
    "단, 가중치와 편향이 이미 생성되어 있다면 새로 생성하지 않고 그대로 사용한다. \n",
    "`tf.keras.layers.Layer` 클래스에서 선언된 `__call__()` 메서드가 하는 일을 간략하게 나타내면 다음과 같다. \n",
    "\n",
    "```python\n",
    "def __call__(self, inputs):\n",
    "    if not self.built:\n",
    "        self.build(inputs.shape)\n",
    "        self.built = True\n",
    "return self.call(inputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드에 사용된 인스턴스 변수와 메서드는 다음과 같다. \n",
    "\n",
    "- `self.build(inputs_shape)`: 입력 배치 데이터셋의 모양 정보를 이용하여 \n",
    "    적절한 모양의 가중치 텐서와 편향 텐서를 생성하고 초기화한다.\n",
    "    - 가중치 텐서 초기화: 무작위적(`random_normal`)\n",
    "    - 편향 텐서 초기화: 0 벡터(`zeros`)\n",
    "- `self.built`: 가중치와 편향이 준비돼 있는지 여부 기억\n",
    "- `self.call(inputs)`: 아핀 변환과 활성화 함수를 이용한 포워드 패스,\n",
    "    입력 데이터셋을 변환하여, 출력 텐서를 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Dense` 클래스 직접 구현하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{numref}`%s절 <sec:nn-mnist>`에서 MNIST 데이터셋을 이용한 분류 모델에 사용된\n",
    "신경망 모델은 `Dense` 클래스 두 개를 연속으로 쌓아 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dense` 클래스와 유사하게 작동하는 클래스를 직접 정의하려면 \n",
    "상속해야 하는 `keras.layers.Layer` 클래스의 `__call()__` 메서드에 의해 호출되는\n",
    "`build()` 메서드와 `call()` 메서드를 구현해야 한다.\n",
    "아래 `SimpleDense` 클래스가 `Dense` 클래스의 기능을 단순화하여 구현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "from tensorflow import keras\n",
    "\n",
    "class SimpleDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]   # 입력 샘플의 특성 수\n",
    "        self.W = self.add_weight(shape=(input_dim, self.units),\n",
    "                                 initializer=\"random_normal\")\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer=\"zeros\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y = tf.matmul(inputs, self.W) + self.b\n",
    "        if self.activation is not None:\n",
    "            y = self.activation(y)\n",
    "        return y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 메서드의 정의에 사용된 매개변수와 메서드는 다음과 같다.\n",
    "\n",
    "- `units`: 출력 샘플의 특성 수 지정\n",
    "- `activation`: 활성화 함수 지정\n",
    "- `input_shape`: 입력값(`inputs`)으로 얻은 입력 배치의 2D 모양 정보. 둘째 항목이 입력 샘플의 특성 수.\n",
    "- `add_weight(모양, 초기화방법)`: 지정된 모양의 텐서 생성 및 초기화. `Layer` 클래스에서 상속."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{prf:example} `SimpleDense` 층 활용법\n",
    ":label: simpledense\n",
    "\n",
    "아래 코드는 `SimpleDense` 층을 하나 생성한다.\n",
    "층은 입렵값을 처리할 때 입력값의 모양을 확인하기 때문에 \n",
    "입력 데이터에 대한 정보를 미리 요구하지 않는다.\n",
    "\n",
    "```python\n",
    ">>> my_dense = SimpleDense(units=32, activation=tf.nn.relu)\n",
    "```\n",
    "\n",
    "784 개의 특성을 갖는 2 개의 샘플로 구성된 데이터셋을 입력값으로 지정한다.\n",
    "\n",
    "```python\n",
    ">>> input_tensor = tf.ones(shape=(2, 784))\n",
    "```\n",
    "\n",
    "`my_dense`를 함수 호출하듯이 사용하면 출력값이 계산된다.\n",
    "\n",
    "```python\n",
    ">>> output_tensor = my_dense(input_tensor)\n",
    "```\n",
    "\n",
    "내부적으로는 `__call__()` 메서드가 호출되어 다음 사항들이 연속적으로 처리된다. \n",
    "\n",
    "- `(784, 32)` 모양의 가중치 텐서 `W` 생성 및 무작위 초기화\n",
    "- `(32, )` 모양의 편향 텐서 `b` 생성 및 `0`으로 초기화.\n",
    "- 포워드 패스: 생성된 가중치와 편향을 이용하여 출력값 계산\n",
    "\n",
    "층의 출력값은 `(2, 32)` 모양의 텐서다.\n",
    "이유는 784개의 특성이 32개의 특성으로 변환되었기 때문이다.\n",
    "\n",
    "```python\n",
    ">>> print(output_tensor.shape)\n",
    "(2, 32)\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모델은 층으로 구성된다.\n",
    "앞서 살펴 본 `Sequential` 모델은 층을 일렬로 쌓은 모델이며\n",
    "각각의 층은 아래 층에서 전달한 값을 받아 변환해서 다음 층으로 전달한다.\n",
    "\n",
    "앞으로 보다 복잡하고 다양한 방식으로 층을 구성하는 방식들을 살펴볼 것이다.\n",
    "예를 들어, 아래 그림은 {numref}`%s장 자연어 처리 <ch:nlp>`에서 소개하는\n",
    "트랜스포머<font size='2'>Transformer</font> 모델의 복잡한 층 구조를 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/transformer0001.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.keras.Model` 클래스**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스에서 사용되는 모든 층 클래스는 `tf.keras.Model` 클래스를 상속한다.\n",
    "예를 들어 앞서 {numref}`%s장 <ch:building_blocks>`에서 MNist 데이터셋 분류를 위해 사용된 모델은 다음과 같다.\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 모델을 앞서 정의한 `SimpleDense` 층을 이용하여 직접 다음과 같이 정의할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class MyMNistModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = SimpleDense(units=512, activation=tf.nn.relu)\n",
    "        self.layer_2 = SimpleDense(units=10, activation=tf.nn.softmax)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.layer_1(inputs)\n",
    "        outputs = self.layer_2(features)\n",
    "        return outputs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keras.layers.Dense` 층을 이용한다면 다음과 같이 활성화 함수를 문자열로 지정할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class MyMNistModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = keras.layers.Dense(units=512, activation=\"relu\")\n",
    "        self.layer_2 = keras.layers.Dense(units=10, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.layer_1(inputs)\n",
    "        outputs = self.layer_2(features)\n",
    "        return outputs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞으로 다양한 종류의 모델을 다룰 때 알게 되겠지만 기존에 정의된 모델을\n",
    "새로운 모델을 선언할 때 하나의 층으로 활용할 수도 있다.\n",
    "이런 이유로 `tf.keras.Model` 클래스는 `tf.keras.layers.Layer` 클래스를 \n",
    "상속하도록 설계되었다.\n",
    "`tf.keras.Model` 클래스의 활용법에 대한 보다 자세한 설명은 {numref}`%s장 <ch:working_with_keras>`을 참고한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**층의 구성과 모델의 학습과정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 학습과정은 층을 어떻게 구성하였는가에 전적으로 의존한다. \n",
    "앞서 살펴 보았듯이 각각의 층에서 이루어지는 일은 기본적으로 \n",
    "**아핀 변환**과 **활성화 함수 적용**이다. \n",
    "여러 개의 `Dense` 층을 `Sequential` 모델을 이용하여 층을 구성하면 \n",
    "아핀 변환, `relu()` 등의 활성화 함수를 연속적으로 적용하여\n",
    "입력 텐서를 특정 모양의 텐서로 변환한다.\n",
    "반면에 여러 개의 층을 다른 방식으로 구성한 모델은 다른 방식으로 텐서를\n",
    "하나의 표현에서 다른 표현으로 변환한다.\n",
    "\n",
    "일반적으로 딥러닝 신경망의 구성은 주어진 데이터셋과 모델의 목적에 따라 결정된다.\n",
    "특별히 따라야 하는 정해진 규칙은 없지만 문제의 특성에 따라 권장되는 모델 형식이\n",
    "많이 개발되었으며, 이론 보다는 많은 실습을 통한 경험에 의존한다.\n",
    "앞으로 많은 예제를 통해 다양한 모델을 구성하는 방식을 배울 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**모델 컴파일**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선언된 모델을 훈련시키려면 다음 세 가지 설정을 추가로 지정해야 한다.\n",
    "\n",
    "- 손실 함수: 훈련 중 모델의 성능이 얼마나 나쁜지 측정.\n",
    "    미분가능한 함수이어야 하며 옵티마이저가 역전파를 통해\n",
    "    모델의 성능을 향상시키는 방향으로 모델의 가중치를 업데이트할 때 \n",
    "    참고하는 함수임.\n",
    "- 옵티마이저: 백워드 패스와 역전파를 담당하는 알고리즘\n",
    "- 평가지표: 훈련과 테스트 과정을 모니터링 할 때 사용되는 모델 평가 지표.\n",
    "    옵티마이저와 손실함수와는 달리 훈련에 관여하지 않으면서\n",
    "    모델 성능 평가에 사용됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "아래 코드는 옵티마이저, 손실 함수, 평가지표를 문자열로 지정한다.\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([keras.layers.Dense(1)])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"mean_squared_error\",\n",
    "              metrics=[\"accuracy\"])\n",
    "```\n",
    "\n",
    "각각의 문자열은 특정 파이썬 객체를 가리킨다.\n",
    "\n",
    "| 문자열 | 파이썬 객체 |\n",
    "| :--- | :--- |\n",
    "| `\"rmsprop\"` | `keras.optimizers.RMSprop()` |\n",
    "| `\"mean_squared_error\"` | `keras.losses.MeanSquaredError()` |\n",
    "| `\"accuracy\"` | `keras.metrics.BinaryAccuracy()]` |\n",
    "\n",
    "따라서 지정된 문자열을 사용하는 대신 파이썬 객체를 직접 지정해도 된다.\n",
    "만약 사용자가 직접 구현한 클래스의 객체를 이용하려면\n",
    "앞서 `SimpleDense`를 통해 본 것처럼 적절한 기능을 모두 갖추고 있어야만 한다.\n",
    "\n",
    "```python\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.MeanSquaredError(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy()])\n",
    "```\n",
    "\n",
    "옵티마이저 설정에 기본값과 다른 학습률(`learning_rate`)을 지정하는 경우 또는\n",
    "사용자가 직접 정의한 객체를 사용하려는 경우엔 문자열 대신 직접 파이썬 객체를 지정하는 \n",
    "방식을 사용해야 한다.\n",
    "\n",
    "```python\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              loss=사용자정의손실함수객체,\n",
    "              metrics=[사용자정의평가지표_1, 사용자정의평가지표_2])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 가장 많이 사용되는 옵티마이저, 손실함수, 평가지표는 다음과 같으며\n",
    "앞으로 다양한 예제를 통해 옵티마이저, 손실함수, 평가지표를 적절하게 선택하는 방법을 살펴볼 것이다.\n",
    "\n",
    "옵티마이저:\n",
    "\n",
    "- SGD (with or without momentum)\n",
    "- RMSprop\n",
    "- Adam\n",
    "- Adagrad\n",
    "\n",
    "손실 함수:\n",
    "\n",
    "- CategoricalCrossentropy\n",
    "- SparseCategoricalCrossentropy\n",
    "- BinaryCrossentropy\n",
    "- MeanSquaredError\n",
    "- KLDivergence\n",
    "- CosineSimilarity\n",
    "\n",
    "평가지표:\n",
    "\n",
    "- CategoricalAccuracy\n",
    "- SparseCategoricalAccuracy\n",
    "- BinaryAccuracy\n",
    "- AUC\n",
    "- Precision\n",
    "- Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 루프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 컴파일한 다음에 `fit()` 메서드를 호출하면\n",
    "모델은 스텝과 에포크 단위로 반복되는 **훈련 루프**<font size='2'>training loop</font>를\n",
    "지정된 횟수만큼 또는 학습이 충분히 이루어졌다는 평가가 내려질 때까지\n",
    "반복하는 훈련을 시작한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**모델 훈련**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "모델을 훈련시키려면 `fit()` 메서드를 적절한 인자들과 함께 호출해야 한다.\n",
    "\n",
    "- 훈련셋과 타깃셋: 보통 넘파이 어레이 또는 텐서플로우의 `Dataset` 객체 사용\n",
    "- 에포크(`epochs`): 전체 훈련 세트를 몇 번 훈련할 지 지정\n",
    "- 배치 크기(`batch_size`): 배치 경사하강법에 적용될 배치(묶음) 크기 지정\n",
    "\n",
    "아래 코드는 앞서 넘파이 어레이로 생성한 (2000, 2) 모양의 양성, 음성 데이터셋을 대상으로 훈련한다. \n",
    "\n",
    "```python\n",
    "training_history = model.fit(\n",
    "    inputs,\n",
    "    targets,\n",
    "    epochs=5,\n",
    "    batch_size=128\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**훈련 결과**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 훈련 결과로 `History` 객체가 반환된다.\n",
    "예를 들어 `History` 객체의 `history` 속성은 에포크별로 계산된 손실값과 평가지표값을\n",
    "사전 자료형으로 가리킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> training_history.history\n",
    "{'loss': [9.07500171661377,\n",
    "  8.722702980041504,\n",
    "  8.423994064331055,\n",
    "  8.137178421020508,\n",
    "  7.8575215339660645],\n",
    " 'binary_accuracy': [0.07800000160932541,\n",
    "  0.07999999821186066,\n",
    "  0.08049999922513962,\n",
    "  0.08449999988079071,\n",
    "  0.0860000029206276]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**검증 데이터 활용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "머신러닝 모델 훈련의 목표는 훈련셋에 대한 높은 성능이 아니라\n",
    "훈련에서 보지 못한 새로운 데이터에 대한 정확한 예측이다.\n",
    "훈련 중에 또는 훈련이 끝난 후에 모델이 새로운 데이터에 대해 정확한 예측을 하는지\n",
    "여부를 판단하도록 할 수 있다.\n",
    "\n",
    "이를 위해 전체 데이터셋을 훈련셋과 검증셋<font size='2'>validation dataset</font>으로 구분한다.\n",
    "훈련셋과 검증셋의 비율은 보통 8대2 또는 7대3 정도로 하지만\n",
    "훈련셋이 매우 크다면 검증셋의 비율을 보다 적게 잡을 수 있다.\n",
    "훈련셋 자체가 매우 작은 경우엔 검증셋을 따로 분리하기 보다는 K-겹 교차 검증 등을 사용해야 한다.\n",
    "\n",
    "훈련셋과 검증셋이 서로 겹치지 않도록 주의해야 한다.\n",
    "그렇지 않으면 훈련 중에 모델이 검증셋에 포함된 데이터를 학습하기에\n",
    "정확환 모델 평가를 할 수 없게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*훈련 중 모델 검증*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "아래 코드는 미리 지정된 검증셋 `val_inputs`와 검증 타깃값 `val_targets`를\n",
    "`validation_data`의 키워드 인자로 지정해서\n",
    "모델 훈련 중에 에포크 단위로 측정하도록 한다.\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    training_inputs,\n",
    "    training_targets,\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    validation_data=(val_inputs, val_targets)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*훈련 후 모델 검증*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "훈련이 끝난 모델의 성능 검증하려면 `evaluate()` 메서드를 이용한다.\n",
    "배치 크기(`batch_size`)를 지정하여 배치 단위로 학습하도록 한다.\n",
    "\n",
    "```python\n",
    ">>> loss_and_metrics = model.evaluate(val_inputs, val_targets, batch_size=128)\n",
    "```\n",
    "\n",
    "반환값으로 지정된 손실값과 평가지표를 담은 리스트가 생성된다.\n",
    "\n",
    "```python\n",
    ">>> print(loss_and_metrics)\n",
    "[0.29411643743515015, 0.5333333611488342]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 훈련과 검증이 완료되면 실전에서 새로운 데이터에 대한 예측을 진행한다.\n",
    "데이터셋에 포함된 모든 데이터에 대한 예측을 한 번에 실행할 수 있으며\n",
    "두 가지 방식이 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**모델 적용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 마치 함수처럼 이용한다. \n",
    "\n",
    "```python\n",
    "predictions = model(new_inputs)\n",
    "```\n",
    "\n",
    "내부적으론 앞서 설명한 `__call()__` 메서드가 실행된다.\n",
    "따라서 `call()` 메서드를 사용하는 포워드 패스가 실행되어\n",
    "예측값이 계산된다.\n",
    "\n",
    "하지만 이 방식은 입력 데이터셋 전체를 대상으로 한 번에 계산하기에\n",
    "데이터셋이 너무 크면 계산이 너무 오래 걸리거나 메모리가 부족해질 수 있다.\n",
    "따라서 배치를 활용하는 `predict()` 메서드를 활용할 것을 추천한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 모델 함수와 포워드 패스\n",
    ":class: tip\n",
    "\n",
    "모델을 함수처럼 이용하는 방식은 포워드 패스와 관련해서 종종 사용된다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`predict()` 메서드**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련된 모델의 `predict()` 메서드는 배치 크기를 지정하면\n",
    "배치 단위로 예측값을 계산한다.\n",
    "\n",
    "```python\n",
    "predictions = model.predict(new_inputs, batch_size=128)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 손글씨 데이터 분류 모델의 훈련에 사용된 훈련셋과 테스트셋은\n",
    "넘파이 어레이, 즉 `numpy.ndarray`(이하 `np.ndarray`) 자료형으로 저장된다.\n",
    "머신러닝에 사용되는 데이터셋은 일반적으로 넘파이 어레이와 같은 \n",
    "**텐서**<font size='2'>tensor</font>에 저장된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서<font size='2'>tensor</font>는 데이터를 담은 모음 자료형을 가리키며\n",
    "넘파이 어레이가 대표적인 텐서이다. \n",
    "텐서플로우 라이브러리는 자체의 `Tensor` 자료형인 `tensorflow.Tensor`(이하 `tf.Tensor`)를 제공한다.\n",
    "`tf.Tensor`는 넘파이 어레이와 매우 유사하지만 GPU를 활용한 연산을 지원한다는 점에서 넘파이 어레이와 다르다.\n",
    "\n",
    "앞서 신경망 모델을 구성할 때처럼 \n",
    "여기서는 텐서플로우의 케라스 패키지인 `tensorflow.keras`를 기본 패키지로 사용하는데\n",
    "케라스 신경망 모델의 입력, 출력값으로 넘파이 어레이를 기본으로 사용한다.\n",
    "따라서 특별한 경우가 아니라면 넘파이 어레이를 데이터셋을 다룰 때 사용하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서의 차원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서의 **차원**은 텐서의 표현에 사용된 **축**<font size='2'>axis</font>의 수로 \n",
    "결정되며 **랭크**<font size='2'>rank</font>라 불리기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0차원(0D) 텐서 (랭크-0 텐서)\n",
    "    - 정수 한 개, 부동소수점 한 개 등 하나의 수를 표현하는 텐서. \n",
    "    - **스칼라**<font size='2'>scalar</font>라고도 불림.\n",
    "        ```\n",
    "        np.array(12)\n",
    "        np.array(1.34)\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1차원(1D) 텐서 (랭크-1 텐서)\n",
    "    - 수로 이루어진 리스트 형식의 텐서. \n",
    "    - **벡터**<font size='2'>vector</font>로 불리며 한 개의 축을 가짐.\n",
    "        ```\n",
    "        np.array([12, 3, 6, 14, 7])\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2차원(2D) 텐서 (랭크-2 텐서)\n",
    "    - 행<font size='2'>row</font>과 열<font size='2'>column</font> 두 개의 축을 가짐. \n",
    "    - **행렬**<font size='2'>matrix</font>로도 불림.\n",
    "        ```\n",
    "        np.array([[5, 78, 2, 34, 0],\n",
    "                [6, 79, 3, 35, 1],\n",
    "                [7, 80, 4, 36, 2]])\n",
    "        ```\n",
    "    - 흑백 사진 데이터를 2D 텐서로 표현 가능. 아래 그림 참고.\n",
    "        <br>\n",
    "        <div align=\"center\"><img src=\"https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch02-mnist05.png?raw=true\" style=\"width:600px;\"></div>\n",
    "\n",
    "        <p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://towardsdatascience.com/exploring-how-neural-networks-work-and-making-them-interactive-ed67adbf9283\">Towards data science: Mikkel Duif(2019)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3차원(3D) 텐서 (랭크-3 텐서)\n",
    "    - 행, 열, 깊이 세 개의 축 사용.\n",
    "    - 동일 모양의 2D 텐서로 구성된 벡터로 이해 가능. \n",
    "        예를 들어 흑백 사진 샘프로 구성된 데이터셋이 3D 텐서로 표현됨.\n",
    "        ```\n",
    "        np.array([[[5, 78, 2, 34, 0],\n",
    "                    [6, 79, 3, 35, 1],\n",
    "                    [7, 80, 4, 36, 2]],\n",
    "                    [[5, 78, 2, 34, 0],\n",
    "                    [6, 79, 3, 35, 1],\n",
    "                    [7, 80, 4, 36, 2]],\n",
    "                    [[5, 78, 2, 34, 0],\n",
    "                    [6, 79, 3, 35, 1],\n",
    "                    [7, 80, 4, 36, 2]]])\n",
    "        ```\n",
    "    - 또는 동일한 길이의 벡터를 항목으로 사용하는 2D 텐서로 이해 가능.\n",
    "        예를 들어, RGB로 구성된 사진 데이터가 3D 텐서로 표현됨. 아래 그림 참고. \n",
    "        <br>\n",
    "        <div align=\"center\"><img src=\"https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch02-rgb-3d-1.png?raw=true\" style=\"width:600px;\"></div>\n",
    "        <div align=\"center\"><img src=\"https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch02-rgb-3d-2.png?raw=true\" style=\"width:600px;\"></div>\n",
    "\n",
    "        <p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://dev.to/sandeepbalachandran/machine-learning-going-furthur-with-cnn-part-2-41km\">Machine Learning - Going Furthur with CNN Part 2</a>&gt;</div></p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4D 텐서 (랭크-4 텐서)\n",
    "    - 3D 텐서로 이루어진 벡터\n",
    "    - 예를 들어 컬러 사진 데이터로 구성된 훈련셋, 연속된 사진으로 처리될 수 있는 한 편의 동영상 등이 4D 텐서로 표현됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5D 텐서 (랭크-5 텐서)\n",
    "    - 4D 텐서로 이루어진 벡터\n",
    "    - 예를 들어 동영상 데이터로 구성된 훈련셋 등이 5D 텐서로 표현됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6D 텐서는 5D 텐서로 이루어진 벡터, 7D 텐서는 6D 텐서로 구성된 벡터 등으로 임의의 차원의 텐서를 정의할 수 있지만\n",
    "일반적이지는 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 벡터의 차원\n",
    ":class: caution\n",
    "\n",
    "**벡터의 길이**를 **차원**이라 부르기도 한다.\n",
    "예를 들어, `np.array([12, 3, 6, 14, 7])`는 5차원 벡터다.\n",
    "따라서 벡터의 차원인지, 텐서의 차원인지 명확히 구분할 필요가 있다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 주요 속성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서의 주요 속성 세 가지는 다음과 같으며, 넘파이 어레이의 경우와 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ndim` 속성: 텐서의 차원 저장. \n",
    "    예를 들어 MNIST 훈련셋 어레이의 차원은 3.\n",
    "    ```python\n",
    "    >>> train_images.ndim \n",
    "    3\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `shape` 속성: 텐서의 모양을 튜플로 저장. \n",
    "    각 항목은 축(axis)별로 사용되는 벡터의 크기를 가리킴.\n",
    "    예를 들어 MNIST의 훈련셋은 3개의 축으로 구성됨.\n",
    "    0번 축은 6만개의 샘플 데이터를,\n",
    "    1번 축은 각 사진에 사용된 28개의 세로 픽셀 데이터를,\n",
    "    2번 축은 각 사진에 사용된 28개의 가로 픽셀 데이터를 가리킴.\n",
    "    ```python\n",
    "    >>> train_images.shape\n",
    "    (60000, 28, 28)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dtype` 속성: 텐서에 포함된 항목의 통일된 자료형.\n",
    "    `float16`, `float32`,`float64`, `int8`, `uint8`, `string` 등이 \n",
    "    가장 많이 사용됨.\n",
    "    예를 들어, MNIST 훈련셋에 포함된 사진의 픽셀 정보는 0과 255 사이의\n",
    "    정수로 표현되며 따라서 `unit8` 자료형을 사용함.\n",
    "    ```python\n",
    "    >>> train_images.dtype\n",
    "    uint8\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋의 차원과 모양 정보와 인덱싱, 슬라이싱 기능을 이용하여\n",
    "샘플을 확인하고 배치를 생성하는 일 등을 처리할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**인덱싱**\n",
    "\n",
    "예를 들어, 훈련셋에 포함된 4번 인덱스의 사진, 즉 훈련셋의 5번째 사진을 다음처럼 선택하여 확인할 수 있다.\n",
    "```python\n",
    ">>> import matplotlib.pyplot as plt\n",
    ">>> digit = train_images[4]\n",
    ">>> plt.imshow(digit, cmap=plt.cm.binary)\n",
    ">>> plt.show()\n",
    "```\n",
    "\n",
    "<img src=\"https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch02-mnist4.png?raw=true\" style=\"width:250px;\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 사진은 숫자 9를 가리키는 것으로 보인다.\n",
    "실제 해당 샘플의 라벨이 9로 확인된다.\n",
    "\n",
    "```python\n",
    ">>> train_labels[4] \n",
    "9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**슬라이싱**\n",
    "\n",
    "케라스를 포함하여 대부분의 딥러닝 모델은 훈련 세트 전체를 한꺼번에 처리하지 않고\n",
    "지정된 크기(`batch_size`)의 배치를 이용하여 스텝 단위로 훈련한다.\n",
    "앞서 살펴본 모델의 배치 크기는 128이었다.\n",
    "크기가 128인 첫째 배치는 다음과 같이 지정한다.\n",
    "\n",
    "```python\n",
    ">>> batch = train_images[:128]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 둘째 배치를 지정한다.\n",
    "\n",
    "```python\n",
    ">>> batch = train_images[128: 256]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋의 `n`번째 배치는 다음과 같이 지정할 수 있다.\n",
    "\n",
    "```python\n",
    ">>> batch = train_images[128 * n:128 * (n + 1)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 실전 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) 2D 텐서 실전 예제**\n",
    "\n",
    "각각의 샘플이 지정된 개수의 특성으로 구성된 벡터로 표현된다.\n",
    "전체 데이터셋은 `(샘플 수, 특성 수)` 모양의 2D 텐서로 표현된다.\n",
    "\n",
    "- 예제 1: [캘리포니아 구역별 인구조사 데이터셋](https://codingalzi.github.io/handson-ml3/end2end_ml_project.html)\n",
    "    - 샘플: 10개의 특성 사용. 따라서 `(10,)` 모양의 벡터로 표현됨.\n",
    "    - 데이터셋: 20,640개의 구역별 데이터 포함. 따라서 `(20640, 10)` 모양의 2D 텐서로 표현 가능.\n",
    "        <br>\n",
    "        <img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch02/housing-data.png\" style=\"width:600px;\">\n",
    "\n",
    "- 예제 2\n",
    "    - 샘플: 문장에 사용된 단어들의 빈도를 모아놓은 벡터. \n",
    "        예를 들어, 지정된 2만 개의 단어 각각이 지정된 문장에 사용된 빈도를 측정하여\n",
    "        `(20000,)` 모양의 벡터로 표현 가능.\n",
    "    - 데이터셋: 10만 개의 문장을 대상으로 2만 개 단어의 사용빈도를 측정한 데이터셋은 \n",
    "        `(100000, 20000)` 모양의 2D 텐서로 표현 가능.\n",
    "\n",
    "- 예제 3: 사이킷런 모델의 입력 데이터셋은 기본적으로 2D 텐서를 사용함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) 3D 텐서 실전 예제**\n",
    "\n",
    "증시 데이터 등의 시계열 데이터와 트위터 데이터 등의 순차 데이터를 다룰 때 사용하며\n",
    "`(샘플 수, 타임 스텝 수, 특성 수)` 모양의 3D 텐서로 표현된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch02-timeseries_data.png\" style=\"width:350px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제 1\n",
    "    - 샘플: 1분마다 하루 총 390번 (현재 증시가, 지난 1분 동안 최고가, 지난 1분 동안 최저가)를 \n",
    "        측정한 데이터. `(390, 3)` 모양의 2D 텐서로 표현.        \n",
    "    - 데이터셋: 250일 동안 측정한 데이터셋은 `(250, 390, 3)` 모양의 3D 텐서로 표현.\n",
    "\n",
    "- 예제 2\n",
    "    - 샘플: 하나의 트위터 데이터(트윗)는 최대 280개의 문자로 구성되고, 사용할 수 있는 문자가 총 128 개일 때\n",
    "        트위터 샘플 하나를 `(280, 128)` 모양의 2D 텐서로 표현 가능함. \n",
    "        각각의 항목은 128개의 문자 각각의 사용여부를 확인해주는 0 또는 1.\n",
    "    - 데이터셋: 백만 개의 샘플로 구성된 트위터 데이터셋은 `(1000000, 280, 128)` 모양의 3D 텐서로 표현 가능.\n",
    "\n",
    "- 예제 3: 흑백 사진으로 구성된 데이터셋\n",
    "    - 샘플: `28x28` 크기의 (흑백) 손글씨 사진.\n",
    "        `(28, 28)` 모양의 2D 텐서로 표현 가능.\n",
    "    - MNIST 훈련 데이터셋: 총 6만개의 (흑백) 손글씨 사진으로 구성됨.\n",
    "        `(60000, 28, 28)` 모양의 3D 텐서로 표현 가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) 4D 텐서 실전 활용 예제**\n",
    "\n",
    "한 장의 컬러 사진 샘플은 일반적으로 \n",
    "`(높이, 너비, 채널 수)` 또는 `(채널 수, 높이, 너비)`\n",
    "모양의 3D 텐서로 표현한다. \n",
    "따라서 컬러 사진으로 구성된 데이터셋은 \n",
    "`(샘플 수, 높이, 너비, 채널 수)` 또는 `(샘플 수, 채널 수, 높이, 너비)`\n",
    "모양의 4D 텐서로 표현된다.\n",
    "\n",
    "RGB를 사용하는 컬러 어미지는 3개의 커널을, 흑백 사진은 1개의 채널을 갖는다. \n",
    "예를 들어 `256x256` 크기의 컬러 사진 128개를 갖는 데이터셋은\n",
    "`(128, 256, 256, 3)` 모양 4D 텐서로 표현된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch02-image_data.png\" style=\"width:350px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반면에 `28x28` 크기의 흑백 사진 128개를 갖는 데이터셋 또는 배치는\n",
    "`(128, 28, 28, 1)` 모양 4D 텐서로 표현된다.\n",
    "하지만 MNIST의 경우처럼 흑백 사진 데이터셋은 `(128, 28, 28)` 모양의 3D로 표현하기도 한다.\n",
    "예를 들어 `(3, 3, 1)` 모양의 3D 텐서를 `(3, 3)` 모양의 텐서로 표현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> tensor331 = np.array([[[1], [2], [3]],\n",
    "                          [[4], [5], [6]],\n",
    "                          [[7], [8], [9]]])\n",
    ">>> tensor331.reshape(3, 3)\n",
    "np.array([[1, 2, 3],\n",
    "          [4, 5, 6],\n",
    "          [7, 8, 9]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4) 5D 텐서 실전 예제**\n",
    "\n",
    "동영상은 프레임<font size='2'>frame</font>으로 구성된 순차 데이터다.\n",
    "프레임은 한 장의 컬러 사진이며, \n",
    "`(높이, 너비, 채널 수)` 모양의 3D 텐서로 표현된다.\n",
    "따라서 하나의 동영상은 `(프레임 수, 높이, 너비, 채널 수)` 모양의 4D 텐서로\n",
    "표현된다.\n",
    "이제 여러 개의 동영상으로 이루어진 데이터셋은 \n",
    "`(동영상 수, 프레임 수, 높이, 너비, 채널 수)` 모양의 5D 텐서로 표현된다.\n",
    "\n",
    "예를 들어, `144x256` 크기의 프레임으로 구성된 60초 동영상이 초당 4개의 프레임을 사용한다면\n",
    "동영상 한 편은 `(240, 144, 256, 3)` 모양의 4D 텐서로 표현된다.\n",
    "따라서 동영상 10 편으로 구성된 데이터셋은 `(10, 240, 144, 256, 3)` 모양의 5D 텐서로 표현된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 모델의 훈련은 기본적으로 텐서와 관련된 몇 가지 연산으로 이루어진다. \n",
    "예를 들어 이전 신경망에 사용된 층을 살펴보자.\n",
    "\n",
    "```python\n",
    "keras.layers.Dense(512, activation=\"relu\")\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "```\n",
    "\n",
    "첫째 층이 하는 일은 데이터 변환이며 실제로 이루어지는 연산은 다음과 같다.\n",
    "\n",
    "- `W1`: 첫째 층에서 학습되는 가중치 행렬\n",
    "- `b1`: 첫째 층에서 학습되는 편향 벡터\n",
    "\n",
    "`output = relu(np.dot(input, W1) + b1)`\n",
    "\n",
    "사용된 세부 연산은 다음과 같다. \n",
    "\n",
    "- 텐서 점곱: `np.dot()` 함수에 의해 행렬 곲 계산\n",
    "- 텐서 덧셈: `+`. 텐서 대상 항목별 덧셈.\n",
    "- 활성화 함수: `relu()` 함수. 음수 항목을 모두 0으로 대체함.\n",
    "\n",
    "둘째 층은 다른 가중치 행렬과 편향을 학습하여 데이터를 변환한다.\n",
    "\n",
    "- `W2`: 둘째 층에서 학습되는 가중치 행렬\n",
    "- `b2`: 둘째 층에서 학습되는 편향 벡터\n",
    "\n",
    "`output = softmax(np.dot(input, W2) + b2)`\n",
    "\n",
    "`softmax()` 함수는 분류 신경망 모델의 마지막 층인 **출력층**에서 사용되는 활성화 함수이며\n",
    "입력 샘플이 클래스별로 해당 클래스에 속할 확률을 계산한다. \n",
    "위 모델의 경우 10개 유닛에서 계산된 값들을 이용하여 10개 각 클래스별로 속할\n",
    "확률을 계산하며, 확률값의 합은 1이 되도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**항목별 연산과 브로드캐스팅**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 언급된 연산과 함수 중에서 덧셈 연산은 텐서에 포함된 항목별로 연산이 이뤄진다.\n",
    "아래 그림은 텐서의 항목별 덧셈과 브로드캐스팅이 작동하는 방식을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://scipy-lectures.org/_images/numpy_broadcasting.png\" style=\"width:750px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://scipy-lectures.org/intro/numpy/operations.html\">Scipy Lecture Notes</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서 연산과 브로드캐스팅을 가능한 모든 경우에 적용된다.\n",
    "아래 그림은 3차원 텐서와 2차원 텐서의 연산에 브로드캐스팅이 \n",
    "자동으로 적용되는 과정을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/pydata/master/notebooks/images/broadcasting12.png\" style=\"width:300px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**유니버설 함수**\n",
    "\n",
    "덧셈, 뺄셈, 곱셈, 나눗셈의 사칙 연산 이외에 다른 많은 연산과 함수도 항목별로 적용된다.\n",
    "예를 들어, `relu()` 함수가 0보다 작은 항목을 0으로 대체하는 데에 사용하는 `np.maximum()` 함수가\n",
    "텐서의 항목 각각에 대해 작동하는 과정을 보여준다.\n",
    "이와 같이 항목별로 작동하는 함수를 **유니버설**<font size='2'>universal</font> 함수라 부른다.\n",
    "\n",
    "```\n",
    "relu(t) = np.maximum(t, 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch01-universal_functions01.jpg\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.sharpsightlabs.com/blog/numpy-maximum/\">Sharp Sight - How to Use the Numpy Maximum Function</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} `softmax()` 함수\n",
    ":class: warning\n",
    "\n",
    "유니버설 함수만 활성화 함수로 사용되는 것은 아니다. \n",
    "`softmax()` 함수는 유니버설 함수가 아니며, 각 유닛에서 계산된 값들의 상대적 크기를 계산한다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**텐서 점곱**\n",
    "\n",
    "**텐서 점곱**<font size='2'>tensor dot product</font> 함수는\n",
    "두 벡터의 내적 또는 두 행렬의 곱을 계산할 때 사용된다.\n",
    "아래 그림에서 보여지는 것처럼 두 인자의 유형에 따라 다르게 작동한다.\n",
    "\n",
    "- 1D와 스칼라의 점곱: 항목 별 배수 곱셈\n",
    "- 1D와 1D의 점곱: 벡터 내적\n",
    "- 1D와 2D의 점곱: 행렬 곱셈\n",
    "- 2D와 2D의 점곱: 행렬 곱셈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://blog.finxter.com/wp-content/uploads/2021/01/numpy_dot-1-scaled.jpg\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://blog.finxter.com/dot-product-numpy/\">finxter - NumPy Dot Product</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 텐서의 곱셈(`*`)\n",
    ":class: warning\n",
    "\n",
    "텐서 점곱(`np.dot()`)과 텐서 곱셈(`*`)은 다르다.\n",
    "텐서 곱셈은 앞서 브로드캐스팅과 연관지어 설명된 것처럼 동일 모양의 두 텐서를\n",
    "항목별로 곱해서 동일 모양의 새로운 텐서를 생성한다.\n",
    "\n",
    "```python\n",
    ">>> a = np.array([1.0, 2.0, 3.0])\n",
    ">>> b = np.array([2.0, 2.0, 2.0])\n",
    ">>> a * b\n",
    "array([2.,  4.,  6.])\n",
    "\n",
    ">>> a = np.array([1.0, 2.0, 3.0])\n",
    ">>> b = 2.0\n",
    ">>> a * b\n",
    "array([2.,  4.,  6.])\n",
    "\n",
    ">>> a = np.array([[ 0.0,  0.0,  0.0],\n",
    "                  [10.0, 10.0, 10.0],\n",
    "                  [20.0, 20.0, 20.0],\n",
    "                  [30.0, 30.0, 30.0]])\n",
    ">>> b = np.array([1.0, 2.0, 3.0])\n",
    ">>> a*b\n",
    "array([[ 0.,  0.,  0.],\n",
    "       [10., 20., 30.],\n",
    "       [20., 40., 60.],\n",
    "       [30., 60., 90.]])\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**텐서 모양 변형**\n",
    "\n",
    "머신러닝 모델은 입력 텐서의 모양을 제한한다. \n",
    "앞서 사용한 MNIST 데이터셋 분류 모델은 `Dense` 층으로 구성되었는데, \n",
    "입력값으로 사용되는 데이터셋은 2차원 텐서로 표현되어 있어야 한다.\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "```\n",
    "\n",
    "반면에 `tensorflow.keras.datasets`에서 불러온 \n",
    "`train_images`와 `test_images` 는 각각\n",
    "`(60000, 28, 28)`와 `(10000, 28, 28)` 모양의 3차원 텐서다.\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "```\n",
    "\n",
    "따라서 모델을 훈련 및 테스트하고 실전에 활용할 때는 입력값을 항상\n",
    "적절한 모양의 2차원 텐서로 변형해야 한다.\n",
    "이를 위해 다음과 같이 `reshape()` 텐서 메서드를 활용한다.\n",
    "아래 코드는 `(60000, 28, 28)` 모양의 훈련셋인 3차원 텐서를 동일 개수의 항목을 갖는\n",
    "`(60000, 784)` 모양의 2차원 텐서로 변형한다.\n",
    "\n",
    "```python\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 넘파이 어레이 연산\n",
    ":class: info\n",
    "\n",
    "텐서 연산의 기본이 되는 넘파이 어레이 연산, 유니버설 함수, 텐서 모양 변형 등에 대한\n",
    "보다 자세한 설명은 \n",
    "[파이썬 데이터 분석](https://codingalzi.github.io/datapy/intro.html)을 참고한다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 연산의 기하학적 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 모델에 사용되는 연산과 함수들의 기능을 \n",
    "기하학적으로 설명할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이동: 벡터 합\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/translation.png\" style=\"width:400px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 회전: 점 곱\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/rotation.png\" style=\"width:400px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 스케일링: 점 곱\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/scaling.png\" style=\"width:400px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아핀 변환\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/affine_transform.png\" style=\"width:400px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아핀 변환과 relu 활성화 함수\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/dense_transform.png\" style=\"width:400px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망은 기본적으로 앞서 언급된 텐서 연산의 조합을 통해\n",
    "고차원 공간에서의 매우 복잡한 기하학적 변환을 수행한다.\n",
    "\n",
    "예를 들어, 빨간 종이와 파란 종이 두 장을 겹친 후 뭉개서 만든 종이 뭉치를\n",
    "조심스럽게 조금씩 펴서 결국 두 개의 종이로 구분하는 것처럼\n",
    "예를 들어 신경망 이진 분류 모델은 뒤 섞인 두 개 클래스로 구성된 입력 데이터셋을\n",
    "여러 층을 통한 변환과정을 거치면서 결국엔 두 개의 데이터셋으로 구분하기 쉬운\n",
    "표현으로 데이터를 변환한다.\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch02-geometric_interpretation_4.png\" style=\"width:400px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순수 텐서플로우 사용법 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스를 전혀 이용하지 않으면서 신경망 모델을 지정하고 훈련시킬 수 있다.\n",
    "하지만 아래에 언급된 개념, 기능, 도구를 모두 직접 구현해야 한다.\n",
    "\n",
    "- 가중치, 편향 등을 저장할 텐서 지정\n",
    "- 순전파 실행(덧셈, 행렬 곱, `relu()` 함수 등 활용)\n",
    "- 역전파 실행\n",
    "- 층과 모델\n",
    "- 손실 함수\n",
    "- 옵티마이저\n",
    "- 평가지표\n",
    "- 훈련 루프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상수 텐서와 변수 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로우 자체로 두 종류의 새로운 텐서 자료형을 지원한다.\n",
    "사용법은 기본적으로 넘파이 어레이와 유사하지만 GPU 연산과 그레이디언트 자동계산 등\n",
    "신경망 모델 훈련에 최적화된 기능을 제공한다.\n",
    "\n",
    "- `tf.Tensor` 자료형\n",
    "    - 상수 텐서\n",
    "    - 입출력 데이터 등 변하지 않는 텐서로 사용. \n",
    "    - 불변 자료형\n",
    "- `tf.Variable` 자료형\n",
    "    - 변수 텐서\n",
    "    - 모델의 가중치, 편향 등 업데이트가 되는 텐서로 사용. \n",
    "    - 가변 자료형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "덧셈, relu, 점곱 등 텐서 연산은 기본적으로 넘파이 어레이 연산과 동일하다.\n",
    "텐서 연산에 대한 자세한 설명은 \n",
    "[텐서 소개(Introduction to Tensors)](https://colab.research.google.com/drive/1uE85otT0gaDBRXB3LqwZE1U0q-_72b9c?usp=sharing)를 참고하라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GradientTape` 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "넘파이 어레이와의 가장 큰 차이점은 \n",
    "그레이디언트 테이프 기능을 이용하여 변수 텐서에 의존하는 미분가능한 \n",
    "함수의 그레이디언트 자동 계산이다. \n",
    "예를 들어 아래 코드는 제곱 함수의 $x = 3$에서의 미분값인 6을 계산한다.\n",
    "\n",
    "$$\n",
    "f(x) = x^2 \\quad \\Longrightarrow \\quad \\nabla f(x) = \\frac{df(x)}{dx} = 2x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "input_var = tf.Variable(initial_value=3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    result = tf.square(input_var)\n",
    "gradient = tape.gradient(result, input_var)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> print(gradient)\n",
    "tf.Tensor(6.0, shape=(), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제: 순수 텐서플로우 활용 선형 분류기 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스를 전혀 사용하지 않으면서 간단한 선형 분류기를 구현하는 과정을 통해\n",
    "텐서플로우 API의 기본 기능을 살펴 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1단계: 데이터셋 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 사진 모양처럼 양성(노랑색)과 음성(보라색)으로 구분되는 훈련셋을 생성해서\n",
    "훈련셋으로 이용한다.\n",
    "생성되는 훈련셋은 다변량 정규분포를 따르도록 하며,\n",
    "양성과 음성 데이터셋 각각 1,000개의 샘플로 구성된다.\n",
    "데이터셋 생성에 사용되는 공분산은 두 데이터셋에 대해 동일하고 평균값만 서로 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/03-07.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "num_samples_per_class = 1000\n",
    "\n",
    "# 음성 데이터셋\n",
    "negative_samples = np.random.multivariate_normal(\n",
    "    mean=[0, 3], cov=[[1, 0.5],[0.5, 1]], size=num_samples_per_class)\n",
    "\n",
    "# 양성 데이터셋\n",
    "positive_samples = np.random.multivariate_normal(\n",
    "    mean=[3, 0], cov=[[1, 0.5],[0.5, 1]], size=num_samples_per_class)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 데이터셋을 합쳐서 훈련셋, 즉, 모델의 입력값으로 지정한다.\n",
    "자료형을 `np.float32`로 지정함에 주의하라.\n",
    "그렇게 하지 않으면 `np.float64`로 지정되어 보다 많은 메모리와 실행시간을 요구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "inputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "음성 샘플의 레이블은 0, 양성 샘플의 레이블은 1로 지정한다.\n",
    "레이블 데이터셋 또한 2차원 어레이로 지정됨에 주의하라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "targets = np.vstack((np.zeros((num_samples_per_class, 1), dtype=\"float32\"),\n",
    "                     np.ones((num_samples_per_class, 1), dtype=\"float32\")))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2단계: 선형 회귀 모델 훈련에 필요한 가중치와 편향 변수 텐서 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 학습에 사용될 가중치와 편향을 변수 텐서로 선언한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "input_dim = 2     # 입력 샘플의 특성이 2개\n",
    "output_dim = 1    # 하나의 값으로 출력\n",
    "\n",
    "# 가중치: 무작위 초기화\n",
    "W = tf.Variable(initial_value=tf.random.uniform(shape=(input_dim, output_dim)))\n",
    "\n",
    "# 편향: 0으로 초기화\n",
    "b = tf.Variable(initial_value=tf.zeros(shape=(output_dim,)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3단계: 모델 선언(포워드 패스 담당)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 모델을 훈련할 때 입력값에 대한 예측값을 계산하는 과정인\n",
    "포워드 패스를 함수로 구현한다.\n",
    "간단한 모델 표현을 위해 활성화 함수는 사용하지 않는다.\n",
    "\n",
    "`tf.matmul()` 함수는 넘파이의 점 곱 함수처럼 작동하며 아래 코드에서는\n",
    "행렬의 곱을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def model(inputs):\n",
    "    return tf.matmul(inputs, W) + b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4단계: 손실 함수 지정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타깃과 예측값 사이의 평균 제곱 오차를 손실값으로 사용한다. \n",
    "아래 코드에서 `tf.reduce_mean()` 함수는 넘파이의 `np.mean()`처럼\n",
    "평균값을 계산하지만 텐서플로우의 텐서를 대상으로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def square_loss(targets, predictions):\n",
    "    per_sample_losses = tf.square(targets - predictions)\n",
    "    return tf.reduce_mean(per_sample_losses)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5단계: 훈련 스텝(백워드 패스와 역전파) 지정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하나의 배치에 대해 예측값을 계산한 후에 손실 함수의 그레이디언트를 \n",
    "계산한 후에 가중치와 편향을 업데이트하는 함수를 선언한다.\n",
    "그레이디언트 계산은 그레이디언트 테이프를 이용한다.\n",
    "\n",
    "아래 `training_step()` 함수가 백워드 패스와 역전파를 수행하는 옵티마이저\n",
    "역할을 담당한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def training_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs)\n",
    "        loss = square_loss(targets, predictions)\n",
    "    grad_loss_wrt_W, grad_loss_wrt_b = tape.gradient(loss, [W, b])\n",
    "    W.assign_sub(grad_loss_wrt_W * learning_rate)\n",
    "    b.assign_sub(grad_loss_wrt_b * learning_rate)\n",
    "    return loss\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6단계: 훈련 루프 지정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반복해서 훈련한 내용을 지정한다.\n",
    "여기서는 설명을 간단하게 하기 위해 미니 배치가 아닌 배치 훈련을 구현한다.\n",
    "전체 훈련셋을 총 40번 반복 학습할 때마다 손실값을 출력하도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "for step in range(40):\n",
    "    loss = training_step(inputs, targets)\n",
    "    print(f\"Loss at step {step}: {loss:.4f}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7단계: 결정경계 예측**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 예측값이 0.5보다 클 때 양성으로 판정하는 것이 좋은데\n",
    "이유는 샘플들의 레이블이 0 또는 1이기 때문이다.\n",
    "모델은 훈련과정 중에 음성 샘플은 최대한 0에, \n",
    "양성 샘플은 최대한 1에 가까운 값으로 예측하여 손실값을 최대한 줄여야 하는데\n",
    "`training_step()` 함수에서 구현된 경사하강법이 그렇게 유도한다.\n",
    "따라서 예측값이 0과 1의 중간값인 0.5일 때를 결정경계로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결정경계를 직선으로 그리려면 아래 식을 이용한다.\n",
    "\n",
    "```python\n",
    "y = - W[0] /  W[1] * x + (0.5 - b) / W[1]\n",
    "```\n",
    "\n",
    "이유는 위 모델의 예측값이 다음과 같이 계산되며,\n",
    "\n",
    "```python\n",
    "W[0]*x + W[1]*y + b\n",
    "```\n",
    "\n",
    "위 예측값이 0.5보다 큰지 여부에 따라 음성, 양성이 판단되기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/HighResolutionFigures/figure_3-8.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [(실습) 케라스와 텐서플로우](https://colab.research.google.com/github/codingalzi/dlp2/blob/master/excs/exc-keras_and_tf.ipynb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter03_introduction-to-keras-and-tf.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c86b3592b6800d985c04531f2c445f0fa6967131b8dd6395a925f7622e55602"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}