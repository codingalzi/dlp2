#!/usr/bin/env python
# coding: utf-8

# (ch:unversal_workflow_of_ml)=
# # 머신러닝 작업 흐름 일반

# **감사의 글**
# 
# 아래 내용은 프랑소와 숄레의 
# [Deep Learning with Python(2판)](https://github.com/fchollet/deep-learning-with-python-notebooks)의 
# 소스코드 내용을 참고해서 작성되었습니다.
# 자료를 공개한 저자에게 진심어린 감사를 전합니다.

# **소스코드**
# 
# 없음.

# **주요 내용**

# 다양한 종류의 머신러닝 과제를 실전에서 해결해야 할 수 있다.
# 
# - 사진 검색 엔진
# - ...

# :::{admonition} 윤리 문제
# :class: note
# 
# 윤리적으로 문제 있는 문제 ...
# 
# - 얼굴로 인성 평가
# - 보스턴 하우스 데이터셋
# - 백인 우성 유전자 
# - 등등
# :::

# 머신러닝으로 실전 문제를 해결하는 일반적인 과정을 소개한다.
# 
# - 머신러닝 문제 정의하기
# - 모델 구현
# - 모델 실전 배치

# ## 머신러닝 문제 정의하기

# ### 문제 확인

# - 훈련 데이터셋은 무엇? 예측값은 무엇? 필요한 데이터셋과 타깃셋을 직접 구해야 함.
#     그렇지 못하면 머신러닝 모델을 훈련시킬 수 없음.
#     예를 들어, 영화평을 분류하고자 한다면 영화평과 각 영화평이 결론적으로 
#     좋다/싫다인지에 대한 데이터셋이 필요함.

# - 어떤 머신러닝 모델 활용? 이진 분류? 다중클래스 분류? 스칼라 회귀? 벡터 회귀?
#     다중클래스-다중레이블 분류? 이미지 분할? 랭킹? 군집화? 생성? 강화학습? 
#     아니면 심지어 머신러닝 필요? 전통적 통계/확률 기법으로 해결 가능?
#     
#     - 사진 검색 엔진: 다중클래스-다중레이블 분류
#     - 스팸 메일 필터: 이진 분류 또는 다중클래스 분류(스팸은 아니지만 공격적?)
#     - 음악 추천 엔진: 딥러닝 보다는 Collaborative Filtering 기법 중의 하나인
#         행렬 분해(matrix factorization) 기법을 활용한 추천 시스템이 보다 효율적임.
#     - 신용카드 사기 검출(credit card fraud detection): 이진 분류
#     - 클릭율(click-through-rate) 예측: 스칼라 회귀
#     - 비정상(?) 과자 탐지: 이진 분류. 하지만 먼저 객체 탐지 모델 필요. 
#         일반적으로 알려진 "이상치 탐지" 용도의 머신러닝 모델이
#         이 경우엔 그렇게 적절하지 않음.
#     - 고대 유적지 확인: 인공위성 사진 분석. 기존 고대 유적지와의 유사도 측정.
#         이미지-유사도 랭킹 측정.

# - 기존에 사용되는 해결책 존재? 무엇? 전통적 프로그래밍 기법? 담당자가 추천할 음악 등을 직접 선별?

# - 문제를 다룰 때 특별히 고려해야 할 점? 
#     - 스팸 탐지 시스템: 암호화된 이메일인 경우 사용자의 전화기에서 작동해야 함. 
#     - 비정상 과자 탐지가 원격 서버가 아닌 공장의 임베디드 시스템에서 작동해야 할 수 있음.

# 위 사항들을 모두 확인했다 하더라도 준비된 데이터셋의 유효성을 확인해야 함. 즉, 적절한 훈련셋인지, 입력 데이터셋을 이용하여 적절한 예측값을 생성할 수 있는지 등등. 
# 예를 들어 지난 시간 동안의 증권시장의 가격 데이터를 이용하여 미래의 증권시장 동향을 예측하는 일은 별로 성공적이지 않을 것이다. 

# ### 데이터셋 수집

# 문제해결에 필요한 입력 데이터셋과 타깃 데이터셋을 수집하는 일이 가장 어렵고,
# 가장 많은 시간을 요하며, 가장 비용이 많이 든다.

# - 사진 검색 엔진: 사진의 레이블로 사용될 목록 확인. 보통 10,000개의 사진의 범주(category) 지정. 이후에 수 천장의 사진을 직접 태킹(tagging)해야 함. 
# 
# - 채팅 앱에 사용될 스팸 탐지 과제: 채팅 내용 모으기는 암호화 및 개인 정보 보호로 막혀 있기에 기본적으로 불가능. 하지만 소셜 미디어에 게시된 데이터를 수만 건 이상의 데이터셋을 모은 다음에 스팸, 공격성 등에 대해 일일이 직접 태깅해야 함.
# 
# - 음악 추천 엔진: 사용자들의 "좋아요" 누르기 정보 데이터 활용 가능. 
# 
# - 클릭율 예측 과제: 지난 수 년간의 광고에 대한 클릭율 정보 데이터 활용 가능
# 
# - 과자 이상치 탐지 모델: 컨베이어 벨트를 감시하는 카메라를 통한 수 만장의 사진과 어떤 형식으로든 사진에 추가된 태그 정보.
# 
# - 인공위성 이미지 분석 과제: 고고학자들이 모아 놓은 현존하는 유적지 관련 데이터 베이스와 각 유적지별로 다양한 날씨 조건에 찍힌 여러 사진. 수 천개 이상의 유적지 데이터 필요.

# **데이터셋의 중요성**

# 머신러닝 모델의 일반화 성능은 모델 훈련에 거의 사용된 훈련셋에 의존한다. 
# - 훈련셋 크기
# - 레이블에 대한 신뢰도
# - 훈련 특성들의 질(quality)
# 모델의 성능을 향상키려면 우선적으로 양질의 데이터셋을 구하는 데에 보다 많은 시간을 투자해야 한다.

# **타깃 데이터셋 준비의 중요성**

# 사진 검색 엔진의 경우처럼 지도학습의 경우 경우에 따라 타깃 데이터셋을 구하기가 매우 어려울 수 있다.
# 반면에 양질의 타깃 데이터셋이 있어야만 좋은 성능의 모델을 훈련시킬 수 있다.
# 타깃 데이터셋을 준비할 때 아래 옵션 사항들을 고려하라.
# 
# - 데이터 태깅을 직접해야 하는가?
# - 아마존 Mechanical Turk 와 같은 크라우드소싱을 이용해야 하는가?
# - 데이터-레이블링 전문 회사를 이용해야 하는가?
# 
# 어떤 옵션을 선택할 것인가는 다음 사항들에 따라 달리진다.
# 
# - 레이블링 작업 관련 전문가를 요구하는가? 
#     - 강아지 대 고양이 분류: 일반인 가능
#     - 강아지 품종 분류: 전문 지식 필요
#     - CT 스캔 자료 분류: 의학 학위 필요
# - 전문 지식이 요구 되는 경우
#     - 사람들을 직접 훈련시킬 수 있는가?
#     - 아니라면 관련 전문가를 어떻게 어디서 구하는가?
# - 전문가들이 타깃을 지정하는 방식을 이해하는가?
#     - 그렇지 않다면 특성 조작을 직접하지 말아야 한다.

# **타깃 레이블링을 직접 하는 경우**

# 레이블링을 직접 하는 경우 먼저 레이블링을 자동화하는 좋은 프로그램을 
# 과제 기간 초반에 직접 구현하거나 준비해야 한다.

# **훈련셋의 대표성**

# 나중에 제품이 실전에서 사용될 때 입력될 입력 데이터를 잘 반영하는 데이터로 구성된 데이터셋을 모델 훈련에 사용해야 한다.

# 예제 1
# 
# 음식의 이름을 맞추는 앱에 들어갈 머신러닝 모델을 훈련시킬 경우 일반인들이 찍는 사진과 유사한 이미지 데이터셋을 훈련에 사용해야 한다.
# 반면에 전문가들이 찍은 사진만을,
# 즉,훈련셋의 대표성이 너무 떨어진 데이터셋을
# 모델 훈련에 이용한다면 좋은 성능의 머신러닝 모델을 구현할 수 없을 것이다.

# 예제 2
# 
# 트위터에서 작성되는 문장의 감성을 평가하고 싶다면 실제 트위터 문장을 수집해서 레이블링해야 한다. 트위터 문장의 감성 분석에 영화 후기 문장을 훈련셋으로 이용하면 안된다.

# **개념 변동**

# 개념 변동<font size='2'>concept drift</font>은 시간이 흐르면서
# 실전에 사용되는 데이터의 특성이 달라짐을 의미한다.
# 
# - 2013년의 음악을 이용한 음악 추천 시스템이 2022년 음악 추천에 사용되기는 어렵다.
# - 2011년에 수집된 IMDB 영화 후기 데이터셋을 현재 상영되는 영화의 후기 감성 분석에 사용할 수 없다.
#     - 문장에 사용된 어휘와 표현이 다르고 영화 장르가 변화했기 때문임.
# - 신용카드 사기 탐지: 사기 방식이 매일 발전함.
# 
# 개념 변동에 대처하려면 계속된 데이터 수집과 데이터 레이블링, 모델 재훈련이 요구된다.

# **표집 편향**

# 표집 편향<font size='2'>sampling bias</font>은 
# 예측과 연관된 표본<font size='2'>sample</font>이 
# 데이터셋에 포함되는 것을 의미한다. 
# 
# 예를 들어, 1948년 미국 대통령 선거일 밤에
# 시카고 트리뷴<font size='2'>Chicago Tribune</font>이
# "(공화당 후보) 듀이가 (민주장 후보) 트루먼 후보를 이긴다" 라고 기사를 내보냈지만
# 실제로 그 다음 날 트루먼이 대통령으로 당선되었다.

# <div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/06-UN01.png" style="width:600px;"></div>
# 
# <p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p>

# 시카고 트리뷴의 잘못된 예측은 선거 전에 진행된 전화 여론조사 결과에 근거하였지만
# 당시 전화는 미국에서 부자이면서 보수적 성향을 가진 친공화당 사람들만이 
# 갖고 있었다. 
# 즉 공화당 후보를 지지하는 성향이 강한 사람들을 대상으로 여론조사를 벌인 셈이다.

# 이후로 표집 편향을 최대한 피하면서 여론조사를 진행해야 함을 인지하게 되었다.
# 물론 표집 편향이 완전히 사라졌다고는 말할 수 없다. 
# 특히 정치 관련 여론조사가 그렇다.

# ### 데이터 이해하기

# 훈련 시작 전에 데이터를 시각화 등을 이용하여 살펴보고
# 무엇을 이용하여 예측할 것인지, 특성을 어떻게 조저어할 것인지, 
# 발생할 수 있는 문제들을 예측해야 한다.

# - 이미지 또는 문장이 포함된 데이터셋이라면 샘플 몇 개를 레이블과 함께 살펴 본다.
# - 수치 특성이 포함된 경우 히스토그램 등을 그려서 값들의 범위와 빈도 등을 살펴 본다.
# - 위치 정보가  포함된 경우 지도 위에 그려서 어떤 특성이 나타나는지 확인한다.
# - 결측치가 포함된 특성이 포함된 경우 어떻게 처리할지 결정하고 처리한다.
# - 분류 문제일 경우 각 범주별 샘플 수를 확인한다. 한쪽으로 치우친 경우 이유를 확인한다.
# - 타깃에 대한 정보가 입력 데이터셋에 유입되는지 여부를 확인한다. 
#     - 환자 이력 정보를 통해 환자에게 암이 발생할 가능성을 예측하는 모델을 
#         훈련시킬 때 환자의 암 양성진단 이력 정보가 포함될 수도 있다.

# ### 모델 성능 지표 선택

# 얼마나 성공적으로 모델 훈련을 완성했는지 평가해야 한다.
# 해결해야 하는 문제에 따라 모델의 성능 지표가 달라지며,
# 모델 제작을 의뢰한 고객의 사업 성공과 밀접하게 연관된 일이기도 하다.

# 분류 모델의 경우 범주가 공평하게 나눠저 있다면 정확도와
# AUC<font size='2'>Area Under the ROC curve</font>가 성능 지표로 사용된다.
# 범주가 한 쪽으로 쏠린 경우엔 정밀도, 재현율, 가중치가 적용된 정확도와 AUC가
# 활용된다.
# 
# 또한 사용자가 직접 평가 지표를 정의해야 하는 경우도 일반적으로 발생한다.

# ## 모델 구현

# 모델 훈련에 필요한 데이터 준비하기와 완성된 모델을 시제품으로 만들어 관리 유지하는 일보다 어렵다고 말할 수는 없음에도 불구하고 대부분의 머시러닝 관련 정보는 모델 구현에 한정된다. 

# ### 데이터 준비

# 수집된 데이터를 그대로 모델 훈련에 사용하는 경우는 매우 드물다.
# 훈련시킬 모델에 맞추어 데이터셋을 전처리 해야 할 수도 있지만
# 일반적인 전처리 기법은 다음과 같다.

# 벡터화

# 신경망 모델 훈련에 사용되는 데이터는 모두 텐서 형식을 갖춰야 한다.
# 일반적으로 부동소수점으로 이루어진 텐서가 사용되며
# 경우에 따라 정수 또는 문자여로 이루어진 텐서가 사용되기도 한다.
# 
# 앞서 다룬 영화 후기 감성 분석 등의 경우처럼 단어를 정수로, 
# 정수를 원-핫 인코딩 시킨 데이터를 이용하였다.
# 
# 반면에 MNIST 데이터셋과 주택 가격 예측 데이터셋인 이미 텐서 형식이었기에
# 벡터화 과정을 생략할 수 있었다.

# 정규화

# MNIST 데이터셋은 원래 0부터 255사이의 정수로 이루어진 텐서였지만 255로 나누어
# 0과 1사이의 `float32` 부동소수점으로 이뤄진 텐서로 변환했다.
# 이처럼 입력 데이터셋 특성값들을 가능하면 아래 특성을 만족시키도록 하는 게 훈련에 도움된다.
# 
# - 대부분의 값이 0과 1사이에서 움직인다.
# - 모든 특성값이 거의 비슷한 범위(range, scale) 안에서 움직인다.
# 
# MNIST 데이터셋의 경우처럼 항상 그럴 필요는 없지만 이와 더불어 아래 조건이 만족되도록 하는 것도 일반적이다.
# 
# - 특성별 평균값이 0이다.
# - 특성법 표준편차가 1이다.

# 결측치 처리

# 일부 특성에 결측치가 존재하는 경우가 많다.
# 이럴 때 특성 자체를 제거할 수도 있지만 다른 식으로 처리할 수도 있다.
# 
# - 범주형 특성인 경우: "결측치" 여부를 알려주는 새로운 특성 추가 가능
# - 수치형 특성인 경우: 결측치를 단순히 0으로 처리하기 보다는 해당 특성의 
#     평균값 또는 중앙값으로 대체하는 것이 일반적임.
#     아니면 해당 결측치를 예측하는 모델을 훈련시킬 수도 있음.
#     
# 테스트셋 또는 실전 데이터의 일부 예상되는 특성에 결측치가 존재할 수 있다면
# 훈련도 해당 특성에 결측치가 있도록 해야 한다.
# 그렇지 않으면 테스트셋에 포함된 결측치를 모델이 제대로 
# 처리하지 못할 수 있다.

# ### 훈련중 모델 평가

# 훈련중인 모델의 일반화 성능을 검증하기 위한 평가지표를 사용한다.
# 이때 일반적으로 아래 세 가지 방식 중의 하나를 사용한다.
# 
# - 홀드아웃 검증셋 사용: 데이터셋이 큰 경우 적용
# - K-폴드 교차 검증: 매우 적은 데이터셋이 주어진 경우 적용
# - 반복 K-폴드 검증: 적은 양의 데이터이 주어졌을 때 높은 정확도의 모델 평가를 위해 적용
# 
# 훈련셋과 검증셋에 데이터가 중복되지 않도록 조심해야 하며
# 두 데이터셋의 대표성에 대해서 항상 신경써야 한다.

# ### 기준값 지정 및 깨기

# 모델 훈련을 시작하면 우선적으로 통계적으로 의미 있는 성능을 보여줄 수 있어야 한다.
# 즉, 아직 개선의 여지가 많음에도 불구하고 통계적으로 유의미한 기준값을 넘어서는
# 성능의 모델을 훈련시킬 수 있어야 한다. 
# 이때 통계적으로 유의미한 기준값을 베이스라인<font size='2'>baseline</font>이라 한다.

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# 

# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:




