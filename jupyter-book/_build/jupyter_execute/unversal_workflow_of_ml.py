#!/usr/bin/env python
# coding: utf-8

# (ch:unversal_workflow_of_ml)=
# # 머신러닝 작업 흐름 일반

# **감사의 글**
# 
# 아래 내용은 프랑소와 숄레의 
# [Deep Learning with Python(2판)](https://github.com/fchollet/deep-learning-with-python-notebooks)의 
# 소스코드 내용을 참고해서 작성되었습니다.
# 자료를 공개한 저자에게 진심어린 감사를 전합니다.

# **소스코드**
# 
# 없음.

# **주요 내용**

# 다양한 종류의 머신러닝 과제를 실전에서 해결해야 할 수 있다.
# 
# - 사진 검색 엔진
# - ...

# :::{admonition} 윤리 문제
# :class: note
# 
# 윤리적으로 문제 있는 문제 ...
# 
# - 얼굴로 인성 평가
# - 보스턴 하우스 데이터셋
# - 백인 우성 유전자 
# - 등등
# :::

# 머신러닝으로 실전 문제를 해결하는 일반적인 과정을 소개한다.
# 
# - 머신러닝 문제 정의하기
# - 모델 구현
# - 모델 실전 배치

# ## 머신러닝 문제 정의하기

# ### 문제 확인

# - 훈련 데이터셋은 무엇? 예측값은 무엇? 필요한 데이터셋과 타깃셋을 직접 구해야 함.
#     그렇지 못하면 머신러닝 모델을 훈련시킬 수 없음.
#     예를 들어, 영화평을 분류하고자 한다면 영화평과 각 영화평이 결론적으로 
#     좋다/싫다인지에 대한 데이터셋이 필요함.

# - 어떤 머신러닝 모델 활용? 이진 분류? 다중클래스 분류? 스칼라 회귀? 벡터 회귀?
#     다중클래스-다중레이블 분류? 이미지 분할? 랭킹? 군집화? 생성? 강화학습? 
#     아니면 심지어 머신러닝 필요? 전통적 통계/확률 기법으로 해결 가능?
#     
#     - 사진 검색 엔진: 다중클래스-다중레이블 분류
#     - 스팸 메일 필터: 이진 분류 또는 다중클래스 분류(스팸은 아니지만 공격적?)
#     - 음악 추천 엔진: 딥러닝 보다는 Collaborative Filtering 기법 중의 하나인
#         행렬 분해(matrix factorization) 기법을 활용한 추천 시스템이 보다 효율적임.
#     - 신용카드 부정사용 감지(credit card fraud detection): 이진 분류
#     - 클릭율(click-through-rate) 예측: 스칼라 회귀
#     - 비정상(?) 과자 탐지: 이진 분류. 하지만 먼저 객체 탐지 모델 필요. 
#         일반적으로 알려진 "이상치 탐지" 용도의 머신러닝 모델이
#         이 경우엔 그렇게 적절하지 않음.
#     - 고대 유적지 확인: 인공위성 사진 분석. 기존 고대 유적지와의 유사도 측정.
#         이미지-유사도 랭킹 측정.

# - 기존에 사용되는 해결책 존재? 무엇? 전통적 프로그래밍 기법? 담당자가 추천할 음악 등을 직접 선별?

# - 문제를 다룰 때 특별히 고려해야 할 점? 
#     - 스팸 감지 시스템: 암호화된 이메일인 경우 사용자의 전화기에서 작동해야 함. 
#     - 비정상 과자 탐지가 원격 서버가 아닌 공장의 임베디드 시스템에서 작동해야 할 수 있음.

# 위 사항들을 모두 확인했다 하더라도 준비된 데이터셋의 유효성을 확인해야 함. 즉, 적절한 훈련셋인지, 입력 데이터셋을 이용하여 적절한 예측값을 생성할 수 있는지 등등. 
# 예를 들어 지난 시간 동안의 증권시장의 가격 데이터를 이용하여 미래의 증권시장 동향을 예측하는 일은 별로 성공적이지 않을 것이다. 

# ### 데이터셋 수집

# 문제해결에 필요한 입력 데이터셋과 타깃 데이터셋을 수집하는 일이 가장 어렵고,
# 가장 많은 시간을 요하며, 가장 비용이 많이 든다.

# - 사진 검색 엔진: 사진의 레이블로 사용될 목록 확인. 보통 10,000개의 사진의 범주(category) 지정. 이후에 수 천장의 사진을 직접 태킹(tagging)해야 함. 
# 
# - 채팅 앱에 사용될 스팸 감지 과제: 채팅 내용 모으기는 암호화 및 개인 정보 보호로 막혀 있기에 기본적으로 불가능. 하지만 소셜 미디어에 게시된 데이터를 수만 건 이상의 데이터셋을 모은 다음에 스팸, 공격성 등에 대해 일일이 직접 태깅해야 함.
# 
# - 음악 추천 엔진: 사용자들의 "좋아요" 누르기 정보 데이터 활용 가능. 
# 
# - 클릭율 예측 과제: 지난 수 년간의 광고에 대한 클릭율 정보 데이터 활용 가능
# 
# - 과자 이상치 탐지 모델: 컨베이어 벨트를 감시하는 카메라를 통한 수 만장의 사진과 어떤 형식으로든 사진에 추가된 태그 정보.
# 
# - 인공위성 이미지 분석 과제: 고고학자들이 모아 놓은 현존하는 유적지 관련 데이터 베이스와 각 유적지별로 다양한 날씨 조건에 찍힌 여러 사진. 수 천개 이상의 유적지 데이터 필요.

# **데이터셋의 중요성**

# 머신러닝 모델의 일반화 성능은 모델 훈련에 거의 사용된 훈련셋에 의존한다. 
# - 훈련셋 크기
# - 레이블에 대한 신뢰도
# - 훈련 특성들의 질(quality)
# 모델의 성능을 향상키려면 우선적으로 양질의 데이터셋을 구하는 데에 보다 많은 시간을 투자해야 한다.

# **타깃 데이터셋 준비의 중요성**

# 사진 검색 엔진의 경우처럼 지도학습의 경우 경우에 따라 타깃 데이터셋을 구하기가 매우 어려울 수 있다.
# 반면에 양질의 타깃 데이터셋이 있어야만 좋은 성능의 모델을 훈련시킬 수 있다.
# 타깃 데이터셋을 준비할 때 아래 옵션 사항들을 고려하라.
# 
# - 데이터 태깅을 직접해야 하는가?
# - 아마존 Mechanical Turk 와 같은 크라우드소싱을 이용해야 하는가?
# - 데이터-레이블링 전문 회사를 이용해야 하는가?
# 
# 어떤 옵션을 선택할 것인가는 다음 사항들에 따라 달리진다.
# 
# - 레이블링 작업 관련 전문가를 요구하는가? 
#     - 강아지 대 고양이 분류: 일반인 가능
#     - 강아지 품종 분류: 전문 지식 필요
#     - CT 스캔 자료 분류: 의학 학위 필요
# - 전문 지식이 요구 되는 경우
#     - 사람들을 직접 훈련시킬 수 있는가?
#     - 아니라면 관련 전문가를 어떻게 어디서 구하는가?
# - 전문가들이 타깃을 지정하는 방식을 이해하는가?
#     - 그렇지 않다면 특성 조작을 직접하지 말아야 한다.

# **타깃 레이블링을 직접 하는 경우**

# 레이블링을 직접 하는 경우 먼저 레이블링을 자동화하는 좋은 프로그램을 
# 과제 기간 초반에 직접 구현하거나 준비해야 한다.

# **훈련셋의 대표성**

# 나중에 제품이 실전에서 사용될 때 입력될 입력 데이터를 잘 반영하는 데이터로 구성된 데이터셋을 모델 훈련에 사용해야 한다.

# 예제 1
# 
# 음식의 이름을 맞추는 앱에 들어갈 머신러닝 모델을 훈련시킬 경우 일반인들이 찍는 사진과 유사한 이미지 데이터셋을 훈련에 사용해야 한다.
# 반면에 전문가들이 찍은 사진만을,
# 즉,훈련셋의 대표성이 너무 떨어진 데이터셋을
# 모델 훈련에 이용한다면 좋은 성능의 머신러닝 모델을 구현할 수 없을 것이다.

# 예제 2
# 
# 트위터에서 작성되는 문장의 감성을 평가하고 싶다면 실제 트위터 문장을 수집해서 레이블링해야 한다. 트위터 문장의 감성 분석에 영화 후기 문장을 훈련셋으로 이용하면 안된다.

# **개념 변동**

# 개념 변동<font size='2'>concept drift</font>은 시간이 흐르면서
# 실전에 사용되는 데이터의 특성이 달라짐을 의미한다.
# 
# - 2013년의 음악을 이용한 음악 추천 시스템이 2022년 음악 추천에 사용되기는 어렵다.
# - 2011년에 수집된 IMDB 영화 후기 데이터셋을 현재 상영되는 영화의 후기 감성 분석에 사용할 수 없다.
#     - 문장에 사용된 어휘와 표현이 다르고 영화 장르가 변화했기 때문임.
# - 신용카드 부정사용 감지: 부정사용 방식이 매일 발전함.
# 
# 개념 변동에 대처하려면 계속된 데이터 수집과 데이터 레이블링, 모델 재훈련이 요구된다.

# **표집 편향**

# 표집 편향<font size='2'>sampling bias</font>은 
# 예측과 연관된 표본<font size='2'>sample</font>이 
# 데이터셋에 포함되는 것을 의미한다. 
# 
# 예를 들어, 1948년 미국 대통령 선거일 밤에
# 시카고 트리뷴<font size='2'>Chicago Tribune</font>이
# "(공화당 후보) 듀이가 (민주장 후보) 트루먼 후보를 이긴다" 라고 기사를 내보냈지만
# 실제로 그 다음 날 트루먼이 대통령으로 당선되었다.

# <div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/06-UN01.png" style="width:600px;"></div>
# 
# <p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p>

# 시카고 트리뷴의 잘못된 예측은 선거 전에 진행된 전화 여론조사 결과에 근거하였지만
# 당시 전화는 미국에서 부자이면서 보수적 성향을 가진 친공화당 사람들만이 
# 갖고 있었다. 
# 즉 공화당 후보를 지지하는 성향이 강한 사람들을 대상으로 여론조사를 벌인 셈이다.

# 이후로 표집 편향을 최대한 피하면서 여론조사를 진행해야 함을 인지하게 되었다.
# 물론 표집 편향이 완전히 사라졌다고는 말할 수 없다. 
# 특히 정치 관련 여론조사가 그렇다.

# ### 데이터 이해하기

# 훈련 시작 전에 데이터를 시각화 등을 이용하여 살펴보고
# 무엇을 이용하여 예측할 것인지, 특성을 어떻게 조저어할 것인지, 
# 발생할 수 있는 문제들을 예측해야 한다.

# - 이미지 또는 문장이 포함된 데이터셋이라면 샘플 몇 개를 레이블과 함께 살펴 본다.
# - 수치 특성이 포함된 경우 히스토그램 등을 그려서 값들의 범위와 빈도 등을 살펴 본다.
# - 위치 정보가  포함된 경우 지도 위에 그려서 어떤 특성이 나타나는지 확인한다.
# - 결측치가 포함된 특성이 포함된 경우 어떻게 처리할지 결정하고 처리한다.
# - 분류 문제일 경우 각 범주별 샘플 수를 확인한다. 한쪽으로 치우친 경우 이유를 확인한다.
# - 타깃에 대한 정보가 입력 데이터셋에 유입되는지 여부를 확인한다. 
#     - 환자 이력 정보를 통해 환자에게 암이 발생할 가능성을 예측하는 모델을 
#         훈련시킬 때 환자의 암 양성진단 이력 정보가 포함될 수도 있다.

# ### 모델 성능 지표 선택

# 얼마나 성공적으로 모델 훈련을 완성했는지 평가해야 한다.
# 해결해야 하는 문제에 따라 모델의 성능 지표가 달라지며,
# 모델 제작을 의뢰한 고객의 사업 성공과 밀접하게 연관된 일이기도 하다.

# 분류 모델의 경우 범주가 공평하게 나눠저 있다면 정확도와
# AUC<font size='2'>Area Under the ROC curve</font>가 성능 지표로 사용된다.
# 범주가 한 쪽으로 쏠린 경우엔 정밀도, 재현율, 가중치가 적용된 정확도와 AUC가
# 활용된다.
# 
# 또한 사용자가 직접 평가 지표를 정의해야 하는 경우도 일반적으로 발생한다.

# ## 모델 구현

# 모델 훈련에 필요한 데이터 준비하기와 완성된 모델을 시제품으로 만들어 관리 유지하는 일보다 어렵다고 말할 수는 없음에도 불구하고 대부분의 머시러닝 관련 정보는 모델 구현에 한정된다. 

# ### 데이터 준비

# 수집된 데이터를 그대로 모델 훈련에 사용하는 경우는 매우 드물다.
# 훈련시킬 모델에 맞추어 데이터셋을 전처리 해야 할 수도 있지만
# 일반적인 전처리 기법은 다음과 같다.

# 벡터화

# 신경망 모델 훈련에 사용되는 데이터는 모두 텐서 형식을 갖춰야 한다.
# 일반적으로 부동소수점으로 이루어진 텐서가 사용되며
# 경우에 따라 정수 또는 문자여로 이루어진 텐서가 사용되기도 한다.
# 
# 앞서 다룬 영화 후기 감성 분석 등의 경우처럼 단어를 정수로, 
# 정수를 원-핫 인코딩 시킨 데이터를 이용하였다.
# 
# 반면에 MNIST 데이터셋과 주택 가격 예측 데이터셋인 이미 텐서 형식이었기에
# 벡터화 과정을 생략할 수 있었다.

# 정규화

# MNIST 데이터셋은 원래 0부터 255사이의 정수로 이루어진 텐서였지만 255로 나누어
# 0과 1사이의 `float32` 부동소수점으로 이뤄진 텐서로 변환했다.
# 이처럼 입력 데이터셋 특성값들을 가능하면 아래 특성을 만족시키도록 하는 게 훈련에 도움된다.
# 
# - 대부분의 값이 0과 1사이에서 움직인다.
# - 모든 특성값이 거의 비슷한 범위(range, scale) 안에서 움직인다.
# 
# MNIST 데이터셋의 경우처럼 항상 그럴 필요는 없지만 이와 더불어 아래 조건이 만족되도록 하는 것도 일반적이다.
# 
# - 특성별 평균값이 0이다.
# - 특성법 표준편차가 1이다.

# 결측치 처리

# 일부 특성에 결측치가 존재하는 경우가 많다.
# 이럴 때 특성 자체를 제거할 수도 있지만 다른 식으로 처리할 수도 있다.
# 
# - 범주형 특성인 경우: "결측치" 여부를 알려주는 새로운 특성 추가 가능
# - 수치형 특성인 경우: 결측치를 단순히 0으로 처리하기 보다는 해당 특성의 
#     평균값 또는 중앙값으로 대체하는 것이 일반적임.
#     아니면 해당 결측치를 예측하는 모델을 훈련시킬 수도 있음.
#     
# 테스트셋 또는 실전 데이터의 일부 예상되는 특성에 결측치가 존재할 수 있다면
# 훈련도 해당 특성에 결측치가 있도록 해야 한다.
# 그렇지 않으면 테스트셋에 포함된 결측치를 모델이 제대로 
# 처리하지 못할 수 있다.

# ### 훈련중 모델 평가

# 훈련중인 모델의 일반화 성능을 검증하기 위한 평가지표를 사용한다.
# 이때 일반적으로 아래 세 가지 방식 중의 하나를 사용한다.
# 
# - 홀드아웃 검증셋 사용: 데이터셋이 큰 경우 적용
# - K-겹 교차 검증: 매우 적은 데이터셋이 주어진 경우 적용
# - 반복 K-겹 검증: 적은 양의 데이터이 주어졌을 때 높은 정확도의 모델 평가를 위해 적용
# 
# 훈련셋과 검증셋에 데이터가 중복되지 않도록 조심해야 하며
# 두 데이터셋의 대표성에 대해서 항상 신경써야 한다.

# ### 기준선 깨기

# 모델 훈련을 시작하면 우선적으로 통계적으로 의미 있는 성능을 보여줄 수 있어야 한다.
# 즉, 일단은 아직 개선의 여지가 많음에도 불구하고 통계적으로 유의미한 기준선을 넘어서는
# 성능의 모델을 훈련시킬 수 있어야 한다. 
# 이때 통계적으로 유의미한 값을 기준선 또는 베이스라인<font size='2'>baseline</font>이라 한다.

# 성능을 제대로 발휘할 수 있는 모델을 훈련시키기 위해 필요한 주요 요소는 다음 세 가지이다.
# 
# - 특성 조종<font size='2'>feature engineering</font>: 
#     별로 중요하지 않은 특성을 삭제하거나 유용하게 사용될 특성을 새로 생성해야 한다.
# - 모델 구조에 대한 사전 지식: 해결해야 하는 문제에 따라 다른 모델의 구조가 달라진다. 
#     - 밀집 연결망(densely connected network)
#     - 순환 신경망(recurrent neural network)
#     - 트랜스포머(Transformer)
#     - 딥러닝이 아닌 모델?
#     - 통계 및 확률 모델?

# **출력층의 활성화 함수와 모델의 손실 함수**

# 문제 유형에 따라 추천되는 모델의 손실 함수와 출력층의 활성화 함수는 다음과 같다.
# 
# | 문제 유형 | 출력층 활성화 함수 | 모델 손실 함수|
# | --- | --- | --- |
# | 이진 분류| `sigmoid` | `binary_crossentropy` |
# | 다중 클래스 분류 | `softmax`| `categorical_crossentropy` |
# | 다중 클래스, 다중 레이블 분류 | `sigmoid` | `binary_crossentropy` |

# **기존 유명 모델 활용**

# 대부분의 문제는 이미 대부분은 좋은 성능의 모델이 개발되어 있다.
# 
# - 스팸 감지
# - 음악 추천 엔진
# - 이미지 분류기 등등
# 
# 따라서 먼저 어떤 모델을 적용하면 좋을지 기존 모델에 대한 사전 조사를 해야 한다.

# **기준선을 깨지 못하는 경우**

# 여러 유형의 모델을 이용했음에도 불구하고 기준선을 넘어서는
# 모델을 훈련시킬 수 없는 경우 훈련셋이 부적절할 가능성이 높다.
# 즉, 모델 훈련에 사용되는 입력 데이터셋이 타깃을 예측하기에
# 충분한 정보를 제공하지 못할 가능성이 높거나
# 아니면 모델이 데이터셋에 내지된 정보를 끄집어내지 못하는 것이다.

# ### 과대적합 모델 구현

# 기준선을 넘어서는 모델을 구현한 경우 이제는 모델의 성능을 키워 과대적합을 발생시킬 수 있어야 한다.
# 모델의 성능을 키우는 일반적인 방법 세 가지는 다음과 같다.
# 
# - 층<font size='2'>layer</font> 추가
# - 층의 뉴련 수 증가
# - 에포크 수 늘리기

# 모델의 훈련셋에 대한 과대 적합은 에포크마다 평가된 검증셋에 대한 손실값과 평가지표가
# 더 이상 좋아지지 않거나 나빠지는 지점에 발생한다.
# 그런 지점을 찾게 되면 모델 훈련이 그 지점에서 멈추고 그때까지의 최고의 성능을
# 보였던 가중치를 이용하여 좋은 성능의 모델을 얻어야 한다.

# ### 모델 규제와 튜닝

# 과대 적합 모델을 구현한 후에는 일반화 성능이 가장 좋은 모델을 찾는다.
# 일반화 성능이 좋은 모델을 찾는 일반적인 기법은 다음과 같다.
# 
# - 다른 모델 아키텍처 사용: 층 추가 또는 삭제
# - 드롭아웃 적용
# - 작은 모델인 경우 L1 또는 L2 규제 적용
# - 다른 하이퍼파라미터 적용: 층의 유닛 수, 옵티마이저의 학습률 등
# - 데이터 전처리 또는 특성 조종 반복
# - 더 많은 데이터 수집과 레이블링
# 

# `KerasTuner` 등의 도구를 이용하여 모델 규제와 튜닝의 상당 부분을
# 자동화할 수 있다.

# **너무 많이 반복되는 모델 튜닝의 문제**

# 모델 튜닝을 너무 많이 반복하면 검증셋에 대한 정보가 일정 정도 모델 훈련에 흘러들어가는
# 효과가 발생한다.
# 이로 인해 결과적으로 테스트셋, 즉, 실전 데이터에 대한 성능이 상대적으로 많이
# 나쁠 수 있다.
# 
# 따라서 적절할 모델 튜닝 기법을 사용해야 하며 너무 많은 튜닝은 피해야 한다. 
# 또한 K-겹 검증과 같은 보다 신뢰할만한 검증 기법을 사용해야 한다.

# ## 모델 실전 배치

# ### 의뢰인에게 개발된 시스템의 성능 설명하기

# 머신러닝 모델을 사용하는 시스템을 완성해서 제품 의뢰인에게 인수인계하는 단계가
# 프로젝트 전체 과정의 절반을 차지할 정도로 중요하다.
# 
# 첫째, 비전문가 의뢰인이 인공지능 시스템에 대한 기대치가 너무 높다.
# 
# 마치 사람처럼 작동하는 시스템을 기대할 수 있기에 이에 대해 개발된 시스템의 
# 성능과 한계를 명확하게 보여줘야 한다.
# 예를 들어 신용카드 부정사용 분류 문제에서 사람은 구분하지만 AI는 못하는 예제를 보여주는 방식을 사용한다.
# 
# 둘째, 기존에 사람이 하던 일을 시스템으로 모두 대체할 수 있기를 기대한다.
# 
# 아직까지는 대부분의 머신러닝 모델이 기존에 사람이 하던 일을 그대로 또는 그 이상의 성능으로
# 해결하지는 못한다.
# 따라서  예를 들어 분류 모델의 98%의 정확도를 강조하기 보다는
# 5%의 거짓음성(false negative) 비율과 2.5%의 거짓양성(false positive) 비율 등을
# 언급해야 한다.
# 그러면서 평균적으로 하루에 200건 정도의 신용카드 부정사용이 발생한다고 시스템이 감지할 때
# 하루 14건 정도의 실제 부정사용을 놓치게 되고, 하루 266건 정도의 부정사용을
# 제대로 감지한게 된다고 의뢰인의 사업과 직접 연결되는 구체적인 이야기를 해야 한다.
# 
# 셋째, 제품을 실전 배치할 때 사용할 모델의 파라미터를 외뢰인과 함께 상의해야 한다.
# 
# 예를 들어, 신용카드 부정사용 감지 모델의 양성 판단 근거의 확률값 기준을 얼마로 정할지를 논의해야 한다.
# 확률값 기준을 정할 때마다 정확도, 정밀도, 재현율 등이 어떻게 달라지고
# 그에 따른 제품 활용도의 장단점을 명확히 해야 한다.

# ### 인퍼런스 모델 활용

# **인퍼런스 모델**<font size='2'>inference model</font>은
# 훈련이 완성되어 실전에서 예측을 위해 사용되는 모델을 가리킨다.
# 그런데 훈련에서 완성된 모델을 있는 그대로 실전에서 사용하는 일은 매우 드물다.
# 따라서 훈련이 완성된 모델을 환경과 여건에 따른 추가 작업을 통해
# 인퍼런스 모델로 만들어야 한다.

# 첫째, 파이썬이 이외의 언어로 모델을 내보내야 할 수도 있다.
# 
# - 모바일 앱, 임베디스 시스템 등 파이썬이 전혀 지원되지 않는 환경에서 제품이 사용될 수 있다.
# - 파이썬 아닌 다른 언어(자바스크립트, C++ 등)로 구동되는 앱에서 파이썬을 지원하려면 너무 많은 비용이 들 수 있다.

# 둘째, 훈련이 완성된 모델은 훈련이 아닌 **예측값을 생성**하는 
# **추론**<font size='2'>inference</font> 과정에서만 활용될 것이기에
# 환경과 여건에 따라 모델을 보다 빠르고 메모리 효율적으로 작동하도록 하는 
# 최적화를 진행할 수 있다.

# **모델 실전 배치 옵션**

# 모델 실전 배치 옵션은 일반적으로 다음과 같다.

# 첫째, REST API로 활용

# 서버 또는 클라우드 서비스에 텐서플로우를 설치한 후에 REST API를 이용하여
# 인퍼런스 모델을 활용한다.
# 이를 위해 Flask 또는
# [Tensorflow Serving](https://www.tensorflow.org/tfx/guide/serving) 등을 이용할 수 있다.

# :::{admonition} REST API란?
# :class: info
# 
# REST API는 ...
# :::

# 일반적으로 아래 조건이 충족되는 경우 이 방식을 사용한다.
# 
# - 빠르고 안정적인 인터넷 지원이 가능하다.
# - 실시간 활용의 경우처럼 레이턴시(빠른 반응)이 절대적일 필요는 없다.
# - 예측에 사용되는 데이터가 외부 서버에 공개될 수 있을 정도로 민감한 정보를 담지 않는다.
# 

# 머신러닝 모델이 REST API로 활용되는 일반적인 경우는 다음과 같다.
# 
# - 사진 검색 엔진 프로젝트
# - 음악 추천 시스템
# - 신용카드 부정사용 방지 프로젝트
# - 인공위성 사진 분석 프로젝트
# 
# 머신러닝 모델을 REST API로 실전배치하기 위해 개인 서버 또는 클라우드 서비스를 이용할 수 있다.
# 구글, MS, 아마존 등 많은 기업이 클라우드 서비스를 제공한다.

# 둘째, 장치에서 직접 활용

# 경우에 따라 머신러닝 모델을 특정 장치에서 직접 실행할 수도 있다.
# 
# - 스마트폰: 암호화된 이메일을 다루는 스팸 필터. 이메일이 외부에 알려지지 않아야 함.
# - 로봇의 ARM CPU
# - 작은 장치의 마이크로컨트롤러
# - 감시 카메라: 사람 또는 얼굴을 인식하는 카메라
# - 비정상 과자 탐지 모델: 생산 공정 과정에서 지체없이 비정상 과자를 탐지해야 함. 
#     이경우엔 메모리, CPU 파워, 공간 관련 제약이 없어서 훈련된 모델을 그대로 활용 가능.

# 보통 아래 상황에서 REST API 대신 직접 장치에서 활용한다.
# 
# - 모델이 빠르게 반응해야 하는 경우
# - 인터넷이 충분히 빠르지 않은 경우: 몰입형 증강 현실 앱이 외부 서버를 이용하려면 부하가 너무 커진다.
# - 메모리와 CPU 성능이 약한 장치에서도 충분히 잘 돌아갈 수 있으 정도로 모델을 충분히 작게 만들수 있는 경우.
#     [텐서플로우 모델 최적화 툴킷](https://www.tensorflow.org/model_optimization) 활용 가능.
# - 가장 높은 정확도가 반드시 필요하지 않은 경우. 
#     실행 효율성과 정확도는 서로 상충관계(trade-off)이다. 
#     메모리와 CPU 성능이 약하다면 좋은 GPU를 이용하여 훈련된 모델을 그대로 사용할 수 없다.
# - 입력 데이터가 외부에 노출되면 안된느 민감한 정보를 담고 있는 경우.

# 텐서플로우 라이트<font size='2'>TensorFlow Lite</font>를 이용하여 
# 스마트폰, 임베디드 장치에서 사용될 모델을 구현할 수 잇다.
# 
# - 안드로이드, iOS의 앱에서 작동 가능
# - ARM64 기반 컴퓨터
# - 라즈베리 파이(Raspberry Pi)
# - 마이크로 컨트롤러 일부
# 
# 케라스 모델을 TensorFlow Lite 형식으로 변환하는 것도 지원한다.

# 셋째, 웹 브라우저에서 활용

# 딥러닝 모델을 웹 브라우저에서 자바스크립트 앱으로 직접 실행할 수 있다.
# 이때 GPU를 포함하여 사용자 컴퓨터의 재원을 모두 활용한다. 
# 
# 보통 아래 상황에서 이 방식을 사용한다.
# 
# - 서버 유지/사용 비용을 대폭 줄이고자 한느 경우
# - 입력 데이터가 외부로 유출되지 않아야 하는 경우. 스팸 탐지 필터, 채팅 앱 등.
# - 매우 빠른 반응이 요구되는 경우.
# - 인터넷 연결 없이 사용하고자 하는 경우

# 하지만 아래 제약 조건이 따른다.
# 
# - 스마트폰 또는 개인 피씨에서 CPU, GPU, RAM 등에 부하를 주지 않을 정도로 가볍고 작은 모델이어야 함.
# - 누구나 사용하는 모델이기에 모델 자체가 중요한 정보를 제공하지 않는 경우. 
#     훈련된 머신러닝 모델로부터 훈련셋에 대한 정보를 어느 정도 유추해낼 수 있음.

# 자바스크립트 앱에 사용되는 모델은 TensorFlow.js를 이용하여 구현한다. 
# 케라스 모델을 간단하게 TensorFlow.js 모델로 변환할 수 있다.

# **인퍼러스 모델 최적화**

# 

# 

# 

# 

# 

# 

# 

# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:




