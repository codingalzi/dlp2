{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "(ch:fundamentals_of_ml)=\n",
    "# 머신러닝 모델 훈련법 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**감사의 글**\n",
    "\n",
    "아래 내용은 프랑소와 숄레의 \n",
    "[Deep Learning with Python(2판)](https://github.com/fchollet/deep-learning-with-python-notebooks)의 \n",
    "소스코드 내용을 참고해서 작성되었습니다.\n",
    "자료를 공개한 저자에게 진심어린 감사를 전합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스코드**\n",
    "\n",
    "여기서 언급되는 코드를\n",
    "[(구글 코랩) 머신러닝 모델 훈련법 기초](https://colab.research.google.com/github/codingalzi/dlp2/blob/master/notebooks/NB-fundamentals_of_ml.ipynb)에서 \n",
    "직접 실행할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**주요 내용**\n",
    "\n",
    "좋은 모델을 얻기 위해 알아야 할 기본 개념과 훈련법의 기초를 소개한다.\n",
    "\n",
    "- 주요 개념: 일반화 대 최적화\n",
    "- 머신러닝 모델 평가 기법\n",
    "- 모델 훈련 최적화 기법\n",
    "- 모델 일반화 성능 향상 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 머신러닝의 목표: 모델 일반화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련을 많이 할 수록 모델은 훈련 세트에 대해 보다 좋은 성능을 보이지만 새로운 데이터에 대한 \n",
    "성능은 점점 떨어지는 과대적합 현상이 언제나 발생한다. \n",
    "머신러닝 모델 훈련의 주요 과제는 모델 훈련의 **최적화**(optimization)와 \n",
    "모델 **일반화**(generalization) 사이의 관계를 적절히 조절하는 것이다.\n",
    "\n",
    "- **최적화**: 훈련 세트에 대해 가장 좋은 성능을 이끌어 내는 과정\n",
    "- **일반화**: 처음 보는 데이터를 처리하는 모델의 능력\n",
    "\n",
    "문제는 일반화는 훈련을 통해 조절할 수 있는 대상이 아니라는 점이다.\n",
    "하지만 모델 훈련 방식을 조정하면 일반화 성능을 끌어올릴 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**과소적합과 과대적합**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 과소적합\n",
    "    - 신경망이 훈련셋의 패턴을 아직 덜 파악한 상태\n",
    "    - 훈련셋과 검증셋 모두에 대해 성능이 향상되는 과정\n",
    "    - 보통 훈련 초반에 일어나는 현상.\n",
    "    - 모델 설정이 잘못된 경우에도 당연히 발생. 예를 들어, 비선형 분류 모델을 선형 모델로 훈련시키는 경우.\n",
    "\n",
    "- 과대적합\n",
    "    - 잡음, 애매한 또는 매우 특별한 특성 등 훈련셋 고유의 패턴을 학습하기 시작하는 순간 발생\n",
    "    - 새로운 데이터와 무관하거나 혼동을 주는 패턴 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/typical_overfitting.png\" style=\"width:600px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 과대적합 발생 주요 요인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과대적합을 발생시키는 요인은 크게 세 가지로 나뉜다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**_첫째, 훈련셋에 포함된 잡음_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "적절하지 않은 데이터 또는 잘못된 레이블을 갖는 데이터 등을 **잡음** 또는 **노이즈**<font size='2'>noise</font>라 부른다.\n",
    "\n",
    "- 적절하지 않은 데이터: 다음 MNNIST 이미지들처럼 불분명하면 특성 파악이 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/fucked_up_mnist.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 잘못된 레이블: 예를 들어, 잘못 분류된 1처럼 생긴 이미지를 7로 잘못 분류할 가능성이 높아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/mislabeled_mnist.png\" style=\"width:660px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잡음 등의 이상치<font size='2'>outlier</font>를 학습하면\n",
    "아래 오른편 그림의 경우처럼 모델이 이상치의 특별한 특성을 학습하게 되어\n",
    "새루운 데이터에 대한 예측 성능이 불안정해지게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/outliers_and_overfitting.png\" style=\"width:660px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**_둘째, 애매한 특성_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "잡음 등의 이상치가 전혀 없다 하더라도 특정 특성 영역에 대한 예측값이 여러 개의 값을 가질 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/iris01.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "예를 들어, 붓꽃 데이터셋의 경우 꽃잎의 길이와 너비만을 활용해서는 \n",
    "버시컬러<font size='2'>versicolor</font> 품종과 \n",
    "버지니카<font size='2'>virginica</font> 품종의 완벽한 구분이\n",
    "애초에 불가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch05/homl05-03b.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 훈련을 오래 시키면 각 샘플의 특성을 해당 레이블의 고유의 특성으로\n",
    "간주하는 정도까지 모델이 훈련되어 아래 오른편 그림과 같이\n",
    "샘플의 특성에 너무 민감하게 작동한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/HighResolutionFigures/figure_5-5.png\" style=\"width:660px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**_셋째: 특성과 타깃 사이의 거짓 상관관계_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성과 타깃 사이의 거짓 상관관계를 유발하는 여러 상황이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫째, 매우 드문 특성을 사용하는 데이터셋으로 훈련하는 경우.\n",
    "\n",
    "{numref}`%s절 <sec:imdb>`의 이진 분류 모델의 훈련에 사용된\n",
    "IMDB 데이터셋에서 매우 낮은 빈도로 사용되는 단어를 훈련셋에서 포함시키는 경우\n",
    "어쩌다 한 번 사용되는 특성으로 인해 잘못된 판단이 유발될 수 있다.\n",
    "\n",
    "예를 들어, 에쿠아도르, 페루 등 안데스 산맥 지역에서 자라는 Cherimoya(체리모야) 라는\n",
    "과일 이름이 들어간 영화 후기가 단 하나만 있으면서 마침 부정적이었다면,\n",
    "분류 모델은 Cherimoya 단어가 들어간 영화 후기를 기본적으로 부정적으로 판단할 가능이 높아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/cherimoya.jpg\" style=\"width:300px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">체리모야 열매</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇듯 매우 드문 특성은 과대적합을 유발한다. \n",
    "앞서 사용 빈도에서 10,000등 안에 드는 단어만으로 작성된 영화 후기만을 대상으로 훈련시킨 이유가\n",
    "이런 가능성을 제한하기 위해서였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "둘째, 우연에 의한 경우.\n",
    "\n",
    "자주 발생하는 특성이라 하더라도 우연히 잘못된 편견을 훈련중인 모델에 심어줄 수 있다.\n",
    "예를 들어, \"너무\" 라는 단어를 포함한 100개의 영화 후기 중에서 54%는 긍정,\n",
    "나머지 46%는 부정이었다면 훈련중인 모델은 \"너무\"라는 단어를 긍정적으로 평가할 가능성을 높힌다.\n",
    "하지만 \"너무\"라는 단어는 긍정적으로, 부정적으로 사용될 수 있기 때문에 이는 우연에 불과하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "셋째, 의미 없는 특성에 의한 경우.\n",
    "\n",
    "아래 이미지는 MNIST 데이터셋에 **백색 잡음**<font size='2'>white noise</font>이 추가된 경우와\n",
    "단순히 여백이 추가된 경우의 훈련 샘플을 보여준다.\n",
    "\n",
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch05-mnist-noise.png\" style=\"width:400px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "백색 잡음이 포함된 샘플들의 데이터셋으로 훈련시킨 모델과\n",
    "단순한 여백이 추가된 샘플들의 데이터셋으로 훈련시킨 모델의 성능을 비교하면\n",
    "백색 잡음이 포함된 훈련셋을 이용한 모델의 성능이 1% 정도 떨어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch05-mnist-noise03.png\" style=\"width:400px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이유는 모델이 백색 잡음에 특별한 의미를 부여하기 때문이며, 이로 인해 과대적합이\n",
    "보다 쉽게 발생한다.\n",
    "따라서 보다 효율적인 훈련을 위해 백색 잡음 등 과대적합을 유발하는\n",
    "특성을 미리 제거하여 모델에 유용한 특성만을 훈련에 사용해야 한다.\n",
    "하지만 유용한 특성을 선택하는 일이 기본적으로 불가능하거나 매우 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 백색 잡음\n",
    ":class: info\n",
    "\n",
    "프로그래밍 분야에서 백색 잡음<font size='2'>white noise</font>은\n",
    "**무작위적으로 생성되었지만 전 영역에 걸쳐 고르게 퍼진 데이터셋**을 의미한다.\n",
    "백색 잡음이 다른 데이터와 섞일 경우 백색 잡음을 분리하는 것은 원천적으로 불가능하다.\n",
    "백색 잡음을 백색 소음 또는 화이트 노이즈라 부르기도 한다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 딥러닝 모델 일반화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(딥러닝) 모델이 훈련 중에 보지 못한 완전히 새로운 데이터에 대해 예측하는 것을 \n",
    "**일반화**<font size='2'>generalization</font>라고 한다.\n",
    "그런데 모델의 일반화 능력은 모델의 훈련 과정에 별 상관이 없다.\n",
    "이유는 훈련을 통해 모델의 일반화 능력을 조절할 수 있는 방법이 없기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로 딥러닝 모델은 어떤 무엇도 학습할 수 있다.\n",
    "예를 들어 MNIST 모델을 임의로 섞은 레이블과 함께 훈련시키면\n",
    "훈련셋에 대한 성능은 훈련하면서 계속 향상되어 결국\n",
    "모델은 모든 답을 외워버리는 정도에 다달한다.\n",
    "물론 검증셋에 성능은 전혀 향상되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch05-mnist-shuffled.png\" style=\"width:400px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "위 결과는 다음을 의미한다.\n",
    "\n",
    "- 일반화는 모델 훈련 과정 중에 제어할 수 있는 대상이 아니다. \n",
    "- 모델 훈련을 통해 할 수 있는 것은 주어진 훈련 데이터셋에 모델이 적응하도록 하는 것 뿐이다.\n",
    "- 딥러닝 모델은 어떤 데이터셋에도 적응할 수 있기에 \n",
    "    너무 오래 훈련시키면 과대적합은 반드시 발생하고 일반화는 어려워진다. \n",
    "- 모델의 **일반화** 능력은 모델 자체보다는 **훈련셋에 내재하는 정보의 구조**와 \n",
    "    보다 밀접히 관련된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**다양체 가설**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다양체 가설**<font size='2'>manifold hypothesis</font>은 \n",
    "데이터셋에 내재하는 정보의 구조에 대한 다음과 같은 가설이다.\n",
    "\n",
    "> 일반적인 데이터셋은 고차원상에 존재하는 (저차원의) 연속이며 미분가능한 다양체를 구성한다.\n",
    "\n",
    "그리고 모델 훈련은 바로 이 다양체를 찾아가는 과정이다. \n",
    "\n",
    "**참고**: 이런 의미에서 무작위로 섞은 레이블을 사용하는 위 MNIST 예제는 일반적인 데이터셋이 될 수 없다. \n",
    "\n",
    "아래 이미지는 3차원 공간에 존재하는 2차원 다양체를 고차원 상의 다양체로 변환하여 선형 분류가 가능한\n",
    "데이터셋을 구성하는 과정을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch08/homl08-13.png\" style=\"width:550px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://github.com/ageron/handson-ml2\">핸즈온 머신러닝(2판), 8장</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "다양체 가설을 이용하면 적절하게 구성된 모델이 적절한 훈련셋으로 훈련받았을 때 새로운 데이터에 대해 적절한 예측을 할 수 있는 이유를 설명할 수 있다.\n",
    "즉, 모델이 찾은 연속이며 미분가능한 다양체와 학습된 데이터 정보에 **보간법**을 적용하여 새로운 데이터에 대해 예측을 실행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**보간법**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**보간법**(interpolation)은 모델 훈련에 사용된 훈련셋의 데이터와 새로운 데이터를 연결하는 \n",
    "다양체 상의 경로를 이용하여 예측값을 실행하는 것을 의미한다. \n",
    "보다 큰 훈련셋을 사용할 수록 보간법이 보다 잘 작동하지만 \n",
    "**차원의 저주**(curse of dimensions)로 인해 충분한 크기의 훈련셋 구하기가 \n",
    "일반적으로 불가능하거나 매우 어렵다. \n",
    "    \n",
    "**참고**: 사람은 보간법 이외의 다른 능력을 사용하여 사물 예측과 구분, 주변 파악, 상황 판단 등 \n",
    "일반화를 실행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/dense_sampling.png\" style=\"width:660px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**충분치 않은 훈련셋과 정규화**\n",
    "\n",
    "충분히 큰 훈련셋을 준비하지 못하면 예측 과정에서 과대한 추측을 하게되어 과대적합이 발생할 가능성이 높다.\n",
    "이를 방지하기 위해 일반적으로 두 가지 방법을 사용한다.\n",
    "\n",
    "- 모델에 저장되는 정보를 적절하게 조정하기\n",
    "- 모델이 생성하는 다양체의 곡률 완화\n",
    "\n",
    "위 두 방법을 통해 데이터셋의 너무 세세한 패턴 보다는 가장 눈에 띄는 핵심적인 패턴에 모델이 집중하도록 한다.\n",
    "이런식으로 과대적합을 방지하여 일반화를 향상시키는 기법을 **정규화**(regularization)이라 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 5.2 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 일반화 능력을 향상시키려면 주어진 모델의 일반화 능력을 평가할 수 있어야 하며,\n",
    "이를 위해 데이터셋을 훈련셋, 검증셋, 테스트셋으로 구분하는 이유를 먼저 알아야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 튜닝과 정보 유출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋, 테스트셋 이외에 검증셋을 사용해야 하는 이유는 \n",
    "무엇보다도 **최적의 모델을 구성할 때 검증셋에 대한 결과가 반영되기 때문**이다. \n",
    "\n",
    "테스트셋은 모델 구성과 훈련에 전혀 관여하지 않아야 한다.\n",
    "따라서 구성된 모델의 성능을 평가하려면 테스트셋을 제외한 다른 데이터셋이 필요하고\n",
    "이를 위해 훈련셋의 일부를 검증셋으로 활용한다.\n",
    "검증셋은 훈련 과정 중에 일반화 성능을 테스트하는 용도로 사용되며\n",
    "이를 통해 레이어 종류 및 개수, 레이어 별 유닛 개수 등 모델 구성에 필요한\n",
    "**하이퍼파라미터**(hyperparameter)를 조정한다. \n",
    "이것을 **모델 튜닝**(model tuning)이라 하며,\n",
    "바로 이 모델 튜닝을 위해 검증셋이 사용되는 것이다. \n",
    "\n",
    "모델 튜닝도 모델의 좋은 하이퍼파라미터를 찾아가는 일종의 **학습**이다. \n",
    "따라서 튜닝을 많이 하게되면 검증셋에 대한 과대적합이 발생한다.\n",
    "다시 말해, 검증셋에 특화된 튜닝을 하게 되어 모델의 일반화 성능이 떨어질 수 있게 된다. \n",
    "이런 현상을 **정보 유출**이라 부르는데,\n",
    "이유는 튜닝을 하면 할 수록 검증셋에 대한 보다 많은 정보가 모델로 흘려들어가기 때문이다. \n",
    "\n",
    "**참고**: 하이퍼파라미터와 파라미터는 다르다. \n",
    "파라미터(parameter)는 모델 훈련 중에 학습되는 가중치, 편향 등을 가리킨다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련셋, 검증셋, 테스트셋 분류 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋을 훈련셋, 검증셋, 테스트셋으로 분류하여 모델을 훈련을 진행하는\n",
    "전형적인 방식 세 가지를 소개한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 홀드아웃(hold-out) 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋의 일부를 검증셋으로 사용하는 가장 일반적인 방법이며,\n",
    "모델 훈련 후에 테스트셋을 이용하여 모델의 일반화 성능을 확인한다.\n",
    "하지만 그 이후에 모델 튜닝을 진행하지 않아야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/holdout_validation.png\" style=\"width:400px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "홀드아웃 검증의 전형적인 패턴은 다음과 같다.\n",
    "\n",
    "---\n",
    "```python\n",
    "num_validation_samples = 10000\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_data = data[:num_validation_samples]\n",
    "training_data = data[num_validation_samples:]\n",
    "\n",
    "model = get_model()\n",
    "model.fit(training_data, ...)\n",
    "\n",
    "validation_score = model.evaluate(validation_data, ...)\n",
    "\n",
    "...\n",
    "\n",
    "model = get_model()\n",
    "model.fit(np.concatenate([training_data,\n",
    "                          validation_data]), ...)\n",
    "\n",
    "test_score = model.evaluate(test_data, ...)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-겹 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 성능이 사용되는 훈련셋에 따라 심하게 달라질 때 추천되는 검증기법이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/k_fold_validation.png\" style=\"width:650px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-겹 교차검증의 전형적인 패턴은 다음과 같다.\n",
    "\n",
    "---\n",
    "```python\n",
    "k = 3\n",
    "num_validation_samples = len(data) // k\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_scores = []\n",
    "\n",
    "for fold in range(k):\n",
    "    validation_data = data[num_validation_samples * fold:\n",
    "                           num_validation_samples * (fold + 1)]\n",
    "    training_data = np.concatenate(\n",
    "        data[:num_validation_samples * fold],\n",
    "        data[num_validation_samples * (fold + 1):])\n",
    "    \n",
    "    model = get_model()\n",
    "    model.fit(training_data, ...)\n",
    "    \n",
    "    validation_score = model.evaluate(validation_data, ...)\n",
    "    validation_scores.append(validation_score)\n",
    "\n",
    "validation_score = np.average(validation_scores)\n",
    "\n",
    "model = get_model()\n",
    "model.fit(data, ...)\n",
    "\n",
    "test_score = model.evaluate(test_data, ...)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 반복 K-겹 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋의 크기가 너무 작거나 모델의 성능을 최대한 정확하게 평가하기 위해 사용된다.\n",
    "K-겹 교차검증을 여러 번 실행한다. 대신 매번 훈련셋을 무작위로 섞은 뒤에\n",
    "교차검증을 실행한다. \n",
    "최종 결과는 각 교차검증의 평균값을 사용한다. \n",
    "훈련 시간이 매우 오래 걸린다는 게 이 방법의 단점이다. \n",
    "K-겹 교차 검증을 P번 반복하면 총 `P * K` 개의 모델을 훈련시키게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 성능 평가의 기준선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련이 시작되면 평가지표(metrics)를 지켜보는 일 이외에 할 수 있는 게 없다.\n",
    "따라서 검증셋에 대한 평가지표가 특정 기준선 이상인지를 아는 게 매우 중요하다.\n",
    "\n",
    "기준선 예제\n",
    "\n",
    "- MNIST 데이터셋: 10%의 정확도\n",
    "- IMDB 데이터셋: 50%의 정확도\n",
    "- 로이터 통신 기사: 18-19의 정확도. 이런 경우 정밀도 등 정확도 이외의 다른 평가기준도 고려 가능.\n",
    "\n",
    "기준선을 넘는 모델을 생성하는 것이 기본 목표이어야 함.\n",
    "그렇지 않다면 무언가 잘못된 모델을 또는 잘못된 접근법을 사용하고 있을 가능성이 큼."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 준비 관련 주의사항"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적화된 모델 훈련을 위해 아래 세 가지 사항을 준수하며 훈련셋, 검증셋, 테스트셋을 \n",
    "준비해야 한다. \n",
    "\n",
    "- **대표성**: 일반적으로 데이터셋을 무작위로 섞어 레이블이 적절한 비율로 섞인 \n",
    "    훈련셋, 검증셋, 테스트셋을 구성해야 한다.\n",
    "- **시간의 흐름**: 미래를 예측하는 모델을 훈련시킬 때, 테스트셋의 데이터는 훈련셋의 데이터보다\n",
    "    시간상 뒤쪽에 위치하도록 해야 한다. 그렇지 않으면 미래 정보가 모델에 유출된다.\n",
    "    즉, 데이터를 무작위로 섞어 훈련셋과 테스트셋으로 구분하는 일은 하지 않아야 한다. \n",
    "- **중복 데이터 제거**: 훈련셋과 테스트셋에 동일한 데이터가 들어가지 않도록 중복 데이터를 제거해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 5.3 모델 훈련 개선법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련을 최적화하려면 먼저 과대적합을 달성해야 한다.\n",
    "이유는 과대적합이 나타나야만 과대적합의 경계를 알아내서 모델 훈련을\n",
    "언제 멈추어야 하는지 알 수 있기 때문이다. \n",
    "일단 과대적합의 경계를 찾은 다음에 일반화 성능을 목표로 삼아야 한다.\n",
    "\n",
    "모델 훈련 중에 발생하는 문제는 크게 세 종류이다. \n",
    "\n",
    "- 첫째, 훈련셋의 손실값이 줄어들지 않아 훈련이 제대로 진행되지 않는 경우\n",
    "- 둘째, 훈련셋의 손실값은 줄어들지만 검증셋의 성능은 평가 기준선을 넘지 못하는 경우\n",
    "- 셋째, 훈련셋과 검증셋의 평가가 기준선을 넘어 계속 좋아지지만 과대적합이 발생하지 않는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 첫째 경우: 경사하강법 관련 파라미터 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋의 손실값이 줄어들지 않거나 진동하는 등 훈련이 제대로 이루어지지 않는 경우는\n",
    "기본적으로 학습률과 배치 크기를 조절하면 해결된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**MNIST 모델 훈련: 매우 큰 학습률 사용**\n",
    "\n",
    "- 학습률: 1 (옵티마이저의 옵션에서 지정)\n",
    "- 훈련셋/검증셋에 대한 정확도가 30% 수준에 머무름."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1052.2745 - accuracy: 0.3604 - val_loss: 2.0373 - val_accuracy: 0.2853\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.9106 - accuracy: 0.2501 - val_loss: 2.0671 - val_accuracy: 0.2453\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.9203 - accuracy: 0.2402 - val_loss: 2.1236 - val_accuracy: 0.2192\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.5024 - accuracy: 0.2362 - val_loss: 2.3967 - val_accuracy: 0.2854\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.6780 - accuracy: 0.2364 - val_loss: 2.1830 - val_accuracy: 0.2910\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.8584 - accuracy: 0.2582 - val_loss: 2.4019 - val_accuracy: 0.2674\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.5525 - accuracy: 0.2406 - val_loss: 2.4998 - val_accuracy: 0.2412\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.4591 - accuracy: 0.2324 - val_loss: 2.1182 - val_accuracy: 0.2267\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3558 - accuracy: 0.2535 - val_loss: 2.7957 - val_accuracy: 0.2347\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.4698 - accuracy: 0.2403 - val_loss: 2.1845 - val_accuracy: 0.2557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa39afa9910>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1.),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-03.png\" style=\"width:550px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://github.com/ageron/handson-ml2\">핸즈온 머신러닝(2판), 4장</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**MNIST 모델 훈련: 매우 작은 학습률 사용**\n",
    "\n",
    "- 학습률: 0.000001\n",
    "- 검증셋에 대한 정확도가 느리게 증가함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.2697 - accuracy: 0.1516 - val_loss: 2.2277 - val_accuracy: 0.1837\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.1804 - accuracy: 0.2286 - val_loss: 2.1383 - val_accuracy: 0.2746\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.0952 - accuracy: 0.3267 - val_loss: 2.0523 - val_accuracy: 0.3807\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.0135 - accuracy: 0.4342 - val_loss: 1.9703 - val_accuracy: 0.4834\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.9346 - accuracy: 0.5261 - val_loss: 1.8906 - val_accuracy: 0.5653\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.8583 - accuracy: 0.5959 - val_loss: 1.8137 - val_accuracy: 0.6258\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.7843 - accuracy: 0.6465 - val_loss: 1.7392 - val_accuracy: 0.6702\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.7130 - accuracy: 0.6817 - val_loss: 1.6672 - val_accuracy: 0.6997\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.6439 - accuracy: 0.7096 - val_loss: 1.5978 - val_accuracy: 0.7258\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.5774 - accuracy: 0.7293 - val_loss: 1.5310 - val_accuracy: 0.7443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa385497250>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-6),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-02.png\" style=\"width:550px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://github.com/ageron/handson-ml2\">핸즈온 머신러닝(2판), 4장</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**MNIST 모델 훈련: 적절한 학습률 사용**\n",
    "\n",
    "- 학습률: 0.01\n",
    "- 제대로 훈련됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3792 - accuracy: 0.9103 - val_loss: 0.1304 - val_accuracy: 0.9647\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1415 - accuracy: 0.9639 - val_loss: 0.1536 - val_accuracy: 0.9676\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1131 - accuracy: 0.9730 - val_loss: 0.2516 - val_accuracy: 0.9557\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0985 - accuracy: 0.9783 - val_loss: 0.2125 - val_accuracy: 0.9607\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0838 - accuracy: 0.9819 - val_loss: 0.1953 - val_accuracy: 0.9707\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0710 - accuracy: 0.9849 - val_loss: 0.2379 - val_accuracy: 0.9707\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0726 - accuracy: 0.9860 - val_loss: 0.2317 - val_accuracy: 0.9747\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0578 - accuracy: 0.9883 - val_loss: 0.3087 - val_accuracy: 0.9679\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0568 - accuracy: 0.9899 - val_loss: 0.2731 - val_accuracy: 0.9736\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0609 - accuracy: 0.9901 - val_loss: 0.3032 - val_accuracy: 0.9721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3841ca210>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-01.png\" style=\"width:550px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://github.com/ageron/handson-ml2\">핸즈온 머신러닝(2판), 4장</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**배치 크기 조정**\n",
    "\n",
    "- 학습률 이외에 배치크기를 키우면 보다 안정적으로 훈련이 됨. 단, 계산량이 많아질 수 있음.\n",
    "- 아래 그림에서 확인할 수 있듯이, 배치 크기가 클 수록 보다 일관되게 학습됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-05.png\" style=\"width:550px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://github.com/ageron/handson-ml2\">핸즈온 머신러닝(2판), 4장</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 둘째 경우: 보다 적절한 모델 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련은 잘 진행되는데 검증셋에 대한 성능이 좋아지지 않는다면 다음 두 가지 경우를 의심해 보아야 한다. \n",
    "\n",
    "- 좋은 예측값을 구성할 정도로 충분한 정보가 훈련셋에 담겨있지 않는 경우\n",
    "    - 예제: 레이블이 무작위로 섞인 MNIST 데이터셋\n",
    "- 사용하는 모델이 적절하지 않은 경우\n",
    "    - 예제: 선형 분류가 불가능한 데이터셋에 선형분류 모델을 적용하는 경우\n",
    "    - 예제: 시계열 데이터 분석에 앞서 살펴본 `Sequential` 모델을 사용하는 경우(나중에 확인할 것임)\n",
    "    \n",
    "기본적으로, 문제 해결을 위한 적절한 가정을 사용하는 모델을 훈련시켜야 한다.\n",
    "앞으로 다양한 문제에 적용되는 다양한 모델 구성과 훈련을 살펴볼 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셋째 경우: 모델의 저장 능력 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 훈련셋/검증셋의 평가지표가 계속 향상되지만 과대적합이 발생하지 않는 경우 \n",
    "기본적으로 모델의 정보 저장 능력을 키워야 한다. \n",
    "\n",
    "먼저 아래 예제를 살펴보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**MNIST 데이터셋 다중클래스 분류: 매우 단순한 모델**\n",
    "\n",
    "- 은닉층이 없이 출력층 하나만 사용하는 매우 단순한 모델.\n",
    "- 검증셋의 정확도: 93% 정도에서 정체\n",
    "- 검증셋의 손실값: 0.25 이하로 내려가지 않음.\n",
    "\n",
    "결론적으로 모델의 정보 저장/분석 능력이 떨어진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.6539 - accuracy: 0.8410 - val_loss: 0.3580 - val_accuracy: 0.9057\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 0s 794us/step - loss: 0.3504 - accuracy: 0.9039 - val_loss: 0.3074 - val_accuracy: 0.9145\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 0s 868us/step - loss: 0.3152 - accuracy: 0.9126 - val_loss: 0.2907 - val_accuracy: 0.9184\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 0s 796us/step - loss: 0.2994 - accuracy: 0.9170 - val_loss: 0.2811 - val_accuracy: 0.9213\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 0s 788us/step - loss: 0.2896 - accuracy: 0.9194 - val_loss: 0.2757 - val_accuracy: 0.9234\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 0s 829us/step - loss: 0.2832 - accuracy: 0.9214 - val_loss: 0.2719 - val_accuracy: 0.9248\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2784 - accuracy: 0.9229 - val_loss: 0.2705 - val_accuracy: 0.9260\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 0s 773us/step - loss: 0.2741 - accuracy: 0.9237 - val_loss: 0.2677 - val_accuracy: 0.9266\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 0s 795us/step - loss: 0.2715 - accuracy: 0.9249 - val_loss: 0.2655 - val_accuracy: 0.9277\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 0s 801us/step - loss: 0.2689 - accuracy: 0.9253 - val_loss: 0.2642 - val_accuracy: 0.9294\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 0s 784us/step - loss: 0.2667 - accuracy: 0.9270 - val_loss: 0.2647 - val_accuracy: 0.9289\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 0s 790us/step - loss: 0.2649 - accuracy: 0.9272 - val_loss: 0.2628 - val_accuracy: 0.9287\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 0s 836us/step - loss: 0.2635 - accuracy: 0.9276 - val_loss: 0.2626 - val_accuracy: 0.9291\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 0s 874us/step - loss: 0.2619 - accuracy: 0.9283 - val_loss: 0.2614 - val_accuracy: 0.9296\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 0s 776us/step - loss: 0.2605 - accuracy: 0.9286 - val_loss: 0.2618 - val_accuracy: 0.9302\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 0s 780us/step - loss: 0.2595 - accuracy: 0.9287 - val_loss: 0.2607 - val_accuracy: 0.9293\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 0s 796us/step - loss: 0.2586 - accuracy: 0.9293 - val_loss: 0.2622 - val_accuracy: 0.9303\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 0s 798us/step - loss: 0.2571 - accuracy: 0.9298 - val_loss: 0.2624 - val_accuracy: 0.9294\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 0s 817us/step - loss: 0.2568 - accuracy: 0.9306 - val_loss: 0.2607 - val_accuracy: 0.9305\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 0s 789us/step - loss: 0.2556 - accuracy: 0.9304 - val_loss: 0.2611 - val_accuracy: 0.9310\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history_small_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa373fde310>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val_loss = history_small_model.history[\"val_loss\"]\n",
    "epochs = range(1, 21)\n",
    "\n",
    "plt.plot(epochs, val_loss, \"b--\",\n",
    "         label=\"Validation loss\")\n",
    "\n",
    "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**MNIST 데이터셋 다중클래스 분류: 보다 많은 저장/분석/표현 능력 모델**\n",
    "\n",
    "- 두 개의 은닉층: 96개의 많은 유닛 사용\n",
    "\n",
    "잘 훈련되며 과대적합이 발생한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3575 - accuracy: 0.9004 - val_loss: 0.1841 - val_accuracy: 0.9461\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.9528 - val_loss: 0.1372 - val_accuracy: 0.9600\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9656 - val_loss: 0.1214 - val_accuracy: 0.9640\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9734 - val_loss: 0.1049 - val_accuracy: 0.9674\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.9785 - val_loss: 0.1073 - val_accuracy: 0.9704\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9831 - val_loss: 0.0958 - val_accuracy: 0.9728\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0472 - accuracy: 0.9857 - val_loss: 0.0931 - val_accuracy: 0.9729\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0400 - accuracy: 0.9873 - val_loss: 0.0988 - val_accuracy: 0.9732\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9894 - val_loss: 0.0975 - val_accuracy: 0.9752\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.1008 - val_accuracy: 0.9754\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 0.1103 - val_accuracy: 0.9727\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.1063 - val_accuracy: 0.9741\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.1153 - val_accuracy: 0.9737\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 0.1081 - val_accuracy: 0.9772\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.1345 - val_accuracy: 0.9728\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.1362 - val_accuracy: 0.9732\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.1327 - val_accuracy: 0.9736\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.1242 - val_accuracy: 0.9777\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.1291 - val_accuracy: 0.9761\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1379 - val_accuracy: 0.9747\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_large_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 에포크 정도 지나면서 일반화 성능이 떨어진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa3d8b79c90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val_loss = history_large_model.history[\"val_loss\"]\n",
    "epochs = range(1, 21)\n",
    "\n",
    "plt.plot(epochs, val_loss, \"b--\",\n",
    "         label=\"Validation loss\")\n",
    "\n",
    "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 5.4 일반화 향상법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련이 어느 정도 잘 진행되어 일반화 성능이 향상되고 과대적합이 발생하기 시작하면\n",
    "일반화를 극대화하는 방법에 집중해야 한다.\n",
    "이를 위해 아래 요소들이 제대로 작동하는지 확인해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- 데이터셋 큐레이션\n",
    "- 특성 추출\n",
    "- 조기 종료\n",
    "- 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 데이터셋 큐레이션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "양질의 데이터셋을 모델 훈련에 사용해야 모델이 \n",
    "데이터셋에 잠재되어 있는 다양체를 보다 잘 찾아낼 수 있다. \n",
    "양질의 데이터를 보다 많이 수집하는 일이 보다 적절한 모델을 찾으려는 노력보다\n",
    "값어치가 높다. \n",
    "\n",
    "양질의 데이터의 기준은 다음과 같다.\n",
    "\n",
    "- 충분한 양의 샘플(dense sampling): 훈련셋이 크면 클 수록 일반화 성능이 좋아짐.\n",
    "- 레이블링 오류 최소화: 시각화를 통한 특이 사항 파악\n",
    "- 데이터 클리닝과 결측치 처리(나중에 자세히 다룸)\n",
    "- 유용한 특성 선택: 특성 수 감축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 특성 공학"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 모델은 데이터셋에 잠재되어 있는 다양체를 찾기 위해 \n",
    "여러 층을 통해 데이터셋의 표현을 다양한 방식으로 변환시킨다.\n",
    "그렇게 해서 변환된 데이터셋의 표현들에 내재된 보다 쉽게 다양체를 찾아낸다. \n",
    "\n",
    "심층 신경망을 이용하는 이유가 모델 스스로 좋은 표현을 찾아내라고 유도하는 데에 있다.\n",
    "즉, 모델 훈련에 가장 유용한 특성을 모델 스스로 직접 구성하도록 한다.\n",
    "이런 점에서 적절한 심층 신경망을 구성하는 일이 중요하며\n",
    "앞으로 다양한 문제를 다루면서 다양한 모델 구성과 훈련을 살펴볼 것이다.\n",
    "\n",
    "그럼에도 불구하고 모델 훈련 시작 전에 유용한 특성으로 이루어진 데이터셋으로\n",
    "변환할 수 있다면 모델의 성능을 더더욱 높일 수 있다.\n",
    "\n",
    "- 모델 훈련이 보다 효율적으로 진행된다.\n",
    "- 보다 적은 데이터를 이용하여 좋은 모델을 훈련할 수 있다.\n",
    "\n",
    "이처럼 모델 훈련에 가장 유용한 특성을 구성하는 작업을 **특성 공학**(feature engineering)이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 조기 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련 중에 검증셋에 대한 성능이 더 이상 좋아지지 않는 순간에 모델 훈련을 멈추는 것이 \n",
    "**조기 종료**(early stopping)이다.\n",
    "이를 위해 에포크마다 모델의 성능을 측정하여 가장 좋은 성능의 모델을 기억해 두고,\n",
    "더 이상 좋아지지 않으면 그때까지의 최적 모델을 사용하도록 한다. \n",
    "\n",
    "케라스의 경우 `EarlyStopping` 이라는 콜백(callback) 객체를 사용하면 조기 종료 기능을\n",
    "자동으로 수행한다. 콜백에 대해서는 나중에 자세히 다룬다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 중이 모델이 데이터셋에 너무 민감하지 않게 유도하는 것을 **규제**(regularization)라 부른다.\n",
    "즉, 모델 훈련에 규제를 가하여 모델을 보다 더 균형 있고 규칙적으로 예측하도록 유도하여\n",
    "모델의 일반화 성능을 높힌다. \n",
    "\n",
    "여기서는 모델에 규제를 가하는 세 가지 기법을 IMDB 데이터셋을 이용하여 소개한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 규제 기법 1: 신경망 크기 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 보았듯이 모델을 층, 유닛의 수를 줄여 모델을 단순화 하면 \n",
    "과대적합이 없거나 줄어든다. \n",
    "이유는 모델에 저장될 수 있는 정보량이 줄어들어 세세한 정보를 낱낱이 기억하기 보다는\n",
    "보다 압축된 정보를 활용하도록 유도된다. \n",
    "\n",
    "모델이 너무 단순하면 아예 훈련이 제대로 되지 않을 수 있기에 적절하게 줄이도록 해야 한다.\n",
    "하지만 이에 대한 이론적 기준은 없으며 실험을 통해 적절한 규제를 찾아내야 한다.\n",
    "보통 적은 수의 층과 유닛을 사용하다가 점차 수를 늘려 나가는 것이 좋다.\n",
    "\n",
    "아래 코드는 이전에 다루었던 IMDB 데이터셋을 이용한 모델 훈련이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 2s 39ms/step - loss: 0.5153 - accuracy: 0.7932 - val_loss: 0.3933 - val_accuracy: 0.8561\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3084 - accuracy: 0.9007 - val_loss: 0.3137 - val_accuracy: 0.8775\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2268 - accuracy: 0.9273 - val_loss: 0.2898 - val_accuracy: 0.8855\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1800 - accuracy: 0.9407 - val_loss: 0.2806 - val_accuracy: 0.8873\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1465 - accuracy: 0.9526 - val_loss: 0.2760 - val_accuracy: 0.8898\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1238 - accuracy: 0.9620 - val_loss: 0.2993 - val_accuracy: 0.8831\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1025 - accuracy: 0.9699 - val_loss: 0.3030 - val_accuracy: 0.8853\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0886 - accuracy: 0.9744 - val_loss: 0.3294 - val_accuracy: 0.8827\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0724 - accuracy: 0.9807 - val_loss: 0.3431 - val_accuracy: 0.8812\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0627 - accuracy: 0.9832 - val_loss: 0.3993 - val_accuracy: 0.8739\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0505 - accuracy: 0.9873 - val_loss: 0.3978 - val_accuracy: 0.8765\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0426 - accuracy: 0.9895 - val_loss: 0.4389 - val_accuracy: 0.8716\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0359 - accuracy: 0.9922 - val_loss: 0.5083 - val_accuracy: 0.8636\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0290 - accuracy: 0.9936 - val_loss: 0.4953 - val_accuracy: 0.8722\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9956 - val_loss: 0.5164 - val_accuracy: 0.8709\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9965 - val_loss: 0.5585 - val_accuracy: 0.8672\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9967 - val_loss: 0.5876 - val_accuracy: 0.8676\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0124 - accuracy: 0.9984 - val_loss: 0.6221 - val_accuracy: 0.8671\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0099 - accuracy: 0.9990 - val_loss: 0.6640 - val_accuracy: 0.8660\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.6946 - val_accuracy: 0.8651\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "train_data = vectorize_sequences(train_data)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history_original = model.fit(train_data, train_labels,\n",
    "                             epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "은닉층의 유닛수를 4로 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.6269 - accuracy: 0.6606 - val_loss: 0.5702 - val_accuracy: 0.7327\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5360 - accuracy: 0.7881 - val_loss: 0.5297 - val_accuracy: 0.7474\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4868 - accuracy: 0.8447 - val_loss: 0.4943 - val_accuracy: 0.8366\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4519 - accuracy: 0.8819 - val_loss: 0.4754 - val_accuracy: 0.8583\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4253 - accuracy: 0.9059 - val_loss: 0.4696 - val_accuracy: 0.8405\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4037 - accuracy: 0.9209 - val_loss: 0.4668 - val_accuracy: 0.8411\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3857 - accuracy: 0.9339 - val_loss: 0.4619 - val_accuracy: 0.8470\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3690 - accuracy: 0.9436 - val_loss: 0.4556 - val_accuracy: 0.8569\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3540 - accuracy: 0.9533 - val_loss: 0.4547 - val_accuracy: 0.8581\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.3408 - accuracy: 0.9603 - val_loss: 0.4411 - val_accuracy: 0.8714\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3277 - accuracy: 0.9663 - val_loss: 0.4443 - val_accuracy: 0.8706\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3165 - accuracy: 0.9698 - val_loss: 0.4481 - val_accuracy: 0.8667\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3055 - accuracy: 0.9738 - val_loss: 0.4918 - val_accuracy: 0.8433\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2958 - accuracy: 0.9760 - val_loss: 0.4629 - val_accuracy: 0.8599\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2862 - accuracy: 0.9791 - val_loss: 0.4644 - val_accuracy: 0.8621\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2772 - accuracy: 0.9811 - val_loss: 0.5123 - val_accuracy: 0.8446\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2687 - accuracy: 0.9827 - val_loss: 0.5035 - val_accuracy: 0.8512\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2609 - accuracy: 0.9839 - val_loss: 0.4909 - val_accuracy: 0.8582\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2533 - accuracy: 0.9851 - val_loss: 0.4597 - val_accuracy: 0.8702\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2456 - accuracy: 0.9871 - val_loss: 0.5346 - val_accuracy: 0.8496\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history_smaller_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 모델과의 차이점은 다음과 같다.\n",
    "\n",
    "- 기존 모델보다 과대적합이 늦게 발생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/original_model_vs_smaller_model_imdb.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "이번엔 유닛 수를 크게 늘려보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 3s 88ms/step - loss: 0.5572 - accuracy: 0.7635 - val_loss: 0.3305 - val_accuracy: 0.8637\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.2560 - accuracy: 0.8967 - val_loss: 0.2690 - val_accuracy: 0.8922\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.1563 - accuracy: 0.9407 - val_loss: 0.3348 - val_accuracy: 0.8725\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0597 - accuracy: 0.9795 - val_loss: 0.3978 - val_accuracy: 0.8843\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.1047 - accuracy: 0.9769 - val_loss: 0.3745 - val_accuracy: 0.8896\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.5210 - val_accuracy: 0.8879\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.1402 - accuracy: 0.9781 - val_loss: 0.4680 - val_accuracy: 0.8837\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.5193 - val_accuracy: 0.8873\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 2.9514e-04 - accuracy: 1.0000 - val_loss: 0.6106 - val_accuracy: 0.8876\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 7.8052e-05 - accuracy: 1.0000 - val_loss: 0.7125 - val_accuracy: 0.8858\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 1.7741e-05 - accuracy: 1.0000 - val_loss: 0.8122 - val_accuracy: 0.8856\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 6.3514e-06 - accuracy: 1.0000 - val_loss: 2.5362 - val_accuracy: 0.7682\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.2807 - accuracy: 0.9818 - val_loss: 0.7594 - val_accuracy: 0.8817\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 2.6955e-05 - accuracy: 1.0000 - val_loss: 0.7704 - val_accuracy: 0.8829\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 1.2987e-05 - accuracy: 1.0000 - val_loss: 0.7956 - val_accuracy: 0.8840\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 6.7362e-06 - accuracy: 1.0000 - val_loss: 0.8395 - val_accuracy: 0.8844\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 3.1351e-06 - accuracy: 1.0000 - val_loss: 0.8974 - val_accuracy: 0.8858\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 1.2273e-06 - accuracy: 1.0000 - val_loss: 0.9698 - val_accuracy: 0.8868\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 4.4466e-07 - accuracy: 1.0000 - val_loss: 1.0506 - val_accuracy: 0.8864\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 1.6740e-07 - accuracy: 1.0000 - val_loss: 1.1534 - val_accuracy: 0.8859\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_larger_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 모델과의 차이점은 다음과 같다.\n",
    "\n",
    "- 과대적합이 매우 빠르게 발생하며, 검증셋에 대한 성능이 매우 불안정하다.\n",
    "\n",
    "**주의사항**: 검증셋이 너무 작아도 매우 불안정스러울 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/original_model_vs_larger_model_imdb.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 규제 기법 2: 가중치 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델이 학습하는 파라미터(가중치와 편향)의 값이 작은 값을 갖도록 유도하는 기법이 \n",
    "**가중치 규제**(weight regularization)이며,\n",
    "크게 두 종류가 있다. \n",
    "\n",
    "- L1 규제: 절댓값이 상대적으로 보다 작은 가중치를 보다 빠르게 0이 되도록 유도.\n",
    "    즉, 덜 중요한 특성을 무시하도록 유도.\n",
    "- L2 규제: 가중치가 작은 값을 갖도록 유도.\n",
    "    즉, 특정 특성에 심하게 휘둘리지 않도록 유도.\n",
    "\n",
    "**참고**: L1 규제가 적용된 라쏘 회귀(Lasso regression)과 L2 규제가 적용된 릿지 회귀(Ridge regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch04/lasso_vs_ridge_plot.png\" style=\"width:550px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://github.com/ageron/handson-ml2\">핸즈온 머신러닝(2판), 4장</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "아래 코드는 IMDB 훈련 모델에 L2 규제를 가한 결과를 보여준다.\n",
    "\n",
    "- `regularizers.l2(0.002)`: 각 가중치의 제곱에 0.002 곱하기\n",
    "- 규제는 훈련 중에만 적용되며 테스트에는 사용되지 않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 2s 34ms/step - loss: 0.6023 - accuracy: 0.7710 - val_loss: 0.4744 - val_accuracy: 0.8630\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3990 - accuracy: 0.8978 - val_loss: 0.3953 - val_accuracy: 0.8819\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3301 - accuracy: 0.9161 - val_loss: 0.4116 - val_accuracy: 0.8601\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2985 - accuracy: 0.9259 - val_loss: 0.3822 - val_accuracy: 0.8756\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2757 - accuracy: 0.9331 - val_loss: 0.3550 - val_accuracy: 0.8863\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2655 - accuracy: 0.9389 - val_loss: 0.3583 - val_accuracy: 0.8848\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2526 - accuracy: 0.9412 - val_loss: 0.3646 - val_accuracy: 0.8826\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2470 - accuracy: 0.9414 - val_loss: 0.3651 - val_accuracy: 0.8850\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2363 - accuracy: 0.9462 - val_loss: 0.3846 - val_accuracy: 0.8773\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2326 - accuracy: 0.9497 - val_loss: 0.3980 - val_accuracy: 0.8732\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2292 - accuracy: 0.9491 - val_loss: 0.3812 - val_accuracy: 0.8823\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2202 - accuracy: 0.9539 - val_loss: 0.3925 - val_accuracy: 0.8779\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2205 - accuracy: 0.9536 - val_loss: 0.4643 - val_accuracy: 0.8575\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2200 - accuracy: 0.9526 - val_loss: 0.4036 - val_accuracy: 0.8766\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2133 - accuracy: 0.9545 - val_loss: 0.4253 - val_accuracy: 0.8719\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2178 - accuracy: 0.9529 - val_loss: 0.3995 - val_accuracy: 0.8770\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2047 - accuracy: 0.9593 - val_loss: 0.4038 - val_accuracy: 0.8761\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2102 - accuracy: 0.9541 - val_loss: 0.4136 - val_accuracy: 0.8750\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2099 - accuracy: 0.9559 - val_loss: 0.4683 - val_accuracy: 0.8627\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2031 - accuracy: 0.9602 - val_loss: 0.4488 - val_accuracy: 0.8668\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history_l2_reg = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 규제를 가한 결과는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/original_model_vs_l2_regularized_model_imdb.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "`l2` 규제 대신에 `l1`, 또는 L1과 L2를 함께 사용하는 `l1_l2` 규제를 사용할 수 있다.\n",
    "\n",
    "```python\n",
    "regularizers.l1(0.001)\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**참고**: 가중치 규제 기법은 보다 작은 크기의 딥러닝 모델에 효과적이다.\n",
    "큰 딥러닝 모델에 대해서는 드롭아웃 기법이 보다 잘 작동한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 규제 기법 3: 드롭아웃 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**드롭아웃**은 무작위로 선택된 일정한 비율의 유닛을 끄는 것을 의미한다.\n",
    "즉, 해당 유닛에 저장된 값을 0으로 처리한다. \n",
    "\n",
    "- 적절한 드롭아웃 비율을 답은 드롭아웃 층을 적절한 위치에 추가한다.\n",
    "\n",
    "- 검증셋에 대해서는 드롭아웃을 적용하지 않는다. 대신 출력값을 지정된 비율만큼 줄인다.\n",
    "    그래야 층에서 층으로 전달되는 값의 크기가 훈련할 때와 비슷하게 유지되기 때문이다.\n",
    "    \n",
    "아래 코드는 IMDB 데이터셋에 드롯아웃을 적용하여 훈련한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.6332 - accuracy: 0.6373 - val_loss: 0.5116 - val_accuracy: 0.8513\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5115 - accuracy: 0.7645 - val_loss: 0.4120 - val_accuracy: 0.8725\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4286 - accuracy: 0.8241 - val_loss: 0.3393 - val_accuracy: 0.8822\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3633 - accuracy: 0.8619 - val_loss: 0.2936 - val_accuracy: 0.8875\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3172 - accuracy: 0.8840 - val_loss: 0.2843 - val_accuracy: 0.8866\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2727 - accuracy: 0.9035 - val_loss: 0.2721 - val_accuracy: 0.8911\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2486 - accuracy: 0.9129 - val_loss: 0.2784 - val_accuracy: 0.8914\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2167 - accuracy: 0.9263 - val_loss: 0.2902 - val_accuracy: 0.8904\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1947 - accuracy: 0.9321 - val_loss: 0.3019 - val_accuracy: 0.8910\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1727 - accuracy: 0.9411 - val_loss: 0.3191 - val_accuracy: 0.8859\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1578 - accuracy: 0.9461 - val_loss: 0.3230 - val_accuracy: 0.8883\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1472 - accuracy: 0.9523 - val_loss: 0.3525 - val_accuracy: 0.8882\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1346 - accuracy: 0.9528 - val_loss: 0.3735 - val_accuracy: 0.8882\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1237 - accuracy: 0.9561 - val_loss: 0.4016 - val_accuracy: 0.8887\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1135 - accuracy: 0.9629 - val_loss: 0.4250 - val_accuracy: 0.8887\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1029 - accuracy: 0.9625 - val_loss: 0.4592 - val_accuracy: 0.8888\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1005 - accuracy: 0.9665 - val_loss: 0.4858 - val_accuracy: 0.8880\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0940 - accuracy: 0.9679 - val_loss: 0.4944 - val_accuracy: 0.8860\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0872 - accuracy: 0.9675 - val_loss: 0.5313 - val_accuracy: 0.8887\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0854 - accuracy: 0.9676 - val_loss: 0.5591 - val_accuracy: 0.8858\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_dropout = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50%의 드롭아웃을 적용한 결과는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/original_model_vs_dropout_regularized_model_imdb.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 백색 잡음으로 생성된 데이터셋과 무작위로 지정된 타깃 데이터셋을 이용하여 딥러닝 모델을 학습시킨다. \n",
    "    이를 통해 훈련셋에 대한 성능은 매우 좋아지지만 검증셋에 대한 성능은 낮은 상태로 전혀 변하지 않음을 확인한다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dlp05_fundamentals_of_ml",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('homl3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "87326548fe22e0f6dacd268b079dcc7a15583d9081b3203af40b067350baf618"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
