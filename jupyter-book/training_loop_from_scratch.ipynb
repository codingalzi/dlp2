{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daf323e33b84"
      },
      "source": [
        "# 훈련 루프"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**참고**\n",
        "\n",
        "[Writing a training loop from scratch](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch)를 참고하였습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**소스코드**\n",
        "\n",
        "여기서 언급되는 코드를 [(구글 코랩) 훈련 루프](https://colab.research.google.com/github/codingalzi/dlp2/blob/master/notebooks/NB-training_loop_from_scratch.ipynb)에서 직접 실행할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**슬라이드**\n",
        "\n",
        "본문 내용을 요약한 [슬라이드](https://github.com/codingalzi/dlp2/raw/master/slides/slides-training_loop_from_scratch.pdf)를 다운로드할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**주요 내용**\n",
        "\n",
        "신경망 모델의 훈련과 평가 과정을 보다 깊이 이해하기 위해 `fit()` 메서드를 실행할 때 \n",
        "텐서플로우 내부에서 훈련 루프가 처리되는 과정을 자세히 들여다본다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 모델 지정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "설명을 위해 다시 한 번 간단한 MNIST 모델을 이용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "model = keras.Sequential([layers.Dense(256, activation=\"relu\"),\n",
        "                          layers.Dense(512, activation=\"relu\"),\n",
        "                          layers.Dense(10, activation=\"softmax\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 옵티마이저, 손실 함수, 평가지표 지정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "모델 훈련에 필요한 요소인 옵티마이저, 손실 함수, 평가지표를 지정하기 위해\n",
        "일반적으로 모델의 `compile()` 메서드를 다음과 같이 실행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "하지만 여기서는 모델의 훈련 루프를 직접 구현하려 하기에\n",
        "`compile()` 메서드를 실행하는 대신 컴파일 과정에 필요한 API를 직접 선언한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**옵티마이저 API 선언**\n",
        "\n",
        "아래코드는 모델 컴파일에 사용된 문자열 `'rmsprop'`에 해당한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.RMSprop(learning_rate=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**손실 함수 API 선언**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " 0, 1, 2, 3 등 정수 형식의 타깃(레이블)을 예측하는 다중 클래스 분류 모델을 훈련시키는 경우\n",
        "보통 `SparseCategoricalCrossentropy` 클래스를 이용한다.\n",
        "아래코드는 모델 컴파일에 사용된 문자열 `'sparse_categorical_crossentropy'`에 해당한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**평가지표 API 선언**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " 0, 1, 2, 3 등 정수 형식의 타깃(레이블)을 예측하는 다중 클래스 분류 모델을 훈련시키는 경우\n",
        "평가지표는 `SparseCategoricalAccuracy` 클래스를 이용한다.\n",
        "아래코드는 모델 컴파일에 사용된 문자열 `'accuracy'`에 해당한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_acc_metric = keras.metrics.SparseCategoricalAccuracy() # 훈련셋 대상 평가\n",
        "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()   # 검증셋 대상 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 데이터셋 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "훈련과 평가에 사용된 데이터를 준비한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**훈련셋, 검증셋, 테스트셋 지정**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# 훈련셋과 테스트셋 가져오기\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = np.reshape(x_train, (-1, 784))\n",
        "x_test = np.reshape(x_test, (-1, 784))\n",
        "\n",
        "# 훈련셋의 일부를 검증셋으로 지정\n",
        "x_val = x_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "\n",
        "y_val = y_train[-10000:]\n",
        "y_train = y_train[:-10000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**배치 묶음 `Dataset` 객체 지정**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "훈련셋과 검증셋을 대상으로 배치 묶음으로 구성된 모음 자료형 객체를 지정한다.\n",
        "이를 위해 텐서플로우의 `Dataset` 클래스를 이용한다.\n",
        "`tf.data.Dataset` 머신러닝 모델 훈련에 사용되는 대용량 데이터의 효율적인 처리를\n",
        "지원하는 모음 자료형이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "배치 크기는 128로 지정한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 훈련용 `Dataset` 객체 지정\n",
        "    - 훈련셋 어레이와 훈련셋 타깃 어레이로부터 `Dataset` 생성 후 배치로 묶은 `Dataset`으로 변환.\n",
        "    - `shuffle()` 메서드를 이용하여 데이터 무작위 섞기 실행 후 배치 묶음 생성\n",
        "- 검증용 `Dataset` 객체 지정\n",
        "    - 검증셋 어레이와 검증셋 타깃 어레이로부터 `Dataset` 생성 후 배치로 묶은 `Dataset`으로 변환."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 배치크기: 128\n",
        "batch_size = 128\n",
        "\n",
        "# 훈련용 Dataset 객체\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "# 검증용 Dataset 객체\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 훈련 루프"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "학습 및 평가를 진행하는 훈련 루프는 다음과 같다.\n",
        "\n",
        "- 지정된 에포크 수만큼 에포크를 반복하는 `for` 반복문 실행\n",
        "- 각 에포크에 대해 배치 단위로 스텝을 진행하는 `for` 반복문 실행\n",
        "    - 각 배치에 대해 `GradientTape()` 영역 지정\n",
        "        - 이 영역 내에서 순전파 실행 후 손실값 계산\n",
        "    - 영역 외부에서 손실값에 대한 모델 가중치의 그래디언트 계산\n",
        "    - 옵티마이저를 사용하여 모델의 가중치 업데이트\n",
        "- 평가지표를 확인하면서 에포크 마무리\n",
        "    - 훈련셋 대상 정확도 계산: 매 스텝을 통해 업데이트된 정확도 최종 결과 확인\n",
        "    - 검증셋 대상 정확도 계산: 지정된 배치 단위로 검증셋 정확도 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "평가지표 API는 다음과 같이 활용한다.\n",
        "\n",
        "- 매 스텝마다 훈련셋 평가지표 계산, 즉 `update_state()` 메서드 호출\n",
        "- 검증셋에 대한 평가지표 계산은 스텝 훈련이 끝난후 지정된 배치 단위로 진행.\n",
        "- 에포크를 마무리하면서 끝날 때마다 훈련셋과 검증셋의 평가지표 API 초기화:  `reset_state()` 메서드 호출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 0.3334\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.2486\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9743\n",
            "Validation acc: 0.9673\n",
            "Time taken: 7.75s\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 0.0620\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.1358\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9786\n",
            "Validation acc: 0.9633\n",
            "Time taken: 6.48s\n",
            "\n",
            "Start of epoch 2\n",
            "Training loss (for one batch) at step 0: 0.1861\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.2354\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9792\n",
            "Validation acc: 0.9662\n",
            "Time taken: 7.04s\n",
            "\n",
            "Start of epoch 3\n",
            "Training loss (for one batch) at step 0: 0.6180\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.0278\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9812\n",
            "Validation acc: 0.9724\n",
            "Time taken: 6.62s\n",
            "\n",
            "Start of epoch 4\n",
            "Training loss (for one batch) at step 0: 0.0326\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.8386\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9830\n",
            "Validation acc: 0.9711\n",
            "Time taken: 6.74s\n",
            "\n",
            "Start of epoch 5\n",
            "Training loss (for one batch) at step 0: 0.0638\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.2035\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9845\n",
            "Validation acc: 0.9668\n",
            "Time taken: 7.01s\n",
            "\n",
            "Start of epoch 6\n",
            "Training loss (for one batch) at step 0: 0.3963\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.0374\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9863\n",
            "Validation acc: 0.9675\n",
            "Time taken: 6.99s\n",
            "\n",
            "Start of epoch 7\n",
            "Training loss (for one batch) at step 0: 0.1129\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.3808\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9865\n",
            "Validation acc: 0.9646\n",
            "Time taken: 6.91s\n",
            "\n",
            "Start of epoch 8\n",
            "Training loss (for one batch) at step 0: 0.0260\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.1818\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9874\n",
            "Validation acc: 0.9633\n",
            "Time taken: 7.59s\n",
            "\n",
            "Start of epoch 9\n",
            "Training loss (for one batch) at step 0: 0.1073\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.3317\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9881\n",
            "Validation acc: 0.9714\n",
            "Time taken: 8.02s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(x_batch_train, training=True)\n",
        "            loss_value = loss_fn(y_batch_train, logits)\n",
        "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "        # Update training metric.\n",
        "        train_acc_metric.update_state(y_batch_train, logits)\n",
        "\n",
        "        # Log every 200 batches.\n",
        "        if step % 200 == 0:\n",
        "            print(\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                % (step, float(loss_value))\n",
        "            )\n",
        "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
        "\n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_state()\n",
        "\n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        val_logits = model(x_batch_val, training=False)\n",
        "        # Update val metrics\n",
        "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_acc_metric.reset_state()\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c9a16c21790"
      },
      "source": [
        "## `@tf.function` 데코레이터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "텐서플로우의 텐서를 다루는 함수에 `@tf.function` 데코레이터를 추가하면 모델 훈련 속도가 빨라질 수 있다.\n",
        "훈련 속도의 변화가 발생하는 이유는 여기서는 다루지 않는다.\n",
        "다만 전적으로 텐서플로우의 텐서 연산만 사용하는 함수에만 적용될 수 있음에 주의한다.\n",
        "\n",
        "아래 코드는 훈련 스텝을 담당하는 함수를 선언한 다음에\n",
        "`@tf.function` 데코레이터를 추가한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "fdacc2d48ade"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(x, training=True)\n",
        "        loss_value = loss_fn(y, logits)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    train_acc_metric.update_state(y, logits)\n",
        "    return loss_value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "아래 코드는 검증셋에 대한 정확도를 계산하는 함수를 선언한 다음에\n",
        "`@tf.function` 데코레이터를 추가한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "da4828fd8ef7"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    val_logits = model(x, training=False)\n",
        "    val_acc_metric.update_state(y, val_logits)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d552377968f1"
      },
      "source": [
        "아래 코드는 위 두 개의 함수를 이용하여 모델 훈련을 훨씬 빠르게 진행한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 0.7231\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.0731\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9940\n",
            "Validation acc: 0.9777\n",
            "Time taken: 1.00s\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 0.0000\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.0007\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9949\n",
            "Validation acc: 0.9760\n",
            "Time taken: 0.79s\n",
            "\n",
            "Start of epoch 2\n",
            "Training loss (for one batch) at step 0: 0.0173\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.0363\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9947\n",
            "Validation acc: 0.9755\n",
            "Time taken: 0.77s\n",
            "\n",
            "Start of epoch 3\n",
            "Training loss (for one batch) at step 0: 0.0000\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.0517\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9950\n",
            "Validation acc: 0.9729\n",
            "Time taken: 0.79s\n",
            "\n",
            "Start of epoch 4\n",
            "Training loss (for one batch) at step 0: 0.0000\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.0000\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9940\n",
            "Validation acc: 0.9736\n",
            "Time taken: 0.86s\n",
            "\n",
            "Start of epoch 5\n",
            "Training loss (for one batch) at step 0: 0.0000\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.0000\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9947\n",
            "Validation acc: 0.9757\n",
            "Time taken: 0.83s\n",
            "\n",
            "Start of epoch 6\n",
            "Training loss (for one batch) at step 0: 0.1587\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.0000\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9950\n",
            "Validation acc: 0.9761\n",
            "Time taken: 0.82s\n",
            "\n",
            "Start of epoch 7\n",
            "Training loss (for one batch) at step 0: 0.0000\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.0001\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9952\n",
            "Validation acc: 0.9750\n",
            "Time taken: 0.87s\n",
            "\n",
            "Start of epoch 8\n",
            "Training loss (for one batch) at step 0: 0.1037\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.0002\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9951\n",
            "Validation acc: 0.9769\n",
            "Time taken: 0.83s\n",
            "\n",
            "Start of epoch 9\n",
            "Training loss (for one batch) at step 0: 0.0000\n",
            "Seen so far: 128 samples\n",
            "Training loss (for one batch) at step 200: 0.0000\n",
            "Seen so far: 25728 samples\n",
            "Training acc over epoch: 0.9958\n",
            "Validation acc: 0.9736\n",
            "Time taken: 0.81s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        loss_value = train_step(x_batch_train, y_batch_train)\n",
        "\n",
        "        # Log every 200 batches.\n",
        "        if step % 200 == 0:\n",
        "            print(\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                % (step, float(loss_value))\n",
        "            )\n",
        "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
        "\n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_state()\n",
        "\n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        test_step(x_batch_val, y_batch_val)\n",
        "\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_acc_metric.reset_state()\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::{admonition} 주의사항\n",
        ":class: note\n",
        "\n",
        "`@tf.function` 데코레이터를 추가한다 해서 모델 훈련 속도가 항상 빨라지는 것은 아님에 주의한다.\n",
        "어느 경우에 빠르고, 언제 그렇지 않은지에 대한 설명은 \n",
        "[Better performance with tf.function](https://www.tensorflow.org/guide/function)을\n",
        "참고한다.\n",
        ":::"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
