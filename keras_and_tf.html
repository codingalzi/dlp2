
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3. 케라스와 텐서플로우 &#8212; Deep Learning with Python(2판)</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="2. 신경망 구성 요소" href="building_blocks_of_NN.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Deep Learning with Python(2판)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="what_is_deep_learning.html">
   1. 딥러닝 소개
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="building_blocks_of_NN.html">
   2. 신경망 구성 요소
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3. 케라스와 텐서플로우
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/keras_and_tf.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/codingalzi/dlp2"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/codingalzi/dlp2/issues/new?title=Issue%20on%20page%20%2Fkeras_and_tf.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/codingalzi/dlp2/master?urlpath=tree/jupyter-book/keras_and_tf.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   3.1. 텐서플로우 소개
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   3.2. 케라스 소개
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   3.3. 딥러닝 주요 라이브러리 약력
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   3.4. 딥러닝 개발환경
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id6">
   3.5. 순수 텐서플로우 사용법 기초
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#api">
   3.6. 케라스 신경망 모델의 핵심 API
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     3.6.1. 층
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     3.6.2. 모델
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     3.6.3. 모델 컴파일
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>케라스와 텐서플로우</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   3.1. 텐서플로우 소개
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   3.2. 케라스 소개
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   3.3. 딥러닝 주요 라이브러리 약력
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   3.4. 딥러닝 개발환경
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id6">
   3.5. 순수 텐서플로우 사용법 기초
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#api">
   3.6. 케라스 신경망 모델의 핵심 API
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     3.6.1. 층
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     3.6.2. 모델
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     3.6.3. 모델 컴파일
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="ch-keras-tf">
<span id="id1"></span><h1><span class="section-number">3. </span>케라스와 텐서플로우<a class="headerlink" href="#ch-keras-tf" title="Permalink to this headline">¶</a></h1>
<p><strong>감사의 글</strong></p>
<p>아래 내용은 프랑소와 숄레의
<a class="reference external" href="https://github.com/fchollet/deep-learning-with-python-notebooks">Deep Learning with Python(2판)</a>의
소스코드 내용을 참고해서 작성되었습니다.
자료를 공개한 저자에게 진심어린 감사를 전합니다.</p>
<p><strong>소스코드</strong></p>
<p>여기서 언급되는 코드를
<a class="reference external" href="https://colab.research.google.com/github/codingalzi/dlp2/blob/master/notebooks/NB-keras_and_tf.ipynb">(구글 코랩) 케라스와 텐서플로우</a>에서
직접 실행할 수 있다.</p>
<p><strong>주요 내용</strong></p>
<p>케라스와 텐서플로우를 이용한 딥러닝의 활용법을 소개한다.</p>
<div class="section" id="id2">
<h2><span class="section-number">3.1. </span>텐서플로우 소개<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>텐서플로우는 파이썬 기본 머신러닝 플랫폼이며,
머신러닝 모델의 훈련에 필요한 계산에 필요한 텐서 연산을 지원한다.
넘파이(Numpy) 패키지와 유사하지만 보다 많은 기능을 제공한다.</p>
<ul class="simple">
<li><p>그레이디언트 자동 계산</p></li>
<li><p>GPU, TPU 등 고성능 병렬 하드웨어 가속기 활용 가능</p></li>
<li><p>여러 대의 컴퓨터 또는 클라우드 컴퓨팅 서비스 활용 가능</p></li>
<li><p>C++(게임), 자바스크립트(웹브라우저), TFLite(모바일 장치) 등 다른 언어가 선호되는
도메인 특화 프로그램에 쉽게 이식 가능</p></li>
</ul>
<p>텐서플로우는 또한 단순한 패키지 기능을 넘어서는 머신러닝 플랫폼 역할도 수행한다.</p>
<ul class="simple">
<li><p>TF-Agents: 강화학습 연구 지원</p></li>
<li><p>TFX: 머신러닝 프로젝트 운영 지원</p></li>
<li><p>TensorFlow-Hub: 사전 훈련된 머신러닝 모델 제공</p></li>
</ul>
</div>
<div class="section" id="id3">
<h2><span class="section-number">3.2. </span>케라스 소개<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>딥러닝 모델 구성 및 훈련에 단순하지만 활용성이 높은 다양한 수준의 API를 제공한다.
원래 텐서플로우와 독립적으로 개발되었지만 텐서플로우 2.0부터 텐서플로우 라이브러리의 최상위 프레임워크(framework)로 포함됐다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/keras_and_tf.png" style="width:600px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p></div>
<div class="section" id="id4">
<h2><span class="section-number">3.3. </span>딥러닝 주요 라이브러리 약력<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>2007년: 씨아노(Theano) 공개. 텐서를 이용한 계산 그래프, 미분 자동화 등을 최초로 지원한 딥러닝 라이브러리.</p></li>
<li><p>2015년 3월: 케라스 라이브러리 공개. Theano를 백앤드로 사용하는 고수준 패키지.</p></li>
<li><p>2015년 11월: 텐서플로우 라이브러리 공개.</p></li>
<li><p>2016년: 텐서플로우가 케라스의 기본 백엔드로 지정됨.</p></li>
<li><p>2016년 9월: 페이스북이 개발한 PyTorch 공개.</p></li>
<li><p>2017년: Theano, 텐서플로우, CNTK(마이크로소프트), MXNet(아마존)이 케라스의 백엔드로 지원됨.
현재 Theano, CNTK 등은 더 이상 개발되지 않으며, MXNet은 아마존에서만 주로 사용됨.</p></li>
<li><p>2018년 3월: PyTorch와 Caffe2를 합친 PyTorch 출시(페이스북과 마이크로소프트의 협업)</p></li>
<li><p>2019년 9월: 텐서플로우 2.0부터 케라스가 텐서플로우의 최상위 프레임워크로 지정됨.</p></li>
</ul>
<div class="info admonition">
<p class="admonition-title">텐서플로우 대 파이토치</p>
<p>파이토치<font size='2'>PyTorch</font> 또한 텐서 연산을 지원하는 딥러닝 라이브러리다.
텐서플로우와 케라스의 조합이 강력하지만 신경망의 보다 섬세한 조정은 약하다는 지적을 많이 받는 반면에
파이토치는 상대적으로 보다 자유롭게 신경망을 구성할 수 있다는 장점이 많이 언급된다.
텐서플로우와 케라스의 조합이 여전히 보다 많이 사용되지만 파이토치의 비중 또한 점점 늘고 있다.</p>
</div>
</div>
<div class="section" id="id5">
<h2><span class="section-number">3.4. </span>딥러닝 개발환경<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h2>
<p>딥러닝 신경망 모델의 훈련을 위해서 GPU를 활용할 것을 강력히 추천한다.
GPU를 사용하지 않으면 모델의 훈련이 너무 느려 제대로 활용할 수 없을 것이다.
<a class="reference external" href="https://colab.research.google.com/?hl=ko">구글 코랩</a>을 이용하면
특별한 준비가 필요 없이 바로 신경망 모델을 GPU와 함께 훈련시킬 수 있다.
구글 코랩은 주피터 노트북을 사용하는데, 주피터 노트북 사용법과
구글 코랩에서 GPU를 이용하는 방법을 여기서는 설명하지 않는다.
필요한 경우 인터넷에서 쉽게 관련 내용을 찾아볼 수 있다.</p>
<p>하지만 딥러닝 모델 훈련을 많이 시키려면 NVIDIA 그래픽카드가 장착된
개인용 컴퓨터를 활용하는 것이 좋다.
운영체제는 <a class="reference external" href="https://ubuntu.com/download/desktop">Ubuntu</a> 또는 <a class="reference external" href="https://docs.microsoft.com/ko-kr/windows/wsl/install">WSL 2(Windows Subsystem for Linux 2)</a> 사용할 것을 추천한다.</p>
<p>윈도우 10/11에서 GPU를 지원하는 텐서플로우를 설치하는 가장 간단한 방식은
<a class="reference external" href="https://github.com/ageron/handson-ml3/issues/21#issuecomment-1177864010">conda를 활용한 gpu 지원 tensorflow 설치 요령</a>과
<a class="reference external" href="https://github.com/ageron/handson-ml3/blob/main/INSTALL.md">Anaconda와 conda 환경 활용</a>을 참고한다.</p>
<p>보다 전문적인 딥러닝 연구를 위해 대용량의 메모리와 고성능의 CPU, GPU가 필요한 경우
비용이 들기는 하지만
<a class="reference external" href="https://cloud.google.com/">구글 클라우드 플랫폼</a> 또는
<a class="reference external" href="https://aws.amazon.com/ko/?nc2=h_lg">아마존 웹서비스(AWS EC2)</a>를
단기간동안 고성능 컴퓨터를 활용할 수 있다.</p>
</div>
<div class="section" id="id6">
<h2><span class="section-number">3.5. </span>순수 텐서플로우 사용법 기초<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p>케라스를 전혀 이용하지 않으면서 신경망 모델을 지정하고 훈련시킬 수 있다.
하지만 다음 개념, 기능, 도구를 모두 직접 구현해야 한다.</p>
<ul class="simple">
<li><p>가중치, 편향 등을 저장할 텐서 지정</p></li>
<li><p>덧셈, 행렬 곱, <code class="docutils literal notranslate"><span class="pre">relu()</span></code> 함수 등 정의</p></li>
<li><p>역전파 실행</p></li>
<li><p>층과 모델</p></li>
<li><p>손실 함수</p></li>
<li><p>옵티마이저</p></li>
<li><p>평가지표</p></li>
<li><p>훈련 루프</p></li>
</ul>
<p><strong>상수 텐서와 변수 텐서</strong></p>
<p>텐서플로우 자체로 두 종류의 텐서 자료형을 지원한다.
사용법은 기본적으로 넘파이 어레이와 유사하지만 GPU 연산과 그레이디언트 자동계산 등
신경망 모델 훈련에 최적화된 기능을 제공한다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> 자료형</p>
<ul>
<li><p>상수 텐서</p></li>
<li><p>입출력 데이터 등 변하지 않는 텐서로 사용.</p></li>
<li><p>불변 자료형</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code> 자료형</p>
<ul>
<li><p>변수 텐서</p></li>
<li><p>모델의 가중치, 편향 등 업데이트가 되는 텐서로 사용.</p></li>
<li><p>가변 자료형</p></li>
</ul>
</li>
</ul>
<p><strong>텐서 연산</strong></p>
<p>덧셈, relu, 점곱 등 텐서 연산은 기본적으로 넘파이 어레이 연산과 동일하다.</p>
<p><strong><code class="docutils literal notranslate"><span class="pre">GradientTape</span></code> 활용</strong></p>
<p>넘파이 어레이와의 가장 큰 차이점은
그레이디언트 테이프 기능을 이용하여 변수 텐서에 의존하는 미분가능한
함수의 그레이디언트 자동 계산이다.
예를 들어 아래 코드는 제곱 함수의 <span class="math notranslate nohighlight">\(x = 3\)</span>에서의 미분값인 6을 계산한다.</p>
<div class="math notranslate nohighlight">
\[
f(x) = x^2 \quad \Longrightarrow \quad \nabla f(x) = \frac{df(x)}{dx} = 2x
\]</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="mf">3.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">input_var</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gradient</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">input_var</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">gradient</span><span class="p">)</span>
<span class="go">tf.Tensor(6.0, shape=(), dtype=float32)</span>
</pre></div>
</div>
<p>그레이디언트 테이프 기능을 이용하여 신경망 모델 훈련 중에
손실 함수의 그레이디언트를 계산한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gradient</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
</pre></div>
</div>
<div class="info admonition">
<p class="admonition-title">상수 텐서와 그레이디언트 테이프</p>
<p>상수 텐서에 대해 그레이디언트 테이프를 이용하려면 <code class="docutils literal notranslate"><span class="pre">tape.watch()</span></code> 메서드로 감싸야 한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">input_const</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">3.</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">tape</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">input_const</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">input_const</span><span class="p">)</span>
<span class="n">gradient</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">input_const</span><span class="p">)</span>
</pre></div>
</div>
<p>이유는 모델의 가중치와 편향 등 모델 훈련에 중요한 텐서들에 대해 미분 연산을
집중하기 위해서이다. 그렇지 않으면 너무 많은 계산을 해야 한다.</p>
</div>
<p><strong>순수 텐서플로우로 선형 분류기 구현</strong></p>
<p>케라스를 전혀 사용하지 않으면서 간단한 선형 분류기를 구현하는 과정을 통해
텐서플로우 API의 기본 기능을 살펴 본다.</p>
<p><strong><em>1단계: 데이터셋 생성</em></strong></p>
<p>아래 사진 모양처럼 양성(노랑색)과 음성(보라색)으로 구분되는 훈련셋을 생성한다.
훈련셋은 다변량 정규분포를 따르도록 하며 각각 1,000개의 샘플로 구성된 양성과 음성 데이터셋의
공분산은 동일하고 평균값만 다르도록 한다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/03-07.png" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">num_samples_per_class</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># 음성 데이터셋</span>
<span class="n">negative_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span>
    <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">cov</span><span class="o">=</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">size</span><span class="o">=</span><span class="n">num_samples_per_class</span><span class="p">)</span>

<span class="c1"># 양성 데이터셋</span>
<span class="n">positive_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span>
    <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cov</span><span class="o">=</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">size</span><span class="o">=</span><span class="n">num_samples_per_class</span><span class="p">)</span>
</pre></div>
</div>
<p>두 데이터셋을 합쳐서 훈련셋, 즉, 모델의 입력값으로 지정한다.
자료형을 <code class="docutils literal notranslate"><span class="pre">np.float32</span></code>로 지정함에 주의하라.
그렇게 하지 않으면 <code class="docutils literal notranslate"><span class="pre">np.float64</span></code>로 지정되어 보다 많은 메모리와 실행시간을 요구한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">negative_samples</span><span class="p">,</span> <span class="n">positive_samples</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p>음성 샘플의 레이블은 0, 양성 샘플의 레이블은 1로 지정한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_samples_per_class</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_samples_per_class</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)))</span>
</pre></div>
</div>
<p><strong><em>2단계: 선형 회귀 모델 훈련에 필요한 가중치와 편향 변수 텐서 생성</em></strong></p>
<p>모델 학습에 사용될 가중치와 편향을 변수 텐서로 선언한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">2</span>     <span class="c1"># 입력 샘플의 특성이 2개</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">1</span>    <span class="c1"># 하나의 값으로 출력</span>

<span class="c1"># 가중치: 무작위 초기화</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)))</span>

<span class="c1"># 편향: 0으로 초기화</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,)))</span>
</pre></div>
</div>
<p><strong><em>3단계: 모델 선언(포워드 패스)</em></strong></p>
<p>신경망 모델을 훈련할 때 입력값에 대한 예측값을 계산하는 과정인
포워드 패스를 함수로 구현한다.
간단한 모델 표현을 위해 활성화 함수는 사용하지 않는다.</p>
<p><code class="docutils literal notranslate"><span class="pre">tf.matmul()</span></code> 함수는 넘파이의 점 곱 함수처럼 작동하며 아래 코드에서는
행렬의 곱을 나타낸다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
</pre></div>
</div>
<p><strong><em>4단계: 손실 함수 지정</em></strong></p>
<p>타깃과 예측값 사이의 평균 제곱 오차를 손실값으로 사용한다.
아래 코드에서 <code class="docutils literal notranslate"><span class="pre">tf.reduce_mean()</span></code> 함수는 넘파이의 <code class="docutils literal notranslate"><span class="pre">np.mean()</span></code>처럼
평균값을 계산하지만 텐서플로우의 텐서를 대상으로 한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">square_loss</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
    <span class="n">per_sample_losses</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">targets</span> <span class="o">-</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">per_sample_losses</span><span class="p">)</span>
</pre></div>
</div>
<p><strong><em>5단계: 훈련 스텝(백워드 패스와 역전파) 지정</em></strong></p>
<p>하나의 배치에 대해 예측값을 계산한 후에 손실 함수의 그레이디언트를
계산한 후에 가중치와 편향을 업데이트하는 함수를 선언한다.
그레이디언트 계산은 그레이디언트 테이프를 이용한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">square_loss</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="n">grad_loss_wrt_W</span><span class="p">,</span> <span class="n">grad_loss_wrt_b</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>
    <span class="n">W</span><span class="o">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="n">grad_loss_wrt_W</span> <span class="o">*</span> <span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">b</span><span class="o">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="n">grad_loss_wrt_b</span> <span class="o">*</span> <span class="n">learning_rate</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
<p><strong><em>6단계: 훈련 루프 지정</em></strong></p>
<p>반복해서 훈련한 내용을 지정한다.
여기서는 설명을 간단하게 하기 위해 미니 배치가 아닌 배치 훈련을 구현한다.
전체 훈련셋을 총 40번 반복 학습할 때마다 손실값을 출력하도록 한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">40</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">training_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss at step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong><em>7단계: 결정경계 예측</em></strong></p>
<p>모델의 예측값이 0.5보다 클 때 양성으로 판정하는 것이 좋은데
이유는 샘플들의 레이블이 0 또는 1이기 때문이다.
모델은 훈련과정 중에 음성 샘플은 최대한 0에,
양성 샘플은 최대한 1에 가까운 값으로 예측하여 손실값을 최대한 줄여야 하는데
옵티마이저가 그렇게 유도한다.
따라서 예측값이 0과 1의 중간값인 0.5일 때를 결정경계로 사용한다.</p>
<p>결정경계를 직선으로 그리려면 아래 식을 이용한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="o">-</span> <span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span>  <span class="n">W</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.5</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="n">W</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>이유는 위 모델의 예측값이 다음과 같이 계산되며,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">W</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">y</span> <span class="o">+</span> <span class="n">b</span>
</pre></div>
</div>
<p>위 예측값이 0.5보다 큰지 여부에 따라 음성, 양성이 판단되기 때문이다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/HighResolutionFigures/figure_3-8.png" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p></div>
<div class="section" id="api">
<h2><span class="section-number">3.6. </span>케라스 신경망 모델의 핵심 API<a class="headerlink" href="#api" title="Permalink to this headline">¶</a></h2>
<p>신경망 모델은 층<font size='2'>layer</font>으로 구성된다.
모델에 사용되는 층의 종류와 층을 쌓는 방식에 따라
모델이 처리할 수 있는 데이터와 훈련 방식이 달라진다.
모델과 훈련 방식이 정해지면 이후에 훈련을 어떻게 진행할 것인가를 정해야 한다.
이또한 많은 선택이 필요하지만 케라스가
쉽고 간단하게 활용할 수 있는 다양한 API를 제공한다.</p>
<div class="section" id="id7">
<h3><span class="section-number">3.6.1. </span>층<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p><strong>층의 기능</strong></p>
<p>층은 입력 데이터를 지정된 방식에 따라 다른 모양의 데이터로 변환하는 포워드 패스 기능을 담당한다.
또한 데이터 변환에 사용되는 가중치<font size='2'>weight</font>와
편향<font size='2'>bias</font>을 저장한다.</p>
<p><strong>층의 종류</strong></p>
<p>층은 사용되는 클래스에 따라 다양한 형식의 텐서를 취급한다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Dense</span></code> 클래스: 밀집층(dense layer)이며, <code class="docutils literal notranslate"><span class="pre">(샘플</span> <span class="pre">수,</span> <span class="pre">특성</span> <span class="pre">수)</span></code> 모양의 2D 텐서 데이터셋 처리.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LSTM</span></code> 또는 <code class="docutils literal notranslate"><span class="pre">Conv1D</span></code> 클래스: 순차 데이터 및 시계열 데이터 분석에 사용되는 순환층이며,
<code class="docutils literal notranslate"><span class="pre">(샘플</span> <span class="pre">수,</span> <span class="pre">타임스텝</span> <span class="pre">수,</span> <span class="pre">특성</span> <span class="pre">수)</span></code> 모양의 3D 텐서로 제공된 순차 데이터셋 처리.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 클래스: <code class="docutils literal notranslate"><span class="pre">(샘플</span> <span class="pre">수,</span> <span class="pre">가로,</span> <span class="pre">세로,</span> <span class="pre">채널</span> <span class="pre">수)</span></code> 모양의 4D 텐서로 제공된 이미지 데이터셋 처리.</p></li>
</ul>
<p>케라스를 활용하여 딥러닝 모델을 구성하는 것은 호환 가능한 층들을 적절하게 연결하여 층을 쌓는 것을 의미한다.</p>
<p><strong><code class="docutils literal notranslate"><span class="pre">Layer</span></code> 클래스</strong></p>
<p>케라스에서 사용되는 모든 층 클래스는 <code class="docutils literal notranslate"><span class="pre">Layer</span></code> 클래스를 상속하며,
이를 통해 상속받는 <code class="docutils literal notranslate"><span class="pre">__call__()</span></code> 메서드가
가중치와 편향 텐서를 생성 및 초기화 하고 입력 데이터를 출력 데이터로 변환하는
포워드 패스를 수행한다.
단, 가중치와 편향이 이미 생성되어 있다면 새로 생성하지 않고 그대로 사용한다.
<code class="docutils literal notranslate"><span class="pre">Layer</span></code> 클래스에서 선언된 <code class="docutils literal notranslate"><span class="pre">__call__()</span></code> 메서드가 하는 일을 간략하게 나타내면 다음과 같다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">built</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">built</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<p>위 코드에 사용된 인스턴스 변수와 메서드는 다음과 같다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">self.build(inputs_shape)</span></code>: 입력 배치 데이터셋의 모양 정보를 이용하여
적절한 모양의 가중치 텐서와 편향 텐서를 생성하고 초기화한다.</p>
<ul>
<li><p>가중치 텐서 초기화: 무작위적(<code class="docutils literal notranslate"><span class="pre">random_normal</span></code>)</p></li>
<li><p>편향 텐서 초기화: 0 벡터(<code class="docutils literal notranslate"><span class="pre">zeros</span></code>)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.built</span></code>: 가중치와 편향이 준비돼 있는지 여부 기억</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self.call(inputs)</span></code>: 아핀 변환과 활성화 함수를 이용한 포워드 패스,
입력 데이터셋을 변환하여, 출력 텐서를 계산한다.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Dense</span></code> 클래스 직접 구현하기</strong></p>
<p><a class="reference internal" href="building_blocks_of_NN.html#sec-nn-mnist"><span class="std std-numref">2.1절</span></a>에서 MNIST 데이터셋을 이용한 분류 모델에 사용된
신경망 모델은 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 클래스 두 개를 연속으로 쌓아 사용한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Dense</span></code> 클래스와 유사하게 작동하는 클래스를 직접 정의하려면
<code class="docutils literal notranslate"><span class="pre">__call()__</span></code> 메서드에 의해 호출되는
<code class="docutils literal notranslate"><span class="pre">build()</span></code> 메서드와 <code class="docutils literal notranslate"><span class="pre">call()</span></code> 메서드를 구현해야 한다.
아래 <code class="docutils literal notranslate"><span class="pre">SimpleDense</span></code> 클래스가 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 클래스의 기능을 단순화하여 구현한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleDense</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">units</span> <span class="o">=</span> <span class="n">units</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>   <span class="c1"># 입력 샘플의 특성 수</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">),</span>
                                 <span class="n">initializer</span><span class="o">=</span><span class="s2">&quot;random_normal&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,),</span>
                                 <span class="n">initializer</span><span class="o">=</span><span class="s2">&quot;zeros&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
<p>두 메서드의 정의에 사용된 매개변수와 메서드는 다음과 같다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">units</span></code>: 출력 샘플의 특성 수 지정</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">activation</span></code>: 활성화 함수 지정</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_shape</span></code>: 입력값(<code class="docutils literal notranslate"><span class="pre">inputs</span></code>)으로 얻은 입력 배치의 2D 모양 정보. 둘째 항목이 입력 샘플의 특성 수.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">add_weight(모양,</span> <span class="pre">초기화방법)</span></code>: 지정된 모양의 텐서 생성 및 초기화. <code class="docutils literal notranslate"><span class="pre">Layer</span></code> 클래스에서 상속.</p></li>
</ul>
<div class="proof example admonition" id="simpledense">
<p class="admonition-title"><span class="caption-number">Example 3.1 </span> (<code class="docutils literal notranslate"><span class="pre">SimpleDense</span></code> 층 활용법)</p>
<div class="example-content section" id="proof-content">
<p>아래 코드는 <code class="docutils literal notranslate"><span class="pre">SimpleDense</span></code> 층을 하나 생성한다.
층은 입렵값을 처리할 때 입력값의 모양을 확인하기 때문에
2장에서 살펴본 MNIST 모델 사용된 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 클래스처럼 입력 데이터에 대한 정보를
미리 요구하지 않는다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">my_dense</span> <span class="o">=</span> <span class="n">SimpleDense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
</pre></div>
</div>
<p>784 개의 특성을 갖는 1,000 개의 샘플로 구성된 데이터셋을 입력값으로 지정한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">my_dense</span></code>를 함수 호출하듯이 사용하면 출력값이 계산된다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">output_tensor</span> <span class="o">=</span> <span class="n">my_dense</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
</pre></div>
</div>
<p>내부적으로는 <code class="docutils literal notranslate"><span class="pre">__call__()</span></code> 메서드가 호출되어 다음 사항들이 연속적으로 처리된다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">(784,</span> <span class="pre">32)</span></code> 모양의 가중치 텐서 <code class="docutils literal notranslate"><span class="pre">W</span></code> 생성 및 무작위 초기화</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">(32,</span> <span class="pre">)</span></code> 모양의 편향 텐서 <code class="docutils literal notranslate"><span class="pre">b</span></code> 생성 및 <code class="docutils literal notranslate"><span class="pre">0</span></code>으로 초기화.</p></li>
<li><p>포워드 패스: 생성된 가중치와 편향을 이용하여 출력값 계산</p></li>
</ul>
<p>층의 출력값은 <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">32)</span></code> 모양의 텐서다.
이유는 784개의 특성이 32개의 특성으로 변환되었기 때문이다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(2, 32)</span>
</pre></div>
</div>
</div>
</div></div>
<div class="section" id="id8">
<h3><span class="section-number">3.6.2. </span>모델<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p><strong>층에서 모델로</strong></p>
<p>딥러닝 모델은 층으로 구성된다.
앞서 살펴 본 <code class="docutils literal notranslate"><span class="pre">Sequential</span></code> 모델은 층을 일렬로 쌓은 모델이며
각각의 층은 아래 층에서 전달한 값을 받아 변환해서 다음 층으로 전달한다.</p>
<div class="proof example admonition" id="exp-layertomodel">
<p class="admonition-title"><span class="caption-number">Example 3.2 </span> (Sequential 모델)</p>
<div class="example-content section" id="proof-content">
<p>아래 모델은 입력값이 들어오면 첫째층은 32개의 특성으로 이루어진 텐서로,
그 다음층은 64개의 특성으로 이루어진 텐서로,
그 다음층은 다시 32개의 특성으로 이루어진 텐서로,
마지막 층은 10개의 특성으로 이루어진 텐서로 변환해서
최종적으로 10개의 클래스에 속할 확률을 계산한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">SimpleDense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">SimpleDense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">SimpleDense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">SimpleDense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div><p>앞으로 층을 구성하는 다양한 방식을 살펴볼 것이다.
예를 들어, 아래 그림은 나중에 살펴 볼
트랜스포머<font size='2'>Transformer</font> 모델에
사용된 층들의 복잡한 구조를 보여준다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/transformer0001.png" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>층의 구성과 모델의 학습과정</strong></p>
<p>모델의 학습과정은 층을 어떻게 구성하였는가에 전적으로 의존한다.
앞서 살펴 보았듯이 각각의 층에서 이루어지는 일은 기본적으로
<strong>아핀 변환</strong>과 <strong>활성화 함수 적용</strong>이다.
여러 개의 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층을 <code class="docutils literal notranslate"><span class="pre">Sequential</span></code> 모델을 이용하여 층을 구성하면
아핀 변환,<code class="docutils literal notranslate"><span class="pre">relu()</span></code> 등의 활성화 함수를 연속적으로 적용하여
입력 텐서를 특정 모양의 텐서로 변환한다.</p>
<p>반면에 여러 개의 층을 다른 방식으로 구성한 모델은 다른 방식으로 텐서를
하나의 표현에서 다른 표현으로 변환한다.
이렇듯 층을 구성하는 방식에 따라 텐서들의 변환 방식이 정해진다.</p>
<p>딥러닝 신경망의 구성은 주어진 데이터셋과 모델의 목적에 따라 결정되며
특별히 따라야 하는 정해진 규칙은 없다.
따라서 모델의 구조는 이론 보다는 많은 실습을 통한 경험에 의존한다.
앞으로 많은 예제를 통해 다양한 모델을 구성하는 방식을 배울 것이다.</p>
</div>
<div class="section" id="id9">
<h3><span class="section-number">3.6.3. </span>모델 컴파일<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>모델의 훈련을 위해서 먼저 다음 세 가지 설정을 추가로 지정해야 한다.</p>
<ul class="simple">
<li><p>손실 함수: 훈련 중 모델의 성능이 얼마나 나쁜지 측정.
미분가능한 함수이어야 하며 옵티마이저가 역전파를 통해
모델의 성능을 향상시키는 방향으로 모델의 가중치를 업데이트할 때
참고하는 함수임.</p></li>
<li><p>옵티마이저: 백워드 패스와 역전파를 담당하는 알고리즘</p></li>
<li><p>평가지표: 훈련과 테스트 과정을 모니터링 할 때 사용되는 모델 평가 지표.
옵티마이저와 손실함수와는 달리 훈련에 관여하지 않으면서
모델 성능 평가에 사용됨.</p></li>
</ul>
<div class="proof example admonition" id="exc-compile">
<p class="admonition-title"><span class="caption-number">Example 3.3 </span></p>
<div class="example-content section" id="proof-content">
<p>아래 코드는 …</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;mean_squared_error&quot;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div><p>세 가지 설정에 사용된 문자열은 지정된 함수를 가리키도록 준비되어 있다.
예를 들어 아래 코드는 앞서의 컴파일과 동일한
결과가 나오도록 옵티마이저, 손실함수, 평가지표에 필요한 객체들을 직접 지정하였다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(),</span>
              <span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">(),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BinaryAccuracy</span><span class="p">()])</span>
</pre></div>
</div>
<p>앞으로 다양한 예제를 통해 옵티마이저, 손실함수, 평가지표를 적절하게 선택하는 방법을 살펴볼 것이다.</p>
<p><strong><code class="docutils literal notranslate"><span class="pre">fit()</span></code> 메서드 작동법</strong></p>
<p>모델을 훈련시키려면 <code class="docutils literal notranslate"><span class="pre">fit()</span></code> 메서드를 적절한 인자들과 함께 호출해야 함.</p>
<ul class="simple">
<li><p>훈련 세트: 보통 넘파이 어레이 또는 텐서플로우의 <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> 객체 사용</p></li>
<li><p>에포크(<code class="docutils literal notranslate"><span class="pre">epochs</span></code>): 전체 훈련 세트를 몇 번 훈련할 지 지정</p></li>
<li><p>배치 크기(<code class="docutils literal notranslate"><span class="pre">batch_size</span></code>): 배치 경사하강법에 적용될 배치(묶음) 크기 지정</p></li>
</ul>
<p>아래 코드는 앞서 넘파이 어레이로 생성한 (2000, 2) 모양의 양성, 음성 데이터셋을 대상으로 훈련한다.</p>
<p><strong>검증 세트 활용</strong></p>
<p>훈련된 모델이 완전히 새로운 데이터에 대해 예측을 잘하는지 여부를 판단하려면
전체 데이터셋을 훈련 세트와 <strong>검증 세트</strong>로 구분해야 함.</p>
<ul class="simple">
<li><p>훈련 세트: 모델 훈련에 사용되는 데이터셋</p></li>
<li><p>검증 세트: 훈련된 모델 평가에 사용되는 데이터셋</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">training_inputs</span><span class="p">,</span>
    <span class="n">training_targets</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_inputs</span><span class="p">,</span> <span class="n">val_targets</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="building_blocks_of_NN.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">2. </span>신경망 구성 요소</p>
        </div>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By 코딩알지<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>