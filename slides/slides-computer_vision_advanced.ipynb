{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 고급 컴퓨터 비전"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 주요 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 합성곱 신경망의 주요 활용 분야(컴퓨터 비전)\n",
    "    - 이미지 분류\n",
    "    - 이미지 분할\n",
    "    - 객체 탐지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 합성곱 신경망 기본 아키텍처\n",
    "    - 잔차 연결\n",
    "    - 배치 정규화\n",
    "    - 채널 분리 합성곱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 컴퓨터 비전 주요 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/computer_vision_tasks.png\" style=\"width:70%;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 기타 다양한 활용법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 유사도 측정(image similarity scoring)\n",
    "- 키포인트 탐지(keypoint detection)\n",
    "- 자세 추정(pose estimation)\n",
    "- 3D 메쉬 추정(3D mesh estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://github.com/Jeff-sjtu/HybrIK/raw/main/assets/hybrik.png\" style=\"width:70%;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 객체 탐지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 작동원리 설명: 핸즈온 머신러닝 14장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기초 활용법: [RetinaNet 활용 객체 탐지](https://keras.io/examples/vision/retinanet/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주요 활용 예제: [YOLOv5](https://github.com/ultralytics/yolov5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 이미지 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시맨틱 분할(semantic segmentation)\n",
    "\n",
    "- 인스턴스 분할(instance segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/instance_segmentation.png\" style=\"width:100%;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Oxford-IIIT 애완동물 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터셋 크기: 7,390"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 클래스(범주) 개수: 37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 클래스별 사진 수: 약 200 장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사진별 라벨: 종과 품종, 머리 표시 경계상자, 트라이맵 분할<font size='2'>trimap segmentation</font> 마스크 등 4 종류로 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 트라이맵 분할 마스크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원본 사진과 동일한 크기의 칼라 사진\n",
    "- 1, 2, 3 셋 중에 하나의 값만 사용\n",
    "\n",
    "    - 1: 동물의 몸에 해당하는 픽셀\n",
    "    - 2: 배경에 해당하는 픽셀\n",
    "    - 3: 동물과 배경을 구분하는 경계에 해당하는 픽셀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://www.robots.ox.ac.uk/~vgg/data/pets/pet_annotations.jpg\" style=\"width:70%;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 이미지 분할 모델 구성: 다운 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "inputs = keras.Input(shape=img_size + (3,))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "x = layers.Conv2D(64, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2D(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2D(256, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 이미지 분할 모델 구성: 업 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
    "x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
    "\n",
    "outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```python\n",
    "input_1 (InputLayer)         [(None, 200, 200, 3)]     0         \n",
    "_________________________________________________________________\n",
    "rescaling (Rescaling)        (None, 200, 200, 3)       0         \n",
    "_________________________________________________________________\n",
    "conv2d (Conv2D)              (None, 100, 100, 64)      1792      \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 100, 100, 64)      36928     \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 50, 50, 128)       73856     \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 50, 50, 128)       147584    \n",
    "_________________________________________________________________\n",
    "conv2d_4 (Conv2D)            (None, 25, 25, 256)       295168    \n",
    "_________________________________________________________________\n",
    "conv2d_5 (Conv2D)            (None, 25, 25, 256)       590080    \n",
    "_________________________________________________________________\n",
    "conv2d_transpose (Conv2DTran (None, 25, 25, 256)       590080    \n",
    "_________________________________________________________________\n",
    "conv2d_transpose_1 (Conv2DTr (None, 50, 50, 256)       590080    \n",
    "_________________________________________________________________\n",
    "conv2d_transpose_2 (Conv2DTr (None, 50, 50, 128)       295040    \n",
    "_________________________________________________________________\n",
    "conv2d_transpose_3 (Conv2DTr (None, 100, 100, 128)     147584    \n",
    "_________________________________________________________________\n",
    "conv2d_transpose_4 (Conv2DTr (None, 100, 100, 64)      73792     \n",
    "_________________________________________________________________\n",
    "conv2d_transpose_5 (Conv2DTr (None, 200, 200, 64)      36928     \n",
    "_________________________________________________________________\n",
    "conv2d_6 (Conv2D)            (None, 200, 200, 3)       1731      \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 컴파일과 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model.compile(optimizer=\"rmsprop\", \n",
    "              loss=\"sparse_categorical_crossentropy\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"oxford_segmentation\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(train_input_imgs, train_targets,\n",
    "                    epochs=50,\n",
    "                    callbacks=callbacks,\n",
    "#                    batch_size=64, # 고성능 GPU 활용\n",
    "                    batch_size=16,  # 저성능 GPU 활용\n",
    "                    validation_data=(val_input_imgs, val_targets))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 훈련 결과: `batch_size = 16`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0JfmCB2pYvG",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch09-training02.png\" style=\"width:500px;\"></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 훈련 결과: `batch_size = 64`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0JfmCB2pYvG"
   },
   "source": [
    "<p><div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch09-training01.png\" style=\"width:500px;\"></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0JfmCB2pYvG"
   },
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/09-06.png\" style=\"width:700px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CNN 아키텍처 주요 유형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "계속 이어짐..."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "dlp09_part01_image_segmentation",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "33b995ba57ec8806df76ad412cbfca6e91844af7e84c0aab5f00a2382a2b11c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
