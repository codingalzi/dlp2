{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 케라스와 텐서플로우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 딥러닝 주요 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텐서플로우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 케라스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파이토치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 텐서플로우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 파이썬에 기반한 머신러닝 플랫폼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 머신러닝 모델의 훈련에 필요한 텐서 연산을 지원\n",
    "    - 그레이디언트 자동 계산\n",
    "    - GPU, TPU 등 고성능 병렬 하드웨어 가속기 활용 가능\n",
    "    - 여러 대의 컴퓨터 또는 클라우드 컴퓨팅 서비스 활용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- C++(게임), 자바스크립트(웹브라우저), TFLite(모바일 장치) 등과 호환 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 단순한 패키지 기능을 넘어서는 머신러닝 플랫폼\n",
    "    - TF-Agents: 강화학습 연구 지원\n",
    "    - TFX: 머신러닝 프로젝트 운영 지원\n",
    "    - TensorFlow-Hub: 사전 훈련된 머신러닝 모델 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 케라스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 딥러닝 모델 구성 및 훈련에 효율적으로 사용될 수 있는 다양한 수준의 API를 제공\n",
    "- 텐서플로우의 프론트엔드<font size='2'>front end</font> 인터페이스 기능 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/keras_and_tf.png\" style=\"width:600px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 딥러닝 주요 라이브러리 약력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 2007년: 씨아노<font size='2'>Theano</font> 공개. \n",
    "    텐서를 이용한 계산 그래프, 미분 자동화 등을 최초로 지원한 딥러닝 라이브러리.\n",
    "- 2015년 3월: 케라스 라이브러리 공개. Theano를 백앤드로 사용하는 고수준 패키지.\n",
    "- 2015년 11월: 텐서플로우 라이브러리 공개.\n",
    "- 2016년: 텐서플로우가 케라스의 기본 백엔드로 지정됨.\n",
    "- 2016년 9월: 페이스북이 개발한 파이토치<font size='2'>PyTorch</font> 공개.\n",
    "- 2017년: Theano, 텐서플로우, CNTK(마이크로소프트), MXNet(아마존)이 케라스의 백엔드로 지원됨.\n",
    "    현재 Theano, CNTK 등은 더 이상 개발되지 않으며, MXNet은 아마존에서만 주로 사용됨.\n",
    "- 2018년 3월: PyTorch와 Caffe2를 합친 PyTorch 출시(페이스북과 마이크로소프트의 협업)\n",
    "- 2019년 9월: 텐서플로우 2.0부터 케라스가 텐서플로우의 최상위 프레임워크로 지정됨.\n",
    "- 2023년 가을: Keras Core가 케라스 3.0으로 출시 예정. 텐서플로우, PyTorch, JAX의 프론트엔드 기능 지원."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch03-keras-core.png?raw=true\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 텐서플로우 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndQbmG6DFAG2"
   },
   "source": [
    "- `tf.Tensor` 자료형\n",
    "    - 상수 텐서\n",
    "    - 입출력 데이터 등 변하지 않는 값을 다룰 때 사용.\n",
    "    - 불변 자료형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndQbmG6DFAG2"
   },
   "source": [
    "- `tf.Variable` 자료형\n",
    "    - 변수 텐서\n",
    "    - 모델의 가중치, 편향 등 항목의 업데이트가 필요할 때 사용되는 텐서.\n",
    "    - 가변 자료형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5vru5j1FAG2"
   },
   "source": [
    "### 상수 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0vwISUoFAG3"
   },
   "source": [
    "다양한 방식으로 상수 텐서를 생성할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ik-7kgRvFAG3",
    "outputId": "5e6203c3-d986-438e-de77-3de29930ccde"
   },
   "source": [
    "```python\n",
    ">>> x = tf.constant([[1., 2.], [3., 4.]])\n",
    ">>> print(x)\n",
    "tf.Tensor(\n",
    "[[1. 2.]\n",
    " [3. 4.]], shape=(2, 2), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9cKkurOFAG4",
    "outputId": "5208ce93-96ca-49a0-f184-28a23df68a27",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```python\n",
    ">>> x = tf.ones(shape=(2, 1))\n",
    ">>> print(x)\n",
    "tf.Tensor(\n",
    "[[1.]\n",
    " [1.]], shape=(2, 1), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnQI7pjoFAG4",
    "outputId": "36a7a2c3-b07f-46d8-d571-aec48ab40bc1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```python\n",
    ">>> x = tf.zeros(shape=(2, 1))\n",
    ">>> print(x)\n",
    "tf.Tensor(\n",
    "[[0.]\n",
    " [0.]], shape=(2, 1), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhYg7coSFAG4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- `normal()` 함수: 정규 분포 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sbkziq-8FAG5",
    "outputId": "30a65b88-c0d9-44aa-d64c-0685d39beb09",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    ">>> x = tf.random.normal(shape=(3, 1), mean=0., stddev=1.)\n",
    ">>> print(x)\n",
    "tf.Tensor(\n",
    "[[-0.5644841 ]\n",
    " [-0.76016265]\n",
    " [ 0.30502525]], shape=(3, 1), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zqwCJ7hFAG5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- `uniform()` 함수: 균등 분포 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qmYorXi5FAG5",
    "outputId": "06edee6b-0c9b-4243-d03f-54cdfc969fa3",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    ">>> x = tf.random.uniform(shape=(3, 1), minval=0., maxval=1.)\n",
    ">>> print(x)\n",
    "tf.Tensor(\n",
    "[[0.33661604]\n",
    " [0.09824598]\n",
    " [0.32487237]], shape=(3, 1), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CV8pyHNnFAG5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**상수 텐서의 수정 불가능성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vg5KyONiFAG6"
   },
   "source": [
    "```python\n",
    ">>> x[0, 0] = 1.0\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-7-242a5d4d3c4a> in <module>\n",
    "----> 1 x[0, 0] = 1.0\n",
    "\n",
    "TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaMXIVgVFAG6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**텐서 항목의 자료형**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2xvuVdJFAG7"
   },
   "source": [
    "텐서 항목의 자료형은 `EagerTensor` 라는 텐서다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96zsfMQzFAG7",
    "outputId": "4e84cd10-b13f-48a7-bad6-19cc07e7a69e"
   },
   "source": [
    "```python\n",
    ">>> type(x[0, 0])\n",
    "tensorflow.python.framework.ops.EagerTensor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VujYaZeAFAG7",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 변수 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0aTLKr4mFAG7",
    "outputId": "69422e5c-3eaa-421d-d941-350ee753dcef"
   },
   "source": [
    "```python\n",
    ">>> v = tf.Variable(initial_value=tf.random.normal(shape=(3, 1)))\n",
    ">>> print(v)\n",
    "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
    "array([[-1.3837979 ],\n",
    "       [-0.23704937],\n",
    "       [-0.9790895 ]], dtype=float32)>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cHdR9y3FAG7",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**변수 텐서 교체**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UhHAaaIFAG7"
   },
   "source": [
    "`assign()` 메서드는 해당 텐서를 통채로 다른 텐서로 대체한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6Q4b_S6FAG7",
    "outputId": "b8bfc8de-6547-4534-fd15-bca4e3edcf56"
   },
   "source": [
    "```python\n",
    ">>> v.assign(tf.ones((3, 1)))\n",
    "<tf.Variable 'UnreadVariable' shape=(3, 1) dtype=float32, numpy=\n",
    "array([[1.],\n",
    "       [1.],\n",
    "       [1.]], dtype=float32)>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpdPpCRGFAG7",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "단, 대체하는 텐서의 모양(shape)이 기존 텐서의 모양과 동일해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCCnDJrXFAG8"
   },
   "source": [
    "```python\n",
    ">>> v.assign(tf.ones((3, 2)))\n",
    "ValueError                                Traceback (most recent call last)\n",
    "<ipython-input-13-e381ab0c94e6> in <module>\n",
    "----> 1 v.assign(tf.ones((3, 2)))\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py in assign(self, value, use_locking, name, read_value)\n",
    "    886         else:\n",
    "    887           tensor_name = \" \" + str(self.name)\n",
    "--> 888         raise ValueError(\n",
    "    889             (\"Cannot assign to variable%s due to variable shape %s and value \"\n",
    "    890              \"shape %s are incompatible\") %\n",
    "\n",
    "ValueError: Cannot assign to variable Variable:0 due to variable shape (3, 1) and value shape (3, 2) are incompatible\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdwzz0TTFAG8",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**변수 텐서 항목 수정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEVgeGYIFAG8",
    "outputId": "8236ec7e-bf07-4eb2-929a-60a50861cbc8"
   },
   "source": [
    "```python\n",
    ">>> v[0, 0].assign(3.)\n",
    "<tf.Variable 'UnreadVariable' shape=(3, 1) dtype=float32, numpy=\n",
    "array([[3.],\n",
    "       [1.],\n",
    "       [1.]], dtype=float32)>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-gFG2uaFAG_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `assign_add()`와 `assign_sub()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYM5RzvMFAHA"
   },
   "source": [
    "- `assign_sub()` 메서드는 `-=` 연산자 \n",
    "- `assign_add()` 메서드는 `+=` 연산자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-42Xd2hFAHA",
    "outputId": "3d0dcab7-a8d1-4dad-efd6-2a75f12fee7f"
   },
   "source": [
    "```python\n",
    ">>> v.assign_sub(tf.ones((3, 1)))\n",
    "<tf.Variable 'UnreadVariable' shape=(3, 1) dtype=float32, numpy=\n",
    "array([[2.],\n",
    "       [0.],\n",
    "       [0.]], dtype=float32)>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 텐서플로우 활용법 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 그레이디언트 테이프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x) = x^2 \\quad \\Longrightarrow \\quad \\nabla f(x) = \\frac{df(x)}{dx} = 2x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> input_var = tf.Variable(initial_value=3.)\n",
    "\n",
    ">>> with tf.GradientTape() as tape:\n",
    "...     result = tf.square(input_var)\n",
    "\n",
    ">>> gradient = tape.gradient(result, input_var)\n",
    "\n",
    ">>> print(gradient)\n",
    "tf.Tensor(6.0, shape=(), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예제: 선형 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**1단계: 데이터셋 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "num_samples_per_class = 1000\n",
    "\n",
    "# 음성 데이터셋\n",
    "negative_samples = np.random.multivariate_normal(\n",
    "    mean=[0, 3], cov=[[1, 0.5],[0.5, 1]], size=num_samples_per_class)\n",
    "\n",
    "# 양성 데이터셋\n",
    "positive_samples = np.random.multivariate_normal(\n",
    "    mean=[3, 0], cov=[[1, 0.5],[0.5, 1]], size=num_samples_per_class)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/03-07.png\" style=\"width:300px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- `negative_sample`: (1000, 2) 모양의 텐서\n",
    "- `positive_sample`: (1000, 2) 모양의 텐서\n",
    "- `inputs = np.vstack(negative_sample, positive_sample)`: (2000, 2) 모양의 텐서\n",
    "    - `negative_sample` 데이터셋이 0번부터 999번까지 인덱스.\n",
    "    - `positive_sample` 데이터셋이 1000번부터 1999번까지 인덱스."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "inputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "음성 샘플의 레이블은 0, 양성 샘플의 레이블은 1로 지정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.zeros((num_samples_per_class, 1), dtype=\"float32\")`: (1000, 1) 모양의 어레이. 0으로 채워짐. \n",
    "    0번부터 999번 인덱스까지의 모든 음성 데이터의 타깃은 0임.\n",
    "- `np.ones((num_samples_per_class, 1), dtype=\"float32\")`: (1000, 1) 모양의 어레이. 1로 채워짐. \n",
    "    999번부터 1999번 인덱스까지의 모든 양성 데이터의 타깃은 1임.\n",
    "- `targets`: (2000, 1) 모양의 어레이."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "targets = np.vstack((np.zeros((num_samples_per_class, 1), dtype=\"float32\"),\n",
    "                     np.ones((num_samples_per_class, 1), dtype=\"float32\")))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**2단계: 선형 회귀 모델 훈련에 필요한 가중치 변수 텐서와 편향 변수 텐서 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형 분류기 모델의 예측값 계산은 다음과 같이 아핀 변환으로 이뤄진다.\n",
    "\n",
    "```python\n",
    "inputs @ W + b\n",
    "```\n",
    "\n",
    "- `inputs`: (2000, 2) 모양의 입력 데이터셋 행렬\n",
    "- `W`: (2, 1) 모양의 가중치 행렬\n",
    "- `inputs @ W`: (2000, 1) 모양의 행렬\n",
    "-  `b`: (1,) 모양의 편향 벡터\n",
    "- `inputs @ W + b`: (2000, 1) 모양의 출력값 행렬. 즉, 2000 개의 입력 데이터 각각에 대해 하나의 값의 계산됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "input_dim = 2     # 입력 샘플의 특성이 2개\n",
    "output_dim = 1    # 각각의 입력 샘플에 대해 하나의 부동소수점을 예측값으로 계산\n",
    "```\n",
    "\n",
    "```python\n",
    "# 가중치: (2, 1) 모양의 가중치 행렬을 균등분포를 이용한 무작위 초기화\n",
    "W = tf.Variable(initial_value=tf.random.uniform(shape=(input_dim, output_dim)))\n",
    "\n",
    "# 편향: (1,) 모양의 벡터를 0으로 초기화\n",
    "b = tf.Variable(initial_value=tf.zeros(shape=(output_dim,)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**3단계: 모델 선언(포워드 패스)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def dense(inputs, W, b, activation=None):\n",
    "    outputs = tf.matmul(inputs, W) + b\n",
    "    if activation != None:\n",
    "        return activation(outputs)\n",
    "    else:\n",
    "        return outputs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def model(inputs):\n",
    "    outputs = dense(inputs, W, b)\n",
    "    return outputs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**4단계: 손실 함수 지정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{1}{m_b}\\sum (y - \\hat y)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def square_loss(targets, predictions):\n",
    "    per_sample_losses = tf.square(targets - predictions)\n",
    "    return tf.reduce_mean(per_sample_losses)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**5단계: 훈련 스텝(역전파) 지정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def training_step(inputs, targets):\n",
    "    \"\"\"\n",
    "    - inputs: 입력 데이터 배치\n",
    "    - targets: 타깃 배치\n",
    "    \"\"\"\n",
    "\n",
    "    # 손실 함수의 그레이디언트 계산 준비\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs)\n",
    "        loss = square_loss(targets, predictions)\n",
    "\n",
    "    # 가중치와 편향에 대한 손실 함수의 그레이디언트 계산\n",
    "    grad_loss_wrt_W, grad_loss_wrt_b = tape.gradient(loss, [W, b])\n",
    "    \n",
    "    # 가중치 행렬과 편향 벡터 업데이트\n",
    "    W.assign_sub(grad_loss_wrt_W * learning_rate) # 가중치 행렬 업데이트\n",
    "    b.assign_sub(grad_loss_wrt_b * learning_rate) # 편향 업데이트\n",
    "    \n",
    "    return loss\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**6단계: 훈련 루프 지정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 반복해서 훈련한 내용을 출력\n",
    "- 설명을 간단하게 하기 위해 전체 데이터셋을 하나의 배치로 사용하는 훈련 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "for step in range(40):\n",
    "    loss = training_step(inputs, targets)\n",
    "    print(f\"Loss at step {step}: {loss:.4f}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**7단계: 결정경계**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결정경계를 직선으로 그리려면 아래 일차 함수를 이용한다.\n",
    "\n",
    "```python\n",
    "y = - W[0] /  W[1] * x + (0.5 - b) / W[1]\n",
    "```\n",
    "\n",
    "이유는 아래 식으로 계산되는 모델의 예측값이\n",
    "0.5보다 큰지 여부에 따라 양성/음성이 판단되기 때문이다.\n",
    "\n",
    "```python\n",
    "W[0]*x + W[1]*y + b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch03-bin_classification.png?raw=true\" style=\"width:300px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 케라스 신경망 모델의 핵심 API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 신경망 모델은 층으로 구성됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 모델에 사용되는 층의 종류와 층을 쌓는 방식에 따라 모델이 처리할 수 있는 데이터와 훈련 방식이 달라짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 케라스 라이브러리가 층을 구성하고 훈련 방식을 관장하는 다양한 API 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 입력 데이터를 지정된 방식에 따라 다른 모양의 데이터로 변환하는 **포워드 패스**<font size='2'>forward pass</font> 담당"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 데이터 변환에 사용되는 가중치<font size='2'>weight</font>와 편향<font size='2'>bias</font> 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**층의 종류**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "층의 종류에 따라 입력 배치 데이터셋 텐서의 모양이 달라진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Dense` 클래스\n",
    "    - 밀집층 생성\n",
    "    - `(배치 크기, 특성 수)` 모양의 2D 텐서로 입력된 데이터셋 처리."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `LSTM` 또는 `Conv1D` 클래스\n",
    "    - 순차 데이터와 시계열 데이터 분석에 사용되는 순환층 생성\n",
    "    - `(배치 크기, 타임스텝 수, 특성 수)` 모양의 3D 텐서로 입력된 순차 데이터셋 처리."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Conv2D` 클래스\n",
    "    - 합성곱 신경망(CNN) 구성에 사용되는 합성곱층 생성\n",
    "    - `(배치 크기, 가로, 세로, 채널 수)` 모양의 4D 텐서로 제공된 이미지 데이터셋 처리."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**`tf.keras.layers.Layer` 클래스**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 케라스의 모든 층 클래스는 `tf.keras.layers.Layer` 클래스를 상속한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 상속되는 `__call__()` 메서드: \n",
    "    - 가중치와 편향 텐서의 초기화. 가중치와 편향이 이미 생성되어 있다면 새로 생성하지 않고 그대로 사용.\n",
    "    - 입력 데이터셋을 출력 데이터셋으로 변환하는 포워드 패스를 수행    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `__call__()` 메서드가 하는 일\n",
    "\n",
    "```python\n",
    "def __call__(self, inputs):\n",
    "    if not self.built:\n",
    "        self.build(inputs.shape)\n",
    "        self.built = True\n",
    "    return self.call(inputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Dense` 클래스 직접 구현하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{numref}`%s절 <sec:nn-mnist>`에서 MNIST 데이터셋을 이용한 분류 모델에 사용된\n",
    "신경망 모델은 연속으로 쌓은 두 개의 `Dense` 층으로 구성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dense` 클래스와 유사하게 작동하는 클래스를 직접 정의하려면 \n",
    "상속해야 하는 `keras.layers.Layer` 클래스의 `__call()__` 메서드에 의해 호출되는\n",
    "`build()` 메서드와 `call()` 메서드를 구현해야 한다.\n",
    "아래 `SimpleDense` 클래스가 `Dense` 클래스의 기능을 단순화하여 구현한다.\n",
    "\n",
    "두 메서드의 정의에 사용된 매개변수와 메서드는 다음과 같다.\n",
    "\n",
    "- `units`: 출력 샘플의 특성 수 지정\n",
    "- `activation`: 활성화 함수 지정\n",
    "- `input_shape`: 입력값(`inputs`)으로 얻은 입력 배치의 2D 모양 정보. 둘째 항목이 입력 샘플의 특성 수.\n",
    "- `add_weight(모양, 초기화방법)`: 지정된 모양의 텐서 생성 및 초기화. `Layer` 클래스에서 상속."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "from tensorflow import keras\n",
    "\n",
    "class SimpleDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None):\n",
    "        super().__init__()\n",
    "        self.units = units           # 유닛 개수 지정\n",
    "        self.activation = activation # 활성화 함수 지정\n",
    "\n",
    "    # 가중치와 편향 초기화\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]   # 입력 샘플의 특성 수\n",
    "        self.W = self.add_weight(shape=(input_dim, self.units),\n",
    "                                 initializer=\"random_normal\")\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer=\"zeros\")\n",
    "\n",
    "    # 데이터 변환(포워드 패스)\n",
    "    def call(self, inputs):\n",
    "        y = tf.matmul(inputs, self.W) + self.b\n",
    "        if self.activation is not None:\n",
    "            y = self.activation(y)\n",
    "        return y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{prf:example} `SimpleDense` 층의 데이터 변환\n",
    ":label: simpledense\n",
    "\n",
    "모델 훈련 과정에서 포워드 패스는 층에서 층으로 이어지는 연속된 데이터 변환으로 이뤄진다.\n",
    "`SimpleDense` 층을 이용하여 입력 데이터셋이 어떻게 변환되어 다음 층으로 전달되는 과정을 살펴본다.\n",
    "\n",
    "아래 코드에서 `my_dense` 변수는 하나의 `SimpleDense` 층을 가리킨다.\n",
    "\n",
    "- 유닛 수: 32개\n",
    "- 활성화 함수: `relu`\n",
    "\n",
    "```python\n",
    ">>> my_dense = SimpleDense(units=512, activation=tf.nn.relu)\n",
    "```\n",
    "\n",
    "아래 코드는 입력 배치 데이터셋으로 사용할 (128, 784) 모양의 텐서를 생성한다.\n",
    "\n",
    "- 128: 배치 크기\n",
    "- 784: MNIST 데이터셋의 손글씨 이미지 한 장의 특성 수(`28 * 28 = 128`)\n",
    "\n",
    "```python\n",
    ">>> input_tensor = tf.ones(shape=(128, 784))\n",
    "```\n",
    "\n",
    "이제 `my_dense`를 함수 호출하듯이 사용하면 출력값이 계산된다.\n",
    "즉, 포워드 패스가 실행된다.\n",
    "층은 입렵 데이터셋을 처리할 때 입력 데이터셋의 모양을 확인하기에 \n",
    "굳이 입력 데이터셋에 대한 정보를 미리 요구하지 않는다.\n",
    "\n",
    "\n",
    "```python\n",
    ">>> output_tensor = my_dense(input_tensor)\n",
    "```\n",
    "\n",
    "내부적으로는 `__call__()` 메서드가 호출되어 다음 사항들이 연속적으로 처리된다. \n",
    "\n",
    "- 가중치 텐서와 와 편향 텐서가 생성되지 않은 경우\n",
    "    - `(784, 512)` 모양의 가중치 텐서 `W` 생성 및 무작위 초기화. 782는 입력 샘플의 특성 수, 512는 층의 유닛 수.\n",
    "    - `(512, )` 모양의 편향 텐서 `b` 생성 및 `0`으로 초기화. 512는 층의 유닛 수.\n",
    "    - 포워드 패스: 생성된 가중치와 편향을 이용하여 출력값 계산.\n",
    "\n",
    "- 가중치 텐서와 와 편향 텐서가 생성되어 있는 경우. 즉 훈련이 반복되는 경우.\n",
    "    - 포워드 패스: 역전파로 업데이트된 가중치와 편향을 이용하여 출력값 계산.\n",
    "\n",
    "층의 출력값은 `(128, 32)` 모양의 텐서다.\n",
    "이유는 각 데이터 샘플의 784개의 특성이 32개의 특성으로 변환되었기 때문이다.\n",
    "\n",
    "```python\n",
    ">>> print(output_tensor.shape)\n",
    "(128, 512)\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 살펴 본 `Sequential` 모델은 층을 일렬로 쌓는 모델이며\n",
    "각각의 층은 이전 층에서 전달된 배치 데이터셋을 변환해서 다음 층으로 전달한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.keras.Model` 클래스**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sequential` 클래스를 포함하여 케라스에서 지원되는 모든 모델 클래스는 `tf.keras.Model` 클래스를 상속한다.\n",
    "예를 들어 `Sequential` 클래스를 이용하여 정의된 MNIST 분류 모델을 `SimpleDense` 층을 이용하여 직접 다음과 같이 정의할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class MyMNistModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = SimpleDense(units=512, activation=tf.nn.relu)   # 첫째 밀집층\n",
    "        self.layer_2 = SimpleDense(units=10, activation=tf.nn.softmax) # 둘째 밀집층\n",
    "\n",
    "    # 포워드 패스: 층과 층을 연결하는 방식으로 구현\n",
    "    def call(self, inputs):\n",
    "        features = self.layer_1(inputs)\n",
    "        outputs = self.layer_2(features)\n",
    "        return outputs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} 직접 구현한 `SimpleDense` 층과 케라스의 `Dense` 층의 차이점\n",
    ":class: note\n",
    "\n",
    "`keras.layers.Dense` 층을 이용한다면 다음과 같이 활성화 함수를 문자열로 지정할 수 있다.\n",
    "\n",
    "```python\n",
    "class MyMNistModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = keras.layers.Dense(units=512, activation=\"relu\")\n",
    "        self.layer_2 = keras.layers.Dense(units=10, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.layer_1(inputs)\n",
    "        outputs = self.layer_2(features)\n",
    "        return outputs\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**모델을 하나의 층으로 활용하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존에 정의된 모델을 다른 모델을 구성할 때 하나의 층으로 활용할 수도 있다.\n",
    "이런 이유로 `tf.keras.Model` 클래스는 `tf.keras.layers.Layer` 클래스를 \n",
    "상속하도록 설계되어 있다.\n",
    "`tf.keras.Model` 클래스의 활용법에 대한 보다 자세한 설명은 {numref}`%s장 <ch:working_with_keras>`을 참고한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**모델의 학습과정과 층의 구성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "모델의 학습과정은 전적으로 층의 구성방식에 의존한다. \n",
    "그리고 층의 구성 방식은 주어진 데이터셋과 모델이 해결해야 하는 문제에 따라 달라진다.\n",
    "층을 구성할 때 특별히 정해진 규칙은 없지만 \n",
    "문제 유형에 따른 권장 모델이 다양하게 개발되어 있다.\n",
    "\n",
    "앞으로 보다 복잡하고 다양한 방식으로 층을 구성하는 방식들을 살펴볼 것이다.\n",
    "예를 들어, 아래 그림은 {numref}`%s장 자연어 처리 <ch:nlp>`에서 소개하는\n",
    "트랜스포머<font size='2'>Transformer</font> 모델의 복잡한 층 연결 구조를 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/transformer0001.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**모델 컴파일**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선언된 모델을 훈련시키려면 다음 세 가지 설정을 추가로 지정해야 한다.\n",
    "\n",
    "- 손실 함수\n",
    "    - 훈련 중 모델의 성능이 얼마나 나쁜지 측정.\n",
    "    - 가중치와 편향 의존하는 함수\n",
    "    - 가중치와 편향에 대해 미분 가능해야 함.\n",
    "    - 옵티마이저가 역전파를 통해 모델의 성능을 향상시키는 방향으로 모델의 가중치를 업데이트할 때 참고하는 함수임.\n",
    "- 옵티마이저\n",
    "    - 가중치와 편향을 업데이트하는 역전파 반복 실행\n",
    "- 평가지표 \n",
    "    - 훈련과 테스트 과정을 모니터링 할 때 사용되는 모델 평가 지표.\n",
    "    - 손실 함수와는 달리 훈련에 사용되지 않음.\n",
    "    - 단순히 모델 성능 평가에 사용됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "케라스를 이용하면 옵티마이저, 손실 함수, 평가지표를 문자열로 지정할 수 있다.\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([keras.layers.Dense(1)])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"mean_squared_error\",\n",
    "              metrics=[\"accuracy\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "각각의 문자열은 특정 파이썬 객체를 가리킨다.\n",
    "\n",
    "| 문자열 | 파이썬 객체 |\n",
    "| :--- | :--- |\n",
    "| `\"rmsprop\"` | `keras.optimizers.RMSprop()` |\n",
    "| `\"mean_squared_error\"` | `keras.losses.MeanSquaredError()` |\n",
    "| `\"accuracy\"` | `keras.metrics.BinaryAccuracy()]` |\n",
    "\n",
    "따라서 지정된 문자열을 사용하는 대신 파이썬 객체를 직접 지정해도 된다.\n",
    "만약 사용자가 직접 구현한 클래스의 객체를 이용하려면\n",
    "앞서 `SimpleDense`를 통해 본 것처럼 적절한 클래스를 상속하면서\n",
    "동시에 필수 메서드를 모두 적절하게 재정의해야<font size='2'>overriding</font> 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.MeanSquaredError(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy()])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "다음 두 가지의 경우엔 문자열 대신 해당 객체를 지정해야 한다.\n",
    "- 예를 들어, 기본값과 다른 학습률(`learning_rate`)을 사용하는 옵티마이저를 지정하는 경우\n",
    "- 사용자가 직접 정의한 객체를 사용하는 경우\n",
    "\n",
    "아래 코드는 직접 객체를 지정하는 방식으로 모델을 컴파일하는 형식을 보여준다.\n",
    "```python\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              loss=사용자정의손실함수객체,\n",
    "              metrics=[사용자정의평가지표_1, 사용자정의평가지표_2])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 가장 많이 사용되는 옵티마이저, 손실함수, 평가지표는 다음과 같으며\n",
    "앞으로 다양한 예제를 통해 적절한 옵티마이저, 손실함수, 평가지표를 선택하는 방법을 살펴볼 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "옵티마이저:\n",
    "\n",
    "- SGD (with or without momentum)\n",
    "- RMSprop\n",
    "- Adam\n",
    "- Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실 함수:\n",
    "\n",
    "- CategoricalCrossentropy\n",
    "- SparseCategoricalCrossentropy\n",
    "- BinaryCrossentropy\n",
    "- MeanSquaredError\n",
    "- KLDivergence\n",
    "- CosineSimilarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가지표:\n",
    "\n",
    "- CategoricalAccuracy\n",
    "- SparseCategoricalAccuracy\n",
    "- BinaryAccuracy\n",
    "- AUC\n",
    "- Precision\n",
    "- Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 루프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 컴파일한 다음에 `fit()` 메서드를 호출하면\n",
    "모델은 스텝 단위로 반복되는 **훈련 루프**<font size='2'>training loop</font>가 작동한다.\n",
    "지정된 에포크 만큼 또는 학습이 충분히 이루어졌다는 평가가 내려질 때까지\n",
    "훈련을 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**모델 훈련**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "모델을 훈련시키려면 `fit()` 메서드를 적절한 인자들과 함께 호출해야 한다.\n",
    "\n",
    "```python\n",
    "training_history = model.fit(\n",
    "    inputs,\n",
    "    targets,\n",
    "    epochs=5,\n",
    "    batch_size=128\n",
    ")\n",
    "```\n",
    "\n",
    "- (지도 학습 모델의 경우) 훈련셋(inputs)과 타깃셋(targets): 보통 넘파이 어레이 또는 텐서플로우의 `Dataset` 객체 사용\n",
    "- 에포크(`epochs`): 전체 훈련 세트를 몇 번 훈련할 지 지정\n",
    "- 배치 크기(`batch_size`): 하나의 스텝 과정에서 사용되는 데이터 묶음(배치)의 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`History` 객체: 훈련 결과**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 훈련 결과로 `History` 객체가 반환된다.\n",
    "예를 들어 `History` 객체의 `history` 속성은 에포크별로 계산된 손실값과 평가지표값을\n",
    "사전 자료형으로 가리킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> training_history.history\n",
    "{'loss': [9.07500171661377,\n",
    "  8.722702980041504,\n",
    "  8.423994064331055,\n",
    "  8.137178421020508,\n",
    "  7.8575215339660645],\n",
    " 'binary_accuracy': [0.07800000160932541,\n",
    "  0.07999999821186066,\n",
    "  0.08049999922513962,\n",
    "  0.08449999988079071,\n",
    "  0.0860000029206276]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**검증 데이터 활용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "머신러닝 모델 훈련의 목표는 훈련셋에 대한 높은 성능이 아니라\n",
    "훈련에서 보지 못한 새로운 데이터에 대한 정확한 예측이다.\n",
    "훈련 중에 또는 훈련이 끝난 후에 모델이 새로운 데이터에 대해 정확한 예측을 하는지\n",
    "여부를 판단하도록 할 수 있다.\n",
    "\n",
    "이를 위해 전체 데이터셋을 훈련셋과 검증셋<font size='2'>validation dataset</font>으로 구분한다.\n",
    "훈련셋과 검증셋의 비율은 보통 8대2 또는 7대3 정도로 하지만\n",
    "훈련셋이 매우 크다면 검증셋의 비율을 보다 적게 잡을 수 있다.\n",
    "훈련셋 자체가 매우 작은 경우엔 검증셋을 따로 분리하기 보다는 K-겹 교차 검증 등을 사용해야 한다.\n",
    "\n",
    "훈련셋과 검증셋이 서로 겹치지 않도록 주의해야 한다.\n",
    "그렇지 않으면 훈련 중에 모델이 검증셋에 포함된 데이터를 학습하기에\n",
    "정확환 모델 평가를 할 수 없게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*훈련 중 모델 검증*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "아래 코드는 미리 지정된 검증셋 `val_inputs`와 검증 타깃값 `val_targets`를\n",
    "`validation_data`의 키워드 인자로 지정해서\n",
    "모델 훈련 중에 에포크 단위로 측정하도록 한다.\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    training_inputs,\n",
    "    training_targets,\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    validation_data=(val_inputs, val_targets)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*훈련 후 모델 검증*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "훈련이 끝난 모델의 성능 검증하려면 `evaluate()` 메서드를 이용한다.\n",
    "배치 크기(`batch_size`)를 지정하여 배치 단위로 학습하도록 한다.\n",
    "\n",
    "```python\n",
    ">>> loss_and_metrics = model.evaluate(val_inputs, val_targets, batch_size=128)\n",
    "```\n",
    "\n",
    "반환값으로 지정된 손실값과 평가지표를 담은 리스트가 생성된다.\n",
    "\n",
    "```python\n",
    ">>> print(loss_and_metrics)\n",
    "[0.29411643743515015, 0.5333333611488342]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 훈련과 검증이 완료되면 실전에서 새로운 데이터에 대한 예측을 진행한다.\n",
    "데이터셋에 포함된 모든 데이터에 대한 예측을 한 번에 실행할 수 있으며\n",
    "두 가지 방식이 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**모델 적용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 마치 함수처럼 이용한다. \n",
    "\n",
    "```python\n",
    "predictions = model(new_inputs)\n",
    "```\n",
    "\n",
    "내부적으론 앞서 설명한 `__call()__` 메서드가 실행된다.\n",
    "따라서 `call()` 메서드를 사용하는 포워드 패스가 실행되어\n",
    "예측값이 계산된다.\n",
    "\n",
    "하지만 이 방식은 입력 데이터셋 전체를 대상으로 한 번에 계산하기에\n",
    "데이터셋이 너무 크면 계산이 너무 오래 걸리거나 메모리가 부족해질 수 있다.\n",
    "따라서 배치를 활용하는 `predict()` 메서드를 활용할 것을 추천한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`predict()` 메서드**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련된 모델의 `predict()` 메서드는 배치 크기를 지정하면\n",
    "배치 단위로 예측값을 계산한다.\n",
    "\n",
    "```python\n",
    "predictions = model.predict(new_inputs, batch_size=128)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [(실습) 케라스와 텐서플로우](https://colab.research.google.com/github/codingalzi/dlp2/blob/master/excs/exc-keras_and_tf.ipynb)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "chapter03_introduction-to-keras-and-tf.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c86b3592b6800d985c04531f2c445f0fa6967131b8dd6395a925f7622e55602"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
