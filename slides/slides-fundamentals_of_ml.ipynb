{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 최적화와 일반화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 주요 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 최적화, 일반화, 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 모델 훈련 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 모델 일반화 성능 향상 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 최적화, 일반화, 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 머신러닝 모델 훈련의 핵심: 최적화 vs. 일반화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최적화<font size='2'>optimization</font>: 훈련셋에 대해 가장 좋은 성능 이끌어내기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일반화<font size='2'>generalization</font>: 훈련 과정에서 보지 못한 데이터에 대한 성능 향상시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 훈련의 핵심: 최적화 대 일반화 사이의 적절한 관계 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 과대적합 vs. 과소적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/typical_overfitting.png\" style=\"width:700px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 과대적합 발생 주요 요인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "첫째, 훈련셋에 포함된 노이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "둘째, 애매한 특성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "셋째: 특성과 타깃 사이의 거짓 상관관계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 첫째, 훈련셋에 포함된 노이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- 노이즈<font size='2'>noise</font>: 적절하지 않은 데이터 또는 잘못된 라벨을 갖는 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 예제: 불분명한 MNNIST 이미지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/fucked_up_mnist.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 예제: 잘못된 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/mislabeled_mnist.png\" style=\"width:660px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 노이즈 영향\n",
    "    - 노이즈 또는 이상치를 학습하면 일반적이지 않은 특별한 특성을 학습하게 됨\n",
    "    - 일반화 성능 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/outliers_and_overfitting.png\" style=\"width:660px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 둘째, 애매한 특성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "노이즈 등의 이상치가 전혀 없다 하더라도 특정 특성 영역에 대한 예측값이 여러 개의 값을 가질 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/iris01.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 예제: 붓꽃 데이터셋. 꽃잎의 길이와 너비만을 활용해서는 완전한 분류 불가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch05/homl05-03b.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 훈련을 오래 시키면 각 샘플 고유의 특성을 일반적인 특성으로 해석.해당 라벨의 고유의 특성으로\n",
    "- 샘플의 특성에 너무 민감하게 작동"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/HighResolutionFigures/figure_5-5.png\" style=\"width:660px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 셋째: 특성과 타깃 사이의 거짓 상관관계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 매우 드문 특성을 사용하는 데이터셋으로 훈련하는 경우\n",
    "    - 체리모야를 언급한 리뷰가 긍정인 경우. 체리모야를 긍정과 연계시킴."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/cherimoya.jpg\" style=\"width:300px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">체리모야 열매</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 우연에 의한 경우\n",
    "    - 예제: \"너무\" 라는 단어를 포함한 100개의 영화 후기 중에서 54%는 긍정, 나머지 46%는 부정인 경우\n",
    "        훈련중인 모델은 \"너무\"라는 단어를 긍정적으로 평가할 가능성을 높힘."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 의미 없는 특성에 의한 경우: 화이트 노이즈 추가\n",
    "\n",
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch05-mnist-noise.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 화이트 노이즈가 추가되면 성능 떨어짐\n",
    "\n",
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch05-mnist-noise03.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증셋을 활용하여 모델의 일반화 능력을 평가하는 방법을 소개한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 훈련셋, 검증셋, 테스트셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트셋은 모델 구성과 훈련에 전혀 관여하지 않아야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 구성된 모델의 성능을 평가하려면 테스트셋을 제외한 다른 데이터셋이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련셋의 일부를 검증셋으로 활용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 검증셋은 훈련 과정 중에 모델의 일반화 성능을 테스트하는 용도로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 튜닝: 모델의 검증셋에 대한 성능 평가를 바탕으로 모델 구성과 모델의 하이퍼파라미터<font size='2'>hyperparameter</font> 설정 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 튜닝과 정보 유출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 튜닝도 모델의 좋은 하이퍼파라미터를 찾아가는 일종의 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 튜닝을 많이 하게되면 검증셋에 특화된 모델이 얻어질 가능성이 커짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정보 유출: 검증셋에 과대적합된 모델이 훈련될 가능성이 높아지는 현상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 평가용 데이터셋 준비 관련 주의사항"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대표성: 데이터셋 무작위 섞은 후 훈련셋, 검증셋, 데이터셋 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 순서 준수: 미래를 예측하는 모델을 훈련시킬 때, 테스트셋의 데이터는 훈련셋의 데이터보다\n",
    "    시간상 뒤쪽에 위치하도록 해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중복 데이터 제거: 훈련셋과 테스트셋에 동일한 데이터가 들어가지 않도록 중복 데이터를 제거해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 검증셋 활용법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "홀드아웃<font size='2'>hold-out</font> 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/holdout_validation.png\" style=\"width:350px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "K-겹 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/k_fold_validation.png\" style=\"width:650px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 성능 평가의 기준선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MNIST 데이터셋: 10%의 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IMDB 데이터셋: 50%의 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 로이터 통신 기사: 18-19%의 정확도. 기사들이 균등하게 분포되어 있지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 모델 훈련 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 첫째, 훈련셋의 손실값이 줄어들지 않아 훈련이 제대로 진행되지 않는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 둘째, 훈련셋의 손실값은 줄어들지만 검증셋의 성능은 평가 기준선을 넘지 못하는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 셋째, 훈련셋과 검증셋의 평가가 기준선을 넘어 계속 좋아지지만 과대적합이 발생하지 않아\n",
    "    계속해서 과소적합 상태로 머무는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일반적인 해결책 \n",
    "    - 모델의 보다 적절한 하이퍼파라미터 선택\n",
    "    - 보다 많은 양질의 데이터 수집\n",
    "    - 다른 종류의 모델 선택, 규제 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 첫째 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 훈련셋의 손실값이 줄어들지 않거나 진동하는 등 훈련이 제대로 이루어지지 않는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습률과 배치 크기 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**학습률 조정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- 매우 큰 학습률을 사용하는 경우: 모델이 제대로 학습되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-03.png\" style=\"width:550px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 매우 작은 학습률을 사용하는 경우: 모델이 너무 느리게 학습된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-02.png\" style=\"width:550px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 적절한 학습률을 사용하는 경우: 모델이 적절한 속도로 학습된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-01.png\" style=\"width:550px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**배치 크기 조정**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-05.png\" style=\"width:550px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 둘째 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 훈련셋의 손실값은 줄어들지만 검증셋의 성능은 평가 기준선을 넘지 못하는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련셋이 적절한지 않을 수 있음. 예를 들어, 이상한 라벨이 많은 경우."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사용하는 모델이 적절하지 않을 수 있음. 예를 들어 선형 분류가 불가능한 데이터셋에 선형분류 모델을 적용하는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 셋째 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델의 훈련셋/검증셋의 평가지표가 계속 향상되지만 과대적합이 발생하지 않는 경우 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기본적으로 모델의 정보 저장 능력을 키워야 함. 즉, 신경망 모델의 은닉층을 늘리거나 층에 사용되는 유닛의 수를 증가시켜야 함. 아니면 보다 적절한 모델을 찾아야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 일반화 향상법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 조기 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 규제: 드롭아웃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 조기 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `EarlyStopping` 이라는 **콜백**<font size='2'>callback</font> 기능 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch05-early-stopping.png\" style=\"width:600px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 규제: 드롭아웃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Dropout` 층 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/05-20.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**드롭 아웃 효과**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/original_model_vs_dropout_regularized_model_imdb.png\" style=\"width:500px;\"></div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "dlp05_fundamentals_of_ml",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad0f3c8a064f687cbf898a0868fd45ba1c7e928ac8a0404f7c241d812ddc1e76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
