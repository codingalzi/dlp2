{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 머신러닝 모델 훈련 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 주요 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 최적화, 일반화, 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 다양체 가설"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 모델 훈련 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 모델 일반화 성능 향상 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 최적화, 일반화, 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 머신러닝 모델 훈련의 핵심: 최적화 vs. 일반화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최적화<font size='2'>optimization</font>: 훈련셋에 대해 가장 좋은 성능 이끌어내기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일반화<font size='2'>generalization</font>: 훈련 과정에서 보지 못한 데이터를 처리하는 능력 향상시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 훈련의 핵심: 최적화 대 일반화 사이의 적절한 관계 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 과대적합 vs. 과소적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/typical_overfitting.png\" style=\"width:700px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 과대적합 발생 주요 요인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "첫째, 훈련셋에 포함된 노이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "둘째, 애매한 특성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "셋째: 특성과 타깃 사이의 거짓 상관관계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 첫째, 훈련셋에 포함된 노이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- 노이즈<font size='2'>noise</font>: 적절하지 않은 데이터 또는 잘못된 라벨을 갖는 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 예제: 불분명한 MNNIST 이미지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/fucked_up_mnist.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 예제: 잘못된 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/mislabeled_mnist.png\" style=\"width:660px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 노이즈 영향\n",
    "    - 노이즈 또는 이상치를 학습하면 일반적이지 않은 특별한 특성을 학습하게 됨\n",
    "    - 일반화 성능 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/outliers_and_overfitting.png\" style=\"width:660px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 둘째, 애매한 특성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "노이즈 등의 이상치가 전혀 없다 하더라도 특정 특성 영역에 대한 예측값이 여러 개의 값을 가질 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/iris01.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 예제: 붓꽃 데이터셋. 꽃잎의 길이와 너비만을 활용해서는 완전한 분류 불가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch05/homl05-03b.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 훈련을 오래 시키면 각 샘플 고유의 특성을 일반적인 특성으로 해석.해당 라벨의 고유의 특성으로\n",
    "- 샘플의 특성에 너무 민감하게 작동"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/HighResolutionFigures/figure_5-5.png\" style=\"width:660px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 셋째: 특성과 타깃 사이의 거짓 상관관계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 매우 드문 특성을 사용하는 데이터셋으로 훈련하는 경우\n",
    "    - 체리모야를 언급한 리뷰가 긍정인 경우. 체리모야를 긍정과 연계시킴."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/cherimoya.jpg\" style=\"width:300px;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">체리모야 열매</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 우연에 의한 경우\n",
    "    - 예제: \"너무\" 라는 단어를 포함한 100개의 영화 후기 중에서 54%는 긍정, 나머지 46%는 부정인 경우\n",
    "        훈련중인 모델은 \"너무\"라는 단어를 긍정적으로 평가할 가능성을 높힘."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 의미 없는 특성에 의한 경우: 화이트 노이즈 추가\n",
    "\n",
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch05-mnist-noise.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 화이트 노이즈가 추가되면 성능 떨어짐\n",
    "\n",
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch05-mnist-noise03.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 다양체 가설과 일반화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 딥러닝 모델은 어떤 무엇도 학습할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch05-mnist-shuffled.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "이는 다음 네 가지를 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "첫째, 일반화는 모델 훈련 과정 중에 제어할 수 있는 대상이 아니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "둘째, 모델 훈련을 통해 할 수 있는 것은 주어진 훈련 데이터셋에 모델이 잘 적응하도록 하는 것 뿐이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "셋째, 딥러닝 모델은 어떤 데이터셋에도 적응할 수 있기에 \n",
    "너무 오래 훈련시키면 과대적합은 반드시 발생하고 일반화는 어려워진다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "넷째, 모델의 일반화 능력은 모델 자체보다는 훈련셋에 내재하는 정보의 구조와 \n",
    "보다 밀접히 관련된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 다양체 가설"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다양체 가설<font size='2'>manifold hypothesis</font>:\n",
    "\n",
    "> 일반적인 데이터셋은 고차원상에 존재하는 (저차원의) 연속이며 미분가능한 다양체를 구성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/05-10.png\" style=\"width:600px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 보간법과 일반화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/dense_sampling.png\" style=\"width:660px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증셋을 활용하여 모델의 일반화 능력을 평가하는 방법을 소개한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 훈련셋, 검증셋, 테스트셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트셋은 모델 구성과 훈련에 전혀 관여하지 않아야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 구성된 모델의 성능을 평가하려면 테스트셋을 제외한 다른 데이터셋이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련셋의 일부를 검증셋으로 활용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 검증셋은 훈련 과정 중에 모델의 일반화 성능을 테스트하는 용도로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 튜닝: 모델의 검증셋에 대한 성능 평가를 바탕으로 모델 구성과 모델의 하이퍼파라미터<font size='2'>hyperparameter</font> 설정 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 튜닝과 정보 유출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 튜닝도 모델의 좋은 하이퍼파라미터를 찾아가는 일종의 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 튜닝을 많이 하게되면 검증셋에 특화된 모델이 얻어질 가능성이 커짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정보 유출: 검증셋에 과대적합된 모델이 훈련될 가능성이 높아지는 현상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 평가용 데이터셋 준비 관련 주의사항"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대표성: 데이터셋 무작위 섞은 후 훈련셋, 검증셋, 데이터셋 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 순서 준수: 미래를 예측하는 모델을 훈련시킬 때, 테스트셋의 데이터는 훈련셋의 데이터보다\n",
    "    시간상 뒤쪽에 위치하도록 해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중복 데이터 제거: 훈련셋과 테스트셋에 동일한 데이터가 들어가지 않도록 중복 데이터를 제거해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 검증셋 활용법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "홀드아웃<font size='2'>hold-out</font> 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/holdout_validation.png\" style=\"width:350px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "K-겹 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/k_fold_validation.png\" style=\"width:650px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 성능 평가의 기준선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MNIST 데이터셋: 10%의 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IMDB 데이터셋: 50%의 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 로이터 통신 기사: 18-19%의 정확도. 기사들이 균등하게 분포되어 있지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 모델 훈련 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "첫째 경우: 경사하강법 관련 파라미터 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련셋의 손실값이 줄어들지 않거나 진동하는 등 훈련이 제대로 이루어지지 않는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습률과 배치 크기 조절"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 학습률 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- 매우 큰 학습률을 사용하는 경우: 모델이 제대로 학습되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-03.png\" style=\"width:550px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 매우 작은 학습률을 사용하는 경우: 모델이 너무 느리게 학습된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-02.png\" style=\"width:550px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 적절한 학습률을 사용하는 경우: 모델이 적절한 속도로 학습된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-01.png\" style=\"width:550px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 배치 크기 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch04/homl04-05.png\" style=\"width:550px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 둘째 경우: 보다 적절한 모델 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련은 잘 진행되는데 검증셋에 대한 성능이 좋아지지 않는다면 다음 두 가지 경우를 의심해 보아야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련셋이 적절한지 않은 경우\n",
    "    - 예제: 라벨이 무작위로 섞인 MNIST 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사용하는 모델이 적절하지 않은 경우\n",
    "    - 예제: 선형 분류가 불가능한 데이터셋에 선형분류 모델을 적용하는 경우\n",
    "    - 예제: 시계열 데이터 분석에 앞서 살펴본 `Sequential` 모델을 사용하는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 셋째 경우: 모델의 정보 저장 능력 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델의 훈련셋/검증셋의 평가지표가 계속 향상되지만 과대적합이 발생하지 않는 경우 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기본적으로 모델의 정보 저장 능력을 키워야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 즉, 신경망 모델의 은닉층 또는 층에 사용되는 유닛의 수를 증가시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 일반화 향상법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 양질의 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 특성 공학"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 조기 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 양질의 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 양질의 데이터를 보다 많이 수집하는 일이 보다 적절한 모델을 찾으려는 노력보다 값어치가 높음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 충분한 양의 샘플: 훈련셋이 크면 클 수록 일반화 성능이 좋아짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 타깃(라벨) 지정 오류 최소화."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 적절한 데이터 전처리: 데이터 클리닝과 결측치 처리."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 유용한 특성 선택: 주요 특성에 집중하면 훈련 시간도 줄이면서 동시에 \n",
    "    보다 높은 일반화 성능의 모델을 훈련시킬 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 특성 공학"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 유용한 특성으로 구성된 훈련셋으로 모델을 훈련하면 보다 적은 양의 데이터로 보다 효율적인 훈련 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 특성 공학: 모델 훈련에 가장 유용한 특성으로 구성된 데이터셋을 준비하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예제: 시간 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/05-16.png\" style=\"width:400px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 조기 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch05-early-stopping.png\" style=\"width:600px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 규제 기법 1: 신경망 크기 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 작은 모델\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/original_model_vs_smaller_model_imdb.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 큰 모델\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/original_model_vs_larger_model_imdb.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 규제 기법 2: 가중치 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L1 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L2 규제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```python\n",
    "layers.Dense(16, \n",
    "             kernel_regularizer=regularizers.l2(0.002), \n",
    "             activation=\"relu\")\n",
    "```\n",
    "\n",
    "```python\n",
    "layers.Dense(16, \n",
    "             kernel_regularizer=regularizers.l1(0.001), \n",
    "             activation=\"relu\")\n",
    "```\n",
    "\n",
    "```python\n",
    "layers.Dense(16, \n",
    "             kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.002), \n",
    "             activation=\"relu\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/original_model_vs_l2_regularized_model_imdb.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "규제는 훈련 중에만 적용되며 실전에는 사용되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 규제 기법 3: 드롭아웃 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/05-20.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/original_model_vs_dropout_regularized_model_imdb.png\" style=\"width:500px;\"></div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "dlp05_fundamentals_of_ml",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad0f3c8a064f687cbf898a0868fd45ba1c7e928ac8a0404f7c241d812ddc1e76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
