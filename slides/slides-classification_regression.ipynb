{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 분류와 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 주요 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 이진 분류: 영화 후기 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 다중 클래스 분류: 뉴스 기사 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 회귀: 주택 가격 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 머신러닝 주요 용어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ml_concepts.png\" style=\"width:400px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 이진 분류: 영화 후기 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영화 후기의 긍정/부정 여부를 판단하는 이진 분류 모델을 구성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 데이터 준비: IMDB 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- 긍정 후기와 부정 후기 각각 25,000개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- [IMDB(Internet Moview Database)](https://www.imdb.com/) 영화 후기 사이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 케라스 데이터셋 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`tf.keras.datasets` 모듈](https://keras.io/api/datasets/)이 몇 개의 연습용 데이터셋을 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MNIST 손글씨 숫자 분류 데이터셋\n",
    "- CIFAR10 작은 이미지 분류 데이터셋\n",
    "- CIFAR100 작은 이미지 분류 데이터셋\n",
    "- IMDB 영화 후기 감성 분류 데이터셋\n",
    "- Reuters 단문 기사 주제 분류 데이터셋\n",
    "- 패션 MNIST(Fashion MNIST) dataset\n",
    "- 보스턴 주택 가격(Boston Housing price) 회귀 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 케라스 데이터셋의 `load_data()` 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 사용 빈도가 높은 10,000개 단어만 사용한다.\n",
    "\n",
    "- 그 이외에는 사용 빈도가 너무 낮아 모델 훈련에 도움되지 않는다.\n",
    "- `num_words=10000` 키워드 인자를 활용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "후기 샘플 각각에 사용되는 단어의 수는 일정하지 않다. \n",
    "즉 각 후기 문장의 길이가 일정하지 않다.\n",
    "\n",
    "예를 들어, 훈련셋의 첫째 후기 문장은 218개의 단어로,\n",
    "둘째 후기 문장은 189개의 단어로 구성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> len(train_data[0])\n",
    "218\n",
    "\n",
    ">>> len(train_data[1])\n",
    "189\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "각각의 정수는 특정 단어를 가리킨다.\n",
    "훈련셋의 0번 입력 샘플의 처음 10개 값(단어)은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> train_data[0][:10]\n",
    "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋 0번 샘플은 긍정 후기를 가리킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> train_labels[0]\n",
    "1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **벡터화**<font size='2'>vectorization</font>\n",
    "    - 가장 긴 길이의 샘플에 맞춰 모든 샘플을 확장한다.\n",
    "    - 확장에 사용되는 값은 기존 샘플에 사용되지 않은 값을 사용한다.\n",
    "    - 예를 들어 여백을 의미하는 0을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **멀티-핫 인코딩**<font size='2'>multi-hot encoding</font>\n",
    "    - 0과 1로만 이루어진 일정한 길이의 벡터(1차원 어레이)로 변환한다.\n",
    "    - 벡터의 길이는 사용된 단어의 총 수, 예를 들어 10,000을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 영화 후기 멀티-핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 어레이 길이: 10,000\n",
    "- 항목: 0 또는 1\n",
    "- 후기 샘플에 포함된 정수에 해당하는 인덱스의 항목만 1로 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "예를 들어, `[1, 5, 9998]` 변환하기:\n",
    "\n",
    "- 길이가 10,000인 1차원 어레이(벡터)로 변환\n",
    "- 1번, 5번, 9998번 인덱스의 항목만 1이고 나머지는 0\n",
    "\n",
    "    ```\n",
    "    [1, 5, 9998] => [0, 1, 0, 0, 0, 1, 0, ..., 0, 0, 1, 0]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 멀티-핫 인코딩 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "def vectorize_text_sequences(text_sequences, dimension=10000):\n",
    "    results = np.zeros((len(text_sequences), dimension))\n",
    "    \n",
    "    for i, seq in enumerate(text_sequences):\n",
    "        for j in seq:\n",
    "            results[i, j] = 1.\n",
    "    return results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "x_train = vectorize_text_sequences(train_data).astype(\"float32\")\n",
    "x_test = vectorize_text_sequences(test_data).astype(\"float32\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 라벨 멀티-핫 인코딩: &#10060;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "라벨(타깃)은 멀티-핫 인코딩을 적용하지 않는다.\n",
    "다만 입력 샘플의 자료형과 맞추기 위해 `float32` 자료형으로 변환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> y_train = np.asarray(train_labels).astype(\"float32\")\n",
    ">>> y_train\n",
    "array([1., 0., 0., ..., 0., 1., 0.], dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MNIST 데이터셋을 이용했을 때처럼 `Dense` 층과 `Sequential` 클래스를 이용하여 단순한 모델을 구성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Dense` 층으로 신경망을 구성할 때 다음 두 가지를 정해야 한다.\n",
    "\n",
    "    - 몇 개의 층을 사용하는가?\n",
    "    - 각 층마다 몇 개의 유닛<font size='2'>unit</font>을 사용하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여기서는 세 개의 `Dense` 층으로 순차 모델을 구성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 은닉층과 출력층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 출력층: 딥러닝 신경망 모델에 사용된 층 중에서 모델의 예측값을 계산하는 마지막 층\n",
    "- 은닉층: 출력층 이외의 다른 층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/04-01.png\" style=\"width:200px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **출력층의 유닛 수**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이진 분류 모델의 출력층\n",
    "    - 유닛 1개\n",
    "    - 긍정과 부정 중의 하나, 양성과 음성 중의 하나를 결정하는 데에 사용될 하나의 값 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다중 클래스 분류 모델의 출력층\n",
    "    - 범주 개수만큼의 유닛 사용\n",
    "    - MNIST 모델 훈련: 유닛 10개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 회귀 모델의 출력층\n",
    "    - 유닛 1개\n",
    "    - 하나의 예측값 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 은닉층의 활성화 함수 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 보통 음수값을 제거하는 `relu()` 함수가 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def relu(x):\n",
    "    if x > 0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 은닉층의 활성화 함수로 `relu()` 이외에 `prelu()`, `elu()`, `tanh()` 등이 많이 활용됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 출력의 활성화 함수 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 출력층의 활성화 함수: 모델의 종류에 따라 다르게 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 영화 후기의 긍정/부정을 예측하는 이진 분류 모델의 출력층: 0과 1사이의 확률값을 계삲하는 `sigmoid()` 함수 사용\n",
    "\n",
    "```python\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp/master/slides/images/relu_sigmoid.png\" style=\"width:600px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다중 클래스 분류 모델의 경우: `softmax()` 함수를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 회귀 모델의 경우: 일반적으로 활성화 함수를 사용하지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 이진 분류 모델 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"]\n",
    "             )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 훈련과 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    "x_val = x_train[:10000]            # 검증용\n",
    "partial_x_train = x_train[10000:]  # 훈련용\n",
    "y_val = y_train[:10000]            # 검증용 타깃셋\n",
    "partial_y_train = y_train[10000:]  # 훈련용 타깃셋\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val) # 검증 데이터셋 지정\n",
    "                   )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `fit()` 메서드 반환값: `History` 객체"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> history_dict = history.history\n",
    ">>> history_dict.keys()\n",
    "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 손실값 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/training_val_loss.png\" style=\"width:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 정확도 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/training_val_acc.png\" style=\"width:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 과대적합 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **과대적합**<font size='2'>overfitting</font>: 모델이 훈련셋에 익숙해져서 처음 보는 데이터에 대해서 성능이 더 이상 좋아지지 않거나 떨어지는 현상\n",
    "\n",
    "- 4번째 에포크 이후로 과대적합 발생. 4번의 에포크만 훈련 반복을 진행하면 과대적합되지 않은 모델이 훈련됨\n",
    "\n",
    "- 모델 재훈련: 모델 구성부터, 컴파일, 훈련을 모두 처음부터 다시 시작. 가중치와 편향이 초기화된 상태로 훈련이 다시 시작됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 훈련 결과 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> results = model.evaluate(x_test, y_test)\n",
    ">>> results\n",
    "[0.3139097988605499, 0.8770800232887268]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "```python\n",
    ">>> model.predict(x_test, batch_size=512)\n",
    "array([[0.25440323],\n",
    "       [0.9999424 ],\n",
    "       [0.95840394],\n",
    "       ...,\n",
    "       [0.17153329],\n",
    "       [0.10725482],\n",
    "       [0.6672551 ]], dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 다중 클래스 분류: 뉴스 기사 주제 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로이터<font size='2'>Reuter</font> 통신사가 1986년에 작성한 단문 기사를 주제별로 분류한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 데이터 준비: 로이터 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from tensorflow.keras.datasets import reuters\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 총 11,228개의 단문 기사\n",
    "    - 훈련셋 크기: 8,982\n",
    "    - 테스트셋 크기: 2,246\n",
    "\n",
    "- 기사 주제: 총 46 개\n",
    "\n",
    "- 각각의 기사는 하나의 주제와 연관됨.\n",
    "\n",
    "- **다중 클래스 분류**<font size='2'>multiclass classification</font> 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 샘플은 정수들의 리스트이다.\n",
    "\n",
    "```python\n",
    ">>> train_data[10]\n",
    "[1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979,\n",
    "3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 샘플에 대한 라벨은 0부터 45까지의 정수로 표현된다.\n",
    "3번 주제는 소득(earn)을 가리킨다.\n",
    "\n",
    "```python\n",
    ">>> train_labels[10]\n",
    "3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 로이터 기사 주제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 번호 | 주제 | 번호 | 주제 | 번호 | 주제 | 번호 | 주제 |\n",
    "| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| 0 | cocoa | 1 | grain| 2 | veg-oil | 3 | earn |\n",
    "| 4 | acq | 5 | wheat | 6 | copper | 7 | housing |\n",
    "| 8 | money-supply | 9 | coffee | 10 | sugar | 11 | trade |\n",
    "| 12 | reserves | 13 | ship | 14 | cotton | 15 | carcass |\n",
    "| 16 | crude | 17 | nat-gas | 18 | cpi | 19 | money-fx |\n",
    "| 20 | interest | 21 | gnp | 22 | meal-feed | 23 | alum |\n",
    "| 24 | oilseed | 25 | gold | 26 | tin | 27 | strategic-metal |\n",
    "| 28 | livestock | 29 | retail | 30 | ipi | 31 | iron-steel |\n",
    "| 32 | rubber | 33 | heat | 34 | jobs | 35 | lei |\n",
    "| 36 | bop | 37 | zinc | 38 | orange | 39 | pet-chem |\n",
    "| 40 | dlr | 41 | gas | 42 | silver | 43 | wpi |\n",
    "| 44 | hog | 45 | lead | | | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 입력 데이터셋 멀티-핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "```python\n",
    "x_train = vectorize_text_sequences(train_data)\n",
    "x_test = vectorize_text_sequences(test_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 라벨 데이터셋 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터셋의 경우와는 달리 **원-핫 인코딩**<font size='2'>one-hot encoding</font> 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "3 => [0, 0, 0, 1, 0, 0, ...., 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `to_categorical()` 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> y_train[0]\n",
    "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\")\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- 은닉층: 64개의 유닛 사용.\n",
    "    - 이진 분류보다 훨씬 많은 46개의 클래스로 분류하기 위해 보다 많은 정보 필요\n",
    "    - 출력층의 유닛 수보다 커야 함.\n",
    "\n",
    "- 다중 클래스 분류 모델의 출력층: 클래스 수 만큼의 유닛을 사용하는 `Dense` 밀집층을 사용\n",
    "    - 활성화 함수: 모든 유닛에 대한 확률값의 합이 1이 되도록 하는 `softmax()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원-핫 인코딩된 라벨을 예측하는 다중 클래스 분류 모델의 손실함수는 `categorical_crossentropy`로 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "```python\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 훈련과 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "```python\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "y_val = y_train[:1000]\n",
    "partial_y_train = y_train[1000:]\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 정확도의 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/training_val_loss_1.png\" style=\"width:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 정확도의 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/training_val_acc_1.png\" style=\"width:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 재훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "9번 에포크를 지나면서 과대적합이 발생한다.\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(46, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 회귀: 주택가격 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미국 보스턴<font size='2'>Boston</font> 시의 1970년대 중반의 \n",
    "주택가격을 예측하는 회귀 모델을 훈련시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 데이터 준비: 보스턴 주택가격 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 1970년대 중반의 미국 보스턴 시 외곽의 총 506개 지역에서 수집된 통계 자료\n",
    "- 주의사항: 윤리적 이슈\n",
    "\n",
    "| 특성 | 의미 |\n",
    "|:------|:---------|\n",
    "| <font color=\"#FF0000\">CRIM</font>  | <font color=\"#FF0000\">구역별 1인당 범죄율</font> |\n",
    "| ZN    | 25,000 평방 피트 이상의 주거 구역 비율 |\n",
    "| INDUS | 구역별 비 소매 사업 면적(에이커) 비율 |\n",
    "| CHAS  | Charles River 경계 접촉 여부 |\n",
    "| NOX   | 산화 질소 농도 |\n",
    "| RM    | 주택 당 평균 방 수 |\n",
    "| AGE   | 1940년 이전에 지어졌으면서 소유주가 살고 있는 주택 비율 |\n",
    "| DIS   | 보스턴 고용 센터 다섯 곳 까지의 가중(weighted) 거리 |\n",
    "| RAD   | 방사형 고속도로 접근성 지수 |\n",
    "| TAX   | 1만달러당 재산세율 |\n",
    "| PTRATIO | 구역별 학생-교사 비율 |\n",
    "| <font color=\"#FF0000\">B</font>     | <font color=\"#FF0000\">1000(Bk - 0.63)^2 (Bk는구역별 흑인 비율)</font> |\n",
    "| <font color=\"#FF0000\">LSTAT</font> | <font color=\"#FF0000\">구역별 하위 계층 인구 비율</font> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 보스턴 데이터셋의 윤리 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 구역별로 범죄율, 흑인 비율, 하위 계층 비율 등을 포함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 특히 흑인 비율을 사용하는 `B` 특성이 윤리적 논쟁을 불러 일으킴."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1970년대 미국에서 인종 차별이 여전히 주요 쟁점이었음을 단편적으로 보여줌."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여기서는 단순히 데이터 활용 차원에서만 보스턴 데이터셋을 이용할 뿐 다른 어떤 의도도 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 데이터셋 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 506개의 데이터 샘플로 구성된 매우 작은 데이터셋이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타깃은 구역별 중앙 주택가격이며 부동소수점을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> train_targets\n",
    "[ 15.2,  42.3,  50. ...  19.4,  19.4,  29.1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 데이터 전처리: 표준화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성별 스케일을 통일시키기 위해 모든 \n",
    "특성별로 표준화를 사용한다.\n",
    "\n",
    "$$\n",
    "\\frac{x - \\mu}{\\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 훈련셋의 특성별 평균값/표준편차\n",
    "mean = train_data.mean(axis=0)\n",
    "std = train_data.std(axis=0)\n",
    "\n",
    "# 훈련셋 표준화\n",
    "train_data -= mean\n",
    "train_data /= std\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 테스트셋 표준화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트셋의 입력값도 표준화를 진행한다.\n",
    "- 다만 훈련셋의 평균값과 표준편차를 사용한다.\n",
    "- 이유는 테스트셋에 대한 어떤 정보도 미리 알 수 없다는 전제가 실현되야 하기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 테스트셋 표준화\n",
    "test_data -= mean\n",
    "test_data /= std\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 구성과 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터셋이 작음\n",
    "\n",
    "- 출력층을 제외하고 두 개 층만 사용\n",
    "\n",
    "- 머신러닝 모델은 훈련셋이 작을 수록 과대적합을 보다 잘하기 때문에 보다 단순한 모델을 사용 권장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 훈련에서는 동일한 모델을 반복해서 재구성할 것이기에 모델 구성과 컴파일을 하나의 함수로 지정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "    return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 훈련과 활용: K-겹 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋이 너무 작은 경우 검증셋을 별도로 지정하기 보다는 K-겹 교차검증을 이용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/3-fold-cross-validation.png\" style=\"width:600px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사이킷런의 `KFold` 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k = 3\n",
    "num_epochs = 300\n",
    "\n",
    "kf = KFold(n_splits=k)\n",
    "all_mae_histories = []   # 모든 에포크에 대한 평균절대오차 저장\n",
    "\n",
    "i = 0\n",
    "for train_index, val_index in kf.split(train_data, train_targets):\n",
    "    i+=1\n",
    "    print(f\"{i}번 째 폴드(fold) 훈련 시작\")\n",
    "\n",
    "    val_data, val_targets = train_data[val_index], train_targets[val_index]\n",
    "    partial_train_data, partial_train_targets = train_data[train_index], train_targets[train_index]\n",
    "    \n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=16, verbose=0)\n",
    "\n",
    "    mae_history = history.history[\"val_mae\"]    \n",
    "    all_mae_histories.append(mae_history)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 과대 적합 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch04-overfitting02.png\" style=\"width:600px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 재훈련 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "mae가 최소가 되는 에포크를 확인하여 그만큼의  에포크만 사용해서 모델을 재훈련 하면 좋은 성능의 모델을 얻는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "```python\n",
    "overfitting_epoch = np.argmin(average_mae_history)\n",
    "\n",
    "model = build_model()\n",
    "model.fit(train_data, \n",
    "          train_targets,\n",
    "          epochs=overfitting_epoch, \n",
    "          batch_size=16, \n",
    "          verbose=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - loss: 14.3688 - mae: 2.7425\n",
    ">>> test_mae_score\n",
    "2.888192892074585\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 특성 `B` 제외 후 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`B` 특성을 제외하고 훈련시킨 결과를 `B` 특성을 포함시킨 경우와 비교한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 훈련 1편"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `B` 특성을 제외\n",
    "- 이전과 동일한 방식: 3겹 교차검증\n",
    "- 유사한 결과 나옴."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch04-overfitting03.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 재훈련 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "# 최소의 mae가 위치한 인덱스 확인\n",
    "overfitting_epoch = np.argmin(average_mae_history)\n",
    "\n",
    "model = build_model()\n",
    "model.fit(train_data,\n",
    "          train_targets,\n",
    "          epochs=overfitting_epoch,\n",
    "          batch_size=16,\n",
    "          verbose=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "4/4 ━━━━━━━━━━━━━━━━━━━━ 1s 51ms/step - loss: 12.7020 - mae: 2.5867\n",
    ">>> test_mae_score\n",
    "2.726799964904785\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 훈련 2편"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`B` 특성을 제거한 다음에 데이터 전처리를 다르게 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- 범주형 특성 원-핫 인코딩\n",
    "    - 특성 `'CHAS'`는 찰스강<font size='2'>Charles River</font>과의 인접성 여부 판단\n",
    "    - `CHAS` 특성은 원-핫 인코딩으로 변환 후 표준화 대상에서 제외.\n",
    "- 4-겹 교차검증\n",
    "- 모델 성능이 보다 좋아짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch04-overfitting05.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 재훈련 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "# 최소의 mae가 위치한 인덱스 확인\n",
    "overfitting_epoch = np.argmin(average_mae_history)\n",
    "\n",
    "model = build_model()\n",
    "model.fit(train_data,\n",
    "          train_targets,\n",
    "          epochs=overfitting_epoch,\n",
    "          batch_size=16,\n",
    "          verbose=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 35ms/step - loss: 11.8448 - mae: 2.4151\n",
    ">>> test_mae_score\n",
    "2.527559518814087\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 특정 특성의 유효성 여부를 확인하는 일반적인 방식을 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 특성 `B`를 포함하지 않더라도 성능이 좋은 모델을 훈련시킬 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 특성 `B`의 유효성이 그리 높지 않음"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "dlp04-started_with_neural_networks",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
