{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# 7장 케라스 모델 고급 활용법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**감사말**\n",
    "\n",
    "프랑소와 숄레의 [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff) 7장에 사용된 코드에 대한 설명을 담고 있으며 텐서플로우 2.6 버전 이상에서 작성되었습니다. 소스코드를 공개한 저자에게 감사드립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**구글 코랩 설정**\n",
    "\n",
    "'런타임 -> 런타임 유형 변경' 메뉴에서 GPU를 지정한다.\n",
    "TensorFlow 버전을 확인하려면 아래 명령문을 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow가 GPU를 사용하는지 여부를 확인하려면 아래 명령문을 실행한다.\n",
    "아래와 같은 결과가 나오면 GPU가 제대로 지원됨을 의미한다.\n",
    "\n",
    "```\n",
    "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**참고**\n",
    "\n",
    "아래 코드에 대한 자세한 설명은\n",
    "[머신러닝 모델 고급 활용법](https://codingalzi.github.io/dlp2/working_with_keras.html)를 \n",
    "참고한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 7.1 케라스 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 7.2 케라스 모델 구성법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 7.2.1. 모델 구성법 1: `Sequential` 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`Sequential` 클래스**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "층의 추가는 `add` 메서드를 이용할 수도 있다.\n",
    "아래 코드는 앞서 정의한 모델과 동일한 모델을 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**모델의 가중치와 `build()` 메서드**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "입력값 대신 `build()` 메서드를 특성 수 정보를 이용하여 직접 호출하면\n",
    "가중치 텐서가 무작위로 초기화된 형식으로 생성된다.\n",
    "즉, **모델 빌드**가 완성된다.\n",
    "\n",
    "- `input_shape` 키워드 인자: `(None, 특성수)`\n",
    "- `None`은 임의의 크기의 배치도 다룰 수 있다는 것을 의미함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**층별 가중치 텐서**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 빌드가 완성되면 `weights` 속성에 생성된 모델 훈련에 필요한 모든 가중치와 편향이 저장된다.\n",
    "위 모델에 대해서 층별로 가중치와 편향 텐서 하나씩 총 4 개의 텐서가 생성된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-0.01305223,  0.20250821, -0.237908  , -0.02574873, -0.26955786,\n",
       "          0.04522336, -0.05171975, -0.08204277,  0.14872321, -0.17852062,\n",
       "          0.25629282, -0.12422022, -0.06252867,  0.06813109,  0.22049868,\n",
       "         -0.0535862 , -0.18964818, -0.12878703, -0.23303461,  0.00643247,\n",
       "          0.20961899,  0.05660641, -0.2564634 ,  0.07248384, -0.11544207,\n",
       "         -0.28283063,  0.08631313, -0.22706962,  0.28438437,  0.26596075,\n",
       "         -0.0575233 , -0.1254394 , -0.25638685, -0.05582987,  0.2747426 ,\n",
       "         -0.13748407, -0.18444788, -0.19648412,  0.11662707,  0.11232647,\n",
       "          0.00263494,  0.0863705 ,  0.05948955, -0.27429277,  0.01340383,\n",
       "         -0.25403687,  0.14156735,  0.15759248,  0.02716681,  0.2302025 ,\n",
       "          0.13777944, -0.046096  , -0.25796506, -0.05273716,  0.09991029,\n",
       "          0.2025336 , -0.08021663,  0.06179893,  0.0086028 , -0.2780624 ,\n",
       "          0.18655497, -0.20985441,  0.15226513, -0.12873174],\n",
       "        [ 0.07153293, -0.08661449,  0.01013753,  0.05852985, -0.1571522 ,\n",
       "         -0.24265525,  0.10340896, -0.2807083 , -0.05324538,  0.1893216 ,\n",
       "          0.26988572, -0.26329148,  0.23882365,  0.08031067,  0.09429461,\n",
       "         -0.03615782,  0.07266858,  0.04690322, -0.2607225 , -0.24271733,\n",
       "          0.02001289,  0.18490106, -0.08557968, -0.07715276, -0.19792926,\n",
       "         -0.07868479, -0.18263629,  0.21580505, -0.13420758,  0.1453855 ,\n",
       "         -0.16118962,  0.24664623,  0.23739946, -0.17911744,  0.24756205,\n",
       "          0.03802353,  0.1147072 ,  0.12307268,  0.13649634,  0.04260233,\n",
       "         -0.01012799,  0.2991885 ,  0.14583385,  0.19757351, -0.00307372,\n",
       "          0.17250738, -0.08275303, -0.16833134, -0.25177395, -0.05396356,\n",
       "         -0.03305227,  0.04381782,  0.07308289,  0.02188489, -0.09480019,\n",
       "         -0.00722435,  0.2898696 , -0.16244361, -0.15389177, -0.16008109,\n",
       "          0.290842  ,  0.1234698 , -0.28746384, -0.14051683],\n",
       "        [ 0.20827758,  0.01300985,  0.29650468, -0.13700612, -0.03546786,\n",
       "         -0.17951912, -0.17025673, -0.14731975, -0.19128823,  0.00575459,\n",
       "         -0.20013276, -0.03279519,  0.03163347, -0.0753573 , -0.173413  ,\n",
       "          0.26320922, -0.03044224, -0.16323906,  0.02229542, -0.12532333,\n",
       "          0.09750569,  0.17847624,  0.25495756,  0.21368867,  0.07343027,\n",
       "          0.17814988, -0.26751482, -0.25785303, -0.00872821,  0.21181023,\n",
       "          0.20647979, -0.06026275, -0.23294038,  0.24287045, -0.04530841,\n",
       "         -0.1776962 ,  0.22986048,  0.23975635, -0.14944617,  0.29878062,\n",
       "         -0.07531063, -0.12768151,  0.09502906, -0.17641678, -0.10964173,\n",
       "         -0.16032538, -0.01252824, -0.28052646,  0.16527325,  0.17180347,\n",
       "          0.21976095,  0.15899062,  0.01772618,  0.16843566, -0.00792727,\n",
       "          0.08765253, -0.1314665 ,  0.06491154,  0.28298318,  0.2857811 ,\n",
       "         -0.0310753 , -0.14898035, -0.29648596, -0.04549482]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[ 1.19653463e-01,  2.45313376e-01, -3.70746255e-02,\n",
       "         -4.72315103e-02, -2.38471329e-02, -1.51879460e-01,\n",
       "         -9.57656801e-02,  1.71254575e-01,  2.82239348e-01,\n",
       "          1.48858666e-01],\n",
       "        [-1.97729021e-01, -2.54484147e-01, -1.60868913e-01,\n",
       "         -5.79711795e-03, -9.73527879e-02, -1.09307438e-01,\n",
       "          2.01664478e-01,  2.54605740e-01, -2.45307684e-02,\n",
       "         -6.96633458e-02],\n",
       "        [-9.20932889e-02, -1.81325674e-02,  1.93557233e-01,\n",
       "         -1.36190698e-01, -2.53907233e-01, -2.05878079e-01,\n",
       "         -1.97337627e-01,  2.41716832e-01,  1.79496199e-01,\n",
       "         -1.96080804e-01],\n",
       "        [-1.38076246e-02,  2.11322248e-01,  1.41336024e-01,\n",
       "         -1.05604097e-01,  1.22254848e-01,  2.39319056e-01,\n",
       "          1.70571148e-01,  1.29260182e-01, -1.81308746e-01,\n",
       "         -1.55176222e-02],\n",
       "        [ 1.72144175e-02,  7.81254470e-02,  4.06262577e-02,\n",
       "          1.73455179e-02, -8.60353410e-02, -1.85372800e-01,\n",
       "          3.31258774e-03, -3.93077731e-03,  1.97611839e-01,\n",
       "         -5.54365814e-02],\n",
       "        [ 1.76912397e-01,  1.85661525e-01,  2.30159193e-01,\n",
       "         -4.81985956e-02, -2.69959390e-01, -2.34470248e-01,\n",
       "         -2.18214065e-01, -2.32990801e-01, -2.84644872e-01,\n",
       "         -2.19231993e-01],\n",
       "        [ 2.25130111e-01,  1.13475025e-01,  1.07455909e-01,\n",
       "         -7.74063766e-02,  6.16844296e-02, -4.79434580e-02,\n",
       "         -1.36451393e-01,  1.69973671e-01,  2.18979269e-01,\n",
       "         -1.30408719e-01],\n",
       "        [ 1.30527467e-01,  7.08158910e-02, -2.82862723e-01,\n",
       "         -8.61701667e-02, -2.51630425e-01,  6.58876896e-02,\n",
       "         -2.14945480e-01, -4.21938002e-02,  1.68117702e-01,\n",
       "          1.04624033e-03],\n",
       "        [-2.03513235e-01,  2.45367855e-01, -1.78430870e-01,\n",
       "         -2.38904685e-01, -2.29983047e-01,  2.26332814e-01,\n",
       "         -1.36179298e-01,  2.61399537e-01,  2.53327936e-01,\n",
       "         -2.48900205e-01],\n",
       "        [ 2.51080006e-01, -2.07131714e-01,  1.02371752e-01,\n",
       "         -1.74204707e-02, -2.28415221e-01,  2.81788558e-01,\n",
       "          2.39779085e-01,  1.84632748e-01,  1.08467370e-01,\n",
       "          1.63271368e-01],\n",
       "        [ 2.07916796e-01,  2.20765501e-01, -1.74401656e-01,\n",
       "         -1.47165164e-01,  9.01048779e-02,  6.56707883e-02,\n",
       "          9.90134478e-03, -1.28859282e-03, -8.21860284e-02,\n",
       "         -1.23797610e-01],\n",
       "        [-1.49141282e-01,  1.23850644e-01,  2.60808140e-01,\n",
       "          1.07678652e-01,  1.07339144e-01, -2.41328254e-01,\n",
       "         -1.20822236e-01,  1.79711133e-01, -8.05960745e-02,\n",
       "         -1.13064960e-01],\n",
       "        [-6.37789965e-02,  2.22201675e-01, -2.75652021e-01,\n",
       "          6.20189011e-02, -1.81896329e-01,  9.43112969e-02,\n",
       "          1.96966827e-01, -1.71726882e-01,  2.71263391e-01,\n",
       "          6.75660670e-02],\n",
       "        [ 8.02116692e-02,  1.48067683e-01, -2.06095055e-01,\n",
       "         -7.71169513e-02, -1.59491375e-01,  2.48440593e-01,\n",
       "          1.53480202e-01,  3.28940749e-02,  2.62559026e-01,\n",
       "         -2.58237123e-01],\n",
       "        [-2.57727951e-01, -1.62959427e-01,  1.43413484e-01,\n",
       "         -6.73927367e-02,  2.18320340e-01, -1.91794902e-01,\n",
       "         -7.77810812e-04, -2.10350484e-01,  1.28880143e-01,\n",
       "         -2.68213421e-01],\n",
       "        [ 2.00654566e-01,  1.97619110e-01,  1.66656137e-01,\n",
       "          2.30572909e-01, -8.65740478e-02,  1.97684348e-01,\n",
       "         -2.82363266e-01, -2.01873645e-01,  2.70522386e-01,\n",
       "          2.27069110e-01],\n",
       "        [-1.06895134e-01, -2.83556700e-01,  2.35471576e-01,\n",
       "          1.05749309e-01, -1.80250764e-01,  1.55445546e-01,\n",
       "          1.07310772e-01,  7.97013044e-02, -7.91904926e-02,\n",
       "          9.59007144e-02],\n",
       "        [ 1.36263609e-01,  1.89665616e-01, -2.73754448e-01,\n",
       "          2.17311293e-01,  2.40355343e-01,  8.75180960e-02,\n",
       "          2.09077209e-01, -1.31672755e-01, -2.64367372e-01,\n",
       "          9.46795344e-02],\n",
       "        [ 7.91179836e-02, -2.55348295e-01,  1.81843728e-01,\n",
       "          2.35991508e-01, -1.58204749e-01, -1.75802827e-01,\n",
       "          1.79991424e-02,  3.84108126e-02, -1.95412040e-02,\n",
       "         -2.46830329e-01],\n",
       "        [ 1.91429526e-01, -9.66585577e-02,  1.68201327e-03,\n",
       "          9.05927420e-02, -1.35976911e-01, -1.87339485e-01,\n",
       "         -6.64755702e-03,  2.45887548e-01,  1.00817770e-01,\n",
       "          1.12545669e-01],\n",
       "        [-1.92580819e-02,  1.57787800e-02, -2.53869057e-01,\n",
       "          1.04041845e-01, -2.77373224e-01, -1.98659509e-01,\n",
       "          1.09415591e-01,  4.90224361e-02, -8.14742148e-02,\n",
       "          7.48094618e-02],\n",
       "        [ 1.96898460e-01, -1.13586217e-01, -7.08766580e-02,\n",
       "         -1.80078670e-01, -2.40958735e-01, -1.21172205e-01,\n",
       "         -1.16870970e-01,  2.62057781e-02,  3.68841290e-02,\n",
       "         -2.34992042e-01],\n",
       "        [-1.97926030e-01,  6.78852797e-02, -2.75490910e-01,\n",
       "          2.14130342e-01,  1.31252795e-01,  1.29475117e-01,\n",
       "         -1.85208783e-01, -2.03707263e-01, -1.83919370e-01,\n",
       "          2.67266363e-01],\n",
       "        [ 3.62099111e-02,  2.81033546e-01, -1.60382897e-01,\n",
       "         -1.40238404e-02,  2.53902286e-01,  9.43364799e-02,\n",
       "          2.12757289e-01,  2.03263879e-01,  7.99546540e-02,\n",
       "         -5.26605994e-02],\n",
       "        [-2.24062979e-01,  1.87747300e-01, -2.83122063e-05,\n",
       "          1.67727202e-01, -1.87365711e-02,  1.70184940e-01,\n",
       "          2.13887572e-01,  1.16094649e-01,  4.47152853e-02,\n",
       "         -2.35392511e-01],\n",
       "        [ 5.78751564e-02, -2.08737567e-01,  2.62988120e-01,\n",
       "          2.16529995e-01,  8.34599137e-02, -2.70901024e-02,\n",
       "         -7.74337947e-02, -2.01320946e-02,  1.58801168e-01,\n",
       "          1.34176016e-03],\n",
       "        [-1.87662214e-01,  1.57465845e-01,  3.68497074e-02,\n",
       "          5.21223843e-02, -2.58854896e-01, -1.93454921e-01,\n",
       "         -2.63616234e-01,  7.48926401e-02, -1.42867252e-01,\n",
       "          1.28945708e-01],\n",
       "        [-2.31414139e-01,  1.40649438e-01,  2.82278985e-01,\n",
       "          7.45458007e-02,  1.31168395e-01,  1.35893077e-01,\n",
       "         -9.17103887e-02,  1.07322365e-01, -2.28612632e-01,\n",
       "          1.34222537e-01],\n",
       "        [ 1.15331173e-01, -2.54359424e-01, -6.51827455e-02,\n",
       "         -2.36308873e-01, -1.84118420e-01, -5.75250536e-02,\n",
       "         -8.39210749e-02,  1.57816023e-01, -1.95502043e-02,\n",
       "         -1.60964847e-01],\n",
       "        [ 1.25550181e-01,  9.51421261e-02, -1.84563756e-01,\n",
       "          5.75903654e-02,  9.18537080e-02, -2.78702408e-01,\n",
       "         -1.64340287e-01, -2.08973885e-01,  2.69044489e-01,\n",
       "          2.72441953e-01],\n",
       "        [-2.73520648e-01,  1.67325139e-03, -2.76672721e-01,\n",
       "         -2.34544098e-01, -2.25628912e-01, -7.92359114e-02,\n",
       "         -8.27655941e-02,  2.48718828e-01, -1.66979954e-01,\n",
       "          2.01980442e-01],\n",
       "        [ 1.55621916e-01,  8.73518586e-02, -4.81122434e-02,\n",
       "         -1.58119485e-01, -2.32459709e-01,  2.88948417e-03,\n",
       "          6.35138750e-02, -1.06158853e-03,  2.20823973e-01,\n",
       "          1.62397325e-02],\n",
       "        [-1.08201399e-01,  1.49914205e-01, -1.63093507e-01,\n",
       "          1.24660730e-02,  2.02475220e-01, -2.34831750e-01,\n",
       "         -2.29753315e-01,  1.15268767e-01, -2.09688693e-01,\n",
       "          1.62730306e-01],\n",
       "        [-2.53165454e-01, -2.25931406e-02, -2.37653896e-01,\n",
       "         -1.47353157e-01, -8.54231864e-02,  3.28629315e-02,\n",
       "          2.29576319e-01,  1.20111793e-01,  4.00296450e-02,\n",
       "          1.67566448e-01],\n",
       "        [ 4.23371792e-02, -9.28450227e-02,  2.67130166e-01,\n",
       "          8.19463730e-02, -2.51211286e-01, -1.50332257e-01,\n",
       "          2.74588495e-01,  8.34876597e-02, -2.08682925e-01,\n",
       "          1.23138815e-01],\n",
       "        [ 2.22889572e-01,  1.27953649e-01,  1.90662980e-01,\n",
       "         -2.49163330e-01, -1.85618073e-01, -2.14656949e-01,\n",
       "         -2.12827474e-01, -2.15060487e-01, -3.17234099e-02,\n",
       "         -2.50029266e-01],\n",
       "        [ 4.10837531e-02,  2.57178336e-01,  1.15107298e-02,\n",
       "          1.60315752e-01,  9.19653773e-02,  2.04117179e-01,\n",
       "          1.60352558e-01,  1.83035314e-01,  2.23190159e-01,\n",
       "          4.66116071e-02],\n",
       "        [ 2.49688476e-01, -2.17576325e-02,  1.26303941e-01,\n",
       "          2.35549599e-01,  2.47163385e-01,  2.48908013e-01,\n",
       "         -1.45512953e-01, -2.60212958e-01,  1.02171004e-02,\n",
       "          2.67014176e-01],\n",
       "        [ 4.53306139e-02, -1.32929370e-01,  5.30953705e-02,\n",
       "          2.26720184e-01, -1.45034790e-02, -8.36916715e-02,\n",
       "          6.05201721e-02,  1.29052788e-01,  1.94321066e-01,\n",
       "         -9.62607265e-02],\n",
       "        [ 1.39683127e-01, -9.47503299e-02, -1.59722000e-01,\n",
       "          1.36479437e-02,  1.57939702e-01, -1.75745308e-01,\n",
       "          1.37580037e-01,  1.65524602e-01,  1.01220161e-01,\n",
       "         -6.97027892e-02],\n",
       "        [-2.42113128e-01, -2.66034395e-01,  4.37355042e-03,\n",
       "         -1.86502934e-04,  2.05583721e-01,  1.98887557e-01,\n",
       "          2.44303644e-02,  1.50593758e-01,  1.84077352e-01,\n",
       "          7.03669488e-02],\n",
       "        [-2.60813653e-01,  2.02569634e-01,  1.47221506e-01,\n",
       "         -1.80084795e-01,  1.99086070e-02, -2.59391963e-01,\n",
       "         -1.81659743e-01,  3.69906425e-03,  2.44430274e-01,\n",
       "          8.54521096e-02],\n",
       "        [ 1.94974005e-01, -9.07911807e-02, -9.09638107e-02,\n",
       "          2.44078428e-01, -1.31773561e-01, -1.76220596e-01,\n",
       "         -2.72138089e-01, -1.08100370e-01,  2.54083008e-01,\n",
       "         -4.56457585e-02],\n",
       "        [ 8.62702429e-02, -2.12086737e-01,  3.42880487e-02,\n",
       "         -8.67697001e-02,  1.06449664e-01,  2.16747671e-01,\n",
       "         -1.53276339e-01,  2.45601445e-01, -2.08050936e-01,\n",
       "         -6.50353581e-02],\n",
       "        [ 7.29430616e-02,  1.85978502e-01, -2.65097916e-02,\n",
       "          8.72569382e-02, -2.10735202e-03,  5.78082204e-02,\n",
       "          2.66330987e-01,  1.17925078e-01,  1.37228370e-02,\n",
       "          2.93451250e-02],\n",
       "        [ 1.80964887e-01,  8.16298723e-02, -2.61867762e-01,\n",
       "          1.95925266e-01,  1.72698379e-01, -2.73467153e-01,\n",
       "          2.95774937e-02,  2.78091997e-01, -1.08610898e-01,\n",
       "         -2.50428647e-01],\n",
       "        [-6.14263713e-02, -1.25513643e-01, -1.95077404e-01,\n",
       "         -2.74496287e-01, -2.26346433e-01,  2.00939029e-01,\n",
       "          1.72461987e-01,  1.17448151e-01,  2.35155255e-01,\n",
       "          2.42732137e-01],\n",
       "        [ 1.33739084e-01, -2.00571463e-01, -9.48760659e-02,\n",
       "          1.08078390e-01,  6.27672374e-02, -2.77665824e-01,\n",
       "          6.65911734e-02, -5.53454161e-02,  6.21568561e-02,\n",
       "          1.57349139e-01],\n",
       "        [ 1.09170705e-01, -1.24308005e-01,  8.01040828e-02,\n",
       "          2.65296251e-01, -2.10447431e-01, -1.61879241e-01,\n",
       "         -1.62893772e-01,  1.70884132e-02, -1.34700462e-01,\n",
       "          1.12255245e-01],\n",
       "        [-5.78419566e-02, -2.07378775e-01,  2.24406570e-01,\n",
       "          5.25234640e-02, -2.45280832e-01,  1.27631783e-01,\n",
       "         -1.29931808e-01,  1.23058379e-01, -1.82226345e-01,\n",
       "         -1.31925568e-01],\n",
       "        [ 2.46665031e-01, -1.83484122e-01,  2.69621462e-01,\n",
       "         -1.12345338e-01,  5.86511195e-02,  6.50916398e-02,\n",
       "         -8.90473723e-02,  1.93432450e-01, -1.03226408e-01,\n",
       "         -1.00756332e-01],\n",
       "        [-2.75467038e-01, -7.41781741e-02, -2.06489623e-01,\n",
       "          2.52126455e-02,  1.00020409e-01, -1.94588393e-01,\n",
       "         -1.27170280e-01,  1.27945989e-01,  3.46619785e-02,\n",
       "         -7.00514764e-02],\n",
       "        [ 1.65872872e-01,  1.05022162e-01,  2.60004193e-01,\n",
       "         -2.76993513e-02, -1.02354988e-01,  1.62210882e-01,\n",
       "         -2.52213120e-01, -8.37937146e-02, -1.02784932e-01,\n",
       "         -5.89321256e-02],\n",
       "        [ 9.25959945e-02,  5.49226999e-04, -1.25036523e-01,\n",
       "          1.62560999e-01,  3.13305259e-02, -4.04223055e-02,\n",
       "          1.57627553e-01, -2.42801651e-01, -1.82023555e-01,\n",
       "         -2.44354278e-01],\n",
       "        [-7.55842328e-02,  2.36558914e-03,  5.14877439e-02,\n",
       "         -2.19224125e-01, -5.57427704e-02,  1.39474362e-01,\n",
       "          7.22937882e-02, -1.21231958e-01, -2.31721759e-01,\n",
       "         -1.80241346e-01],\n",
       "        [ 1.46870315e-01,  2.50181586e-01,  2.32909352e-01,\n",
       "          3.50560844e-02, -2.16537416e-01,  8.00856054e-02,\n",
       "         -1.70169443e-01, -2.05885172e-02, -1.19585916e-01,\n",
       "         -1.78625032e-01],\n",
       "        [ 2.06080735e-01,  5.53546548e-02,  4.75975573e-02,\n",
       "         -2.73558587e-01, -2.76382983e-01, -2.55192488e-01,\n",
       "          9.44317281e-02,  7.72420168e-02,  2.38344222e-01,\n",
       "         -2.44383469e-01],\n",
       "        [-9.76407081e-02,  1.37084126e-01, -1.84670687e-01,\n",
       "         -7.34087825e-02,  2.46103078e-01,  1.73394680e-02,\n",
       "         -6.66073263e-02,  2.63619572e-01,  9.20811892e-02,\n",
       "         -7.80111253e-02],\n",
       "        [-1.97729707e-01,  4.04785275e-02, -9.65501368e-02,\n",
       "          2.18393832e-01,  5.24482429e-02, -1.17425621e-02,\n",
       "         -1.37420505e-01, -1.95732057e-01,  6.93050325e-02,\n",
       "         -6.38912171e-02],\n",
       "        [ 1.18723243e-01,  5.29940128e-02, -1.09353274e-01,\n",
       "         -1.94460496e-01, -2.53473401e-01, -1.08029291e-01,\n",
       "          1.12216681e-01,  2.77433842e-01, -1.43818259e-02,\n",
       "         -2.12472081e-01],\n",
       "        [-9.90680754e-02, -1.86255485e-01,  8.02290738e-02,\n",
       "          2.23477036e-01, -1.07334524e-01,  2.58360177e-01,\n",
       "         -4.23578173e-02,  1.63121223e-02, -6.72186613e-02,\n",
       "         -1.22378170e-02],\n",
       "        [ 1.98334873e-01, -7.56293535e-04, -1.22924224e-01,\n",
       "          6.70121312e-02,  2.68155426e-01,  1.89246356e-01,\n",
       "          1.52927786e-01, -1.88196927e-01,  9.39188898e-02,\n",
       "         -1.53892770e-01],\n",
       "        [ 4.57671583e-02,  3.62681150e-02, -1.33254021e-01,\n",
       "         -2.59766042e-01,  1.92330211e-01,  2.30280191e-01,\n",
       "         -2.54796445e-02, -1.07506275e-01, -2.31173620e-01,\n",
       "         -1.54010087e-01],\n",
       "        [-2.61262268e-01,  2.74642378e-01, -8.79365057e-02,\n",
       "         -5.79309613e-02,  1.07663095e-01,  6.25789762e-02,\n",
       "          2.76055902e-01,  2.19197303e-01, -1.57302096e-01,\n",
       "          5.28030992e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1층의 가중치와 편향 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2층의 가중치와 편향 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`summary()` 메서드**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완성된 모델의 요악한 내용은 확인할 수 있다.\n",
    "\n",
    "- 모델과 층의 이름\n",
    "- 층별 파라미터 수\n",
    "- 파라미터 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`name` 인자**\n",
    "\n",
    "모델 또는 층을 지정할 때 생성자 메서등의 `name` 키워드 인자를 이용하여 이름을 지정할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`Input()` 함수**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구성 중간에 구성 과정을 확인하려면 `Input()`함수를 이용하여\n",
    "**케라스텐서**(`KerasTensor`) 객체를\n",
    "가장 먼저 모델에 추가한다.\n",
    "그러면 층을 추가할 때마다 `summary()`를 실행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 7.2.2. 모델 구성법 2: 함수형 API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**기본 활용법**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 살펴 본 `Sequential` 모델을 함수형 API를 이용하여 구성하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")          # 입력층\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)     # 은닉층\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features) # 출력층\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**다중 입력, 다중 출력 모델**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제: 고객 요구사항 접수 모델\n",
    "\n",
    "고객의 요구사항의 처리할 때 필요한 우선순위와 담당부서를 지정하는 시스템을 구현하려 한다. 시스템에 사용될 딥러닝 모델은 세 개의 입력과 두 개의 출력을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000    # 요구사항에 사용되는 단어 총 수\n",
    "num_tags = 100             # 태그 수\n",
    "num_departments = 4        # 부서 수\n",
    "\n",
    "# 입력층: 세 개\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "# 은닉층\n",
    "features = layers.Concatenate()([title, text_body, tags]) # shape=(None, 10000+10000+100)\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "# 출력층: 두 개\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "# 모델 빌드\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "모델 훈련을 위해 적절한 개수의 입력 텐서와 타깃 텐서를 지정해야 한다.\n",
    "여기서는 훈련 과정을 설명하기 위해 \n",
    "적절한 모양의 입력 텐서 3개와 타깃 텐서 2개를 무작위로 생성해서 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 샘플 수\n",
    "num_samples = 1280\n",
    "\n",
    "# 입력 텐서 3 개 무작위 생성\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))    # 멀티-핫-인코딩\n",
    "\n",
    "# 타깃 텐서 2 개 무작위 생성\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))  # 멀티-핫-인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 컴파일 과정에서 지정된 타깃 수만큼 손실함수와 측정 기준을 지정해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련은 `fit()` 함수에 세 개의 훈련 텐서로 이루어진 리스트와 \n",
    "두 개의 타깃 텐서로 이루어진 리스트를 지정한 후에 실행한다. \n",
    "여기서는 시험삼아 한 번의 에포크만 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 3s 11ms/step - loss: 11.3375 - priority_loss: 0.2379 - department_loss: 11.0996 - priority_mean_absolute_error: 0.4073 - department_accuracy: 0.3453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x190ee17d360>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 평가도 훈련과 동일한 방식의 인자가 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 7ms/step - loss: 3.4414 - priority_loss: 0.3322 - department_loss: 3.1092 - priority_mean_absolute_error: 0.5011 - department_accuracy: 0.3859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.441380739212036,\n",
       " 0.33222872018814087,\n",
       " 3.109152317047119,\n",
       " 0.5011064410209656,\n",
       " 0.38593751192092896]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측값은 두 개의 어레이로 구성된 리스트이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9793627 ],\n",
       "       [0.9962972 ],\n",
       "       [0.9902402 ],\n",
       "       ...,\n",
       "       [0.99423414],\n",
       "       [0.99419665],\n",
       "       [0.9919777 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2669355 , 0.06555925, 0.64991295, 0.01759234],\n",
       "       [0.4556242 , 0.10985738, 0.22733322, 0.20718516],\n",
       "       [0.30470237, 0.10842637, 0.5610666 , 0.02580466],\n",
       "       ...,\n",
       "       [0.36132422, 0.08186947, 0.48606652, 0.07073977],\n",
       "       [0.24140638, 0.14201947, 0.5758787 , 0.04069547],\n",
       "       [0.5205403 , 0.19161297, 0.20801933, 0.07982744]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "department_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**사전 객체 활용**\n",
    "\n",
    "입력층과 출력층의 이름을 이용하여 사전 형식으로 입력값과 출력값을 지정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 11ms/step - loss: 5.8717 - priority_loss: 0.1486 - department_loss: 5.7230 - priority_mean_absolute_error: 0.3129 - department_accuracy: 0.3430\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 4.2823 - priority_loss: 0.0864 - department_loss: 4.1959 - priority_mean_absolute_error: 0.2483 - department_accuracy: 0.2703\n",
      "40/40 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**층 연결 구조**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plot_model()`을 이용하여 층 연결 구조를 그래프로 나타낼 수 있다.\n",
    "\n",
    "```python\n",
    ">>> keras.utils.plot_model(model, \"ticket_classifier.png\")\n",
    "```\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ticket_classifier.png\" style=\"width:400px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 텐서와 출력 텐서의 모양을 함께 표기할 수도 있다.\n",
    "\n",
    "```python\n",
    ">>> keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)\n",
    "```\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ticket_classifier_with_shapes.png\" style=\"width:900px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 재활용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련된 모델의 특성을 이용하여 새로운 모델을 빌드할 수 있다.\n",
    "먼저 모델의 `layers` 속성을 이용하여 사용된 층에 대한 정보를 확인한다. \n",
    "`layers` 속성은 사용된 층들의 객체로 이루어진 리스트를 가리킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x190ee17f280>,\n",
       " <keras.engine.input_layer.InputLayer at 0x190ee17fdf0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x190ee17f940>,\n",
       " <keras.layers.merging.concatenate.Concatenate at 0x190ee17e860>,\n",
       " <keras.layers.core.dense.Dense at 0x190ee17edd0>,\n",
       " <keras.layers.core.dense.Dense at 0x190ee17fe20>,\n",
       " <keras.layers.core.dense.Dense at 0x190ee0cb670>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어, 3번 인덱스에 해당하는 층의 입력값과 출력값에 대한 정보는 아래처럼 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "출력층을 제외한 나머지 층을 재활용해보자.\n",
    "출력층은 5번과 6번 인덱스에 위치하기에 4번 인덱스가\n",
    "가리키는 (은닉)층의 출력 정보를 따로 떼어낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 출력층에 문제해결의 어려움 정도를 \"quick\", \"medium\", \"difficult\"로\n",
    "구분하는 어려움(difficulty) 정도를 판별하는 층을 추가해보자.\n",
    "먼저, `difficulty` 층을 준비한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "준비된 `'difficulty'` 층을 출력층으로 추가하여 \n",
    "`priority`, `department`, `difficulty`\n",
    "세 개의 출력값을 생성하는 새로운 모델을 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "새로 생성된 모델은 기존에 훈련된 모델의 가중치,\n",
    "즉, 은닉층에 사용된 가중치는 그대로 사용되며,\n",
    "모델 구성 그래프는 다음과 같다.\n",
    "\n",
    "```python\n",
    ">>> keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)\n",
    "```\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/updated_ticket_classifier.png\" style=\"width:900px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요약 결과는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " title (InputLayer)             [(None, 10000)]      0           []                               \n",
      "                                                                                                  \n",
      " text_body (InputLayer)         [(None, 10000)]      0           []                               \n",
      "                                                                                                  \n",
      " tags (InputLayer)              [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 20100)        0           ['title[0][0]',                  \n",
      "                                                                  'text_body[0][0]',              \n",
      "                                                                  'tags[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 64)           1286464     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " priority (Dense)               (None, 1)            65          ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " department (Dense)             (None, 4)            260         ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " difficulty (Dense)             (None, 3)            195         ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,286,984\n",
      "Trainable params: 1,286,984\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 구성법 3: 서브클래싱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 함수형 API로 구성한 티켓 모델을 서브클래싱을 기법을 이용하여 구현하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):               # inputs: 사전 객체 입력값. 모양은 미정.\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])    # 은닉층\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)                 # 출력층\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department                               # outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구성은 해당 모델의 객체를 생성하면 된다.\n",
    "다만 `Layer`의 경우처럼 가중치는 실제 데이터와 함께 호출되지 전까지 생성되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컴파일, 훈련, 평가, 예측은 이전과 완전히 동일한 방식으로 실행된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 10ms/step - loss: 9.1956 - output_1_loss: 0.3344 - output_2_loss: 8.8612 - output_1_mean_absolute_error: 0.5032 - output_2_accuracy: 0.3172\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 5.8072 - output_1_loss: 0.3384 - output_2_loss: 5.4688 - output_1_mean_absolute_error: 0.5070 - output_2_accuracy: 0.3797\n",
      "40/40 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 7.2.4. 혼합 모델 구성법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "소개된 세 가지 방식을 임의로 혼합하여 활용할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**예제: 서브클래싱 모델을 함수형 모델에 활용하기** (강추!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**예제: 함수형 모델을 서브클래싱 모델에 활용하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 7.3 훈련 모니터링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "케라스 모델의 구성, 훈련, 평가, 예측은 정해진 방식으로 차례대로 이루어진다.\n",
    "아래 코드는 MNIST 데이터셋을 이용한 모델 훈련 전반 과정을 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2953 - accuracy: 0.9119 - val_loss: 0.1480 - val_accuracy: 0.9579\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1671 - accuracy: 0.9527 - val_loss: 0.1220 - val_accuracy: 0.9684\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1412 - accuracy: 0.9613 - val_loss: 0.1125 - val_accuracy: 0.9711\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9717\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 사용자 정의 평가지표(`metrics`) 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`Metric` 클래스 상속**\n",
    "\n",
    "아래 세 개의 메서드를 재정의(overriding)해야 한다.\n",
    "\n",
    "- `update_state()`\n",
    "- `result()`\n",
    "- `reset_state()`\n",
    "\n",
    "아래 코드는 평균제곱근오차(RMSE)를 평가지표로 사용하는 클래스를 \n",
    "이용하는 모델 훈련을 소개한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.2935 - accuracy: 0.9141 - rmse: 7.1828 - val_loss: 0.1709 - val_accuracy: 0.9510 - val_rmse: 7.3536\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1676 - accuracy: 0.9530 - rmse: 7.3561 - val_loss: 0.1227 - val_accuracy: 0.9657 - val_rmse: 7.4048\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1410 - accuracy: 0.9623 - rmse: 7.3852 - val_loss: 0.1244 - val_accuracy: 0.9691 - val_rmse: 7.4222\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.9711 - rmse: 7.4363\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 콜백(callback) 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**콜백**(callback)은 모델 훈련 도중에 부가적으로 호출되는 객체이며\n",
    "학습 과정을 모니터링 하면서 일부 제어기능을 수행하는 다양한 메서드를 제공한다.\n",
    "콜백이 활용되는 주요 기능은 다음과 같다.\n",
    "\n",
    "- 모델 체크포인팅: 훈련 중 모델 상태 수시로 저장\n",
    "- 훈련 조기 중단: 검증셋 손실이 더 이상 개선되지 않는 경우 훈련 중단\n",
    "- 하이퍼 파라미터 조정: 학습률의 동적 변경\n",
    "- 훈련 기록 작성: 훈련셋 및 검증셋의 손실값, 평가지표 등 기록 및 시각화\n",
    "\n",
    "```python\n",
    "keras.callbacks.ModelCheckpoint\n",
    "keras.callbacks.EarlyStopping\n",
    "keras.callbacks.LearningRateScheduler\n",
    "keras.callbacks.ReduceLROnPlateau\n",
    "keras.callbacks.CSVLogger\n",
    "```\n",
    "\n",
    "여기서는 `EarlyStopping`과 `ModelCheckpoint` 두 콜백의 기능을 살펴본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`fit()` 메서드에서 `callbacks` 인자 사용하기**\n",
    "\n",
    "아래 코드에 사용된 옵션은 다음과 같다.\n",
    "\n",
    "- `EarlyStopping`: 검증셋에 대한 정확도가 2 에포크(epoch) 연속 개선되지 않을 때 훈련 종료\n",
    "- `ModelCheckpoint`: 매 에포크마다 훈련된 모델 저장. \n",
    "    `save_best_only=True`가 설정된 경우 검증셋에 대한 손실값이 가장 낮은 모델만 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2962 - accuracy: 0.9114 - val_loss: 0.1489 - val_accuracy: 0.9575\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1645 - accuracy: 0.9532 - val_loss: 0.1184 - val_accuracy: 0.9692\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1412 - accuracy: 0.9617 - val_loss: 0.1192 - val_accuracy: 0.9692\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1276 - accuracy: 0.9670 - val_loss: 0.1139 - val_accuracy: 0.9700\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1212 - accuracy: 0.9694 - val_loss: 0.1102 - val_accuracy: 0.9747\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1115 - accuracy: 0.9731 - val_loss: 0.1070 - val_accuracy: 0.9759\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1033 - accuracy: 0.9747 - val_loss: 0.1043 - val_accuracy: 0.9764\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1041 - accuracy: 0.9761 - val_loss: 0.1049 - val_accuracy: 0.9784\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0994 - accuracy: 0.9774 - val_loss: 0.1070 - val_accuracy: 0.9785\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0948 - accuracy: 0.9780 - val_loss: 0.1181 - val_accuracy: 0.9768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fafaec86ee0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조기종료 후 훈련과정에서 저장된 최고 성능의 모델을 불러오면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 사용자 정의 콜백 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`Callback` 클래스 상속**\n",
    "\n",
    "매 에포크와 매 배치 훈련 단계의 시작과 종료 지점에서\n",
    "수행해야 할 기능을 정의해야 하며 아래 메서드를 재정의하는 방식으로 이루어진다.\n",
    "\n",
    "```python\n",
    "on_epoch_begin(epoch, logs)\n",
    "on_epoch_end(epoch, logs)\n",
    "on_batch_begin(batch, logs)\n",
    "on_batch_end(batch, logs)\n",
    "on_train_begin(logs)\n",
    "on_train_end(logs)\n",
    "```\n",
    "\n",
    "각 메서드에 사용되는 인자는 훈련 과정 중에 자동으로 생성된 객체로부터 값을 받아온다.\n",
    "\n",
    "- `logs` 인자: 이전 배치와 에포크의 훈련셋과 검증셋에 대한 손실값, 평가지표 등을 포함한 사전 객체.\n",
    "- `batch`, `epoch`: 배치와 에포크 정보\n",
    "\n",
    "다음 `LossHistory` 콜백 클래스는 배치 훈련이 끝날 때마다 손실값을 저장하고\n",
    "에포크가 끝날 때마다 배치별 손실값을 그래프로 저장하여 훈련이 종료된 후 시각화하여 보여주도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2943 - accuracy: 0.9124 - val_loss: 0.1439 - val_accuracy: 0.9585\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1617 - accuracy: 0.9554 - val_loss: 0.1232 - val_accuracy: 0.9685\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1413 - accuracy: 0.9618 - val_loss: 0.1168 - val_accuracy: 0.9719\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1265 - accuracy: 0.9676 - val_loss: 0.1098 - val_accuracy: 0.9729\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1142 - accuracy: 0.9715 - val_loss: 0.1086 - val_accuracy: 0.9755\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1120 - accuracy: 0.9729 - val_loss: 0.1148 - val_accuracy: 0.9760\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1064 - accuracy: 0.9743 - val_loss: 0.1161 - val_accuracy: 0.9763\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1010 - accuracy: 0.9770 - val_loss: 0.1080 - val_accuracy: 0.9776\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0980 - accuracy: 0.9774 - val_loss: 0.1118 - val_accuracy: 0.9786\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0952 - accuracy: 0.9790 - val_loss: 0.1271 - val_accuracy: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fafe1f6af70>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 텐서보드(TensorBoard) 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**텐서보드**(TensorBoard)는 모델 훈련과정을 모니터링하는 최고의 어플이며\n",
    "텐서플로우와 함께 기본적으로 설치된다.\n",
    "\n",
    "**주의사항**: 텐서보드 데이터의 저장경로를 \n",
    "\n",
    "```python\n",
    "/full_path_to_your_log_dir\n",
    "```\n",
    "\n",
    "대신에 \n",
    "\n",
    "```python\n",
    "./tensorboard_log_dir\n",
    "```\n",
    "\n",
    "등을 사용해야 리눅스, 맥 운영체제에서 오류가 발생하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2950 - accuracy: 0.9128 - val_loss: 0.1475 - val_accuracy: 0.9591\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1677 - accuracy: 0.9528 - val_loss: 0.1224 - val_accuracy: 0.9668\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1395 - accuracy: 0.9621 - val_loss: 0.1158 - val_accuracy: 0.9697\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1285 - accuracy: 0.9675 - val_loss: 0.1157 - val_accuracy: 0.9712\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1192 - accuracy: 0.9708 - val_loss: 0.1141 - val_accuracy: 0.9722\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1145 - accuracy: 0.9724 - val_loss: 0.1039 - val_accuracy: 0.9766\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1059 - accuracy: 0.9740 - val_loss: 0.1045 - val_accuracy: 0.9790\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1050 - accuracy: 0.9754 - val_loss: 0.1107 - val_accuracy: 0.9770\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0965 - accuracy: 0.9776 - val_loss: 0.1082 - val_accuracy: 0.9788\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0960 - accuracy: 0.9780 - val_loss: 0.1094 - val_accuracy: 0.9788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fafb1441370>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"./tensorboard_log_dir\",\n",
    ")\n",
    "\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서보드를 주피터 노트북에서 아래처럼 실행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab_type": "code",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4111b7461bd29e23\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4111b7461bd29e23\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./tensorboard_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서보드를 독립적으로 실행하여 훈련과정을 실시간으로 모니터링 하려면\n",
    "아래 명령어를 터미널 창에서 실행하고 반환된 주소로 접속하면 된다.\n",
    "\n",
    "```python\n",
    "tensorboard --logdir ./full_path_to_your_log_dir\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 7.4 사용자 정의 훈련 알고리즘: `fit()` 메서드 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with `tf.function`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging `fit()` with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dlp07_working_with_keras",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('dlp2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "67e18e8c5b218f8ec6edba0081aa41b85bc1001751730ec2980297f5f4b43e0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
