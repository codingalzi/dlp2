{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "986bcd44",
   "metadata": {},
   "source": [
    "# Deep Learning with Python - PyTorch Version\n",
    "\n",
    "This notebook demonstrates the mathematical building blocks of neural networks using **PyTorch** instead of Keras/TensorFlow. It performs the same MNIST classification task as the original Keras version.\n",
    "\n",
    "**Key Differences from Keras Version:**\n",
    "- Uses PyTorch tensors and datasets\n",
    "- Manual training loop implementation\n",
    "- No high-level Keras abstractions\n",
    "- Direct gradient computation and optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef11808d",
   "metadata": {},
   "source": [
    "## PyTorch ë²„ì „ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e23533d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "TorchVision version: 0.20.1\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# PyTorch ë²„ì „ í™•ì¸\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"TorchVision version: {torchvision.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "except ImportError:\n",
    "    print(\"âŒ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d56190",
   "metadata": {},
   "source": [
    "## Load and Explore the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff881ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dbf9e725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (60000, 28, 28)\n",
      "Train labels shape: (60000,)\n",
      "Test images shape: (10000, 28, 28)\n",
      "Test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# MNIST ë°ì´í„°ì…‹ ë¡œë“œ (PyTorch ë°©ì‹)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.5,), (0.5,))  # [0,1] -> [-1,1] ì •ê·œí™”\n",
    "])\n",
    "\n",
    "# í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ (ì›ë³¸ Keras ì½”ë“œì™€ ë™ì¼í•œ í˜•íƒœë¡œ)\n",
    "train_images = train_dataset.data.numpy()\n",
    "train_labels = train_dataset.targets.numpy()\n",
    "test_images = test_dataset.data.numpy()\n",
    "test_labels = test_dataset.targets.numpy()\n",
    "\n",
    "print(f\"Train images shape: {train_images.shape}\")\n",
    "print(f\"Train labels shape: {train_labels.shape}\")\n",
    "print(f\"Test images shape: {test_images.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2621ed05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels: [5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training labels: {train_labels[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28c12596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test labels: [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test labels: {test_labels[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668f8403",
   "metadata": {},
   "source": [
    "## Build a Simple Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c5e49ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜ (Keras Sequentialê³¼ ë™ì¼í•œ êµ¬ì¡°)\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # ì²« ë²ˆì§¸ ì€ë‹‰ì¸µ: 784 -> 512, ReLU í™œì„±í™”\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        # ì¶œë ¥ì¸µ: 512 -> 10, SoftmaxëŠ” loss í•¨ìˆ˜ì—ì„œ ì²˜ë¦¬\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # ì…ë ¥ì„ í‰ë©´í™” (28x28 -> 784)\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        # ì²« ë²ˆì§¸ ì¸µ + ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # ì¶œë ¥ì¸µ (softmaxëŠ” lossì—ì„œ ì²˜ë¦¬)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d34712d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ êµ¬ì¡°:\n",
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "model = SimpleNN()\n",
    "print(\"ëª¨ë¸ êµ¬ì¡°:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "30c45795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„° ìƒì„¸ ë¶„ì„:\n",
      "==================================================\n",
      "fc1.weight      | Shape: torch.Size([512, 784]) | Parameters: 401,408\n",
      "fc1.bias        | Shape: torch.Size([512]) | Parameters:     512\n",
      "fc2.weight      | Shape: torch.Size([10, 512]) | Parameters:   5,120\n",
      "fc2.bias        | Shape: torch.Size([10]) | Parameters:      10\n",
      "==================================================\n",
      "ì´ íŒŒë¼ë¯¸í„° ìˆ˜: 407,050\n",
      "\n",
      "ğŸ” ìˆ˜ë™ ê³„ì‚° ê²€ì¦:\n",
      "fc1 ê°€ì¤‘ì¹˜: 401,408 (784 Ã— 512)\n",
      "fc1 í¸í–¥:   512\n",
      "fc2 ê°€ì¤‘ì¹˜: 5,120 (512 Ã— 10)\n",
      "fc2 í¸í–¥:   10\n",
      "ì´í•©:       407,050\n"
     ]
    }
   ],
   "source": [
    "# íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚° (ìì„¸í•œ ë¶„ì„)\n",
    "print(\"ğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„° ìƒì„¸ ë¶„ì„:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "total_params = 0\n",
    "for name, param in model.named_parameters():\n",
    "    param_count = param.numel()\n",
    "    total_params += param_count\n",
    "    print(f\"{name:15} | Shape: {str(param.shape):15} | Parameters: {param_count:>7,}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}\")\n",
    "\n",
    "# ìˆ˜ë™ ê³„ì‚°ìœ¼ë¡œ ê²€ì¦\n",
    "print(f\"\\nğŸ” ìˆ˜ë™ ê³„ì‚° ê²€ì¦:\")\n",
    "fc1_weights = 28 * 28 * 512  # 784 * 512\n",
    "fc1_bias = 512\n",
    "fc2_weights = 512 * 10\n",
    "fc2_bias = 10\n",
    "\n",
    "print(f\"fc1 ê°€ì¤‘ì¹˜: {fc1_weights:,} (784 Ã— 512)\")\n",
    "print(f\"fc1 í¸í–¥:   {fc1_bias:,}\")\n",
    "print(f\"fc2 ê°€ì¤‘ì¹˜: {fc2_weights:,} (512 Ã— 10)\")\n",
    "print(f\"fc2 í¸í–¥:   {fc2_bias:,}\")\n",
    "print(f\"ì´í•©:       {fc1_weights + fc1_bias + fc2_weights + fc2_bias:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce208c4",
   "metadata": {},
   "source": [
    "## Compile the Model (PyTorch Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "698a3a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Loss function: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# PyTorchì—ì„œ ëª¨ë¸ êµ¬ì„± (Keras compileê³¼ ìœ ì‚¬)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜: CrossEntropyLoss (sparse_categorical_crossentropyì™€ ë™ì¼)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì €: Adam\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Loss function: {criterion}\")\n",
    "print(f\"Optimizer: {optimizer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4be270",
   "metadata": {},
   "source": [
    "## Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "be501892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²˜ë¦¬ëœ í›ˆë ¨ ë°ì´í„° í˜•íƒœ: (60000, 784)\n",
      "ì „ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° í˜•íƒœ: (10000, 784)\n",
      "ë°°ì¹˜ í¬ê¸°: 128\n",
      "í›ˆë ¨ ë°°ì¹˜ ìˆ˜: 469\n",
      "í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìˆ˜: 79\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬ (Keras ë²„ì „ê³¼ ë™ì¼)\n",
    "# ì´ë¯¸ì§€ë¥¼ í‰ë©´í™”í•˜ê³  ì •ê·œí™”\n",
    "train_images_processed = train_images.reshape((60000, 28 * 28)).astype(np.float32) / 255.0\n",
    "test_images_processed = test_images.reshape((10000, 28 * 28)).astype(np.float32) / 255.0\n",
    "\n",
    "# NumPy ë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜\n",
    "train_images_tensor = torch.FloatTensor(train_images_processed)\n",
    "train_labels_tensor = torch.LongTensor(train_labels)\n",
    "test_images_tensor = torch.FloatTensor(test_images_processed)\n",
    "test_labels_tensor = torch.LongTensor(test_labels)\n",
    "\n",
    "# ë°ì´í„°ì…‹ê³¼ ë°ì´í„°ë¡œë” ìƒì„±\n",
    "train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"ì „ì²˜ë¦¬ëœ í›ˆë ¨ ë°ì´í„° í˜•íƒœ: {train_images_processed.shape}\")\n",
    "print(f\"ì „ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° í˜•íƒœ: {test_images_processed.shape}\")\n",
    "print(f\"ë°°ì¹˜ í¬ê¸°: 128\")\n",
    "print(f\"í›ˆë ¨ ë°°ì¹˜ ìˆ˜: {len(train_loader)}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìˆ˜: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a938083",
   "metadata": {},
   "source": [
    "## Train the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d939ebce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‹ ê²½ë§ í›ˆë ¨ ì‹œì‘...\n",
      "Epoch 1/5, Batch 0/469, Loss: 2.3080, Accuracy: 11.72%\n",
      "Epoch 1/5, Batch 0/469, Loss: 2.3080, Accuracy: 11.72%\n",
      "Epoch 1/5, Batch 100/469, Loss: 0.3546, Accuracy: 83.61%\n",
      "Epoch 1/5, Batch 100/469, Loss: 0.3546, Accuracy: 83.61%\n",
      "Epoch 1/5, Batch 200/469, Loss: 0.1627, Accuracy: 87.55%\n",
      "Epoch 1/5, Batch 200/469, Loss: 0.1627, Accuracy: 87.55%\n",
      "Epoch 1/5, Batch 300/469, Loss: 0.1602, Accuracy: 89.53%\n",
      "Epoch 1/5, Batch 300/469, Loss: 0.1602, Accuracy: 89.53%\n",
      "Epoch 1/5, Batch 400/469, Loss: 0.2466, Accuracy: 90.71%\n",
      "Epoch 1 ì™„ë£Œ - Loss: 0.3193, Accuracy: 91.29%\n",
      "\n",
      "Epoch 2/5, Batch 0/469, Loss: 0.1815, Accuracy: 95.31%\n",
      "Epoch 1/5, Batch 400/469, Loss: 0.2466, Accuracy: 90.71%\n",
      "Epoch 1 ì™„ë£Œ - Loss: 0.3193, Accuracy: 91.29%\n",
      "\n",
      "Epoch 2/5, Batch 0/469, Loss: 0.1815, Accuracy: 95.31%\n",
      "Epoch 2/5, Batch 100/469, Loss: 0.2646, Accuracy: 95.61%\n",
      "Epoch 2/5, Batch 100/469, Loss: 0.2646, Accuracy: 95.61%\n",
      "Epoch 2/5, Batch 200/469, Loss: 0.1179, Accuracy: 95.92%\n",
      "Epoch 2/5, Batch 200/469, Loss: 0.1179, Accuracy: 95.92%\n",
      "Epoch 2/5, Batch 300/469, Loss: 0.0447, Accuracy: 96.04%\n",
      "Epoch 2/5, Batch 300/469, Loss: 0.0447, Accuracy: 96.04%\n",
      "Epoch 2/5, Batch 400/469, Loss: 0.0228, Accuracy: 96.15%\n",
      "Epoch 2 ì™„ë£Œ - Loss: 0.1303, Accuracy: 96.18%\n",
      "\n",
      "Epoch 3/5, Batch 0/469, Loss: 0.0853, Accuracy: 96.09%\n",
      "Epoch 2/5, Batch 400/469, Loss: 0.0228, Accuracy: 96.15%\n",
      "Epoch 2 ì™„ë£Œ - Loss: 0.1303, Accuracy: 96.18%\n",
      "\n",
      "Epoch 3/5, Batch 0/469, Loss: 0.0853, Accuracy: 96.09%\n",
      "Epoch 3/5, Batch 100/469, Loss: 0.1615, Accuracy: 97.32%\n",
      "Epoch 3/5, Batch 100/469, Loss: 0.1615, Accuracy: 97.32%\n",
      "Epoch 3/5, Batch 200/469, Loss: 0.1314, Accuracy: 97.27%\n",
      "Epoch 3/5, Batch 200/469, Loss: 0.1314, Accuracy: 97.27%\n",
      "Epoch 3/5, Batch 300/469, Loss: 0.0650, Accuracy: 97.34%\n",
      "Epoch 3/5, Batch 300/469, Loss: 0.0650, Accuracy: 97.34%\n",
      "Epoch 3/5, Batch 400/469, Loss: 0.0647, Accuracy: 97.48%\n",
      "Epoch 3 ì™„ë£Œ - Loss: 0.0854, Accuracy: 97.50%\n",
      "\n",
      "Epoch 4/5, Batch 0/469, Loss: 0.0522, Accuracy: 99.22%\n",
      "Epoch 3/5, Batch 400/469, Loss: 0.0647, Accuracy: 97.48%\n",
      "Epoch 3 ì™„ë£Œ - Loss: 0.0854, Accuracy: 97.50%\n",
      "\n",
      "Epoch 4/5, Batch 0/469, Loss: 0.0522, Accuracy: 99.22%\n",
      "Epoch 4/5, Batch 100/469, Loss: 0.0439, Accuracy: 98.19%\n",
      "Epoch 4/5, Batch 100/469, Loss: 0.0439, Accuracy: 98.19%\n",
      "Epoch 4/5, Batch 200/469, Loss: 0.0461, Accuracy: 98.23%\n",
      "Epoch 4/5, Batch 200/469, Loss: 0.0461, Accuracy: 98.23%\n",
      "Epoch 4/5, Batch 300/469, Loss: 0.1186, Accuracy: 98.16%\n",
      "Epoch 4/5, Batch 300/469, Loss: 0.1186, Accuracy: 98.16%\n",
      "Epoch 4/5, Batch 400/469, Loss: 0.0497, Accuracy: 98.17%\n",
      "Epoch 4 ì™„ë£Œ - Loss: 0.0621, Accuracy: 98.19%\n",
      "\n",
      "Epoch 5/5, Batch 0/469, Loss: 0.0271, Accuracy: 99.22%\n",
      "Epoch 4/5, Batch 400/469, Loss: 0.0497, Accuracy: 98.17%\n",
      "Epoch 4 ì™„ë£Œ - Loss: 0.0621, Accuracy: 98.19%\n",
      "\n",
      "Epoch 5/5, Batch 0/469, Loss: 0.0271, Accuracy: 99.22%\n",
      "Epoch 5/5, Batch 100/469, Loss: 0.0162, Accuracy: 98.69%\n",
      "Epoch 5/5, Batch 100/469, Loss: 0.0162, Accuracy: 98.69%\n",
      "Epoch 5/5, Batch 200/469, Loss: 0.0872, Accuracy: 98.66%\n",
      "Epoch 5/5, Batch 200/469, Loss: 0.0872, Accuracy: 98.66%\n",
      "Epoch 5/5, Batch 300/469, Loss: 0.0304, Accuracy: 98.62%\n",
      "Epoch 5/5, Batch 300/469, Loss: 0.0304, Accuracy: 98.62%\n",
      "Epoch 5/5, Batch 400/469, Loss: 0.0656, Accuracy: 98.64%\n",
      "Epoch 5 ì™„ë£Œ - Loss: 0.0465, Accuracy: 98.62%\n",
      "\n",
      "Epoch 5/5, Batch 400/469, Loss: 0.0656, Accuracy: 98.64%\n",
      "Epoch 5 ì™„ë£Œ - Loss: 0.0465, Accuracy: 98.62%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# í›ˆë ¨ í•¨ìˆ˜ ì •ì˜\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # ìˆœì „íŒŒ\n",
    "            output = model(data)\n",
    "            \n",
    "            # ì†ì‹¤ ê³„ì‚°\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # ì—­ì „íŒŒ\n",
    "            loss.backward()\n",
    "            \n",
    "            # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "            optimizer.step()\n",
    "            \n",
    "            # í†µê³„ ì—…ë°ì´íŠ¸\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            # ì§„í–‰ìƒí™© ì¶œë ¥ (ë§¤ 100 ë°°ì¹˜ë§ˆë‹¤)\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(train_loader)}, '\n",
    "                      f'Loss: {loss.item():.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
    "        \n",
    "        # ì—í¬í¬ ì¢…ë£Œ ì‹œ í†µê³„ ì¶œë ¥\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1} ì™„ë£Œ - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\\n')\n",
    "\n",
    "# ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰ (5 ì—í¬í¬)\n",
    "print(\"ì‹ ê²½ë§ í›ˆë ¨ ì‹œì‘...\")\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f0d25",
   "metadata": {},
   "source": [
    "## Make Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0ba59ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì²« ë²ˆì§¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ì˜ˆì¸¡ í™•ë¥ :\n",
      "[8.6196195e-08 1.4769905e-08 3.4010934e-06 8.9753339e-05 4.1802733e-10\n",
      " 2.1066103e-07 2.4664220e-12 9.9989688e-01 3.3224021e-06 6.2825375e-06]\n",
      "\n",
      "ì˜ˆì¸¡ í™•ë¥ ì˜ í•©: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì˜ˆì¸¡ ìˆ˜í–‰ (Keras ë²„ì „ê³¼ ë™ì¼í•œ ë™ì‘)\n",
    "model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
    "\n",
    "with torch.no_grad():\n",
    "    # ì²« 10ê°œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡\n",
    "    test_digits = test_images_tensor[0:10].to(device)\n",
    "    predictions = model(test_digits)\n",
    "    \n",
    "    # Softmax ì ìš©í•˜ì—¬ í™•ë¥ ë¡œ ë³€í™˜\n",
    "    predictions_prob = F.softmax(predictions, dim=1)\n",
    "    \n",
    "    print(\"ì²« ë²ˆì§¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ì˜ˆì¸¡ í™•ë¥ :\")\n",
    "    print(predictions_prob[0].cpu().numpy())\n",
    "    print(f\"\\nì˜ˆì¸¡ í™•ë¥ ì˜ í•©: {predictions_prob[0].sum().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b381ac",
   "metadata": {},
   "source": [
    "## Analyze Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b1af8053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ëœ í´ë˜ìŠ¤: 7\n",
      "í´ë˜ìŠ¤ 7ì˜ í™•ë¥ : 0.999897\n",
      "ì‹¤ì œ ë ˆì´ë¸”: 7\n",
      "ì˜ˆì¸¡ ì •í™•ì„±: âœ… ë§ìŒ\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„ (Keras ë²„ì „ê³¼ ë™ì¼)\n",
    "with torch.no_grad():\n",
    "    # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ ì°¾ê¸° (argmax)\n",
    "    predicted_class = torch.argmax(predictions_prob[0]).item()\n",
    "    print(f\"ì˜ˆì¸¡ëœ í´ë˜ìŠ¤: {predicted_class}\")\n",
    "    \n",
    "    # 7ë²ˆ í´ë˜ìŠ¤ì˜ í™•ë¥ \n",
    "    prob_class_7 = predictions_prob[0][7].item()\n",
    "    print(f\"í´ë˜ìŠ¤ 7ì˜ í™•ë¥ : {prob_class_7:.6f}\")\n",
    "    \n",
    "    # ì‹¤ì œ ë ˆì´ë¸”\n",
    "    actual_label = test_labels[0]\n",
    "    print(f\"ì‹¤ì œ ë ˆì´ë¸”: {actual_label}\")\n",
    "    \n",
    "    # ì˜ˆì¸¡ ì •í™•ë„ í™•ì¸\n",
    "    is_correct = predicted_class == actual_label\n",
    "    print(f\"ì˜ˆì¸¡ ì •í™•ì„±: {'âœ… ë§ìŒ' if is_correct else 'âŒ í‹€ë¦¼'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b19c202",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b2d202c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…ŒìŠ¤íŠ¸ ê²°ê³¼:\n",
      "í…ŒìŠ¤íŠ¸ ì†ì‹¤ (test_loss): 0.0652\n",
      "í…ŒìŠ¤íŠ¸ ì •í™•ë„ (test_acc): 0.9798\n",
      "í…ŒìŠ¤íŠ¸ ì •í™•ë„ (ë°±ë¶„ìœ¨): 97.98%\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # ì†ì‹¤ ëˆ„ì \n",
    "            test_loss += criterion(output, target).item()\n",
    "            \n",
    "            # ì •í™•ë„ ê³„ì‚°\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    \n",
    "    # í‰ê·  ì†ì‹¤ê³¼ ì •í™•ë„ ê³„ì‚°\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# ëª¨ë¸ í‰ê°€ ì‹¤í–‰\n",
    "test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ê²°ê³¼:\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì†ì‹¤ (test_loss): {test_loss:.4f}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„ (test_acc): {test_acc:.4f}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„ (ë°±ë¶„ìœ¨): {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d18bb",
   "metadata": {},
   "source": [
    "## ğŸ“Š ê²°ê³¼ ë¹„êµ\n",
    "\n",
    "### PyTorch vs Keras êµ¬í˜„ ë¹„êµ:\n",
    "\n",
    "| í•­ëª© | Keras | PyTorch |\n",
    "|------|-------|----------|\n",
    "| **ëª¨ë¸ ì •ì˜** | `Sequential([layers.Dense(...)])` | `class SimpleNN(nn.Module)` |\n",
    "| **ëª¨ë¸ ì»´íŒŒì¼** | `model.compile(optimizer, loss, metrics)` | ë³„ë„ë¡œ `criterion`, `optimizer` ì •ì˜ |\n",
    "| **í›ˆë ¨** | `model.fit(X, y, epochs, batch_size)` | ìˆ˜ë™ í›ˆë ¨ ë£¨í”„ êµ¬í˜„ |\n",
    "| **ì˜ˆì¸¡** | `model.predict(X)` | `model(X)` + `F.softmax()` |\n",
    "| **í‰ê°€** | `model.evaluate(X, y)` | ìˆ˜ë™ í‰ê°€ í•¨ìˆ˜ êµ¬í˜„ |\n",
    "\n",
    "### ì¥ë‹¨ì :\n",
    "\n",
    "**Keras ì¥ì :**\n",
    "- ê°„ë‹¨í•˜ê³  ì§ê´€ì ì¸ API\n",
    "- ì ì€ ì½”ë“œë¡œ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘\n",
    "- ìë™í™”ëœ í›ˆë ¨/í‰ê°€ ê³¼ì •\n",
    "\n",
    "**PyTorch ì¥ì :**\n",
    "- ë” ì„¸ë°€í•œ ì œì–´ ê°€ëŠ¥\n",
    "- í›ˆë ¨ ê³¼ì •ì˜ ëª¨ë“  ë‹¨ê³„ë¥¼ ëª…ì‹œì ìœ¼ë¡œ êµ¬í˜„\n",
    "- ì—°êµ¬ ë° ì‹¤í—˜ì— ë” ì í•©\n",
    "- ë™ì  ê·¸ë˜í”„ ì§€ì›\n",
    "\n",
    "ë‘ êµ¬í˜„ ëª¨ë‘ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì‚°ì¶œí•´ì•¼ í•˜ë©°, ì•½ 97-98%ì˜ í…ŒìŠ¤íŠ¸ ì •í™•ë„ë¥¼ ë‹¬ì„±í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlp3-tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
