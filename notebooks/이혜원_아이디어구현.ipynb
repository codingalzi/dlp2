{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5j5Xc-6e0cW",
        "outputId": "f4f5f647-9fed-4b0c-cfac-94b140a9b2a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "--- 모델 A (기본) 훈련 시작 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8472 - loss: 0.5238 - val_accuracy: 0.9527 - val_loss: 0.1611\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9490 - loss: 0.1738 - val_accuracy: 0.9644 - val_loss: 0.1201\n",
            "Epoch 3/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9630 - loss: 0.1210 - val_accuracy: 0.9702 - val_loss: 0.0949\n",
            "Epoch 4/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9705 - loss: 0.0995 - val_accuracy: 0.9732 - val_loss: 0.0902\n",
            "Epoch 5/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.0800 - val_accuracy: 0.9737 - val_loss: 0.0872\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.9743 - loss: 0.0834\n",
            "\n",
            "--- 모델 B (좌표 추가) 훈련 시작 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7128 - loss: 0.9128 - val_accuracy: 0.9111 - val_loss: 0.3002\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8784 - loss: 0.3943 - val_accuracy: 0.9226 - val_loss: 0.2539\n",
            "Epoch 3/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8980 - loss: 0.3395 - val_accuracy: 0.9338 - val_loss: 0.2262\n",
            "Epoch 4/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9055 - loss: 0.3140 - val_accuracy: 0.9449 - val_loss: 0.1943\n",
            "Epoch 5/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9104 - loss: 0.2929 - val_accuracy: 0.9463 - val_loss: 0.1830\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.9436 - loss: 0.1780\n",
            "\n",
            "==============================\n",
            "          최종 결과 비교\n",
            "==============================\n",
            "모델 A (기본)      - 정확도: 97.43%\n",
            "모델 B (좌표 추가) - 정확도: 94.36%\n",
            "==============================\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. MNIST 데이터셋 로드\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# 2. 데이터 정규화 (픽셀 밝기 값을 0~1 사이로)\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "def add_coordinates(images):\n",
        "  \"\"\"이미지에 (x, y) 좌표 채널을 추가하는 함수\"\"\"\n",
        "  num_images, height, width = images.shape\n",
        "\n",
        "  # x, y 좌표 격자 생성 (0~27 값)\n",
        "  x_coords = np.arange(width).astype('float32')\n",
        "  y_coords = np.arange(height).astype('float32')\n",
        "  xx, yy = np.meshgrid(x_coords, y_coords)\n",
        "\n",
        "  # 좌표 값도 0~1 사이로 정규화\n",
        "  xx = xx / (width - 1)\n",
        "  yy = yy / (height - 1)\n",
        "\n",
        "  # (밝기, y좌표, x좌표) 3개의 채널로 결합\n",
        "  # images      shape: (num_images, 28, 28)\n",
        "  # yy, xx      shape: (28, 28)\n",
        "  # np.newaxis를 통해 yy와 xx를 (1, 28, 28)로 만든 뒤\n",
        "  # 브로드캐스팅을 활용하여 모든 이미지에 동일한 좌표계를 더해줌\n",
        "  images = images[:, :, :, np.newaxis] # (num_images, 28, 28, 1)\n",
        "  coords = np.stack([yy, xx], axis=-1) # (28, 28, 2)\n",
        "  coords = coords[np.newaxis, :, :, :] # (1, 28, 28, 2)\n",
        "  coords = np.tile(coords, (num_images, 1, 1, 1)) # (num_images, 28, 28, 2)\n",
        "\n",
        "  images_with_coords = np.concatenate([images, coords], axis=-1) # (num_images, 28, 28, 3)\n",
        "\n",
        "  return images_with_coords\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터에 좌표 정보 추가\n",
        "x_train_coords = add_coordinates(x_train)\n",
        "x_test_coords = add_coordinates(x_test)\n",
        "\n",
        "# Dense 층에 넣기 위해 1차원으로 펼치기\n",
        "# (60000, 28, 28, 3)  -> (60000, 2352)\n",
        "x_train_coords_flat = x_train_coords.reshape(x_train_coords.shape[0], -1)\n",
        "x_test_coords_flat = x_test_coords.reshape(x_test_coords.shape[0], -1)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "# 3. 모델 A: 기본 Dense 모델 (입력: 784개)\n",
        "print(\"--- 모델 A (기본) 훈련 시작 ---\")\n",
        "model_A = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)), # 입력: (28, 28) -> 784\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_A.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_A.fit(x_train, y_train, epochs=5, validation_split=0.2)\n",
        "loss_A, acc_A = model_A.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "\n",
        "# 4. 모델 B: 네 아이디어 적용 모델 (입력: 2352개)\n",
        "print(\"\\n--- 모델 B (좌표 추가) 훈련 시작 ---\")\n",
        "model_B = tf.keras.models.Sequential([\n",
        "    # Flatten 대신 InputLayer로 직접 입력 shape 지정\n",
        "    tf.keras.layers.InputLayer(input_shape=(28 * 28 * 3,)), # 입력: 2352\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_B.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_B.fit(x_train_coords_flat, y_train, epochs=5, validation_split=0.2)\n",
        "loss_B, acc_B = model_B.evaluate(x_test_coords_flat, y_test, verbose=2)\n",
        "\n",
        "\n",
        "# 5. 최종 결과 비교\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(\"          최종 결과 비교\")\n",
        "print(\"=\"*30)\n",
        "print(f\"모델 A (기본)      - 정확도: {acc_A*100:.2f}%\")\n",
        "print(f\"모델 B (좌표 추가) - 정확도: {acc_B*100:.2f}%\")\n",
        "print(\"=\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import time\n",
        "\n",
        "# 1) MNIST 데이터셋 로드\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# ---------------------------------------------------------------------------------\n",
        "# 2) 모델 A (기본)를 위한 데이터 로더\n",
        "# ---------------------------------------------------------------------------------\n",
        "train_loader_A = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader_A  = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "# ---------------------------------------------------------------------------------\n",
        "# 3) 모델 B (좌표 추가)를 위한 데이터 전처리와 로더\n",
        "# ---------------------------------------------------------------------------------\n",
        "def add_coordinates(img_tensor):\n",
        "    img_tensor = img_tensor.squeeze(0)\n",
        "    h, w = img_tensor.shape\n",
        "    y_coords, x_coords = torch.meshgrid(torch.arange(h), torch.arange(w), indexing=\"ij\")\n",
        "    x_coords = x_coords.float() / (w - 1)\n",
        "    y_coords = y_coords.float() / (h - 1)\n",
        "    out = torch.stack([img_tensor, y_coords, x_coords], dim=2)  # 채널 순서 (밝기, y, x)\n",
        "    return out.view(-1)\n",
        "\n",
        "class CoordMNIST(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.dataset[idx]\n",
        "        img_with_coords = add_coordinates(img)\n",
        "        return img_with_coords, label\n",
        "\n",
        "train_loader_B = torch.utils.data.DataLoader(CoordMNIST(train_dataset), batch_size=64, shuffle=True)\n",
        "test_loader_B  = torch.utils.data.DataLoader(CoordMNIST(test_dataset), batch_size=1000, shuffle=False)\n",
        "\n",
        "# ---------------------------------------------------------------------------------\n",
        "# 4) 모델 정의\n",
        "# ---------------------------------------------------------------------------------\n",
        "device   = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 모델 A: 기본 Dense 모델 (입력: 784)\n",
        "class DenseNet_A(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1     = nn.Linear(784, 128)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc2     = nn.Linear(128, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 모델 B: 좌표 추가 Dense 모델 (입력: 784*3)\n",
        "class DenseNet_B(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1     = nn.Linear(784*3, 128)  # 입력 크기만 다름\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc2     = nn.Linear(128, 10)\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# ---------------------------------------------------------------------------------\n",
        "# 5) 훈련 및 평가 함수 정의 (코드를 재사용하기 위해)\n",
        "# ---------------------------------------------------------------------------------\n",
        "def train_and_evaluate(model, train_loader, test_loader, epochs=3):\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    # 훈련 루프\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(imgs)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # 평가 루프\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total   = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            output = model(imgs)\n",
        "            preds  = output.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total   += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# ---------------------------------------------------------------------------------\n",
        "# 6) 각 모델 실행 및 결과 저장\n",
        "# ---------------------------------------------------------------------------------\n",
        "print(\"--- [PyTorch] 모델 A (기본) 훈련 시작 ---\")\n",
        "model_A = DenseNet_A()\n",
        "acc_A   = train_and_evaluate(model_A, train_loader_A, test_loader_A)\n",
        "\n",
        "print(\"\\n--- [PyTorch] 모델 B (좌표 추가) 훈련 시작 ---\")\n",
        "model_B = DenseNet_B()\n",
        "acc_B   = train_and_evaluate(model_B, train_loader_B, test_loader_B)\n",
        "\n",
        "# ---------------------------------------------------------------------------------\n",
        "# 7) 최종 결과 비교\n",
        "# ---------------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"          PyTorch 최종 결과 비교\")\n",
        "print(\"=\"*40)\n",
        "print(f\"모델 A (기본)      - 정확도: {acc_A:.2f}%\")\n",
        "print(f\"모델 B (좌표 추가) - 정확도: {acc_B:.2f}%\")\n",
        "print(\"=\"*40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx_UUzEHfVP4",
        "outputId": "a66412ab-ce0a-4139-8afc-3ba20fc9240f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 54.2MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.59MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 13.9MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.70MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [PyTorch] 모델 A (기본) 훈련 시작 ---\n",
            "Epoch 1, Loss: 0.0879\n",
            "Epoch 2, Loss: 0.0554\n",
            "Epoch 3, Loss: 0.0313\n",
            "\n",
            "--- [PyTorch] 모델 B (좌표 추가) 훈련 시작 ---\n",
            "Epoch 1, Loss: 0.2947\n",
            "Epoch 2, Loss: 0.4104\n",
            "Epoch 3, Loss: 0.4457\n",
            "\n",
            "========================================\n",
            "          PyTorch 최종 결과 비교\n",
            "========================================\n",
            "모델 A (기본)      - 정확도: 97.00%\n",
            "모델 B (좌표 추가) - 정확도: 93.12%\n",
            "========================================\n"
          ]
        }
      ]
    }
  ]
}