{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "990ca4b8",
   "metadata": {},
   "source": [
    "# 5. 케라스와 텐서플로우: PyTorch 버전"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28079ab",
   "metadata": {},
   "source": [
    "## 1. 필수 라이브러리 임포트 (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8c48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import math, random\n",
    "import numpy as np\n",
    "\n",
    "# 재현성 설정\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f799c",
   "metadata": {},
   "source": [
    "## 2. GPU 사용 가능 여부 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42eb19f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 디바이스: cpu\n",
      "CUDA 가능 여부: False\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('사용 디바이스:', device)\n",
    "print('CUDA 가능 여부:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08dc86",
   "metadata": {},
   "source": [
    "## 3. 기본 선형 층 소개\n",
    "\n",
    "원래 Keras 예제를 따라 `SimpleDense` 커스텀 클래스를 구현했지만, 입문 단계에서는 PyTorch가 제공하는 `nn.Linear`를 바로 사용하는 편이 훨씬 단순합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff1c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch의 nn.Linear 직접 구현\n",
    "\n",
    "class SimpleDense(nn.Module):\n",
    "    def __init__(self, units, activation=None):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "    def build(self, in_features):\n",
    "        self.W = nn.Parameter(torch.randn(in_features, self.units) * 0.01)\n",
    "        self.b = nn.Parameter(torch.zeros(self.units))\n",
    "    def forward(self, x):\n",
    "        if self.W is None:\n",
    "            self.build(x.shape[-1])\n",
    "        y = x @ self.W + self.b\n",
    "        if self.activation is not None:\n",
    "            y = self.activation(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57284ee4",
   "metadata": {},
   "source": [
    "## 4. Sequential 모델 사용\n",
    "\n",
    "직접 MySequential을 구현하기보다 `nn.Sequential`을 바로 사용하는 것이 초보자에게 더 명확합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "786d2c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential 직접 구현\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84496eb",
   "metadata": {},
   "source": [
    "## 5. 모델 구성 (가장 단순한 형태)\n",
    "\n",
    "입력 784 → 은닉 512(ReLU) → 출력 10 (로짓). Softmax는 `CrossEntropyLoss` 내부에서 처리되므로 마지막 층은 활성함수가 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aad250d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySequential(\n",
      "  (layers): ModuleList(\n",
      "    (0): SimpleDense(\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): SimpleDense()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MySequential([\n",
    "    SimpleDense(512, activation=nn.ReLU()),  # 입력 크기(784)는 첫 forward 때 자동 감지\n",
    "    SimpleDense(10)                        # 최종 로짓 (Softmax 미적용)\n",
    "]).to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# (선택) 더 단순한 대안 (권장):\n",
    "# model = nn.Sequential(\n",
    "#     nn.Linear(784, 512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512, 10)\n",
    "# ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c5bfc",
   "metadata": {},
   "source": [
    "## 6. 손실함수 / 옵티마이저 / 정확도 함수\n",
    "\n",
    "`CrossEntropyLoss`는 `LogSoftmax + NLLLoss`를 합친 형태입니다. 라벨은 정수 인덱스(0~9) 형태면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "925b3b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleDense 는 첫 forward 때 가중치를 build(lazy) 하므로 optimizer 생성 전에 한 번 더미 입력을 통과시켜 파라미터를 초기화합니다.\n",
    "with torch.no_grad():\n",
    "    _ = model(torch.zeros(1, 784, device=device))  # 파라미터 생성 트리거\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def accuracy_fn(logits, targets):\n",
    "    return (logits.argmax(dim=1) == targets).float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42495d51",
   "metadata": {},
   "source": [
    "## 7. MNIST 데이터 로드\n",
    "\n",
    "`transforms.ToTensor()` 후 평탄화만 적용. 추가 전처리 불필요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "903ea482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train full size: 60000\n",
      "Test size: 10000\n"
     ]
    }
   ],
   "source": [
    "# transform 단계에서 이미 각 샘플을 (784,) 로 평탄화\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                # (1,28,28)\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # (784,)\n",
    "])\n",
    "train_dataset_full = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "TEST_SPLIT = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "print('Train full size:', len(train_dataset_full))\n",
    "print('Test size:', len(TEST_SPLIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40004d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fed4c7",
   "metadata": {},
   "source": [
    "## 8. 데이터 전처리 간소화\n",
    "\n",
    "추가 조작 없이 바로 사용. 샘플 텐서 구조만 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb1e6096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784])\n"
     ]
    }
   ],
   "source": [
    "x0, y0 = train_dataset_full[0]\n",
    "print(x0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fa4cc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(0.))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0.max(), x0.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc355afc",
   "metadata": {},
   "source": [
    "## 9. 훈련/검증 분리 (random_split)\n",
    "\n",
    "전체의 30%를 검증셋으로 활용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edb9bde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 18000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "val_count = int(0.3 * len(train_dataset_full))\n",
    "train_count = len(train_dataset_full) - val_count\n",
    "train_subset, val_subset = random_split(train_dataset_full, [train_count, val_count])\n",
    "print(len(train_subset), len(val_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7617e7a3",
   "metadata": {},
   "source": [
    "## 10. DataLoader 구성\n",
    "\n",
    "셔플은 훈련셋에서만. 배치 크기는 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecdd6835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 입력 모양: torch.Size([128, 784]) 배치 라벨 모양: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(TEST_SPLIT, batch_size=BATCH_SIZE)\n",
    "xb, yb = next(iter(train_loader))\n",
    "print('배치 입력 모양:', xb.shape, '배치 라벨 모양:', yb.shape)  # (B,784)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2342ed90",
   "metadata": {},
   "source": [
    "## 11. 기록용 history 딕셔너리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "389e618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c8aa9a",
   "metadata": {},
   "source": [
    "## 12. 학습 함수 (1 에포크)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04cf5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(loader):\n",
    "    model.train()\n",
    "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == yb).sum().item()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        total_samples += xb.size(0)\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct / total_samples\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015dc2bd",
   "metadata": {},
   "source": [
    "## 13. 검증 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "034ddc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == yb).sum().item()\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "            total_samples += xb.size(0)\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct / total_samples\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6f7698",
   "metadata": {},
   "source": [
    "## 14. 훈련 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b14e855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.4093 train_acc=0.8915 val_loss=0.2272 val_acc=0.9359\n",
      "Epoch 2: train_loss=0.1752 train_acc=0.9497 val_loss=0.1482 val_acc=0.9569\n",
      "Epoch 2: train_loss=0.1752 train_acc=0.9497 val_loss=0.1482 val_acc=0.9569\n",
      "Epoch 3: train_loss=0.1171 train_acc=0.9657 val_loss=0.1180 val_acc=0.9649\n",
      "Epoch 3: train_loss=0.1171 train_acc=0.9657 val_loss=0.1180 val_acc=0.9649\n",
      "Epoch 4: train_loss=0.0856 train_acc=0.9752 val_loss=0.1008 val_acc=0.9703\n",
      "Epoch 4: train_loss=0.0856 train_acc=0.9752 val_loss=0.1008 val_acc=0.9703\n",
      "Epoch 5: train_loss=0.0651 train_acc=0.9810 val_loss=0.0986 val_acc=0.9690\n",
      "Epoch 5: train_loss=0.0651 train_acc=0.9810 val_loss=0.0986 val_acc=0.9690\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loss, train_acc = train_one_epoch(train_loader)\n",
    "    val_loss, val_acc = evaluate(val_loader)\n",
    "    history['loss'].append(train_loss)\n",
    "    history['accuracy'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_accuracy'].append(val_acc)\n",
    "    print(f'Epoch {epoch}: train_loss={train_loss:.4f} train_acc={train_acc:.4f} val_loss={val_loss:.4f} val_acc={val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb0d344",
   "metadata": {},
   "source": [
    "## 15. History 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74d530f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.4093397729510353, 0.17519165026573907, 0.11710371780111677, 0.0855711860933474, 0.06508333561587192], 'accuracy': [0.891452380952381, 0.9497380952380953, 0.9657142857142857, 0.9752380952380952, 0.9810476190476191], 'val_loss': [0.2272435281806522, 0.1482427603205045, 0.1180462476015091, 0.10083010280132294, 0.09863487127754424], 'val_accuracy': [0.9358888888888889, 0.9568888888888889, 0.9648888888888889, 0.9702777777777778, 0.969]}\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3092cd25",
   "metadata": {},
   "source": [
    "## 16. 테스트셋 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7705632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.08912140651643276 Test acc: 0.971\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(test_loader)\n",
    "print('Test loss:', test_loss, 'Test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a474b3",
   "metadata": {},
   "source": [
    "## 17. 예측 (샘플 배치)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e66b2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6030e-05, 1.1574e-08, 2.6709e-04, 7.0027e-04, 9.7190e-09, 1.0183e-06,\n",
      "         1.0000e-11, 9.9889e-01, 2.9591e-05, 1.0066e-04],\n",
      "        [7.3675e-07, 1.5518e-05, 9.9996e-01, 1.4584e-05, 2.2857e-13, 5.4621e-06,\n",
      "         2.0750e-07, 1.5682e-12, 1.3118e-06, 1.3611e-13]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    xb, yb = next(iter(test_loader))\n",
    "    xb = xb.to(device)\n",
    "    logits = model(xb)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "print(probs[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bbad8d",
   "metadata": {},
   "source": [
    "## 18. 예측 vs 실제 라벨 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b625cef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측: [7, 2, 1, 0, 4, 1, 4, 9, 5, 9]\n",
      "실제: [7, 2, 1, 0, 4, 1, 4, 9, 5, 9]\n"
     ]
    }
   ],
   "source": [
    "pred_labels = probs.argmax(dim=1)\n",
    "print('예측:', pred_labels[:10].tolist())\n",
    "print('실제:', yb[:10].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9802ce6a",
   "metadata": {},
   "source": [
    "## 19. (선택) 손실식 참고 (교차 엔트로피 수식)\n",
    "\n",
    "다중 클래스 교차 엔트로피: $L = -\\sum_{i=1}^{C} y_i \\log(\\hat{y}_i)$ (여기서 $y_i$는 원핫, PyTorch에서는 타겟 인덱스를 이용해 내부적으로 동일 계산 수행)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlp-cpu-latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
