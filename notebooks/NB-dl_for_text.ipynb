{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5ZZS6o0Z8Oj"
   },
   "source": [
    "# 11장 자연어처리 1부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8OD2TTxZ8Om"
   },
   "source": [
    "## 11.1 자연어처리 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B48vvr6KZ8Oo"
   },
   "source": [
    "## 11.2 텍스트 벡터화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLeiiilMZ8Ou"
   },
   "source": [
    "## 11.3 단어 모음 표현법: 집합과 시퀀스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uzRLQDcZ8Ou"
   },
   "source": [
    "여기서는 IMDB 영화 후기 데이터를 이용하여 두 모델 방식의\n",
    "활용법과 차이점을 소개한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGXhJe5XZ8Ou"
   },
   "source": [
    "### 11.3.1 IMDB 영화 후기 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfwyzgmXZ8Ou"
   },
   "source": [
    "이전과는 달리 여기서는 IMDB 데이터셋을 직접 다운로드하여 전처리하는\n",
    "과정을 살펴본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaO7ilwSZ8Ou"
   },
   "source": [
    "준비 과정 1: 데이터셋 다운로드 압축 풀기\n",
    "\n",
    "압축을 풀면 아래 구조의 디렉토리가 생성된다.\n",
    "\n",
    "```\n",
    "aclImdb/\n",
    "...train/\n",
    "......pos/\n",
    "......neg/\n",
    "...test/\n",
    "......pos/\n",
    "......neg/\n",
    "```\n",
    "\n",
    "`train`의 `pos`와 `neg` 서브디렉토리에 각각 12,500개의 긍정과 부정 후기가\n",
    "포함되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eScCXFlWZ8Ou",
    "outputId": "50e65d8e-090b-491f-e828-2940689ce749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 80.2M  100 80.2M    0     0  49.8M      0  0:00:01  0:00:01 --:--:-- 49.8M\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMRKwRM9Z8Ou"
   },
   "source": [
    "`aclImdb/train/unsup` 서브디렉토리는 필요 없기에 삭제한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xsKw4vPZ8Ou"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !rm -r aclImdb/train/unsup\n",
    "else:\n",
    "    import shutil\n",
    "    unsup_path = './aclImdb/train/unsup'\n",
    "    shutil.rmtree(unsup_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rZ3a9ETZ8Ou"
   },
   "source": [
    "긍정 후기 하나의 내용을 살펴보자.\n",
    "모델 구성 이전에 훈련 데이터셋을 살펴 보고\n",
    "모델에 대한 직관을 갖는 과정이 항상 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VK5FRFX0Z8Ou",
    "outputId": "4294814d-2c62-4c7b-ee53-3867b616ff50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !cat aclImdb/train/pos/4077_10.txt\n",
    "else:\n",
    "    with open('aclImdb/train/pos/4077_10.txt', 'r') as f:\n",
    "        text = f.read()\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfeoV0YCZ8Ov"
   },
   "source": [
    "준비 과정 2: 검증셋 준비\n",
    "\n",
    "훈련셋의 20%를 검증셋으로 떼어낸다.\n",
    "이를 위해 `aclImdb/val` 디렉토리를 생성한 후에\n",
    "긍정과 부정 훈련셋 모두 무작위로 섞은 후 그중 20%를 검증셋 디렉토리로 옮긴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xX30tWVBZ8Ov"
   },
   "outputs": [],
   "source": [
    "import os, pathlib, shutil, random\n",
    "\n",
    "base_dir = pathlib.Path(\"aclImdb\")\n",
    "val_dir = base_dir / \"val\"\n",
    "train_dir = base_dir / \"train\"\n",
    "\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir / category)            # val 디렉토리 생성\n",
    "    files = os.listdir(train_dir / category)\n",
    "\n",
    "    random.Random(1337).shuffle(files)         # 훈련셋 무작위 섞기\n",
    "\n",
    "    num_val_samples = int(0.2 * len(files))    # 20% 지정 후 검증셋으로 옮기기\n",
    "    val_files = files[-num_val_samples:]\n",
    "\n",
    "    for fname in val_files:\n",
    "        shutil.move(train_dir / category / fname,\n",
    "                    val_dir / category / fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fljBC3puZ8Ov"
   },
   "source": [
    "준비 과정 3: 텐서 데이터셋 준비\n",
    "\n",
    "`text_dataset_from_directory()` 함수를 이용하여\n",
    "훈련셋, 검증셋, 테스트셋을 준비한다.\n",
    "자료형은 모두 `Dataset`이며, 배치 크기는 32를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e41g6BtPZ8Ov",
    "outputId": "c2661f50-e0d9-4dc6-8f5e-de2cce8c966f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\", batch_size=batch_size\n",
    "    )\n",
    "\n",
    "val_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/val\", batch_size=batch_size\n",
    "    )\n",
    "\n",
    "test_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLi_rBmlZ8Ov"
   },
   "source": [
    "각 데이터셋은 배치로 구분되며\n",
    "입력은 `tf.string` 텐서이고, 타깃은 `int32` 텐서이다.\n",
    "크기는 모두 32이며 지정된 배치 크기이다.\n",
    "예를 들어, 첫째 배치의 입력과 타깃 데이터의 정보는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G05FSfO1Z8Ov",
    "outputId": "94c82d44-cdc1-4850-b6ce-613b77a454af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32,)\n",
      "inputs.dtype: <dtype: 'string'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor(b\"Obnoxious Eva Longoria dies on her wedding day when an ice sculpture of an angel (without wings) falls on her off the back of a truck and kills her. She is then tries to ruin the relationship of her ex-boyfriend with his new girlfriend, a psychic who can see her.<br /><br />Obvious unoriginal movie wouldn't be bad in a clich\\xc3\\xa9d sort of way, except that Longoria's character is hateful and obnoxious that she drains all of the fun out of the film. Its like having your ears cleaned with sandpaper. To be fair Longoria, nor anyone else in the cast or crew, isn't the problem, its the god awful script that sinks the proceedings. Its just really really stupid.\", shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "\n",
    "    # 예제: 첫째 배치의 첫째 후기\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aM3uJTQVlJSy"
   },
   "source": [
    "### 11.3.3 시퀀스 활용법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXZ34Qg7lJSy"
   },
   "source": [
    "**정수 벡터 데이터셋 준비**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoVifu3DlJSy"
   },
   "source": [
    "훈련셋의 모든 후기 문장을 정수들의 벡터로 변환한다.\n",
    "단, 후기 문장이 최대 600개의 단어만 포함하도록 한다.\n",
    "또한 사용되는 어휘는 빈도 기준 최대 2만 개로 제한한다.\n",
    "\n",
    "- `max_length = 600`\n",
    "- `max_tokens = 20000`\n",
    "- `output_sequence_length=max_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orh58qTYlJSy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "max_length = 600\n",
    "max_tokens = 20000\n",
    "\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length,\n",
    ")\n",
    "\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y))\n",
    "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y))\n",
    "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T94MVnSHlJSy"
   },
   "source": [
    "변환된 첫째 배치의 입력과 타깃 데이터의 정보는 다음과 같다.\n",
    "`output_sequence_length=600`으로 지정하였기에 모든 문장은 단어를 최대 600개에서\n",
    "잘린다. 따라서 생성되는 정수들의 벡터는 길이가 모두 600으로 지정된다.\n",
    "물론 문장이 600개보다 적은 수의 단어를 사용한다면 나머지는 0으로 채워진다.\n",
    "또한 벡터에 사용된 정수는 2만보다 작은 값이며,\n",
    "이는 빈도가 가장 높은 2만개의 단어만을 대상(`max_tokens=20000`)으로 했기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7B-SbA7rlJSy",
    "outputId": "ebb011bb-49b5-4ab2-9746-1ec6959baff1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32, 600)\n",
      "inputs.dtype: <dtype: 'int64'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor(\n",
      "[ 1425   178   386   533     2   726     1  1778     1  5294     8     1\n",
      "     3 10277    57    16  7197   173  2372     1    17    11  4355 12411\n",
      " 13153  1625  8969  1778   286     4  1017  1590  4401  2449  9189   124\n",
      "    40 10813    21    34  1074   115    54 14792    52  9942    40  9629\n",
      "     6    34   931  3120  3696    51     1  3813   265    57  5569     6\n",
      "    28     4  9125     3   160   457  1778  2533    40    62     7    57\n",
      "     1     8     2  1570    30   867     6  8538    44  1778     3  3813\n",
      "    24   114   911    42    44     9    14  1625  3572     6    94    65\n",
      "   102    38  7724    44   172     2   404    92     2   114     7   522\n",
      "  3813 17937    25   408   568     2   693  4963   430   211   131  1778\n",
      "     1  5372   422    63   372    38     7 11498  8779    15 10721     1\n",
      "     1     2  1593     5     1    13    13  3300  4963     7    43    83\n",
      "  9695    62     7     3    83   799   120  1079   361   105  1241  1625\n",
      "  1303    19    30    38     1    33     1    12    66  1778     3  3813\n",
      "    22  8053     9    46    17     2   311   299    65   664  4373  8482\n",
      "    99  2290     2    20    45    59    26    76   324 14125    13    13\n",
      "  4963   121    26  1304     1   376    59    26     6    26    76    46\n",
      "     5  1152     6  5996    57     2   900     5     1     2   667   176\n",
      "   923  8937     1     2    84     1     1    15 10721 11060  1049     3\n",
      "   504 19477    15    40  1499  8985  2564     1    27     3    25  2444\n",
      "    85     4   592    21  3813     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0], shape=(600,), dtype=int64)\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in int_train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dyyQId0xgEWO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCrjK1-zUwFj"
   },
   "source": [
    "**트랜스포머 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iH2T-AQOUwFj"
   },
   "source": [
    "위 그림에서 설명된 트랜스포머 인코더를 층(layer)으로 구현하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6g33CzrUwFk"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(\n",
    "            inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtXomfGDUwFk"
   },
   "source": [
    "**트랜스포머 인코더 활용 모델**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPSowlcGUwFk"
   },
   "source": [
    "훈련 데이터셋이 입력되면 먼저 단어 임베딩을 이용하여\n",
    "단어들 사이의 연관성을 찾는다.\n",
    "이후 트랜스포머 인코더로 셀프 어텐션을 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hxbIVhi3UwFk",
    "outputId": "a005e2d3-a4f5-4995-87c3-16831db1648a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 256)         5120000   \n",
      "                                                                 \n",
      " transformer_encoder (Trans  (None, None, 256)         543776    \n",
      " formerEncoder)                                                  \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 256)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5664033 (21.61 MB)\n",
      "Trainable params: 5664033 (21.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000\n",
    "embed_dim = 256\n",
    "num_heads = 2\n",
    "dense_dim = 32\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "\n",
    "# 길이가 600인 1차원 어레이로 변환\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rJ82rMIUwFl"
   },
   "source": [
    "훈련 과정은 특별한 게 없다.\n",
    "테스트셋에 대한 정확도가 87.5% 정도로 바이그램 모델보다 좀 더 낮다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2BDEYHaUwFl",
    "outputId": "a81a5913-fdf8-44f9-f2ce-d4f983479c51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "625/625 [==============================] - 48s 77ms/step - loss: 0.3207 - accuracy: 0.8619 - val_loss: 0.3410 - val_accuracy: 0.8494\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 48s 77ms/step - loss: 0.2878 - accuracy: 0.8774 - val_loss: 0.3082 - val_accuracy: 0.8710\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 48s 78ms/step - loss: 0.2578 - accuracy: 0.8935 - val_loss: 0.3053 - val_accuracy: 0.8676\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.2257 - accuracy: 0.9112 - val_loss: 0.3263 - val_accuracy: 0.8644\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.1978 - accuracy: 0.9232 - val_loss: 0.3199 - val_accuracy: 0.8714\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 0.3357 - accuracy: 0.8511\n",
      "Test acc: 0.851\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"transformer_encoder\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=5, callbacks=callbacks)\n",
    "# model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\n",
    "    \"transformer_encoder\",\n",
    "    custom_objects={\"TransformerEncoder\": TransformerEncoder})\n",
    "\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tEOxNV_UwFl"
   },
   "source": [
    "**단어 위치 인코딩**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHQszXy-UwFl"
   },
   "source": [
    "다음 `PositionalEmbedding` 층 클래스는 두 개의 임베딩 클래스를 사용한다.\n",
    "하나는 보통의 단어 임베딩이며,\n",
    "다른 하나는 단어의 위치 정보를 임베딩한다.\n",
    "각 임베딩의 출력값을 합친 값을 트랜스포머에게 전달하는 역할을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uRiJ-vBXUwFm"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cG2Db4SRUwFm"
   },
   "source": [
    "**단어위치인식 트랜스포머 아키텍처**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fq24k0wlUwFm"
   },
   "source": [
    "아래 코드는 `PositionalEmbedding` 층을 활용하여 트랜스포머 인코더가\n",
    "단어위치를 활용할 수 있도록 한다.\n",
    "최종 모델의 테스트셋에 대한 정확도가 88.3%까지 향상됨을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYcxHlk7UwFm",
    "outputId": "ba70a092-839a-4307-ec8a-a28610059829"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " positional_embedding (Posi  (None, None, 256)         5273600   \n",
      " tionalEmbedding)                                                \n",
      "                                                                 \n",
      " transformer_encoder_1 (Tra  (None, None, 256)         543776    \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Gl  (None, 256)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5817633 (22.19 MB)\n",
      "Trainable params: 5817633 (22.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 63s 96ms/step - loss: 0.5286 - accuracy: 0.7521 - val_loss: 0.3209 - val_accuracy: 0.8666\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.3014 - accuracy: 0.8733 - val_loss: 0.2812 - val_accuracy: 0.8826\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 0.2344 - accuracy: 0.9080 - val_loss: 0.5238 - val_accuracy: 0.8086\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 48s 76ms/step - loss: 0.1981 - accuracy: 0.9237 - val_loss: 0.2857 - val_accuracy: 0.8866\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.1655 - accuracy: 0.9373 - val_loss: 0.3083 - val_accuracy: 0.8846\n",
      "782/782 [==============================] - 24s 30ms/step - loss: 1.0643 - accuracy: 0.5014\n",
      "Test acc: 0.501\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000\n",
    "sequence_length = 600\n",
    "embed_dim = 256\n",
    "num_heads = 2\n",
    "dense_dim = 32\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"full_transformer_encoder\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "# model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, callbacks=callbacks)\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=5, callbacks=callbacks)\n",
    "model = keras.models.load_model(\n",
    "    \"full_transformer_encoder\",\n",
    "    custom_objects={\"TransformerEncoder\": TransformerEncoder,\n",
    "                    \"PositionalEmbedding\": PositionalEmbedding})\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsHTQVECT_5r"
   },
   "source": [
    "## 11.5. 시퀀스-투-시퀀스 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kRw8L0jT_5r"
   },
   "source": [
    "### A machine translation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4zqvFdKT_5r",
    "outputId": "1e97f4d7-d743-45d0-d29f-d94872e59484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-04 16:04:56--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.4.207, 142.251.10.207, 142.251.12.207, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.4.207|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2638744 (2.5M) [application/zip]\n",
      "Saving to: ‘spa-eng.zip’\n",
      "\n",
      "spa-eng.zip         100%[===================>]   2.52M  2.41MB/s    in 1.0s    \n",
      "\n",
      "2023-12-04 16:04:57 (2.41 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
    "!unzip -q spa-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "adbnHDocT_5r"
   },
   "outputs": [],
   "source": [
    "text_file = \"spa-eng/spa.txt\"\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    english, spanish = line.split(\"\\t\")\n",
    "    spanish = \"[start] \" + spanish + \" [end]\"\n",
    "    text_pairs.append((english, spanish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BN_IurD9T_5s",
    "outputId": "9f1afe71-546f-4b11-ec09-f2eb089174ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I gave her just what she needed.', '[start] Le di justo lo que necesitaba. [end]')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kK2mwr96T_5s"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuqUCPshT_5s"
   },
   "source": [
    "**Vectorizing the English and Spanish text pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "V8CWdFJIT_5t"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import string\n",
    "import re\n",
    "\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "\n",
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "\n",
    "source_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "target_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "train_english_texts = [pair[0] for pair in train_pairs]\n",
    "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
    "source_vectorization.adapt(train_english_texts)\n",
    "target_vectorization.adapt(train_spanish_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7HeM8qPT_5t"
   },
   "source": [
    "**Preparing training and validation datasets for the translation task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XEgEfPpqT_5t"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(eng, spa):\n",
    "    eng = source_vectorization(eng)\n",
    "    spa = target_vectorization(spa)\n",
    "    return ({\n",
    "        \"english\": eng,\n",
    "        \"spanish\": spa[:, :-1],\n",
    "    }, spa[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tvL9A1MQT_5t",
    "outputId": "1db6f2f6-6ba9-406d-80f6-adc0ae681426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs['english'].shape: (64, 20)\n",
      "inputs['spanish'].shape: (64, 20)\n",
      "targets.shape: (64, 20)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
    "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JE4Oo1FT_5x"
   },
   "source": [
    "### Sequence-to-sequence learning with Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HY_E2huQT_5x"
   },
   "source": [
    "**The TransformerDecoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5I9kRgqdT_5x"
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(\n",
    "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask)\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=attention_output_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        attention_output_2 = self.layernorm_2(\n",
    "            attention_output_1 + attention_output_2)\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdyHT-v2T_5y"
   },
   "source": [
    "#### Putting it all together: a Transformer for machine translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFa7AenVT_5y"
   },
   "source": [
    "**PositionalEmbedding layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "D3ooMUyFT_5y"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Yw8lS_QT_5y"
   },
   "source": [
    "**End-to-end Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "W5B1RqwgT_5y"
   },
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "dense_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I53wCz6AT_5y"
   },
   "source": [
    "**Training the sequence-to-sequence Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZdbYo16QT_5y",
    "outputId": "494e1652-1a0f-440d-ec67-d77a613ed071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1302/1302 [==============================] - 104s 76ms/step - loss: 3.7903 - accuracy: 0.4404 - val_loss: 2.8882 - val_accuracy: 0.5304\n",
      "Epoch 2/3\n",
      "1302/1302 [==============================] - 90s 69ms/step - loss: 2.8508 - accuracy: 0.5496 - val_loss: 2.4917 - val_accuracy: 0.5919\n",
      "Epoch 3/3\n",
      "1302/1302 [==============================] - 101s 77ms/step - loss: 2.5524 - accuracy: 0.5940 - val_loss: 2.3856 - val_accuracy: 0.6111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7caadc6bad40>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "transformer.fit(train_ds, epochs=3, validation_data=val_ds)\n",
    "# transformer.fit(train_ds, epochs=30, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_2veTqxT_5y"
   },
   "source": [
    "**Translating new sentences with our Transformer model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtl4ic-tT_5y",
    "outputId": "161655a1-d1dd-408c-cf46-683f3e719223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Tom isn't a good person.\n",
      "[start] tom no es una persona [end]\n",
      "-\n",
      "Automobile sales suffered a setback at the end of the financial year.\n",
      "[start] el examen de [UNK] a la luz al final de la año [end]\n",
      "-\n",
      "I don't need an explanation.\n",
      "[start] no necesito una explicación [end]\n",
      "-\n",
      "Tom is going to college now.\n",
      "[start] tom está a ir a la universidad ahora [end]\n",
      "-\n",
      "The dish is too sweet for Tom.\n",
      "[start] la carta es demasiado bajo para tom [end]\n",
      "-\n",
      "I don't think you know anything.\n",
      "[start] no sé que tú sabes nada [end]\n",
      "-\n",
      "How quickly does the bird fly?\n",
      "[start] cómo se puede correr el pájaro [end]\n",
      "-\n",
      "Do you know what Tom's secret is?\n",
      "[start] sabes lo que es el secreto de tom [end]\n",
      "-\n",
      "I'm going to cry.\n",
      "[start] voy a ir a llorar [end]\n",
      "-\n",
      "The reason she killed herself is unknown.\n",
      "[start] la razón se [UNK] a la razón [end]\n",
      "-\n",
      "If I were you, I'd go home right away.\n",
      "[start] si yo fuera tú yo fuera a casa mismo [end]\n",
      "-\n",
      "Go to work.\n",
      "[start] ve al trabajo [end]\n",
      "-\n",
      "I'll send you the link.\n",
      "[start] te [UNK] la luz [end]\n",
      "-\n",
      "No matter where you go, I'll follow you.\n",
      "[start] no te importa dónde te voy [end]\n",
      "-\n",
      "He came home three hours later.\n",
      "[start] Él vino a casa tres horas más tarde [end]\n",
      "-\n",
      "Tom explained the purpose of the project to Mary.\n",
      "[start] tom le explicó la cuenta de la proyecto a mary [end]\n",
      "-\n",
      "I can't live without her.\n",
      "[start] no puedo vivir sin ella [end]\n",
      "-\n",
      "From time to time she stopped and looked round.\n",
      "[start] de tiempo para que ella se dejó de tiempo [end]\n",
      "-\n",
      "I do not know any of them.\n",
      "[start] no sé que nadie [end]\n",
      "-\n",
      "Tom thinks he's being shadowed by a private detective.\n",
      "[start] tom cree que se está siendo un [UNK] de [UNK] [end]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c86b3592b6800d985c04531f2c445f0fa6967131b8dd6395a925f7622e55602"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
