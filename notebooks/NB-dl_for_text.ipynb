{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5ZZS6o0Z8Oj"
   },
   "source": [
    "# 11장 자연어 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGXhJe5XZ8Ou"
   },
   "source": [
    "##  IMDB 영화 후기 데이터셋 벡터화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfwyzgmXZ8Ou"
   },
   "source": [
    "IMDB 데이터셋을 직접 다운로드하여 벡터화하는 과정을 살펴본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaO7ilwSZ8Ou"
   },
   "source": [
    "준비 과정 1: 데이터셋 다운로드 압축 풀기\n",
    "\n",
    "압축을 풀면 아래 구조의 디렉토리가 생성된다.\n",
    "\n",
    "```\n",
    "aclImdb/\n",
    "...train/\n",
    "......pos/\n",
    "......neg/\n",
    "...test/\n",
    "......pos/\n",
    "......neg/\n",
    "```\n",
    "\n",
    "`train`의 `pos`와 `neg` 서브디렉토리에 각각 12,500개의 긍정과 부정 후기가\n",
    "포함되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eScCXFlWZ8Ou",
    "outputId": "e64fb37f-d5a6-49ac-f8b9-0567bb3ce0b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 80.2M  100 80.2M    0     0  3997k      0  0:00:20  0:00:20 --:--:-- 5328k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMRKwRM9Z8Ou"
   },
   "source": [
    "`aclImdb/train/unsup` 서브디렉토리는 필요 없기에 삭제한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2xsKw4vPZ8Ou"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !rm -r aclImdb/train/unsup\n",
    "else:\n",
    "    import shutil\n",
    "    unsup_path = './aclImdb/train/unsup'\n",
    "    shutil.rmtree(unsup_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rZ3a9ETZ8Ou"
   },
   "source": [
    "긍정 후기 하나의 내용을 살펴보자.\n",
    "모델 구성 이전에 훈련 데이터셋을 살펴 보고\n",
    "모델에 대한 직관을 갖는 과정이 항상 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VK5FRFX0Z8Ou",
    "outputId": "1304a433-6e6f-4ad0-f0e7-80b49147acb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !cat aclImdb/train/pos/4077_10.txt\n",
    "else:\n",
    "    with open('aclImdb/train/pos/4077_10.txt', 'r') as f:\n",
    "        text = f.read()\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfeoV0YCZ8Ov"
   },
   "source": [
    "준비 과정 2: 검증셋 준비\n",
    "\n",
    "훈련셋의 20%를 검증셋으로 떼어낸다.\n",
    "이를 위해 `aclImdb/val` 디렉토리를 생성한 후에\n",
    "긍정과 부정 훈련셋 모두 무작위로 섞은 후 그중 20%를 검증셋 디렉토리로 옮긴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xX30tWVBZ8Ov"
   },
   "outputs": [],
   "source": [
    "import os, pathlib, shutil, random\n",
    "\n",
    "base_dir = pathlib.Path(\"aclImdb\")\n",
    "val_dir = base_dir / \"val\"\n",
    "train_dir = base_dir / \"train\"\n",
    "\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir / category)            # val 디렉토리 생성\n",
    "    files = os.listdir(train_dir / category)\n",
    "\n",
    "    random.Random(1337).shuffle(files)         # 훈련셋 무작위 섞기\n",
    "\n",
    "    num_val_samples = int(0.2 * len(files))    # 20% 지정 후 검증셋으로 옮기기\n",
    "    val_files = files[-num_val_samples:]\n",
    "\n",
    "    for fname in val_files:\n",
    "        shutil.move(train_dir / category / fname,\n",
    "                    val_dir / category / fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fljBC3puZ8Ov"
   },
   "source": [
    "준비 과정 3: 텐서 데이터셋 준비\n",
    "\n",
    "`text_dataset_from_directory()` 함수를 이용하여\n",
    "훈련셋, 검증셋, 테스트셋을 준비한다.\n",
    "자료형은 모두 `Dataset`이며, 배치 크기는 32를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e41g6BtPZ8Ov",
    "outputId": "8fa59267-238d-44c7-87f4-33df0e3e15b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\", batch_size=batch_size\n",
    "    )\n",
    "\n",
    "val_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/val\", batch_size=batch_size\n",
    "    )\n",
    "\n",
    "test_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLi_rBmlZ8Ov"
   },
   "source": [
    "각 데이터셋은 배치로 구분되며\n",
    "입력은 `tf.string` 텐서이고, 타깃은 `int32` 텐서이다.\n",
    "크기는 모두 32이며 지정된 배치 크기이다.\n",
    "예를 들어, 첫째 배치의 입력과 타깃 데이터의 정보는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G05FSfO1Z8Ov",
    "outputId": "8ca36337-3ce3-4a51-d35b-ce16eafbc25b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32,)\n",
      "inputs.dtype: <dtype: 'string'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor(b'Marlon Brando and Frank Sinatra HATED each other while doing this film and in the years following it.Brando asked Sinatra for some singing lessons,but Sinatra (who was already upset over the fact that he was cast as Nathan Detroit,when he wanted the part of Skye Masterson)wanted to be the star singer in the production and didn\\'t want any one to be better than he was.He told Brando to get lost,so to get back at him Marlon kept screwing up the scene in the diner where Sinatra was eating cheesecake so that he would have to keep eating,eating and eating.In the later years,Sinatra gave Brando the nickname \"Mumbles\" or \"Mr.Mumbles\" because of the way he talks.', shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "\n",
    "    # 예제: 첫째 배치의 첫째 후기\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aM3uJTQVlJSy"
   },
   "source": [
    "### 11.3.3 시퀀스 활용법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXZ34Qg7lJSy"
   },
   "source": [
    "**정수 벡터 데이터셋 준비**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoVifu3DlJSy"
   },
   "source": [
    "훈련셋의 모든 후기 문장을 정수들의 벡터로 변환한다.\n",
    "단, 후기 문장이 최대 600개의 단어만 포함하도록 한다.\n",
    "또한 사용되는 어휘는 빈도 기준 최대 2만 개로 제한한다.\n",
    "\n",
    "- `max_length = 600`\n",
    "- `max_tokens = 20000`\n",
    "- `output_sequence_length=max_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "orh58qTYlJSy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "max_length = 600\n",
    "max_tokens = 20000\n",
    "\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length,\n",
    ")\n",
    "# 어휘 색인 생성 대상 훈련셋 후기 텍스트 데이터셋\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
    "\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y))\n",
    "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y))\n",
    "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T94MVnSHlJSy"
   },
   "source": [
    "변환된 첫째 배치의 입력과 타깃 데이터의 정보는 다음과 같다.\n",
    "`output_sequence_length=600`으로 지정하였기에 모든 문장은 단어를 최대 600개에서\n",
    "잘린다. 따라서 생성되는 정수들의 벡터는 길이가 모두 600으로 지정된다.\n",
    "물론 문장이 600개보다 적은 수의 단어를 사용한다면 나머지는 0으로 채워진다.\n",
    "또한 벡터에 사용된 정수는 2만보다 작은 값이며,\n",
    "이는 빈도가 가장 높은 2만개의 단어만을 대상(`max_tokens=20000`)으로 했기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7B-SbA7rlJSy",
    "outputId": "a951c537-5db8-4bfe-eda4-346b2e4145b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32, 600)\n",
      "inputs.dtype: <dtype: 'int64'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor(\n",
      "[   11    19    14     2   240    19   122    91    21     2  1173    10\n",
      "    39  7749    51    71    11    19     2  2770  2765   357     2    19\n",
      "     7  1159     2  2445  2765     4   125    32    10    14  1555     6\n",
      "  4563     2    86    12    91    11     1    81    22   422   617     5\n",
      "   123   121   146    11    19     2    62    50   171    14    52     2\n",
      "    19  1027    11    19     7  2010 10817  8957  1491   469 10817  9616\n",
      "     4     1 10817  1049   577    81    22   422   123    61   146    11\n",
      "    19    23    78  2466     1   176     6   118   131    11    19  1911\n",
      "    74     2  1112  2190     2  2770  2190     2   548   576    10   377\n",
      "     7 14685     2    86   774     6  2558   525    58     2  1128  1354\n",
      "   103    48    32    12     4    69   846    58     6     2  1640    10\n",
      "   377    48    14     3   648 14784  4561   626   798    31     3   248\n",
      "    57  2714     3 13834    31     9    36  1291 14784   242   832  2338\n",
      "    23    69   156   610     9     2   113    14   514    99     1  1491\n",
      "     7   156     3    50    19     4    11    41    66     6   139     4\n",
      "  2406     9     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0], shape=(600,), dtype=int64)\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in int_train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCrjK1-zUwFj"
   },
   "source": [
    "**트랜스포머 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iH2T-AQOUwFj"
   },
   "source": [
    "위 그림에서 설명된 트랜스포머 인코더를 층(layer)으로 구현하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "X6g33CzrUwFk"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(\n",
    "            inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtXomfGDUwFk"
   },
   "source": [
    "**트랜스포머 인코더 활용 모델**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPSowlcGUwFk"
   },
   "source": [
    "훈련 데이터셋이 입력되면 먼저 단어 임베딩을 이용하여\n",
    "단어들 사이의 연관성을 찾는다.\n",
    "이후 트랜스포머 인코더로 셀프 어텐션을 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hxbIVhi3UwFk",
    "outputId": "77b51533-c428-4b80-b704-24227fc076cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 256)         5120000   \n",
      "                                                                 \n",
      " transformer_encoder (Trans  (None, None, 256)         543776    \n",
      " formerEncoder)                                                  \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 256)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5664033 (21.61 MB)\n",
      "Trainable params: 5664033 (21.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000\n",
    "embed_dim = 256\n",
    "num_heads = 2\n",
    "dense_dim = 32\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "\n",
    "# 길이가 600인 1차원 어레이로 변환\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rJ82rMIUwFl"
   },
   "source": [
    "훈련 과정은 특별한 게 없다.\n",
    "테스트셋에 대한 정확도가 87.5% 정도로 바이그램 모델보다 좀 더 낮다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2BDEYHaUwFl",
    "outputId": "a81a5913-fdf8-44f9-f2ce-d4f983479c51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "625/625 [==============================] - 48s 77ms/step - loss: 0.3207 - accuracy: 0.8619 - val_loss: 0.3410 - val_accuracy: 0.8494\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 48s 77ms/step - loss: 0.2878 - accuracy: 0.8774 - val_loss: 0.3082 - val_accuracy: 0.8710\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 48s 78ms/step - loss: 0.2578 - accuracy: 0.8935 - val_loss: 0.3053 - val_accuracy: 0.8676\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.2257 - accuracy: 0.9112 - val_loss: 0.3263 - val_accuracy: 0.8644\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.1978 - accuracy: 0.9232 - val_loss: 0.3199 - val_accuracy: 0.8714\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 0.3357 - accuracy: 0.8511\n",
      "Test acc: 0.851\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"transformer_encoder\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=5, callbacks=callbacks)\n",
    "# model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\n",
    "    \"transformer_encoder\",\n",
    "    custom_objects={\"TransformerEncoder\": TransformerEncoder})\n",
    "\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tEOxNV_UwFl"
   },
   "source": [
    "**단어 위치 인코딩**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHQszXy-UwFl"
   },
   "source": [
    "다음 `PositionalEmbedding` 층 클래스는 두 개의 임베딩 클래스를 사용한다.\n",
    "하나는 보통의 단어 임베딩이며,\n",
    "다른 하나는 단어의 위치 정보를 임베딩한다.\n",
    "각 임베딩의 출력값을 합친 값을 트랜스포머에게 전달하는 역할을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uRiJ-vBXUwFm"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cG2Db4SRUwFm"
   },
   "source": [
    "**단어위치인식 트랜스포머 아키텍처**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fq24k0wlUwFm"
   },
   "source": [
    "아래 코드는 `PositionalEmbedding` 층을 활용하여 트랜스포머 인코더가\n",
    "단어위치를 활용할 수 있도록 한다.\n",
    "최종 모델의 테스트셋에 대한 정확도가 88.3%까지 향상됨을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYcxHlk7UwFm",
    "outputId": "ba70a092-839a-4307-ec8a-a28610059829"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " positional_embedding (Posi  (None, None, 256)         5273600   \n",
      " tionalEmbedding)                                                \n",
      "                                                                 \n",
      " transformer_encoder_1 (Tra  (None, None, 256)         543776    \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Gl  (None, 256)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5817633 (22.19 MB)\n",
      "Trainable params: 5817633 (22.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 63s 96ms/step - loss: 0.5286 - accuracy: 0.7521 - val_loss: 0.3209 - val_accuracy: 0.8666\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.3014 - accuracy: 0.8733 - val_loss: 0.2812 - val_accuracy: 0.8826\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 0.2344 - accuracy: 0.9080 - val_loss: 0.5238 - val_accuracy: 0.8086\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 48s 76ms/step - loss: 0.1981 - accuracy: 0.9237 - val_loss: 0.2857 - val_accuracy: 0.8866\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.1655 - accuracy: 0.9373 - val_loss: 0.3083 - val_accuracy: 0.8846\n",
      "782/782 [==============================] - 24s 30ms/step - loss: 1.0643 - accuracy: 0.5014\n",
      "Test acc: 0.501\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000\n",
    "sequence_length = 600\n",
    "embed_dim = 256\n",
    "num_heads = 2\n",
    "dense_dim = 32\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"full_transformer_encoder\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "# model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, callbacks=callbacks)\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=5, callbacks=callbacks)\n",
    "model = keras.models.load_model(\n",
    "    \"full_transformer_encoder\",\n",
    "    custom_objects={\"TransformerEncoder\": TransformerEncoder,\n",
    "                    \"PositionalEmbedding\": PositionalEmbedding})\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsHTQVECT_5r"
   },
   "source": [
    "## 시퀀스-투-시퀀스 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영어-스페인어 기계 번역과 영어-한국어 기계 번역을 작은 데이터셋을 이용하여 훈련시켜본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kRw8L0jT_5r"
   },
   "source": [
    "### 영어-스페인어 기계 번역"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**텍스트 데이터셋 다운로드**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영어와 스페인어 텍스트가 담긴 압축 파일을 다운로드 한 후에 압축을 풀면\n",
    "\"spa.txt\" 파일이 생성된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4zqvFdKT_5r",
    "outputId": "1e97f4d7-d743-45d0-d29f-d94872e59484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-16 11:33:16--  https://www.manythings.org/anki/spa-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
      "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5413153 (5.2M) [application/zip]\n",
      "Saving to: ‘spa-eng.zip’\n",
      "\n",
      "spa-eng.zip         100%[===================>]   5.16M  4.05MB/s    in 1.3s    \n",
      "\n",
      "2023-12-16 11:33:18 (4.05 MB/s) - ‘spa-eng.zip’ saved [5413153/5413153]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.manythings.org/anki/spa-eng.zip\n",
    "!unzip -q spa-eng.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"spa.txt\" 파일은 각각의 줄은 아래와 같이 영어 텍스트, 스페인어 텍스트, 기타 정보가 탭(tab) 키로 구분되어 있다.\n",
    "\n",
    "```\n",
    "Finally, it's Friday.\tAl fin es viernes.\tCC-BY 2.0 (France) Attribution: tatoeba.org #433868 (CK) & #1427385 (marcelostockle)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 \"spa.txt\"에 포함된 각 줄의 내용을 항목으로 갖는 리스트인 `text_pairs`를 생성한다. \n",
    "단 각 항목은 (영어 텍스트, 스페인어 텍스트)로 구성된 튜플이며, 각각의 줄에 포함된 기타 정보는 버린다.\n",
    "또한 스페인어 텍스트의 처음과 끝에 각각 `'[start] '` 와 `' [end]'`를 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "adbnHDocT_5r"
   },
   "outputs": [],
   "source": [
    "text_file = \"spa.txt\"\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    english, spanish, _ = line.split(\"\\t\")\n",
    "    spanish = \"[start] \" + spanish + \" [end]\"\n",
    "    text_pairs.append((english, spanish))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`text_pairs`에 포함된 임의의 항목을 확인하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BN_IurD9T_5s",
    "outputId": "9f1afe71-546f-4b11-ec09-f2eb089174ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"I'm not going to let anyone stop me.\", '[start] No voy a dejar que nadie me detenga. [end]')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 텍스트를 무작위 섞은 다음 \n",
    "70 대 15 대 15의 비율로 훈련 텍스트셋, 검증 텍스트셋, 테스트 텍스트셋으로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kK2mwr96T_5s"
   },
   "outputs": [],
   "source": [
    "random.shuffle(text_pairs)\n",
    "\n",
    "# 검증셋 크기: 전체 데이터셋의 15%\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "# 훈련셋 크기: 전체 데이터셋의 70%\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "\n",
    "# 훈련 텍스트셋\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "# 검증 텍스트셋\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "# 테스트 텍스트셋\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuqUCPshT_5s"
   },
   "source": [
    "**영어/스페인어 텍스트 벡터화**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자연어로 구성된 훈련 텍스트 데이터셋을 대상으로 어휘 인덱스를 생성한 후에 텍스트 벡터화를 진행한다.\n",
    "먼저 영어 어휘집을 생성한다.\n",
    "생성되는 어휘 벡터의 길이를 20으로 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "V8CWdFJIT_5t"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "\n",
    "# 번역 대상 언어(예를 들어 영어) 텍스트 데이터셋 벡터화 층\n",
    "source_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "# 영어 텍스트만 추출\n",
    "train_english_texts = [pair[0] for pair in train_pairs]\n",
    "# 영어 어휘집 생성\n",
    "source_vectorization.adapt(train_english_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스페인어 텍스트 벡터화는 영어와는 다른 표준화 방식을 사용한다.\n",
    "\n",
    "- 영어에는 없는 `'¿'` 기호도 표준화 과정에서 삭제\n",
    "- 반면에 `'['`와 `']'`는 표준화 과정에서 제거되지 않도록 지정\n",
    "\n",
    "또한 생성되는 어휘 벡터의 길이를 21로 지정한다.\n",
    "그러면 0번 인덱스부터 19번 인덱스까지는 입력값으로,\n",
    "1번 인덱스부터 20번 인덱스까지는 타깃으로 지정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "V8CWdFJIT_5t"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "# 마침표 기호 목록에 \"¿\" 추가. 즉 표준화과정에서 삭제 대상으로 지정.\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "# 마침표 기호 목록으로부터 \"[\" 와 \"]\" 제거. 즉, 표준화 대상에서 삭제하지 않도록 함.\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "# 새로운 표준화 함수 선언\n",
    "# 소문자로 변환한 후에 strip_chars 에 포함된 모든 기호 삭제\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "\n",
    "# 번역 언어 (예를 들어 스페인어) 텍스트 데이터셋 벡터화 층\n",
    "# 벡터의 길이를 20이 아닌 21로 지정. 입력값과 타깃을 구분하기 위해 필요함.\n",
    "target_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "\n",
    "# 스페인어 텍스트만 추출\n",
    "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
    "# 스페인어 어휘집 생성\n",
    "target_vectorization.adapt(train_spanish_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7HeM8qPT_5t"
   },
   "source": [
    "훈련 텍스트셋, 검증 텍스트셋, 테스트 텍스트셋을 모두 어휘 인덱스를 이용하여 벡터화 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 생성된 영어와 스페인어 어휘 인덱스를 이용하여 각각의 텍스트 데이터셋을 \n",
    "벡터화 한 다음에 아래 모양의 튜플로 구성된 훈련셋, 검증셋, 테스트셋을 생성한다.\n",
    "\n",
    "- 튜플의 첫째 항목: 영어 입력 배치와 스페인어 입력 배치로 구성된 사전. 모델의 입력값으로 사용.\n",
    "- 튜플의 둘째 항목: 타깃 배치. 모델 훈련의 타깃으로 사용.\n",
    "\n",
    "```\n",
    "({\"english\": 영어 입력 배치, \"spanish\": 스페인어 입력 배치}, 타깃 배치)\n",
    "```\n",
    "\n",
    "- `format_dataset()` 함수\n",
    "    - 인자: 영어 텍스트 배치와 스페인어 텍스트 배치\n",
    "    - 반환값: 앞서 언급한 모양의 사전\n",
    "    \n",
    "- `make_dataset()` 함수\n",
    "    - 인자: `(영어 텍스트, 스페인어 텍스트)` 모양의 튜플로 구성된 자연어 텍스트 데이터셋\\\n",
    "    - 반환값: 지정된 배치 크기로 묶은 배치들에 대해 `format_dataset()` 함수를 적용하여\n",
    "        생성된 `Dataset` 자료형의 데이터셋. 배치 단위로 묶여 있음.\n",
    "        - `dataset.shuffle(2048).prefetch(16).cache()`: 대용량 데이터셋을 배치 단위로\n",
    "            빠르게 불러오기 위해 사용함.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XEgEfPpqT_5t"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(eng, spa):\n",
    "    eng = source_vectorization(eng)\n",
    "    spa = target_vectorization(spa)\n",
    "    return ({\"english\": eng, \"spanish\": spa[:, :-1]}, spa[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    dataset = dataset.map(format_dataset)\n",
    "    \n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "# 훈련셋\n",
    "train_ds = make_dataset(train_pairs)\n",
    "# 검증셋\n",
    "val_ds = make_dataset(val_pairs)\n",
    "# 테스트셋\n",
    "test_ds = make_dataset(test_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어 훈련셋의 첫째 배치의 모양을 확인하면 다음과 같다.\n",
    "\n",
    "- 영어 입력 배치: 길이가 20인 64개의 벡터로 구성. 즉, 20 개의 단어로 구성된 영어 텍스트 64개로 구성됨.\n",
    "- 스페인어 입력 배치: 길이가 20인 64개의 벡터로 구성. 즉, 20 개의 단어로 구성된 스페인어 텍스트 64개로 구성됨.\n",
    "- 타깃 배치: 길이가 20인 64개의 벡터로 구성. 즉, 20 개의 단어로 구성된 스페인어 텍스트 64개로 구성됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tvL9A1MQT_5t",
    "outputId": "1db6f2f6-6ba9-406d-80f6-adc0ae681426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs['english'].shape: (64, 20)\n",
      "inputs['spanish'].shape: (64, 20)\n",
      "targets.shape: (64, 20)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
    "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 첫째 샘플의 영어 벡터, 스페인어 벡터, 타깃을 보여준다.\n",
    "스페인어 입력 벡터 샘플의 0번 인덱스에 위치한 정수 2가 `'[start]'`에 해당하는 값이다.\n",
    "스페인어 타깃 벡터 샘플은 그 값을 제외한 벡터로 시작함을 확인할 수 있다. \n",
    "또한 정수 3은 `'[end]'`에 해당하는 값이며, 문장의 끝을 가리키기에\n",
    "스페인어 타깃 벡터 샘플에 새로운 단어에 해당하는 인덱스를 추가하지 않고 대신 0 패딩이 하나 더 추가되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tvL9A1MQT_5t",
    "outputId": "1db6f2f6-6ba9-406d-80f6-adc0ae681426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 입력 벡터 샘플: [ 26 792  42   4 153  58  31 209  10   3 897 920   0   0   0   0   0   0\n",
      "   0   0]\n",
      "스페인어 입력 벡터 샘플: [   2   30   26  879    5 4341  317    4   24  158   12  593  595    3\n",
      "    0    0    0    0    0    0]\n",
      "스페인어 타깃 샘플: [  30   26  879    5 4341  317    4   24  158   12  593  595    3    0\n",
      "    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"영어 입력 벡터 샘플: {inputs['english'][0]}\")\n",
    "    print(f\"스페인어 입력 벡터 샘플: {inputs['spanish'][0]}\")\n",
    "    print(f\"스페인어 타깃 샘플: {targets[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JE4Oo1FT_5x"
   },
   "source": [
    "### 기계 번역용도의 트랜스포머"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HY_E2huQT_5x"
   },
   "source": [
    "**트랜스포머 디코더**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5I9kRgqdT_5x"
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        # 마스크 활용\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(\n",
    "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "            \n",
    "        # 셀프 어텐션 적용: 번역 언어(예를 들어 스페인어) 입력값 대상\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask)\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        # 셀프 어텐션이 적용된 (예를 들어 스페인어) 입력 텍스트를 query로\n",
    "        # 셀프 어텐션이 적용된 번역 대상 (예를 들어 영어) 입력 텍스트를 key와 value로\n",
    "        # 지정하여 어텐션 적용\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=attention_output_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        attention_output_2 = self.layernorm_2(\n",
    "            attention_output_1 + attention_output_2)\n",
    "        \n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        \n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFa7AenVT_5y"
   },
   "source": [
    "**단어 위치 임베딩 층**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "D3ooMUyFT_5y"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Yw8lS_QT_5y"
   },
   "source": [
    "**트랜스포머 모델 지정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "W5B1RqwgT_5y"
   },
   "outputs": [],
   "source": [
    "sequence_length = 20 # 텍스트의 단어수\n",
    "vocab_size = 15000 # 어휘집 크기\n",
    "embed_dim = 256    # 단어 임베딩 크기\n",
    "dense_dim = 2048   # 밀집층 유닛수\n",
    "num_heads = 8      # 어텐션 헤드수\n",
    "\n",
    "# 트랜스포머 인코더 활용\n",
    "\n",
    "# 첫째 입력값: 예를 들어 영어 텍스트셋\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "\n",
    "# 트랜스포머 디코더 활용\n",
    "\n",
    "# 둘째 입력값: 예를 들어 스페인어 텍스트셋\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I53wCz6AT_5y"
   },
   "source": [
    "**시퀀스-투-시퀀스 모델 훈련**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZdbYo16QT_5y",
    "outputId": "494e1652-1a0f-440d-ec67-d77a613ed071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1547/1547 [==============================] - 106s 63ms/step - loss: 3.6778 - accuracy: 0.4543 - val_loss: 2.8007 - val_accuracy: 0.5509\n",
      "Epoch 2/30\n",
      "1547/1547 [==============================] - 80s 52ms/step - loss: 2.7766 - accuracy: 0.5617 - val_loss: 2.4662 - val_accuracy: 0.6037\n",
      "Epoch 3/30\n",
      "1547/1547 [==============================] - 81s 52ms/step - loss: 2.5153 - accuracy: 0.6022 - val_loss: 2.3510 - val_accuracy: 0.6209\n",
      "Epoch 4/30\n",
      "1547/1547 [==============================] - 80s 52ms/step - loss: 2.3736 - accuracy: 0.6261 - val_loss: 2.3207 - val_accuracy: 0.6269\n",
      "Epoch 5/30\n",
      "1547/1547 [==============================] - 79s 51ms/step - loss: 2.2797 - accuracy: 0.6429 - val_loss: 2.2862 - val_accuracy: 0.6377\n",
      "Epoch 6/30\n",
      "1547/1547 [==============================] - 79s 51ms/step - loss: 2.2029 - accuracy: 0.6575 - val_loss: 2.2497 - val_accuracy: 0.6503\n",
      "Epoch 7/30\n",
      "1547/1547 [==============================] - 79s 51ms/step - loss: 2.1326 - accuracy: 0.6711 - val_loss: 2.2761 - val_accuracy: 0.6422\n",
      "Epoch 8/30\n",
      "1547/1547 [==============================] - 79s 51ms/step - loss: 2.0686 - accuracy: 0.6828 - val_loss: 2.2063 - val_accuracy: 0.6592\n",
      "Epoch 9/30\n",
      "1547/1547 [==============================] - 1681s 1s/step - loss: 2.0196 - accuracy: 0.6918 - val_loss: 2.2225 - val_accuracy: 0.6620\n",
      "Epoch 10/30\n",
      "1547/1547 [==============================] - 78s 50ms/step - loss: 1.9795 - accuracy: 0.6989 - val_loss: 2.1805 - val_accuracy: 0.6684\n",
      "Epoch 11/30\n",
      "1547/1547 [==============================] - 77s 50ms/step - loss: 1.9485 - accuracy: 0.7050 - val_loss: 2.2054 - val_accuracy: 0.6658\n",
      "Epoch 12/30\n",
      "1547/1547 [==============================] - 78s 50ms/step - loss: 1.9220 - accuracy: 0.7095 - val_loss: 2.2465 - val_accuracy: 0.6584\n",
      "Epoch 13/30\n",
      "1547/1547 [==============================] - 78s 51ms/step - loss: 1.8966 - accuracy: 0.7139 - val_loss: 2.2185 - val_accuracy: 0.6690\n",
      "Epoch 14/30\n",
      "1547/1547 [==============================] - 78s 50ms/step - loss: 1.8768 - accuracy: 0.7180 - val_loss: 2.2510 - val_accuracy: 0.6654\n",
      "Epoch 15/30\n",
      "1547/1547 [==============================] - 78s 50ms/step - loss: 1.8564 - accuracy: 0.7212 - val_loss: 2.2488 - val_accuracy: 0.6692\n",
      "Epoch 16/30\n",
      "1547/1547 [==============================] - 78s 50ms/step - loss: 1.8394 - accuracy: 0.7245 - val_loss: 2.2415 - val_accuracy: 0.6716\n",
      "Epoch 17/30\n",
      "1547/1547 [==============================] - 77s 50ms/step - loss: 1.8185 - accuracy: 0.7282 - val_loss: 2.2710 - val_accuracy: 0.6720\n",
      "Epoch 18/30\n",
      "1547/1547 [==============================] - 77s 50ms/step - loss: 1.8036 - accuracy: 0.7312 - val_loss: 2.2651 - val_accuracy: 0.6718\n",
      "Epoch 19/30\n",
      "1547/1547 [==============================] - 77s 50ms/step - loss: 1.7881 - accuracy: 0.7338 - val_loss: 2.2924 - val_accuracy: 0.6699\n",
      "Epoch 20/30\n",
      "1547/1547 [==============================] - 80s 51ms/step - loss: 1.7699 - accuracy: 0.7366 - val_loss: 2.2938 - val_accuracy: 0.6751\n",
      "Epoch 21/30\n",
      "1547/1547 [==============================] - 77s 50ms/step - loss: 1.7538 - accuracy: 0.7396 - val_loss: 2.2904 - val_accuracy: 0.6726\n",
      "Epoch 22/30\n",
      "1547/1547 [==============================] - 76s 49ms/step - loss: 1.7420 - accuracy: 0.7417 - val_loss: 2.3160 - val_accuracy: 0.6708\n",
      "Epoch 23/30\n",
      "1547/1547 [==============================] - 77s 50ms/step - loss: 1.7268 - accuracy: 0.7445 - val_loss: 2.3188 - val_accuracy: 0.6725\n",
      "Epoch 24/30\n",
      "1547/1547 [==============================] - 76s 49ms/step - loss: 1.7085 - accuracy: 0.7476 - val_loss: 2.3029 - val_accuracy: 0.6749\n",
      "Epoch 25/30\n",
      "1547/1547 [==============================] - 76s 49ms/step - loss: 1.6940 - accuracy: 0.7499 - val_loss: 2.3453 - val_accuracy: 0.6738\n",
      "Epoch 26/30\n",
      "1547/1547 [==============================] - 76s 49ms/step - loss: 1.6820 - accuracy: 0.7520 - val_loss: 2.3469 - val_accuracy: 0.6769\n",
      "Epoch 27/30\n",
      "1547/1547 [==============================] - 76s 49ms/step - loss: 1.6720 - accuracy: 0.7535 - val_loss: 2.3332 - val_accuracy: 0.6755\n",
      "Epoch 28/30\n",
      "1547/1547 [==============================] - 6367s 4s/step - loss: 1.6607 - accuracy: 0.7558 - val_loss: 2.3652 - val_accuracy: 0.6700\n",
      "Epoch 29/30\n",
      "1547/1547 [==============================] - 80s 52ms/step - loss: 1.6481 - accuracy: 0.7580 - val_loss: 2.3618 - val_accuracy: 0.6754\n",
      "Epoch 30/30\n",
      "1547/1547 [==============================] - 80s 52ms/step - loss: 1.6384 - accuracy: 0.7595 - val_loss: 2.3853 - val_accuracy: 0.6719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f25582af750>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "transformer.fit(train_ds, epochs=30, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_2veTqxT_5y"
   },
   "source": [
    "**텍스트 번역**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtl4ic-tT_5y",
    "outputId": "161655a1-d1dd-408c-cf46-683f3e719223"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 어휘집 확인\n",
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "# (단어 인덱스, 단어)로 구성된 사전 지정\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "# 텍스트에 포함되는 단어수\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    # 기계 번역 시작\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        # 트랜스포머 모델 적용\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "                \n",
    "        # i-번째 단어로 사용될 어휘 인덱스 확인\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        # i-번째 단어 확인\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        # 스페인어 입력 텍스트에 i-번째 단어로 추가\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        # 기계 번역 종료 조건 확인\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "            \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xFJXavRueOZC",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "I used to play with my sister in the park.\n",
      "[start] solía jugar con mi hermana en la habitación del parque [end]\n",
      "-\n",
      "This is going to be easy.\n",
      "[start] esto va a ser fácil [end]\n",
      "-\n",
      "Tom doesn't have a bank account.\n",
      "[start] tom no tiene una cuenta de la cuenta [end]\n",
      "-\n",
      "Do you have a budget?\n",
      "[start] tienes algún lado de impuestos [end]\n",
      "-\n",
      "I seriously doubt it.\n",
      "[start] me da dudo [end]\n"
     ]
    }
   ],
   "source": [
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "\n",
    "for _ in range(5):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c86b3592b6800d985c04531f2c445f0fa6967131b8dd6395a925f7622e55602"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
