{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5ZZS6o0Z8Oj"
      },
      "source": [
        "# 11장 자연어처리 2부"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1jxmSaLUwFc"
      },
      "source": [
        "## 11.4 트랜스포머 아키텍처"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14FLKtDUUwFd"
      },
      "source": [
        "2017년 논문 \n",
        "[\"Attention is all you need\"](https://arxiv.org/abs/1706.03762)에서\n",
        "소개된 트랜스포머(Transformer) 아키텍처는 자연어처리 분야에서 혁명을 불러왔다.\n",
        "트랜스포머는 \"**뉴럴 어텐션**(Neural Attention)\" 기법을 이용하여 \n",
        "순환층 또는 합성곱 층과는 다르게 작동하는 순차 모델(sequence model)을 구현한다.\n",
        "\n",
        "여기서는 뉴럴 어텐션의 작동법을 설명한 후에\n",
        "트랜스포머 인코더를 이용하여 IMDB 영화 리뷰 모델을 구현한다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTK1LEjoUwFd"
      },
      "source": [
        "### 11.4.1 셀프 어텐션(self-attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJQjwelzUwFd"
      },
      "source": [
        "입력값의 특성 중에 보다 중요한 특성에 **집중(attention)**하면 보다 효율적으로\n",
        "훈련이 진행될 수 있다. \n",
        "아래 그림이 집중(attention)이 어떻게 활용되는지 잘 보여준다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWP1ElgwUwFe"
      },
      "source": [
        "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/11-05.png\" style=\"width:60%;\"></div>\n",
        "\n",
        "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhT_vmoHUwFe"
      },
      "source": [
        "앞서 유사한 아이디어를 활용한 적이 있다.\n",
        "\n",
        "- 합성곱 신경망의 맥스 풀링(max pooling): 지역적으로 가장 중요한 특성만 사용한다.\n",
        "- TF-IDF 정규화: 텍스트 벡터화를 위해 사용되는 TF-IDF 정규화는\n",
        "    사용되는 토큰(tokens)에 포함된 정보의 중요도를 평가하여\n",
        "    보다 중요한 정보를 담은 토큰에 집중한다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPNRRW2tUwFe"
      },
      "source": [
        "**셀프 어텐션**(self-attention)은 주어진 문장에 사용된 단어들의 연관성을 평가하여\n",
        "그 결과를 해당 문장에 적용하여 입력값을 변환하는 기법을 \n",
        "가리킨다. \n",
        "즉, **문맥**(context)를 활용한다.\n",
        "아래 그림은 \"The train  left the station on time.\" 이라는 문장에\n",
        "셀프 어텐션을 적용하여 입력값을 변환하는 과정을 나타낸다.\n",
        "\n",
        "- 1단계: 문장에 사용된 각 토큰들 사이의 연관성 계산.\n",
        "- 2단계: 계산된 연관성을 (토큰) 벡터와 결합시킨 후 새로운\n",
        "    토큰 벡터들의 시퀀스 생성.\n",
        "    아래 그림에서는 \"station\" 단어에 해당하는 벡터가 변환되는 과정을 보여줌."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYfb-9E8UwFf"
      },
      "source": [
        "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/11-06.png\" style=\"width:70%;\"></div>\n",
        "\n",
        "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuxk90B6UwFf"
      },
      "source": [
        "**질문-키-값(query-key-value) 모델**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi3TZCQFUwFf"
      },
      "source": [
        "셀프 어텐션의 작동 과정을 식으로 표현하면 다음과 같다. \n",
        "\n",
        "    outputs = sum(inputs * pairwise_scores(inputs, inputs))\n",
        "                    |                        |      |\n",
        "                   (C)                      (A)    (B)\n",
        "\n",
        "위 식은 원래 검색 엔진 또는 추천 시스템에 사용되는 \n",
        "보다 일반화된 셀프 어텐션의 작동과정을 표현한 식의 특별한 경우를 보여준다. \n",
        "\n",
        "    outputs = sum(values * pairwise_scores(query, keys))\n",
        "                    |                        |      |\n",
        "                   (C)                      (A)    (B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2AWnWcFUwFf"
      },
      "source": [
        "예를 들어, 아래 그림은 \"dogs on the beach.\" 질문(query)에 가장 \n",
        "적절한 사신을 검색한다면 각 사진과의 연관성(keys) 점수를\n",
        "해당 사진(values)과 결합하여 가장 높은 점수를 갖는 사진을\n",
        "추천하는 것을 보여준다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07-XkAWmUwFg"
      },
      "source": [
        "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/11-07.png\" style=\"width:60%;\"></div>\n",
        "\n",
        "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXjbjiQuUwFg"
      },
      "source": [
        "질문-키-값(query-key-value) 모델을 실전에 적용할 때 많은 경우 키(keys)와 값(values)가 동일하다. \n",
        "\n",
        "- 기계 번역:\n",
        "    \"How's the weather today?\"를 스페인어로 기계 번역하려 할 경우\n",
        "    스페인어로 날씨에 해당하는 \"tiempo\"를 키(key)로 해서 주어진 영어 문장(query)에 \n",
        "    사용된 단어들과 비교해야 한다. \n",
        "- 텍스트 분류:\n",
        "    앞서 셀프 어텐션 설명을 위해 사용된 그림에서처럼 query, keys, values 모두 동일하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-qoVBAKUwFg"
      },
      "source": [
        "### 11.4.2 멀티헤드 어텐션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMuuaf0LUwFg"
      },
      "source": [
        "단어들 사이의 연관성을 다양한 방식으로 알아내기 위해 셀프 어텐션을 수행하는 \n",
        "**헤드**(head)를 여러 개 병렬로 처리한 후에 다시 합치는 기법을\n",
        "**멀티헤드 어텐션**(multi-head attention)이다.\n",
        "아래 그림은 두 개의 헤드를 사용하는 것을 보여주며 각각의 헤드가 하는 일은 다음과 같다.\n",
        "\n",
        "- 질문, 키, 값을 각각 서로 다른 밀집 밀집 층으로 구성된 블록을 통과 시킨다.\n",
        "- 이후 변환된 질문, 키, 값에 셀프 어텐션을 적용한다.\n",
        "\n",
        "각 헤드에 포함된 밀집 층 블록으로 인해 멀티헤드 어텐션 층에서도\n",
        "학습이 이루어진다.\n",
        "\n",
        "**참고**: 채널 분리 합성곱 층의 알고리즘과 기본 아이디어가 유사하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV1nUi-KUwFh"
      },
      "source": [
        "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/11-08.png\" style=\"width:70%;\"></div>\n",
        "\n",
        "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFZP5ImeUwFh"
      },
      "source": [
        "### 11.4.2 트랜스포머 인코더"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZSRzRiSUwFh"
      },
      "source": [
        "멀티헤드 어텐션을 밀집(dense) 층, 정규화 층, 잔차 연결 등과 조합하여\n",
        "**트랜스포머 인코더**(transformer encoder)를 생성한다.\n",
        "\n",
        "아래 그림에서 사용되는 정규화 층인 케라스의 `LayerNormalization`은\n",
        "정규화를 배치 단위가 아닌 시퀀스 단위로 정규화를 실행한다.\n",
        "시퀀스 데이터를 처리할 때는 `BatchNormalization` 보다 잘 작동한다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOx1h4jvUwFh"
      },
      "source": [
        "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/Figures/11-09.png\" style=\"width:35%;\"></div>\n",
        "\n",
        "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsjm-0CFUwFh"
      },
      "source": [
        "**예제: IMDB 데이터셋**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlXRfk89UwFi"
      },
      "source": [
        "데이터셋을 준비하는 과정은 이전과 동일하다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxoxDyVgUwFi",
        "outputId": "a7cd98df-3d5e-44cb-c18e-2ee8f19af334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  10.4M      0  0:00:07  0:00:07 --:--:-- 16.4M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    !rm -r aclImdb/train/unsup\n",
        "else: \n",
        "    import shutil\n",
        "    unsup_path = './aclImdb/train/unsup'\n",
        "    shutil.rmtree(unsup_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDbfT2e0UwFi",
        "outputId": "7768ad03-f4f9-4f3f-f535-7d720fc63efa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import os, pathlib, shutil, random\n",
        "from tensorflow import keras\n",
        "\n",
        "batch_size = 32\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(val_dir / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)\n",
        "    num_val_samples = int(0.2 * len(files))\n",
        "    val_files = files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size=batch_size\n",
        "    )\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        "    )\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        "    )\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SxkvT7MUwFj"
      },
      "source": [
        "텍스트 벡터화는 정수들의 벡터를 사용하며, 리뷰의 최대 길이를 600 단어로 제한한다. \n",
        "\n",
        "- `output_mode=\"int\"`\n",
        "- `output_sequence_length=600`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AMK5WImvUwFj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "max_length = 600\n",
        "max_tokens = 20000\n",
        "\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "\n",
        "# 어휘 색인화\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCrjK1-zUwFj"
      },
      "source": [
        "**트랜스포머 구현**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH2T-AQOUwFj"
      },
      "source": [
        "위 그림에서 설명된 트랜스포머 인코더를 층(layer)으로 구현하면 다음과 같다.\n",
        "생성자의 입력값을 예를 들어 설명하면 다음과 같다.\n",
        "\n",
        "- `embed_dim`\n",
        "    - 트랜스포머 인코더는 \"단어 임베딩\" 층을 통과한 값을 받음.\n",
        "    - 예를 들어 `embed_dim=256`은 단어 임베딩이\n",
        "        `(600, 256)` 모양의 샘플을 생성할 것을 기대함.\n",
        "- `dense_dim`: 밀집 층에서 사용되는 유닛(unit) 수\n",
        "- `num_heads`: 헤드(head) 수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X6g33CzrUwFk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtXomfGDUwFk"
      },
      "source": [
        "**트랜스포머 인코더 활용 모델**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPSowlcGUwFk"
      },
      "source": [
        "훈련 데이터셋이 입력되면 먼저 단어 임베딩을 이용하여 \n",
        "단어들 사이의 연관성을 찾는다.\n",
        "이후 트랜스포머 인코더로 셀프 어텐션을 적용한다.\n",
        "\n",
        "사용되는 변수들은 다음과 같다.\n",
        "\n",
        "- `vocab_size = 20000`: 어휘 색인 크기\n",
        "- `embed_dim = 256`: 단어 임베딩 특성 수\n",
        "- `dense_dim = 32`: 트랜스포머 인코더에 사용되는 밀집층의 유닛(unit) 수\n",
        "- `num_heads = 2`: 트랜스포머 인코더에 사용되는 밀집층의 헤드(head) 수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxbIVhi3UwFk",
        "outputId": "5b68bc77-f78d-42af-ed79-ffba44bd8ba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 256)         5120000   \n",
            "                                                                 \n",
            " transformer_encoder (Transf  (None, None, 256)        543776    \n",
            " ormerEncoder)                                                   \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 256)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,664,033\n",
            "Trainable params: 5,664,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vocab_size = 20000\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "\n",
        "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rJ82rMIUwFl"
      },
      "source": [
        "훈련 과정은 특별한 게 없다.\n",
        "테스트셋에 대한 정확도가 87.5% 정도로 바이그램 모델보다 좀 더 낮다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2BDEYHaUwFl",
        "outputId": "95f9824a-dd52-4433-8744-583cefff244e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "625/625 [==============================] - 49s 69ms/step - loss: 0.4955 - accuracy: 0.7707 - val_loss: 0.3634 - val_accuracy: 0.8396\n",
            "Epoch 2/20\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.3099 - accuracy: 0.8709 - val_loss: 0.2835 - val_accuracy: 0.8798\n",
            "Epoch 3/20\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 0.2445 - accuracy: 0.9011 - val_loss: 0.2730 - val_accuracy: 0.8854\n",
            "Epoch 4/20\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 0.1911 - accuracy: 0.9255 - val_loss: 0.3328 - val_accuracy: 0.8808\n",
            "Epoch 5/20\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 0.1573 - accuracy: 0.9410 - val_loss: 0.3434 - val_accuracy: 0.8842\n",
            "Epoch 6/20\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.1324 - accuracy: 0.9505 - val_loss: 0.4807 - val_accuracy: 0.8788\n",
            "Epoch 7/20\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.1157 - accuracy: 0.9572 - val_loss: 0.4008 - val_accuracy: 0.8696\n",
            "Epoch 8/20\n",
            "625/625 [==============================] - 42s 68ms/step - loss: 0.1005 - accuracy: 0.9621 - val_loss: 0.4564 - val_accuracy: 0.8820\n",
            "Epoch 9/20\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0903 - accuracy: 0.9674 - val_loss: 0.3954 - val_accuracy: 0.8816\n",
            "Epoch 10/20\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 0.0809 - accuracy: 0.9699 - val_loss: 0.4855 - val_accuracy: 0.8748\n",
            "Epoch 11/20\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0718 - accuracy: 0.9740 - val_loss: 0.6046 - val_accuracy: 0.8526\n",
            "Epoch 12/20\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0625 - accuracy: 0.9776 - val_loss: 0.4552 - val_accuracy: 0.8678\n",
            "Epoch 13/20\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 0.0572 - accuracy: 0.9792 - val_loss: 0.5771 - val_accuracy: 0.8674\n",
            "Epoch 14/20\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0487 - accuracy: 0.9818 - val_loss: 0.7217 - val_accuracy: 0.8692\n",
            "Epoch 15/20\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 0.0439 - accuracy: 0.9845 - val_loss: 0.7371 - val_accuracy: 0.8640\n",
            "Epoch 16/20\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 0.0420 - accuracy: 0.9857 - val_loss: 0.5515 - val_accuracy: 0.8734\n",
            "Epoch 17/20\n",
            "625/625 [==============================] - 42s 68ms/step - loss: 0.0357 - accuracy: 0.9883 - val_loss: 0.7540 - val_accuracy: 0.8682\n",
            "Epoch 18/20\n",
            "625/625 [==============================] - 42s 68ms/step - loss: 0.0346 - accuracy: 0.9894 - val_loss: 0.6396 - val_accuracy: 0.8672\n",
            "Epoch 19/20\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0303 - accuracy: 0.9898 - val_loss: 0.7832 - val_accuracy: 0.8636\n",
            "Epoch 20/20\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.7928 - val_accuracy: 0.8590\n",
            "782/782 [==============================] - 26s 32ms/step - loss: 0.2834 - accuracy: 0.8806\n",
            "Test acc: 0.881\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"transformer_encoder.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\n",
        "    \"transformer_encoder.keras\",\n",
        "    custom_objects={\"TransformerEncoder\": TransformerEncoder})\n",
        "\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUb1tZHGUwFl"
      },
      "source": [
        "**모델 비교**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrS09aOXUwFl"
      },
      "source": [
        "자연어처리와 관련된 모델을 단어 순서 인식과 문맥 이해 차원에서 비교하면 다음과 같다.\n",
        "\n",
        "| | 단어순서 인식 | 문맥 이해 |\n",
        "| :---: | :---: | :---: |\n",
        "| 유니그램 주머니 모델 | X | X |\n",
        "| 바이그램 주머니 모델 | $\\triangle$ | X |\n",
        "| RNN | O | X |\n",
        "| 셀프 어텐션 | X | O |\n",
        "| 트랜스포머 | O | O |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tEOxNV_UwFl"
      },
      "source": [
        "**단어 위치 인코딩**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHQszXy-UwFl"
      },
      "source": [
        "앞서 살펴 본 트랜스포머 인코더는 셀프 어텐션과 밀집층을 사용하기에\n",
        "단어순서를 제대로 활용하지는 못한다.\n",
        "하지만 단어 인코딩 과정에서 단어순서 정보를 활용하도록 하는 기능을 추가하면\n",
        "트랜스포머가 알아서 단어위치 정보를 활용한다.\n",
        "\n",
        "다음 `PositionalEmbedding` 층 클래스는 두 개의 임베딩 클래스를 사용한다.\n",
        "하나는 보통의 단어 임베딩이며,\n",
        "다른 하나는 단어의 위치 정보를 임베딩한다. \n",
        "각 임베딩의 출력값을 합친 값을 트랜스포머에게 전달하는 역할을 수행한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uRiJ-vBXUwFm"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG2Db4SRUwFm"
      },
      "source": [
        "**단어위치인식 트랜스포머 아키텍처**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq24k0wlUwFm"
      },
      "source": [
        "아래 코드는 `PositionalEmbedding` 층을 활용하여 트랜스포머 인코더가 \n",
        "단어위치를 활용할 수 있도록 한다. \n",
        "최종 모델의 테스트셋에 대한 정확도가 88.3%까지 향상됨을 확인할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYcxHlk7UwFm",
        "outputId": "8401a1ed-8250-44f5-d0f4-06c0bf1318b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " positional_embedding (Posit  (None, None, 256)        5273600   \n",
            " ionalEmbedding)                                                 \n",
            "                                                                 \n",
            " transformer_encoder_1 (Tran  (None, None, 256)        543776    \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,817,633\n",
            "Trainable params: 5,817,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "625/625 [==============================] - 46s 71ms/step - loss: 0.4718 - accuracy: 0.7831 - val_loss: 0.2937 - val_accuracy: 0.8764\n",
            "Epoch 2/20\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.2331 - accuracy: 0.9112 - val_loss: 0.3013 - val_accuracy: 0.8830\n",
            "Epoch 3/20\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.1754 - accuracy: 0.9346 - val_loss: 0.2880 - val_accuracy: 0.8848\n",
            "Epoch 4/20\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.1459 - accuracy: 0.9456 - val_loss: 0.3600 - val_accuracy: 0.8836\n",
            "Epoch 5/20\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.1229 - accuracy: 0.9546 - val_loss: 0.6453 - val_accuracy: 0.8412\n",
            "Epoch 6/20\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.1096 - accuracy: 0.9598 - val_loss: 0.4088 - val_accuracy: 0.8888\n",
            "Epoch 7/20\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0973 - accuracy: 0.9657 - val_loss: 0.4181 - val_accuracy: 0.8852\n",
            "Epoch 8/20\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0896 - accuracy: 0.9688 - val_loss: 0.3933 - val_accuracy: 0.8896\n",
            "Epoch 9/20\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.0792 - accuracy: 0.9721 - val_loss: 0.3976 - val_accuracy: 0.8856\n",
            "Epoch 10/20\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0692 - accuracy: 0.9758 - val_loss: 0.4314 - val_accuracy: 0.8752\n",
            "Epoch 11/20\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.0638 - accuracy: 0.9776 - val_loss: 0.5629 - val_accuracy: 0.8798\n",
            "Epoch 12/20\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.0572 - accuracy: 0.9802 - val_loss: 0.4880 - val_accuracy: 0.8796\n",
            "Epoch 13/20\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.0486 - accuracy: 0.9833 - val_loss: 0.5932 - val_accuracy: 0.8734\n",
            "Epoch 14/20\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.0451 - accuracy: 0.9859 - val_loss: 0.5504 - val_accuracy: 0.8752\n",
            "Epoch 15/20\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.0393 - accuracy: 0.9884 - val_loss: 0.6325 - val_accuracy: 0.8710\n",
            "Epoch 16/20\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.0372 - accuracy: 0.9884 - val_loss: 0.6292 - val_accuracy: 0.8734\n",
            "Epoch 17/20\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0338 - accuracy: 0.9901 - val_loss: 0.7418 - val_accuracy: 0.8718\n",
            "Epoch 18/20\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.0260 - accuracy: 0.9920 - val_loss: 0.7180 - val_accuracy: 0.8682\n",
            "Epoch 19/20\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.0259 - accuracy: 0.9926 - val_loss: 0.8558 - val_accuracy: 0.8702\n",
            "Epoch 20/20\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.7656 - val_accuracy: 0.8690\n",
            "782/782 [==============================] - 28s 35ms/step - loss: 0.3117 - accuracy: 0.8759\n",
            "Test acc: 0.876\n"
          ]
        }
      ],
      "source": [
        "vocab_size = 20000\n",
        "sequence_length = 600\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"full_transformer_encoder.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, callbacks=callbacks)\n",
        "model = keras.models.load_model(\n",
        "    \"full_transformer_encoder.keras\",\n",
        "    custom_objects={\"TransformerEncoder\": TransformerEncoder,\n",
        "                    \"PositionalEmbedding\": PositionalEmbedding})\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB7Qtns8UwFm"
      },
      "source": [
        "### 11.4.4 트랜스포머 사용 기준"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4rbqfLzUwFn"
      },
      "source": [
        "단어주머니 모델이 여전히 유용하게 활용된다.\n",
        "실제로 IMDB 데이터셋에 대한 성능도 단어주머니 모델이 가장 좋았다.\n",
        "그리고 많은 실험 결과 \"훈련셋의 크기\"와 \"텍스트의 평균 단어 수\"의 비율이 모델 선택에\n",
        "결정적인 역할을 수행한다는 경험 법칙이 알려졌다.\n",
        "\n",
        "- (\"훈련셋의 크기\" $/$ \"텍스트의 평균 단어 수\") $>$ 1500 인 경우: 트랜스포머 등 순차 모델\n",
        "- (\"훈련셋의 크기\" $/$ \"텍스트의 평균 단어 수\") $<$ 1500 인 경우: 바이그램 단어주머니 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raxA-nvGUwFn"
      },
      "source": [
        "**예제 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP7qjzjTUwFn"
      },
      "source": [
        "1천개의 단어를 포함한 텍스트 십만 개로 이루어진 훈련셋을 사용하는 경우 비율이 100이기에 바이그램 모델을 사용하는 것이 좋다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz8lxcM5UwFn"
      },
      "source": [
        "**예제 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3IuzmAkUwFn"
      },
      "source": [
        "평균 40개의 단어를 포함하는 트윗(tweets) 5만 개로 이루어진 훈련셋을 사용하는 경우 비율이 1,250이기에 역시 바이그램 모델을 사용하는 것이 좋다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ACaZ7qHUwFn"
      },
      "source": [
        "**예제 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmLerZgIUwFo"
      },
      "source": [
        "평균 40개의 단어를 포함하는 트윗(tweets) 50만 개로 이루어진 훈련셋을 사용하는 경우 비율이 12,500이기에 이번엔 트랜스포머 인코더를 활용하는 것이 좋다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zCyPBkNUwFo"
      },
      "source": [
        "**예제 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKTNKAERUwFo"
      },
      "source": [
        "IMDB 훈련셋은 2만 개의 리뷰로 구성되며 리뷰 한 개는 평균 233 개의 단어를 포함한다. 비율이 85.84 정도이기에 바이그램 모델이 보다 적합해야 하는데\n",
        "지금까지 살펴본 결과가 이에 입증한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6s2RjcNUwFo"
      },
      "source": [
        "**경험 법칙의 직관적 이해**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV8SE1WhUwFo"
      },
      "source": [
        "짧은 문장이 많을 수록 문맥을 파악하려면 단어들의 순서가 중요하며,\n",
        "문장에 사용된 단어들 사이의 복잡한 연관성을 보다 주의깊게 살펴볼 필요가 있다.\n",
        "예를 들어, \"그 영화는 실패야\"와 \"그 영화는 실패였어\"는 분명 다른 의미를 가지지만\n",
        "단어주머니 모델은 차이점을 파악하기 어렵다. \n",
        "반면에 보다 긴 문장의 주제와 긍정/부정 등의 감성에 대한 분류는\n",
        "단어 관련 통계의 중요성이 보다 크다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTAgQpNKUwFo"
      },
      "source": [
        "**주의사항** \n",
        "\n",
        "앞서 설명한 경험 법칙은은 텍스트 분류(text classification)에 한정된다. \n",
        "예를 들어 기계 번역(machine translation)의 경우 매우 긴 문장을 다룰 때 \n",
        "트랜스포머가 가본적으로 가장 강력한 성능의 모델을 생성한다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "## 11.5. 시퀀스-투-시퀀스 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "준비중 ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "### A machine translation example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
        "!unzip -q spa-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "text_file = \"spa-eng/spa.txt\"\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    english, spanish = line.split(\"\\t\")\n",
        "    spanish = \"[start] \" + spanish + \" [end]\"\n",
        "    text_pairs.append((english, spanish))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "print(random.choice(text_pairs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "**Vectorizing the English and Spanish text pairs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "\n",
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_english_texts = [pair[0] for pair in train_pairs]\n",
        "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_spanish_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "**Preparing training and validation datasets for the translation task**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "def format_dataset(eng, spa):\n",
        "    eng = source_vectorization(eng)\n",
        "    spa = target_vectorization(spa)\n",
        "    return ({\n",
        "        \"english\": eng,\n",
        "        \"spanish\": spa[:, :-1],\n",
        "    }, spa[:, 1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
        "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "### Sequence-to-sequence learning with RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "**GRU-based encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embed_dim = 256\n",
        "latent_dim = 1024\n",
        "\n",
        "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
        "encoded_source = layers.Bidirectional(\n",
        "    layers.GRU(latent_dim), merge_mode=\"sum\")(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "**GRU-based decoder and the end-to-end model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
        "decoder_gru = layers.GRU(latent_dim, return_sequences=True)\n",
        "x = decoder_gru(x, initial_state=encoded_source)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "seq2seq_rnn = keras.Model([source, past_target], target_next_step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "**Training our recurrent sequence-to-sequence model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "seq2seq_rnn.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "seq2seq_rnn.fit(train_ds, epochs=15, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "**Translating new sentences with our RNN encoder and decoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "spa_vocab = target_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization([decoded_sentence])\n",
        "        next_token_predictions = seq2seq_rnn.predict(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(20):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(decode_sequence(input_sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "### Sequence-to-sequence learning with Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "#### The Transformer decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "**The TransformerDecoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "#### Putting it all together: a Transformer for machine translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "**PositionalEmbedding layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "**End-to-end Transformer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "**Training the sequence-to-sequence Transformer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "transformer.fit(train_ds, epochs=30, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text"
      },
      "source": [
        "**Translating new sentences with our Transformer model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "code"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "spa_vocab = target_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization(\n",
        "            [decoded_sentence])[:, :-1]\n",
        "        predictions = transformer(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(20):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(decode_sequence(input_sentence))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "dlp11_part03_transformer",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('homl3')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "87326548fe22e0f6dacd268b079dcc7a15583d9081b3203af40b067350baf618"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
