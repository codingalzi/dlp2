

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>8. 컴퓨터 비전 기초: 합성곱 신경망 &#8212; Deep Learning with Python(2판)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'computer_vision_intro';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="9. 고급 컴퓨터 비전" href="computer_vision_advanced.html" />
    <link rel="prev" title="7. 케라스 신경망 모델 활용법" href="working_with_keras.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    <p class="title logo__title">Deep Learning with Python(2판)</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="what_is_deep_learning.html">1. 딥러닝 소개</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="building_blocks_of_NN.html">2. 신경망 기본 구성 요소</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="tf_tensor.html">2.7. 부록: 텐서플로우 텐서</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="keras_and_tf.html">3. 케라스와 텐서플로우</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started_with_neural_networks.html">4. 신경망 활용 처음부터 끝까지: 분류와 회귀</a></li>
<li class="toctree-l1"><a class="reference internal" href="fundamentals_of_ml.html">5. 머신러닝 모델 훈련 기법</a></li>
<li class="toctree-l1"><a class="reference internal" href="unversal_workflow_of_ml.html">6. 머신러닝 작업 흐름 일반</a></li>
<li class="toctree-l1"><a class="reference internal" href="working_with_keras.html">7. 케라스 신경망 모델 활용법</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">8. 컴퓨터 비전 기초: 합성곱 신경망</a></li>
<li class="toctree-l1"><a class="reference internal" href="computer_vision_advanced.html">9. 고급 컴퓨터 비전</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl_for_timeseries.html">10. 시계열 분석</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl_for_text.html">11. 자연어 처리</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative_dl.html">12. 생성 모델</a></li>
<li class="toctree-l1"><a class="reference internal" href="best_practices.html">13. 딥러닝 실전 적용</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/codingalzi/dlp2" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/codingalzi/dlp2/issues/new?title=Issue%20on%20page%20%2Fcomputer_vision_intro.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/computer_vision_intro.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>컴퓨터 비전 기초: 합성곱 신경망</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">8.1. 합성곱 신경망</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mnist-cnn">8.1.1. MNIST 데이터셋 분류 CNN 모델</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">8.1.2. 합성곱 연산</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">8.1.3. 맥스 풀링 연산</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">8.2. 합성곱 신경망 실전 활용 예제</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">8.2.1. 작은 데이터셋과 딥러닝 모델</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">8.2.2. 데이터 다운로드</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">8.2.3. 모델 구성</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">8.2.4. 데이터 전처리와 모델 훈련</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">8.2.5. 데이터 증식</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">8.3. 모델 재활용</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">8.3.1. 전이 학습</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">8.3.2. 모델 미세 조정</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">8.4. 연습문제</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ch-computer-vision-intro">
<span id="id1"></span><h1><span class="section-number">8. </span>컴퓨터 비전 기초: 합성곱 신경망<a class="headerlink" href="#ch-computer-vision-intro" title="Permalink to this heading">#</a></h1>
<p><strong>감사의 글</strong></p>
<p>아래 내용은 프랑소와 숄레의
<a class="reference external" href="https://github.com/fchollet/deep-learning-with-python-notebooks">Deep Learning with Python(2판)</a>의
소스코드 내용을 참고해서 작성되었습니다.
자료를 공개한 저자에게 진심어린 감사를 전합니다.</p>
<p><strong>소스코드</strong></p>
<p>여기서 언급되는 코드를
<a class="reference external" href="https://colab.research.google.com/github/codingalzi/dlp2/blob/master/notebooks/NB-computer_vision_intro.ipynb">(구글 코랩) 컴퓨터 비전 기초: 합성곱 신경망</a>에서
직접 실행할 수 있다.</p>
<p><strong>슬라이드</strong></p>
<p>본문 내용을 요약한 <a class="reference external" href="https://github.com/codingalzi/dlp2/raw/master/slides/slides-computer_vision_intro.pdf">슬라이드</a>를 다운로드할 수 있다.</p>
<p><strong>주요 내용</strong></p>
<ul class="simple">
<li><p>합성곱 신경망</p></li>
<li><p>데이터 증식</p></li>
<li><p>전이학습</p></li>
</ul>
<section id="id2">
<h2><span class="section-number">8.1. </span>합성곱 신경망<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<p>2011년부터 2015년 사이에 벌어진
컴퓨터 비전 분야에서의 딥러닝 기법이 획기적으로 발전하였다.
그 결과 지금은 사진 검색, 자율주행, 로봇공학, 의학 진단 프로그램,
얼굴 확인, 스마트 팜 등 일상의 많은 영역에서 딥러닝 모델이 사용되고 있다.</p>
<p>컴퓨터 비전 분야에서 일반적으로 가장 많이 사용되는 딥러닝 모델은
<strong>CNN</strong> 또는 <strong>convnet</strong>으로 불리는
<strong>합성곱 신경망</strong><font size='2'>convolutional neural networks</font>이다.
여기서는 이미지 분류 문제에 CNN을 적용하는 방법을 소개한다.</p>
<section id="mnist-cnn">
<h3><span class="section-number">8.1.1. </span>MNIST 데이터셋 분류 CNN 모델<a class="headerlink" href="#mnist-cnn" title="Permalink to this heading">#</a></h3>
<p>아래 층들을 이용하여 모델을 함수형 API 방식으로 선언한다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Input()</span></code>: 입력층</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">shape=(28,</span> <span class="pre">28,</span> <span class="pre">1)</span></code>. 훈련 샘플의 모양 지정.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">28x28</span></code> 픽셀 크기의 흑백 손글씨 사진</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>: 합성곱 층</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">filters</span></code>: 필터 수 지정. 층 출력값의 채널의 수로 사용됨.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernel_size</span></code>: 합성곱 연산에 사용되는 커널의 크기. 층 출력값의 높이, 너비 크기 결정에 사용됨.</p></li>
<li><p>출력값: 3D 텐서 (높이, 너비, 채널수).</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code>: 맥스풀링 층</p>
<ul>
<li><p>입력 사진의 높이와 너비를 지정된 비율만큼 축소. 즉 사진의 크기 축소.</p></li>
<li><p>출력값: 3D 텐서 (높이, 너비, 채널수).</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">Dense</span></code>: 밀집 층</p>
<ul>
<li><p>CNN 모델의 출력층은 일반적으로 밀집층 사용</p></li>
<li><p>이전 층의 출력값을 <code class="docutils literal notranslate"><span class="pre">Flatten()</span></code> 층을 이용하여 1차원 텐서로 변형시킨 후 입력값으로 사용.</p></li>
</ul>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 입력층</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># 은닉층</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 출력층으로 넘기기 전에 1차원 텐서로 변환</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 출력층</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 모델</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>모델 구성 요약</strong></p>
<p>모델 구성을 요약하면 다음과 같다.
각 층별로 출력값의 모양과 사용되는 파라미터의 수에 대해서는
나중에 설명한다.
다만, <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> 층과 <code class="docutils literal notranslate"><span class="pre">Flatten</span></code> 층엔 파라미터가 전혀 사용되지 않음은 기억해 둔다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="go">Model: &quot;model&quot; </span>
<span class="go">_________________________________________________________________</span>
<span class="go">Layer (type)                 Output Shape              Param # </span>
<span class="go">================================================================= </span>
<span class="go">input_1 (InputLayer)         [(None, 28, 28, 1)]       0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">conv2d (Conv2D)              (None, 26, 26, 32)        320 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">flatten (Flatten)            (None, 1152)              0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">dense (Dense)                (None, 10)                11530 </span>
<span class="go">=================================================================</span>
<span class="go">Total params: 104,202 </span>
<span class="go">Trainable params: 104,202 </span>
<span class="go">Non-trainable params: 0 </span>
</pre></div>
</div>
<p><strong>MNIST 이미지 분류 훈련</strong></p>
<p>모델 훈련은 이전과 동일하다.
다만 훈련 샘플은 <code class="docutils literal notranslate"><span class="pre">(28,</span> <span class="pre">28,</span> <span class="pre">1)</span></code> 모양의 3차원 텐서이어야 한다.
이유는 <code class="docutils literal notranslate"><span class="pre">Input()</span></code> 함수에 의해 <code class="docutils literal notranslate"><span class="pre">(28,</span> <span class="pre">28,</span> <span class="pre">1)</span></code> 모양의 입력값이 지정되었기 때문이다.</p>
<p>지금까지 입력층으로 사용한 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층은 입력 샘플의 모양이 1차원 텐서, 즉 벡터이어야 했고,
따라서 MNIST 데이터셋의 샘플들을 모두
1차원 텐서로 변형한 다음에 훈련셋으로 활용하였다.
하지만 여기서는 3차원 텐서 이미지를
모양을 변형시키는 전처리 없이 바로 사용해야 한다.</p>
<ul class="simple">
<li><p>훈련셋 준비</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>

<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
</pre></div>
</div>
<ul class="simple">
<li><p>모델 컴파일과 훈련</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>  <span class="c1"># 레이블이 정수인 경우</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>
</div>
<p>테스트셋에 대한 정확도가 99% 정도로 이전에 사용한 <code class="docutils literal notranslate"><span class="pre">Sequential</span></code> 모델보다 훨씬 좋다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;테스트 정확도: </span><span class="si">{</span><span class="n">test_acc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">313/313 [==============================] - 2s 4ms/step - loss: 0.0395 - accuracy: 0.9893</span>
<span class="go">테스트 정확도: 0.989</span>
</pre></div>
</div>
</section>
<section id="id3">
<h3><span class="section-number">8.1.2. </span>합성곱 연산<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<p>합성곱 층(<code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>)에서 입력값을 변환하는 과정은 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층에서의 변환과 다르다.
차이점의 핵심은 아핀 변환을 적용하는 방식에 있다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층: 입력값의 전체 특성을 대상으로 한 번의 아핀 변환 적용</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층: <code class="docutils literal notranslate"><span class="pre">kernel_size</span></code>로 지정된 크기의 공간에 대해 여러 개의 아핀 변환 적용.</p>
<ul>
<li><p>예를 들어, <code class="docutils literal notranslate"><span class="pre">kernel_size=3</span></code>인 경우 <code class="docutils literal notranslate"><span class="pre">3x3</span></code> 크기의 영역에 대해
지정된 <code class="docutils literal notranslate"><span class="pre">filters</span></code> 수 만큼의 아핀 변환 적용.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층: 입력값 전체를 학습 대상으로 삼는다.
예를 들어, MNIST의 경우 숫자 이미지 전체를 대상으로 학습한다.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층: 예를 들어 <code class="docutils literal notranslate"><span class="pre">kernel_size=3</span></code>으로 설정된 경우
<code class="docutils literal notranslate"><span class="pre">3x3</span></code> 크기의 국소적 특성들을 대상으로 학습한다.</p></li>
</ul>
<p><strong>Conv2D 모델의 장점</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층의 장점은 크게 다음 두 가지로 요약된다.</p>
<p>첫째, 패턴의 위치와 무관하다.
한 번 인식된 패턴은 다른 위치에서도 인식된다.
따라서 적은 수의 샘플을 이용하여 일반화 성능이 높은 모델을 훈련시킬 수 있다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/local_patterns.jpg" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>둘째, 패턴 공간의 계층을 파악한다.
위 층으로 진행할 수록 보다 복잡한 패턴을 파악한다.
이를 <strong>패턴 공간의 계층</strong>(spatial hierarchy of patterns)이라 한다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/visual_hierarchy_hires.png" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>특성맵, 채널, 필터</strong></p>
<p>합성곱 연산의 작동법을 이해하려면 아래 세 개념을 이해해야 한다.</p>
<ul class="simple">
<li><p><strong>특성맵</strong><font size='2'>feature map</font>, <strong>채널</strong><font size='2'>channel</font>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">(높이,</span> <span class="pre">너비)</span></code> 모양의 2D 텐서.</p></li>
<li><p>예제: MNIST 데이터셋에 포함된 흑백 이미지 샘플의 경우 <code class="docutils literal notranslate"><span class="pre">(28,</span> <span class="pre">28)</span></code> 모양의 채널 한 개로 구성됨.</p></li>
<li><p>예제: 컬러사진의 경우 세 개의 채널(특성맵)로 구성됨.</p></li>
<li><p>이미지에 포함된 채널의 수를 <strong>깊이</strong>라 부름.</p></li>
</ul>
</li>
<li><p><strong>필터</strong><font size='2'>filter</font>: <code class="docutils literal notranslate"><span class="pre">kernel_size</span></code>를 이용한 3D 텐서.</p>
<ul>
<li><p>예제: <code class="docutils literal notranslate"><span class="pre">kernel_size=3</span></code>인 경우 필터는 <code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">3,</span> <span class="pre">입력샘플의깊이)</span></code> 모양의 3D 텐서.</p></li>
<li><p>필터 수: <code class="docutils literal notranslate"><span class="pre">filters</span></code> 인자에 의해 결정됨.</p></li>
</ul>
</li>
<li><p><strong>출력맵</strong><font size='2'>response map</font>:
입력 샘플을 대상으로 하나의 필터를 적용해서 생성된 하나의 특성맵(채널).
필터 수만큼의 출력맵이 생성됨.</p></li>
</ul>
<div class="info admonition">
<p class="admonition-title">컬러 이미지와 채널</p>
<p>컬러 이미지는 R(red), G(green), B(blue) 세 개의 채털로 구성된다.
각각의 채널은 2차원 어레이로 다뤄지기에 하나의 컬러 이미지는 세 개의 채널을 모은 3차원 어레이로 표현된다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-reign_pic_breakdown.png" style="width:700px;"></div>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-three_d_array.png" style="width:400px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://e2eml.school/convert_rgb_to_grayscale.html">How to Convert an RGB Image to Grayscale</a>&gt;</div></p>
</div>
<p><strong>필터 적용</strong></p>
<p>아래 그림은 필터의 모양과 동일한 크기의 국소적 텐서를 대상으로 필터를 적용하여 <strong>하나의 값</strong>을
생성하는 과정을 보여준다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-filter-product-1.jpg" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.oreilly.com/library/view/fundamentals-of-deep/9781492082170/">Fundamentals of Deep Learning(2판)</a>&gt;</div></p><p>하나의 필터를 슬라이딩 시키면서 입력 특성맵 전체를 대상으로 위 과정을 적용하여 한 개의 출력맵을
생성한다.
아래 그림은 한 개의 채널로 구성된 입력값을 대상으로 하나의 필터를 적용하여 출력맵을 생성하는 과정을 보여준다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-convSobel.gif" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://mlnotebook.github.io/post/CNN1/">Machine Learning Notebook: CNN - Basics</a>&gt;</div></p><p>예를 들어 6개의 필터를 적용하면 최종적으로 6개의 채널로 구성된 출력 특성맵이 생성된다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-filter-product-2.jpg" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.oreilly.com/library/view/fundamentals-of-deep/9781492082170/">Fundamentals of Deep Learning(2판)</a>&gt;</div></p><p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층을 통과할 때 마다 동일한 작업이 반복된다.
각 층마다 사용되는 필터의 크기와 수가 다를 수 있다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-cnn-layers.jpg" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.hanbit.co.kr/store/books/look.php?p_code=B7033438574">핸즈온 머신러닝(2판)</a>&gt;</div></p><p><strong>합성곱 신경망 모델이란?</strong></p>
<p>합성곱 신경망 모델은 바로 이 필터들을 학습시키는 모델을 가리킨다.</p>
<p><strong>패딩과 보폭</strong></p>
<p>필터를 적용하여 생성된 출력 특성맵의 모양이 입력 특성맵(채널)의 모양과 다를 수 있다.
다만 출력값의 채널 수는 필터의 개수와 동일하다.
이유는 하나의 필터가 하나의 특성맵(채널)을 생성하기 때문이다.
출력 특성맵의 높이와 너비는
<strong>패딩</strong><font size='2'>padding</font>의 사용 여부와
<strong>보폭</strong><font size='2'>stride</font>의 크기에 의에 결정된다.</p>
<p>다음 세 개의 그림은 입력 특성맵의 높이와 너비가 <code class="docutils literal notranslate"><span class="pre">5x5</span></code>일 때
패딩의 사용 여부와 보폭의 크기에 따라
출력 특성맵의 높이와 너비가 어떻게 달라지는가를 보여준다.</p>
<ul class="simple">
<li><p>경우 1: 패딩 없음, 보폭은 1.</p>
<ul>
<li><p>출력 특성맵의 깊이와 너비: <code class="docutils literal notranslate"><span class="pre">3x3</span></code></p></li>
<li><p>출력 특성맥의 깊이와 너비가 줄어듦.</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-padding-stride-01.png" style="width:400px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.analyticsvidhya.com/blog/2022/03/basics-of-cnn-in-deep-learning/">Basics of CNN in Deep Learning</a>&gt;</div></p><ul class="simple">
<li><p>경우 2: 패딩 없음, 보폭은 2.</p>
<ul>
<li><p>출력 특성맵의 깊이와 너비: <code class="docutils literal notranslate"><span class="pre">2x2</span></code></p></li>
<li><p>출력 특성맵의 깊이와 너비가 보폭의 반비례해서 줄어듦.</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-padding-stride-02.png" style="width:350px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.analyticsvidhya.com/blog/2022/03/basics-of-cnn-in-deep-learning/">Basics of CNN in Deep Learning</a>&gt;</div></p><ul class="simple">
<li><p>경우 3: 패딩 있음, 보폭은 1.</p>
<ul>
<li><p>출력 특성맵의 깊이와 너비: <code class="docutils literal notranslate"><span class="pre">5x5</span></code></p></li>
<li><p>출력 특성맵의 깊이와 너비가 동일하게 유지됨.</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-cnn-padding.png" style="width:900px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.researchgate.net/figure/Figure-B2-A-convolutional-filter-with-padding-stride-one-and-filter-size-of-3x3-Image_fig30_324783775">Text to Image Synthesis Using Generative Adversarial Networks</a>&gt;</div></p><ul class="simple">
<li><p>경우 4: 패딩을 사용하고 보폭이 1보다 큰 경우는 굳이 사용할 필요 없음.
이유는 보폭이 1보다 크기에 출력 특성맵의 깊이와 너비가 어차피 보폭에 반비례해서 줄어들기 때문임.</p></li>
</ul>
</section>
<section id="id4">
<h3><span class="section-number">8.1.3. </span>맥스 풀링 연산<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<p>합성곱 신경망의 전형적인 모습은 다음과 같이 풀링 층을 합성곱 층 이후에 바로 위치시킨다.
단, 합성곱 층, 맥스 풀링 층이 연속적으로 몇 개씩 사용될 수 있다.</p>
<div align="center"><img src="http://formal.hknu.ac.kr/handson-ml2/slides/images/ch14/homl14-03.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.hanbit.co.kr/store/books/look.php?p_code=B7033438574">핸즈온 머신러닝(2판)</a>&gt;</div></p><p>풀링 층 중에서 <strong>맥스 풀링</strong>(max-pooling) 층이 많이 사용된다.
맥스 풀링 층은 일정 크기의 영역에서 최댓값만을 선택하여 특성맵의 높이와 너비를 일정 비율로 줄인다.
예를 들어, 아래 맥스 풀링 층은 <code class="docutils literal notranslate"><span class="pre">2x2</span></code>영역에서 최댓값 하나만을 남기고 나머지는 버리며,
이 연산을 보폭 2만큼씩 이동하며 입력 특성맵의 모든 영역(<code class="docutils literal notranslate"><span class="pre">높이x너비</span></code>)에 대해 실행한다.
맥스 풀링 연산은 입력 특성맵의 채녈 단위로 이루어지기에 채널 수는 변하지 않는다.
예를 들어, 만약 <code class="docutils literal notranslate"><span class="pre">x</span></code>가 <code class="docutils literal notranslate"><span class="pre">(26,</span> <span class="pre">26,</span> <span class="pre">32)</span></code> 모양의 3D 텐서이면
다음 맥스 풀링 층의 출력값은 <code class="docutils literal notranslate"><span class="pre">(13,</span> <span class="pre">13,</span> <span class="pre">32)</span></code> 모양의 3D 텐서가 된다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<div align="center"><img src="http://formal.hknu.ac.kr/handson-ml2/slides/images/ch14/homl14-10.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.hanbit.co.kr/store/books/look.php?p_code=B7033438574">핸즈온 머신러닝(2판)</a>&gt;</div></p><p>맥스 풀링 층을 합성곱 층(<code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>)과 함께 사용하는 이유는 두 가지이다.</p>
<ul class="simple">
<li><p>학습해야할 가중치 파라미터의 수 줄이기.</p></li>
<li><p>상위 층으로 갈 수록 입력 특성맵의 보다 넓은 영역에 대한 정보를 얻기 위해.</p></li>
</ul>
<p>아래 코드는 맥스 풀링 층을 사용하지 않는 경우 가중치 파라미터의 수가 엄청나게 증가함을 잘 보여준다.</p>
<ul class="simple">
<li><p>맥스 풀링 사용하는 경우: 104,202개</p></li>
<li><p>그렇지 않은 경우: 712,202개</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model_no_max_pool</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model_no_max_pool</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="go">Model: &quot;model_1&quot; </span>
<span class="go">_________________________________________________________________</span>
<span class="go">Layer (type)                 Output Shape              Param # </span>
<span class="go">=================================================================</span>
<span class="go">input_2 (InputLayer)         [(None, 28, 28, 1)]       0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">conv2d_3 (Conv2D)            (None, 26, 26, 32)        320 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">conv2d_5 (Conv2D)            (None, 22, 22, 128)       73856 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">flatten_1 (Flatten)          (None, 61952)             0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">dense_1 (Dense)              (None, 10)                619530 </span>
<span class="go">=================================================================</span>
<span class="go">Total params: 712,202 </span>
<span class="go">Trainable params: 712,202 </span>
<span class="go">Non-trainable params: 0 </span>
</pre></div>
</div>
<p><strong>적절한 <code class="docutils literal notranslate"><span class="pre">kernel_size</span></code>, <code class="docutils literal notranslate"><span class="pre">stride</span></code>, <code class="docutils literal notranslate"><span class="pre">pool_size</span></code> 지정하기</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층의 기본값: <code class="docutils literal notranslate"><span class="pre">kernel_size=3</span></code>, <code class="docutils literal notranslate"><span class="pre">stride=1</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> 층의 기본값: <code class="docutils literal notranslate"><span class="pre">pool_size=2</span></code>, <code class="docutils literal notranslate"><span class="pre">strides=2</span></code>.
<code class="docutils literal notranslate"><span class="pre">strides</span></code>의 기본값을 지정하지 않으면 <code class="docutils literal notranslate"><span class="pre">pool_size</span></code>의 값과 동일하게 지정됨.</p></li>
</ul>
<p>다른 설정 또는 최댓값 대신에 평균값을 사용하는 <code class="docutils literal notranslate"><span class="pre">AveragePooling2D</span></code>를
활용할 수 있으나 케라스의 기본 설정이 일반적으로 가장 좋은 성능을 보인다.</p>
</section>
</section>
<section id="id5">
<h2><span class="section-number">8.2. </span>합성곱 신경망 실전 활용 예제<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h2>
<section id="id6">
<h3><span class="section-number">8.2.1. </span>작은 데이터셋과 딥러닝 모델<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h3>
<p>이미지 분류 모델을 훈련시킬 때 데이터셋의 크기가 그다지 크지 않은 경우가 일반적이다.
즉, 데이터셋의 크기가 적게는 몇 백 개에서 많게는 몇 만 개 정도이다.
여기서 훈련시켜야 하는 모델은 개와 고양이 사진을 대상으로 하는 이진분류 합성곱 신경망 모델이다.
실전 상황에 맞추기 위해 5천 개의 이미지로 이루어진 작은 데이터셋을 사용한다.</p>
<p>합성곱 신경망 모델은 작은 크기의 데이터셋으로도 어느 정도의 성능을 얻을 수 있으며,
데이터 증식 기법을 적용하거나 기존에 잘 훈련된 모델을 재활용하여 보다 또는 훨씬 높은 성능의 모델을 구현할 수 있음을 보인다.
데이터 증식 기법은 훈련 데이터셋을 크기를 늘리는 기법이며,
사전에 잘 훈련된 모델을 재활용하기 위해 특성 추출 기법과 모델 미세조정 기법을 적용한다.</p>
</section>
<section id="id7">
<h3><span class="section-number">8.2.2. </span>데이터 다운로드<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h3>
<p>데이터 과학과 머신러닝과 관련된 다양한 데이터셋과 모델을 활용할 수 있는
<a class="reference external" href="https://www.kaggle.com">캐글<font size='2'>Kaggle</font></a>에서
훈련에 필요한 데이터셋을 다운로드하려면 다음 사항을 먼저 확인해야 한다.</p>
<ul class="simple">
<li><p>캐글 계정을 갖고 있어야 하며, 로그인된 상태에서 아래 두 과정을 먼저 해결해야 한다.</p></li>
<li><p>캐글에 로그인한 후 “Account” 페이지의 계정 설정 창에 있는 “API” 항목에서
“Create New API Token”을 생성하여 다운로드한다.</p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/c/dogs-vs-cats/rules">캐글: Dogs vs. Cats</a>를
방문해서 “I Understand and Accept” 버튼을 클릭해야 한다.</p></li>
</ul>
<p>다운로드된 데이터셋은 총 25,000장의 강아지와 고양이 사진으로 구성되었으며 570MB 정도로 꽤 크다.
강아지 사진 고양이 사진이 각각 12,500 장씩 포함되어 있으며, 사진들의 크기가 다음과 같이 일정하지 않다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/dog_and_cat_samples.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>훈련셋, 검증셋, 테스트셋 준비</strong></p>
<p>25,000 장의 사진 중에서 총 5,000 장의 사진만 사용해서 합성곱 신경을 훈련시키려 한다.</p>
<ul class="simple">
<li><p>훈련셋: 강아지와 고양이 각각 1,000 장</p></li>
<li><p>검증셋: 강아지와 고양이 각각 500 장</p></li>
<li><p>테스트셋: 강아지와 고양이 각각 1,000 장</p></li>
</ul>
</section>
<section id="id8">
<h3><span class="section-number">8.2.3. </span>모델 구성<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h3>
<p>CNN 모델은 앞서 설명한대로 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>와 <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> 레이어를
연속에서 쌓는 방식을 사용한다.
다만, 보다 큰 이미지와 보다 복잡한 문제를 해결하기 위해 모델을 보다 크게 만들기 위해
<code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>와 <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> 층을 두 번 더 쌓는다.</p>
<p>이렇게 하면 모델의 정보 저장 능력을 키우면서 동시에 특성맵의 크기를 더 작게 만들어
<code class="docutils literal notranslate"><span class="pre">Flatten</span></code> 층에 최종적으로 <code class="docutils literal notranslate"><span class="pre">7</span> <span class="pre">x</span> <span class="pre">7</span></code> 크기의 않은 특성맵이 전달된다.
반면에 특성맵의 깊이(필터 개수)는 32에서 256으로 점차 키운다.
이렇게 층을 쌓아 합성곱 신경망을 구성하는 방식이 매우 일반적이다.</p>
<ul class="simple">
<li><p>입력층: 입력 샘플의 모양을 <code class="docutils literal notranslate"><span class="pre">(180,</span> <span class="pre">180,</span> <span class="pre">3)</span></code>으로 지정. 픽셀 크기는 임의로 지정함.
사진의 크기가 제 각각이기에 먼저 지정된 크기의 텐서로 변환을 해주는 전처리 과정이 필요함.</p></li>
<li><p>출력층: 이항분류 모델이기에 한 개의 유닛과 시그모이드 활성화 함수 사용.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Rescaling(1./255)</span></code> 층: 0에서 255 사이의 값을 0에서 1 사이의 값으로 변환하는 용도로 사용</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 입력층</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">180</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="c1"># 은닉층</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Rescaling</span><span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 출력층</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
<p>강아지와 고양이의 비율이 동일하기에 정확도를 평가지표로 사용한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="id9">
<h3><span class="section-number">8.2.4. </span>데이터 전처리와 모델 훈련<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h3>
<p><strong>데이터 전처리</strong></p>
<p>샘플 사진의 크기가 제 각각이기에 모델의 입력값으로 지정된 크기인 <code class="docutils literal notranslate"><span class="pre">(180,</span> <span class="pre">180,</span> <span class="pre">3)</span></code> 모양의
텐서로 변환해야 한다.
케라스의 <code class="docutils literal notranslate"><span class="pre">image_dataset_from_directory()</span></code> 함수를 이용하면 변환 뿐만 아니라
지정된 크기의 배치로 구성된 훈련셋, 검증셋, 테스트셋을 쉽게 생성할 수 있다.</p>
<p>예를 들어, 아래 코드는 <code class="docutils literal notranslate"><span class="pre">new_base_dir/train</span></code> 라는 디렉토리에 크기가 32인 배치들로 구성된
훈련셋을 저장한다.
각각의 배치는 <code class="docutils literal notranslate"><span class="pre">(32,</span> <span class="pre">180,</span> <span class="pre">180,</span> <span class="pre">3)</span></code> 모양의 텐서로 저장된다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">image_dataset_from_directory</span><span class="p">(</span>
    <span class="n">new_base_dir</span> <span class="o">/</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span>
    <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">180</span><span class="p">,</span> <span class="mi">180</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>모델 훈련</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> 콜백을 이용하여 검증셋에 대한 손실값(<code class="docutils literal notranslate"><span class="pre">&quot;val_loss&quot;</span></code>)을
기준으로 최고 성능의 모델을 저장한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
        <span class="n">filepath</span><span class="o">=</span><span class="s2">&quot;convnet_from_scratch.keras&quot;</span><span class="p">,</span>
        <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">)</span>
    <span class="p">]</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p>과대 적합이 10번 정도의 에포크 이후에 빠르게 발생한다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/08-09.png" style="width:800px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>훈련된 최고 성능의 모델에 대한 테스트셋에 대한 정확도가 70% 정도의 정확도로 그렇게 높지 않다.
과대적합이 매우 빠르게 발생했기 때문인데 이는 훈련셋의 크기가 2,000 정도로 너무 작기 때문이다.</p>
</section>
<section id="id10">
<h3><span class="section-number">8.2.5. </span>데이터 증식<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h3>
<p>데이터 증식 기법을 사용하여 훈련셋의 크기를 키우는 효과를 추가하면,
과대적합이 보다 늦게 발생하여 학습된 모델의 성능이 올로간다.</p>
<p>데이터 증식을 지원하는 층을 이용하면 쉽게 데이터 증식 기법을 적용할 수 있다.
아래 코드의 <code class="docutils literal notranslate"><span class="pre">data_augmentation</span></code>는 Sequential 모델을 이용하여 간단하게 구현된 데이터 증식 층을 가리킨다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">RandomFlip()</span></code>: 사진을 50%의 확률로 지정된 방향으로 회전.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RandomRotation()</span></code>: 사진을 지정된 범위 안에서 임의로 좌우로 회전</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RandomZoom()</span></code>: 사진을 지정된 범위 안에서 임의로 확대 및 축소</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data_augmentation</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span><span class="n">layers</span><span class="o">.</span><span class="n">RandomFlip</span><span class="p">(</span><span class="s2">&quot;horizontal&quot;</span><span class="p">),</span>
     <span class="n">layers</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
     <span class="n">layers</span><span class="o">.</span><span class="n">RandomZoom</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)]</span>
<span class="p">)</span>
</pre></div>
</div>
<p>훈련셋의 첫째 이미지를 대상으로 데이터 증식 층을 아홉 번 적용한 결과를
다음고 같다. 실행결과가 다를 수 있음에 주의하라.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/08-10.png" style="width:800px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>데이터 증식 층을 이용하여 모델 구성을 다시 한다.
과대적합을 최대한 방지하기 위해 출력층 바로 이전에 드롭아웃(Dropout) 층도 추가한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">180</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">data_augmentation</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Rescaling</span><span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
<p>과대 적합이 보다 늦게 발생한다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/08-11.png" style="width:800px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>테스트셋에 대한 정확도가 83% 정도로 올라간다.
<code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>와 <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> 층을 더 쌓거나 층에 사용된 필터수를 늘리는 방식으로
모델의 성능을 90% 정도까지 끌어올릴 수는 있지만 그 이상은 어려울 것이다.</p>
</section>
</section>
<section id="id11">
<h2><span class="section-number">8.3. </span>모델 재활용<a class="headerlink" href="#id11" title="Permalink to this heading">#</a></h2>
<p>적은 양의 데이터셋을 대상으로 훈련하는 것보다 대용량의 데이터셋을 이용하여 훈련하면
보다 좋은 성능의 모델을 구현할 수 있다.
하지만 대용량의 데이터를 구하기는 매우 어렵거나 아예 불가능할 수 있다.
하지만 유사한 목적으로 대용량의 훈련 데이터셋을 이용하여 사전에 훈련된 모델을 재활용하면
높은 성능의 모델을 얻을 수 있다.</p>
<p>여기서는 좋은 성능으로 잘 알려진 모델인 VGG16을 재활용하여 높은 성능의
강아지와 고양이 분류 모델을 구현하는 두 가지 방식을 소개한다.</p>
<ul class="simple">
<li><p>전이 학습<font size='2'>transfer learning</font></p></li>
<li><p>모델 미세조정<font size='2'>model fine tuning</font></p></li>
</ul>
<p><strong>VGG16 모델</strong></p>
<p>VGG16 모델은 <a class="reference external" href="https://www.image-net.org/challenges/LSVRC/2014/">ILSVRC 2014</a>
경진대회에 참여해서 2등을 차지한 모델이다.
당시 훈련에 사용된 데이터셋은 120만 장의 이미지와 1,000개의 클래스로 구성되었으며
훈련은 여러 주(weeks)에 걸쳐서 진행되었다.</p>
<div align="center"><img src="https://www.image-net.org/static_files/figures/ILSVRC2012_val_00042692.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.image-net.org/challenges/LSVRC/2014/">ILSVRC 2014</a>&gt;</div></p><p>VGG16은 당시 1등을 차지한 모델인 GoogleNet 보다 인기가 높다.
이유는 VGG16가 최상위에 위치한 몇 개의 밀집층(<code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층)을  제외한 나머지 층을
합성곱 신경망의 기본인 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>와 <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> 두 종류의 층만으로
구성해서 모델의 구조가 매우 단순하기 때문이다.
보다 자세한 소개는 <a class="reference external" href="https://brunch.co.kr/&#64;hvnpoet/126">1등보다 빛나는 2등, VGG16</a>을
참고할 수 있다.</p>
<div align="center"><img src="https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://neurohive.io/en/popular-networks/vgg16/">https://neurohive.io/en/popular-networks/vgg16/</a>&gt;</div></p><p><strong>유명 합성곱 신경망 모델</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">ketas.applications</span></code> 에 포함된 유명 합성곱 신경모델은 다음과 같다.</p>
<ul class="simple">
<li><p>VGG16</p></li>
<li><p>Xception</p></li>
<li><p>ResNet</p></li>
<li><p>MobileNet</p></li>
<li><p>EfficientNet</p></li>
<li><p>DenseNet</p></li>
<li><p>등등</p></li>
</ul>
<p><strong>이미지넷(ImagNet) 소개</strong></p>
<p><a class="reference external" href="https://www.image-net.org/index.php">이미지넷(Imagenet)</a>은
대용량의 이미지 데이터셋이며,
<a class="reference external" href="https://www.image-net.org/challenges/LSVRC/index.php">ILSVRC</a>
이미지 분류 경진대회에 사용된다.
이미지넷의 전체 데이터셋은 총 2만2천 개 정도의 클래스로 구분되는 동물, 사물 등의 객체를 담은
고화질 사진 1500만장 정도로 구성된다.
2017년까지 진행된 ILSVRC 경진대회는 보통 1000 개의 클래스로 구분되는
사물을 담은 1백만장 정도의 이미지를 이용한다.</p>
<div align="center"><img src="https://cs.stanford.edu/people/karpathy/cnnembed/cnn_embed_full_1k.jpg" style="width:100%;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://cs.stanford.edu/people/karpathy/cnnembed/">https://cs.stanford.edu/people/karpathy/cnnembed/</a>&gt;</div></p><section id="id12">
<h3><span class="section-number">8.3.1. </span>전이 학습<a class="headerlink" href="#id12" title="Permalink to this heading">#</a></h3>
<p><strong>전이 학습 기본 아이디어</strong></p>
<p>사전에 잘 훈련된 모델은 새롭게 구현하고자 하는 모델과 일반적으로 다른 목적으로 구현되었다.
하지만 예를 들어 강아지와 고양이를 포함한 동물 및 기타 여러 사물을
분류할 목적으로 훈련된 모델은 기본적으로 강아지와 고양이를
분류하는 능력을 갖고 있어야 한다.</p>
<p>반면에 이항 분류 모델과 다중클래스 분류 모델은 기본적으로 출력층에서 서로 다른
종류의 값을 출력한다.
고양이와 강아지를 포함해서 총 1000개의 사물 클래스로 이미지를 분류하는 모델의 출력층은
1000개의 유닛과 softmax 등과 같은 활성화 함수를 사용할 것이지만
고양이-강아지 분류 모델은 1개의 유닛과 sigmoid 등과 같은 활성화 함수를 사용해야 한다.</p>
<p>따라서 기존 모델의 출력층을 포함하여 분류값을 직접적으로 예측하는 마지막 몇 개의 층
(일반적으로 밀집층)을 제외시킨 나머지 합성곱 층으로 이루어진 기저(베이스, base)만을
가져와서 그 위에 원하는 목적에 맞는 층을 새롭게 구성한다(아래 그림 참조).</p>
<p>학습 관점에 보았을 때 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 합성곱층과 <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> 맥스풀링층으로 구성된 기저는
이미지의 일반적인 특성을 파악한 정보(가중치)를 포함하고 있기에
강아지/고양이 분류 모델의 기저로 사용될 수 있는 것이다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/08-12.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>VGG16 모델을 이용한 전이 학습</strong></p>
<p>VGG16 합성곱 모델에서 밀집층(dense 층)을 제외한 나머지 합성곱 층으로만 이루어진 모델을 가져온다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">conv_base</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">vgg16</span><span class="o">.</span><span class="n">VGG16</span><span class="p">(</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;imagenet&quot;</span><span class="p">,</span>
    <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">180</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
<p>모델을 가져올 때 사용된 옵션의 의미는 다음과 같다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">weights=&quot;imagenet&quot;</span></code>: Imagenet 데이터셋으로 훈련된 모델의 가중치 가져옴.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">include_top=False</span></code>: 출력값을 결정하는 밀집층은 제외함.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_shape=(180,</span> <span class="pre">180,</span> <span class="pre">3)</span></code>: 앞서 준비해 놓은 데이터셋을 활용할 수 있도록 지정함. 사용자가 직접 지정해야 함.
지정하지 않으면 임의의 크기의 이미지를 처리할 수 있음.
층 별 출력 텐서의 모양의 변화 과정을 확인하기 위해 특정 모양으로 지정함.</p></li>
</ul>
<p>가져온 모델을 요약하면 다음과 같다.
마지막 맥스풀링 층을 통과한 특성맵의 모양은 <code class="docutils literal notranslate"><span class="pre">(5,</span> <span class="pre">5,</span> <span class="pre">512)</span></code>이다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">conv_base</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="go">Model: &quot;vgg16&quot; </span>
<span class="go">_________________________________________________________________</span>
<span class="go">Layer (type)                 Output Shape              Param # </span>
<span class="go">=================================================================</span>
<span class="go">input_19 (InputLayer)        [(None, 180, 180, 3)]     0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block1_conv1 (Conv2D)        (None, 180, 180, 64)      1792 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block1_conv2 (Conv2D)        (None, 180, 180, 64)      36928 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block1_pool (MaxPooling2D)   (None, 90, 90, 64)        0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block2_conv1 (Conv2D)        (None, 90, 90, 128)       73856 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block2_conv2 (Conv2D)        (None, 90, 90, 128)       147584 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block2_pool (MaxPooling2D)   (None, 45, 45, 128)       0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block3_conv1 (Conv2D)        (None, 45, 45, 256)       295168 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block3_conv2 (Conv2D)        (None, 45, 45, 256)       590080 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block3_conv3 (Conv2D)        (None, 45, 45, 256)       590080 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block3_pool (MaxPooling2D)   (None, 22, 22, 256)       0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block4_conv1 (Conv2D)        (None, 22, 22, 512)       1180160 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block4_conv2 (Conv2D)        (None, 22, 22, 512)       2359808 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block4_conv3 (Conv2D)        (None, 22, 22, 512)       2359808 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block4_pool (MaxPooling2D)   (None, 11, 11, 512)       0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block5_conv1 (Conv2D)        (None, 11, 11, 512)       2359808 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block5_conv2 (Conv2D)        (None, 11, 11, 512)       2359808 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block5_conv3 (Conv2D)        (None, 11, 11, 512)       2359808 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block5_pool (MaxPooling2D)   (None, 5, 5, 512)         0 </span>
<span class="go">=================================================================</span>
<span class="go">Total params: 14,714,688 </span>
<span class="go">Trainable params: 14,714,688 </span>
<span class="go">Non-trainable params: 0 </span>
</pre></div>
</div>
<p><strong>특성 추출</strong></p>
<p><strong>특성 추출</strong><font size='2'>feature extraction</font>은 전이 학습에 사용되는 모델을 이용하여
데이터를 변환하는 과정을 의미한다.
여기서는 <code class="docutils literal notranslate"><span class="pre">conv_base</span></code> 기저를 특성 추출에 활용하는 두 가지 방식을 소개한다.</p>
<p><strong>1) 단순 특성 추출</strong></p>
<p>아래 <code class="docutils literal notranslate"><span class="pre">get_features_and_labels()</span></code> 함수는
<code class="docutils literal notranslate"><span class="pre">conv_base</span></code> 모델의 <code class="docutils literal notranslate"><span class="pre">predict()</span></code> 메서드를 이용하여
준비된 훈련 데이터셋을 변환,
즉 특성 추출을 실행한다.
단, 레이블은 그대로 둔다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">keras.applications.vgg16.preprocess_input()</span></code> 함수는 텐서플로우와 호환이 되도록 데이터를 전처리한다.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_features_and_labels</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="n">all_features</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_labels</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># 배치 단위로 VGG16 모델 적용</span>
    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
        <span class="n">preprocessed_images</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">vgg16</span><span class="o">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">conv_base</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">preprocessed_images</span><span class="p">)</span>
        <span class="n">all_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="n">all_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        
    <span class="c1"># 생성된 배치를 하나의 텐서로 묶어서 반환</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_features</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_labels</span><span class="p">)</span>
</pre></div>
</div>
<p>훈련셋, 검증셋, 테스트셋을 변환하면 다음과 같다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span> <span class="o">=</span>  <span class="n">get_features_and_labels</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
<span class="n">val_features</span><span class="p">,</span> <span class="n">val_labels</span> <span class="o">=</span>  <span class="n">get_features_and_labels</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span>
<span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span>  <span class="n">get_features_and_labels</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>
</pre></div>
</div>
<p>예를 들어, 변환된 강아지/고양이 이미지 샘플 2,000개는 이제 각각 <code class="docutils literal notranslate"><span class="pre">(5,</span> <span class="pre">5,</span> <span class="pre">512)</span></code> 모양을 갖는다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_features</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2000, 5, 5, 12)</span>
</pre></div>
</div>
<p>변환된 데이터셋을 훈련 데이터셋으로 사용하는
간단한 분류 모델을 구성하여 훈련만 하면 된다.
<code class="docutils literal notranslate"><span class="pre">Dropout</span></code> 층은 과대적합을 예방하기 위해 사용한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 입력층</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>

<span class="c1"># 은닉층</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 출력층</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 모델</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
<p>검증셋에 대한 정확도가 97% 정도까지 향상되지만 과대적합이 매우 빠르게 발생한다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/08-13.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>2) 데이터 증식과 특성 추출</strong></p>
<p>데이터 증식 기법을 활용하려면
VGG16 합성곱 기저(베이스)를 구성요소로 사용하는 모델을 직접 정의해야 한다.
다만 앞서 설명한 방식과는 달리 가져온 VGG16 기저에 포함된 파라미터가 새로운
모델의 훈련 과정동안 함께 훈련되지 않도록 <strong>동결</strong>(freezing)해야 한다.</p>
<ul class="simple">
<li><p>기저 동결하기: <code class="docutils literal notranslate"><span class="pre">trainable=False</span></code>로 지정.</p></li>
<li><p>입력 데이터의 모양도 미리 지정하지 않음에 주의할 것.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">conv_base</span>  <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">vgg16</span><span class="o">.</span><span class="n">VGG16</span><span class="p">(</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;imagenet&quot;</span><span class="p">,</span>
    <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 새로운 학습 금지 설정</span>
<span class="n">conv_base</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>동결 해제(<code class="docutils literal notranslate"><span class="pre">trainable=True</span></code>)로 설정하는 경우와 그렇지 않은 경우 학습되어야 하는
파라미터의 수가 달라짐을 다음처럼 확인할 수 있다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">conv_base</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;합성곱 기저의 학습을 허용하는 경우 학습 가능한 가중치 행렬 개수: &quot;</span><span class="p">,</span> 
<span class="go">          len(conv_base.trainable_weights))</span>
<span class="go">      </span>
<span class="go">합성곱 기저의 학습을 허용하는 경우 학습 가능한 파라미터 수: 26</span>
</pre></div>
</div>
<p>동결 설정(<code class="docutils literal notranslate"><span class="pre">trainable=False</span></code>)인 경우에 학습되는 파라미터 수가 0이 된다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">conv_base</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;합성곱 기저의 학습을 금지하는 경우 학습 가능한 가중치 행렬 개수: &quot;</span><span class="p">,</span> 
<span class="go">          len(conv_base.trainable_weights))</span>
<span class="go">      </span>
<span class="go">합성곱 기저의 학습을 허용하는 경우 학습 가능한 파라미터 수: 0</span>
</pre></div>
</div>
<p>아래 모델은 데이터 증식을 위한 층과 VGG16 기저를 함께 이용한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data_augmentation</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">RandomFlip</span><span class="p">(</span><span class="s2">&quot;horizontal&quot;</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">RandomZoom</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># 모델 구성</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">180</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">data_augmentation</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>                     <span class="c1"># 데이터 증식</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">vgg16</span><span class="o">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># VGG16용 전처리</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">conv_base</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>                                  <span class="c1"># VGG16 베이스</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 출력층</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
<p>이렇게 훈련하면 재활용된 합성곱 기저에 속한 층은 학습하지 않으며
두 개의 밀집층에서만 파라미터 학습이 이뤄진다.
과대적합이 보다 늦게 이루어지며 성능도 향상되었다.
테스트셋에 대한 정확도가 97.7%까지 향상된다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/08-14.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p></section>
<section id="id13">
<h3><span class="section-number">8.3.2. </span>모델 미세 조정<a class="headerlink" href="#id13" title="Permalink to this heading">#</a></h3>
<p>모델 <strong>미세 조정</strong>(파인 튜닝, fine-tuning)은 특성 추출 방식과는 달리
기존 합성곱 모델의 최상위 합성곱 층 몇 개를 동결 해제해서
새로운 모델에 맞추어 학습되도록 하는 모델 훈련기법이다.</p>
<p>여기서는 아래 그림에처럼 노락색 배경을 가진 상자 안에 포함된 합성곱 층을
동결 해제해서 함께 학습되도록 한다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/08-15.png" style="width:200px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>아래 코드는 모든 층에 대해 동결해제를 진행한 후에
마지막 4개 층을 제외한 나머지 층에 대해 다시 동결을 설정한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">conv_base</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">conv_base</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">]:</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>상위 4개 층만 동결 해제하는 이유는
합성곱 신경망의 하위층은 보다 일반적인 형태의 패턴을 학습하는 반면에
최상위층은 주어진 문제 해결에 특화된 패턴을 학습하기 때문이다.
따라서 이미지넷으로 훈련된 모델 전체를 대상으로 훈련하기 보다는
최상위층 몇 개만 훈련시키는 것이 보다 유용하다.</p>
<p>모델 컴파일과 훈련 과정은 이전과 동일하며,
정확도가 98%(<span class="math notranslate nohighlight">\(\pm\!\)</span> 1%)에 육박하는 모델을 얻게 된다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>

<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
        <span class="n">filepath</span><span class="o">=</span><span class="s2">&quot;fine_tuning.keras&quot;</span><span class="p">,</span>
        <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">)</span>
<span class="p">]</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id14">
<h2><span class="section-number">8.4. </span>연습문제<a class="headerlink" href="#id14" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://colab.research.google.com/github/codingalzi/dlp2/blob/master/excs/exc-computer_vision_intro.ipynb">(실습) 컴퓨터 비전 기초: 합성곱 신경망</a></p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="working_with_keras.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">7. </span>케라스 신경망 모델 활용법</p>
      </div>
    </a>
    <a class="right-next"
       href="computer_vision_advanced.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">9. </span>고급 컴퓨터 비전</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">8.1. 합성곱 신경망</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mnist-cnn">8.1.1. MNIST 데이터셋 분류 CNN 모델</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">8.1.2. 합성곱 연산</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">8.1.3. 맥스 풀링 연산</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">8.2. 합성곱 신경망 실전 활용 예제</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">8.2.1. 작은 데이터셋과 딥러닝 모델</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">8.2.2. 데이터 다운로드</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">8.2.3. 모델 구성</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">8.2.4. 데이터 전처리와 모델 훈련</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">8.2.5. 데이터 증식</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">8.3. 모델 재활용</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">8.3.1. 전이 학습</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">8.3.2. 모델 미세 조정</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">8.4. 연습문제</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By 코딩알지
</p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>