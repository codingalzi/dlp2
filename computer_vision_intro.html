
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>10. 컴퓨터 비전 기초: 합성곱 신경망 &#8212; Deep Learning with Python(2판)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'computer_vision_intro';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="11. 고급 컴퓨터 비전" href="computer_vision_advanced.html" />
    <link rel="prev" title="9. 케라스 신경망 모델 활용법" href="working_with_keras.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Deep Learning with Python(2판)</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="what_is_deep_learning.html">1. 딥러닝 소개</a></li>
<li class="toctree-l1"><a class="reference internal" href="building_blocks_of_NN.html">2. 신경망 기본 구성 요소</a></li>
<li class="toctree-l1"><a class="reference internal" href="tf_tensor.html">3. 텐서</a></li>
<li class="toctree-l1"><a class="reference internal" href="training_loop_from_scratch.html">4. 훈련 루프 상세</a></li>
<li class="toctree-l1"><a class="reference internal" href="keras_and_tf.html">5. 케라스와 텐서플로우</a></li>
<li class="toctree-l1"><a class="reference internal" href="classification_regression.html">6. 분류와 회귀</a></li>
<li class="toctree-l1"><a class="reference internal" href="fundamentals_of_ml.html">7. 머신러닝 모델 훈련 기법</a></li>
<li class="toctree-l1"><a class="reference internal" href="unversal_workflow_of_ml.html">8. 머신러닝 작업 흐름 일반</a></li>
<li class="toctree-l1"><a class="reference internal" href="working_with_keras.html">9. 케라스 신경망 모델 활용법</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">10. 컴퓨터 비전 기초: 합성곱 신경망</a></li>
<li class="toctree-l1"><a class="reference internal" href="computer_vision_advanced.html">11. 고급 컴퓨터 비전</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl_for_timeseries.html">12. 시계열 분석</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl_for_text.html">13. 자연어 처리</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative_dl.html">14. 생성 모델</a></li>
<li class="toctree-l1"><a class="reference internal" href="best_practices.html">15. 딥러닝 실전 적용</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/codingalzi/dlp2" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/codingalzi/dlp2/issues/new?title=Issue%20on%20page%20%2Fcomputer_vision_intro.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/computer_vision_intro.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>컴퓨터 비전 기초: 합성곱 신경망</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">10.1. 합성곱 신경망</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mnist-cnn">10.1.1. MNIST 데이터셋 분류 CNN 모델</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">10.1.2. 합성곱 연산</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">10.1.3. 맥스 풀링</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">10.2. 합성곱 신경망 실전 활용 예제</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">10.2.1. 작은 데이터셋과 딥러닝 모델</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">10.2.2. 데이터 다운로드</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">10.2.3. 모델 구성</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">10.2.4. 데이터 전처리와 모델 훈련</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">10.2.5. 데이터 증식</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">10.3. 모델 재활용</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">10.3.1. 전이 학습</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">10.3.2. 모델 미세 조정</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">10.4. 연습문제</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ch-computer-vision-intro">
<span id="id1"></span><h1><span class="section-number">10. </span>컴퓨터 비전 기초: 합성곱 신경망<a class="headerlink" href="#ch-computer-vision-intro" title="Link to this heading">#</a></h1>
<p><strong>감사의 글</strong></p>
<p>아래 내용은 프랑소와 숄레의
<a class="reference external" href="https://github.com/fchollet/deep-learning-with-python-notebooks">Deep Learning with Python(2판)</a>의
소스코드 내용을 참고해서 작성되었습니다.
자료를 공개한 저자에게 진심어린 감사를 전합니다.</p>
<p><strong>소스코드</strong></p>
<p>여기서 언급되는 코드를
<a class="reference external" href="https://colab.research.google.com/github/codingalzi/dlp2/blob/master/notebooks/NB-computer_vision_intro.ipynb">(구글 코랩) 컴퓨터 비전 기초: 합성곱 신경망</a>에서
직접 실행할 수 있다.</p>
<p><strong>슬라이드</strong></p>
<p>본문 내용을 요약한 <a class="reference external" href="https://github.com/codingalzi/dlp2/raw/master/slides/slides-computer_vision_intro.pdf">슬라이드</a>를 다운로드할 수 있다.</p>
<p><strong>주요 내용</strong></p>
<ul class="simple">
<li><p>합성곱 신경망</p></li>
<li><p>데이터 증식</p></li>
<li><p>모델 재활용: 전이학습</p></li>
</ul>
<section id="id2">
<h2><span class="section-number">10.1. </span>합성곱 신경망<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>2011년부터 2015년 사이에
컴퓨터 비전 분야에서 딥러닝 기법이 획기적으로 발전하였다.
그 결과 지금은 사진 검색, 자율주행, 로봇공학, 의학 진단 프로그램,
얼굴 인식 등 일상의 많은 영역에서 딥러닝 모델이 사용되고 있다.</p>
<p>컴퓨터 비전 분야에서 일반적으로 가장 많이 사용되는 딥러닝 모델은
<strong>CNN</strong> 또는 <strong>convnet</strong>으로 불리는
<strong>합성곱 신경망</strong><font size='2'>convolutional neural networks</font>이다.
여기서는 이미지 분류 문제에 CNN을 적용하는 방법을 소개한다.</p>
<section id="mnist-cnn">
<h3><span class="section-number">10.1.1. </span>MNIST 데이터셋 분류 CNN 모델<a class="headerlink" href="#mnist-cnn" title="Link to this heading">#</a></h3>
<p>아래 층들을 이용하여 모델을 함수형 API 방식으로 선언한다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Input()</span></code>: 입력층</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">shape=(28,</span> <span class="pre">28,</span> <span class="pre">1)</span></code>. 훈련 샘플의 모양 지정.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">28x28</span></code> 픽셀 크기의 흑백 손글씨 사진</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>: 합성곱 층</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">filters</span></code>: 필터 수 지정. 층 출력값의 채널 수로 사용됨. 하나의 필터를 이용해 하나의 채널 생성.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernel_size</span></code>: 합성곱 연산에 사용되는 커널의 크기. 일반적으로 3 사용.</p></li>
<li><p>출력값: 3D 텐서 (높이, 너비, 채널수).</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code>: 맥스풀링 층</p>
<ul>
<li><p>입력 사진의 높이와 너비를 지정된 비율만큼 축소. 즉 사진 크기 축소.</p></li>
<li><p>출력값: 3D 텐서 (높이, 너비, 채널수).</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">Dense</span></code>: 밀집 층</p>
<ul>
<li><p>CNN 모델의 출력층은 일반적으로 밀집층 사용</p></li>
<li><p>입력값: <code class="docutils literal notranslate"><span class="pre">Flatten()</span></code> 층을 통과해서 <code class="docutils literal notranslate"><span class="pre">(None,</span> <span class="pre">N)</span></code> 모양의 2차원 텐서</p></li>
</ul>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 입력층</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># 은닉층</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 출력층으로 넘기기 전에 1차원 텐서로 변환</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 출력층</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 모델</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>모델 구성 요약</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> 층과 <code class="docutils literal notranslate"><span class="pre">Flatten</span></code> 층엔 파라미터가 전혀 사용되지 않는다.
왜 그런지를 포함해서 각 층별로 출력값의 모양과 사용되는 파라미터의 수에 대해
나중에 자세히 다룬다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="go">Model: &quot;model&quot; </span>
<span class="go">_________________________________________________________________</span>
<span class="go">Layer (type)                 Output Shape              Param # </span>
<span class="go">================================================================= </span>
<span class="go">input_1 (InputLayer)         [(None, 28, 28, 1)]       0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">conv2d (Conv2D)              (None, 26, 26, 32)        320 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">flatten (Flatten)            (None, 1152)              0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">dense (Dense)                (None, 10)                11530 </span>
<span class="go">=================================================================</span>
<span class="go">Total params: 104,202 </span>
<span class="go">Trainable params: 104,202 </span>
<span class="go">Non-trainable params: 0 </span>
</pre></div>
</div>
<p><strong>MNIST 이미지 분류 훈련</strong></p>
<p>모델 훈련은 이전과 동일하다.
다만 훈련 샘플은 <code class="docutils literal notranslate"><span class="pre">(28,</span> <span class="pre">28,</span> <span class="pre">1)</span></code> 모양의 3차원 텐서이어야 한다.
이유는 합성곱 층(<code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>)이 3차원 텐서를 입력값으로 받기 때문이며,
따라서 <code class="docutils literal notranslate"><span class="pre">Input()</span></code> 함수의 인자로 <code class="docutils literal notranslate"><span class="pre">(28,</span> <span class="pre">28,</span> <span class="pre">1)</span></code> 모양이 지정되었다.</p>
<p>지금까지 입력층으로 사용한 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층은 입력 샘플의 모양이 1차원 텐서, 즉 벡터이어야 했고,
따라서 MNIST 데이터셋의 샘플들을 모두
1차원 텐서로 변형한 다음에 훈련셋으로 활용하였다.
하지만 여기서는 3차원 텐서 이미지를
모양을 변형시키는 전처리 없이 바로 사용한다.
단, 항목의 값을 0과 1사이의 값을 갖는 부동소수점으로 변환한다.</p>
<ul class="simple">
<li><p>훈련셋 준비</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>

<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
</pre></div>
</div>
<ul class="simple">
<li><p>모델 컴파일과 훈련</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>  <span class="c1"># 레이블이 정수인 경우</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>
</div>
<p>테스트셋에 대한 정확도가 99% 정도로 이전에 사용한 <code class="docutils literal notranslate"><span class="pre">Sequential</span></code> 모델보다 훨씬 좋다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;테스트 정확도: </span><span class="si">{</span><span class="n">test_acc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">313/313 [==============================] - 2s 4ms/step - loss: 0.0395 - accuracy: 0.9893</span>
<span class="go">테스트 정확도: 0.989</span>
</pre></div>
</div>
</section>
<section id="id3">
<h3><span class="section-number">10.1.2. </span>합성곱 연산<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p>합성곱 층(<code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>)에서 입력값을 변환하는 과정은 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층에서의 변환과 다르다.
차이점의 핵심은 아핀 변환을 적용하는 방식에 있다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층: 입력값의 전체 특성을 대상으로 한 번의 아핀 변환 적용</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층: <code class="docutils literal notranslate"><span class="pre">kernel_size</span></code>로 지정된 크기의 공간에 대해 여러 개의 아핀 변환 적용.
예를 들어, <code class="docutils literal notranslate"><span class="pre">kernel_size=3</span></code>인 경우 <code class="docutils literal notranslate"><span class="pre">3x3</span></code> 크기의 영역에 대해 아핀 변환 적용.</p></li>
</ul>
<p>직관적으로 풀어서 말하면 다음과 같다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층: 입력값 전체를 대상으로 지정된 개수의 좋은 특성으로 구성된 텐서로 데이터 변환을 진행한다.
예를 들어, <code class="docutils literal notranslate"><span class="pre">Dense(64,</span> <span class="pre">activation=&quot;relu&quot;)</span></code>에 MNIST 데이터셋을 입력하면
흑백 손글씨 이미지 각각에 대해 784개 특성을 아핀 변환하여 64개의 좋은 특성을 생성한다.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층: 예를 들어 <code class="docutils literal notranslate"><span class="pre">kernel_size=3</span></code>으로 설정된 경우 <code class="docutils literal notranslate"><span class="pre">3x3</span></code> 크기의 영역에 대해 국소적 패턴을 찾아낸다.
그리고 그런 국소적 패턴들을 종합하여 모델 예측에 도움되는 데이터로 변환한다.</p></li>
</ul>
<p><strong>합성곱 층의 특징</strong></p>
<p>합성곱 층의 특징은 크게 다음 두 가지로 요약된다.</p>
<p>첫째, 위치와 무관하게 패턴을 찾아낸다.
즉, 서로 다른 위치에 있는 동일한 패턴은 동일한 방식으로 인식된다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/local_patterns.jpg" style="width:400px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>둘째, <code class="docutils literal notranslate"><span class="pre">Con2D</span></code> 층 여러 개를 연속적으로 통과시키면  패턴 공간의 계층을 파악할 수 있다.
<strong>패턴 공간의 계층</strong><font size='2'>spatial hierarchy of patterns</font>은
아래 층에서는 단순한 패턴을 인식하고, 위 층으로 진행할 수록 이미지에 포함된 보다 복잡한 패턴을 파악하는 것을 가리킨다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/visual_hierarchy_hires.png" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>특성맵(채널), 필터, 출력맵</strong></p>
<p>합성곱 연산의 작동법을 이해하려면 아래 세 개념을 이해해야 한다.</p>
<ul class="simple">
<li><p><strong>특성맵</strong><font size='2'>feature map</font> 또는 <strong>채널</strong><font size='2'>channel</font>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">(높이,</span> <span class="pre">너비)</span></code> 모양의 2D 텐서.</p></li>
<li><p>예제: MNIST 데이터셋에 포함된 흑백 이미지 샘플의 경우 <code class="docutils literal notranslate"><span class="pre">(28,</span> <span class="pre">28)</span></code> 모양의 채널(특성맵) 한 개로 구성됨.</p></li>
<li><p>예제: 컬러사진의 경우 세 개의 채널(특성맵)로 구성됨.</p></li>
<li><p>이미지에 포함된 채널(특성맵)의 수를 <strong>깊이</strong>라 부름.</p></li>
</ul>
</li>
<li><p><strong>필터</strong><font size='2'>filter</font>: <code class="docutils literal notranslate"><span class="pre">kernel_size</span></code>를 이용한 3D 텐서.</p>
<ul>
<li><p>예제: <code class="docutils literal notranslate"><span class="pre">kernel_size=3</span></code>인 경우 필터는 <code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">3,</span> <span class="pre">입력샘플의깊이)</span></code> 모양의 3D 텐서.</p></li>
<li><p>필터 수: <code class="docutils literal notranslate"><span class="pre">filters</span></code> 인자에 의해 결정됨.</p></li>
</ul>
</li>
<li><p><strong>출력맵</strong><font size='2'>response map</font>:
입력 샘플을 대상으로 하나의 필터를 적용해서 생성된 하나의 특성맵(채널).
필터 수만큼의 출력맵 생성.</p></li>
</ul>
<div class="info admonition">
<p class="admonition-title">컬러 이미지와 채널</p>
<p>컬러 이미지는 R(red), G(green), B(blue) 세 개의 채털로 구성된다.
각각의 채널은 2차원 어레이로 다뤄지기에 하나의 컬러 이미지는 세 개의 채널을 모은 3차원 어레이로 표현된다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-reign_pic_breakdown.png" style="width:700px;"></div>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-three_d_array-a.jpg" style="width:600px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://e2eml.school/convert_rgb_to_grayscale.html">How to Convert an RGB Image to Grayscale</a>&gt;</div></p>
</div>
<p><strong>필터 적용</strong></p>
<p>아래 그림은 필터의 모양과 동일한 크기의 국소 텐서 하나를 대상으로 하나의 필터를 적용하여 하나의 값을
생성하는 과정을 보여준다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-filter-product-1c.jpg" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.oreilly.com/library/view/fundamentals-of-deep/9781492082170/">Fundamentals of Deep Learning(2판)</a>&gt;</div></p><p><strong>출력맵</strong></p>
<p>하나의 필터를 슬라이딩 시키면서 입력 텐서 전체를 대상으로 위 과정을 적용하여 한 개의 출력맵을
생성한다.
아래 그림은 (5, 5, 1) 모양의 입력 텐서를 대상으로
(3, 3, 1) 모양의 필터 하나를 적용하여 (3, 3, 1) 모양의 출력맵을 생성하는 과정을 보여준다.
단, 편향은 0이라고 가정한다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-convSobel-2a.gif" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://mlnotebook.github.io/post/CNN1/">Machine Learning Notebook: CNN - Basics</a>&gt;</div></p><p>예를 들어 출력맵의 맨 상단 왼쪽에 위치한 155가 계산되는 과정은 다음과 같으며
이와 같은 방식으로 파랑색으로 표시된 높이와 너비 각각 3인 2차원 텐서 항목의 값들이 정해진다.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">0</span> <span class="o">*</span> <span class="o">-</span><span class="mi">1</span>  <span class="o">+</span> <span class="mi">0</span>  <span class="o">*</span> <span class="o">-</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">75</span> <span class="o">*</span> <span class="o">-</span><span class="mi">1</span> <span class="o">+</span>
<span class="mi">0</span> <span class="o">*</span>  <span class="mi">0</span>  <span class="o">+</span> <span class="mi">75</span> <span class="o">*</span>  <span class="mi">0</span> <span class="o">+</span> <span class="mi">80</span> <span class="o">*</span>  <span class="mi">0</span> <span class="o">+</span>
<span class="mi">0</span> <span class="o">*</span>  <span class="mi">1</span>  <span class="o">+</span> <span class="mi">75</span> <span class="o">*</span>  <span class="mi">2</span> <span class="o">+</span> <span class="mi">80</span> <span class="o">*</span>  <span class="mi">1</span> <span class="o">+</span>
<span class="mi">0</span>
<span class="o">=</span> <span class="mi">155</span>
</pre></div>
</div>
<p><strong>필터와 출력맵</strong></p>
<p>출력 텐서의 채널 수, 즉 출력맵의 개수는 사용되는 필터의 개수와 동일하다.
예를 들어 아래 그림은 6개의 필터를 적용하면 최종적으로 6개의 출력맵(채널)으로 구성된 출력 텐서가 생성된다.</p>
<ul class="simple">
<li><p>입력 텐서: (10, 8, 3) 모양의 텐서</p></li>
<li><p>필터: (3, 3, 3) 모양의 텐서</p>
<ul>
<li><p>커널 크기(<code class="docutils literal notranslate"><span class="pre">kernel_size</span></code>): 3</p></li>
<li><p>입력 텐서의 깊이: 3</p></li>
</ul>
</li>
<li><p>출력 텐서: (8, 6, 6) 모양의 텐서</p>
<ul>
<li><p>필터 수가 6이기에 출력 텐서의 깊이가 6이 됨.</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-filter-product-2a.jpg" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.oreilly.com/library/view/fundamentals-of-deep/9781492082170/">Fundamentals of Deep Learning(2판)</a>&gt;</div></p><p><strong>합성곱 층 연속 적용</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층을 통과할 때 마다 동일한 작업이 반복된다.
앞서 패턴 공간의 계층에서 설명했듯이
위쪽의 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층을 통과할 수록 보다 복잡한 구조의 패턴을 알아낸다.</p>
<ul class="simple">
<li><p>입력 샘플: 3개의 채털로 구성된 칼라 사진</p></li>
<li><p>첫째 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층: 필터 12개</p></li>
<li><p>둘째 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층: 필터 7개</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-cnn-layers-a.jpg" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.hanbit.co.kr/store/books/look.php?p_code=B7033438574">핸즈온 머신러닝(2판)</a>&gt;</div></p><p><strong>합성곱 신경망 모델</strong></p>
<p>합성곱 신경망 모델은 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층에서 필터로 사용되는 텐서들을 학습시킨다.
앞서 설명한 대로 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층의 아핀 변환에 필요한 가중치와 편향 벡터와는 다르게
각각의 필터는 국소적으로 아핀 변환을 적용한다.</p>
<p><strong>패딩과 보폭</strong></p>
<p>필터를 적용하여 생성된 출력 특성맵의 모양이 입력 특성맵(채널)의 모양과 다를 수 있다.
다만 출력값의 채널 수는 필터의 개수와 동일하다.
이유는 하나의 필터가 하나의 특성맵(채널)을 생성하기 때문이다.
출력 특성맵의 높이와 너비는
<strong>패딩</strong><font size='2'>padding</font>의 사용 여부와
<strong>보폭</strong><font size='2'>stride</font>의 크기에 의에 결정된다.</p>
<p>다음 세 개의 그림은 입력 특성맵의 높이와 너비가 <code class="docutils literal notranslate"><span class="pre">5x5</span></code>일 때
패딩의 사용 여부와 보폭의 크기에 따라
출력 특성맵의 높이와 너비가 어떻게 달라지는가를 보여준다.</p>
<ul class="simple">
<li><p>경우 1: 패딩 없음, 보폭은 1.</p>
<ul>
<li><p>필터가 1칸씩 슬라이딩</p></li>
<li><p>출력 특성맵의 깊이와 너비: <code class="docutils literal notranslate"><span class="pre">3x3</span></code></p></li>
<li><p>출력 특성맥의 깊이와 너비가 줄어듦.</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-padding-stride-01.png" style="width:400px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.analyticsvidhya.com/blog/2022/03/basics-of-cnn-in-deep-learning/">Basics of CNN in Deep Learning</a>&gt;</div></p><ul class="simple">
<li><p>경우 2: 패딩 없음, 보폭은 2.</p>
<ul>
<li><p>필터가 2칸씩 건너 뛰며 슬라이딩</p></li>
<li><p>출력 특성맵의 깊이와 너비: <code class="docutils literal notranslate"><span class="pre">2x2</span></code></p></li>
<li><p>출력 특성맵의 깊이와 너비가 보폭의 반비례해서 줄어듦.</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-padding-stride-02.png" style="width:350px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.analyticsvidhya.com/blog/2022/03/basics-of-cnn-in-deep-learning/">Basics of CNN in Deep Learning</a>&gt;</div></p><ul class="simple">
<li><p>경우 3: 패딩 있음, 보폭은 1.</p>
<ul>
<li><p>입력 텐서의 테두리에 0으로 채워진 패딩 추가.</p></li>
<li><p>출력 특성맵의 깊이와 너비가 동일하게 유지됨.</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-cnn-padding.png" style="width:900px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.researchgate.net/figure/Figure-B2-A-convolutional-filter-with-padding-stride-one-and-filter-size-of-3x3-Image_fig30_324783775">Text to Image Synthesis Using Generative Adversarial Networks</a>&gt;</div></p><ul class="simple">
<li><p>경우 4: 패딩을 사용하고 보폭이 1보다 큰 경우는 굳이 사용할 필요 없음.
이유는 보폭이 1보다 크기에 출력 특성맵의 깊이와 너비가 어차피 보폭에 반비례해서 줄어들기 때문임.</p></li>
</ul>
</section>
<section id="id4">
<h3><span class="section-number">10.1.3. </span>맥스 풀링<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<p>합성곱 신경망의 전형적인 구조는 아래 그림에서처럼 합성곱 층과 풀링 층을 번갈아 가며 사용한다.</p>
<div align="center"><img src="http://formal.hknu.ac.kr/handson-ml2/slides/images/ch14/homl14-03.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.hanbit.co.kr/store/books/look.php?p_code=B7033438574">핸즈온 머신러닝(2판)</a>&gt;</div></p><p><strong>맥스 풀링 기능</strong></p>
<p>풀링 층은 일정 크기의 영역에서 하나의 값만 선택하여 특성맵의 높이와 너비를 일정 비율로 줄인다.
일정 영역에서 최댓값을 선택하는 <strong>맥스 풀링</strong>(max-pooling) 층이 가장 많이 사용된다.
예를 들어 아래 그림은 <code class="docutils literal notranslate"><span class="pre">2x2</span></code>영역에서 최댓값만 선택하는 과정을
보폭 2만큼씩 이동하며 반복한 결과를 보여준다.
결과적으로 입력 사진의 높이와 너비를 각각 1/2씩 줄인 사진이 생성된다.</p>
<div align="center"><img src="http://formal.hknu.ac.kr/handson-ml2/slides/images/ch14/homl14-10.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.hanbit.co.kr/store/books/look.php?p_code=B7033438574">핸즈온 머신러닝(2판)</a>&gt;</div></p><p>맥스 풀링은 입력 샘플의 채녈 단위로 적용된다.
따라서 사진의 가로, 세로 사이즈는 줄어들지만 채널 수는 그대로 유지한다.
예를 들어, 만약 <code class="docutils literal notranslate"><span class="pre">x</span></code>가 <code class="docutils literal notranslate"><span class="pre">(26,</span> <span class="pre">26,</span> <span class="pre">32)</span></code> 모양의 3D 텐서이면
다음 맥스 풀링 층의 출력값은 <code class="docutils literal notranslate"><span class="pre">(13,</span> <span class="pre">13,</span> <span class="pre">32)</span></code> 모양의 3D 텐서가 된다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>맥스 풀링 사용 이유</strong></p>
<p>맥스 풀링 층을 합성곱 층(<code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>)과 함께 사용하는 이유는 두 가지이다.</p>
<ul class="simple">
<li><p>모델이 훈련 중에 학습해야할 파라미터(가중치와 편향)의 수를 줄인다.</p>
<ul>
<li><p>합성곱 층 자체에서 사용되는 파라미터의 수는 맥스 풀링 층에 줄어들지 않는다.</p></li>
<li><p>반면에 합성곱 층에 이어서 사용되는 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층의 입력값에 갖는 특성 수가 획기적으로 줄어든다.</p></li>
</ul>
</li>
<li><p>상위 합성곱 층으로 이동 수록 입력 데이터의 보다 넓은 영역에 대한 정보를 얻을 수 있다.
따라서 모델이 위치와 무관한 패턴을 학습할 수 있다.</p></li>
</ul>
<p>아래 코드는 맥스 풀링 층을 사용하지 않는 경우 가중치 파라미터의 수가 엄청나게 증가함을 잘 보여준다.</p>
<ul class="simple">
<li><p>맥스 풀링 사용하는 경우: 104,202개</p></li>
<li><p>그렇지 않은 경우: 712,202개</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model_no_max_pool</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model_no_max_pool</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="go">Model: &quot;model_1&quot; </span>
<span class="go">_________________________________________________________________</span>
<span class="go">Layer (type)                 Output Shape              Param # </span>
<span class="go">=================================================================</span>
<span class="go">input_2 (InputLayer)         [(None, 28, 28, 1)]       0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">conv2d_3 (Conv2D)            (None, 26, 26, 32)        320 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">conv2d_5 (Conv2D)            (None, 22, 22, 128)       73856 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">flatten_1 (Flatten)          (None, 61952)             0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">dense_1 (Dense)              (None, 10)                619530 </span>
<span class="go">=================================================================</span>
<span class="go">Total params: 712,202 </span>
<span class="go">Trainable params: 712,202 </span>
<span class="go">Non-trainable params: 0 </span>
</pre></div>
</div>
</section>
</section>
<section id="id5">
<h2><span class="section-number">10.2. </span>합성곱 신경망 실전 활용 예제<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<section id="id6">
<h3><span class="section-number">10.2.1. </span>작은 데이터셋과 딥러닝 모델<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<p>이미지 분류 모델을 훈련시킬 때 데이터셋의 크기가 그다지 크지 않은 경우가 일반적이다.
즉, 데이터셋의 크기가 적게는 몇 백 개에서 많게는 몇 만 개 정도이다.
여기서 훈련시켜야 하는 모델은 개와 고양이 사진을 대상으로 하는 이진 분류 합성곱 신경망 모델이다.
실전 상황을 재현하기 위해 5천 개의 이미지로 이루어진 작은 데이터셋을 사용한다.</p>
<p>합성곱 신경망 모델은 작은 크기의 데이터셋으로도 어느 정도의 성능을 얻을 수 있다.
또한 데이터 증식 기법을 이용하여 훈련셋의 크기를 늘리거나 기존에 잘 훈련된 모델을 재활용하면
보다 높은 성능의 모델을 구현할 수 있다.</p>
</section>
<section id="id7">
<h3><span class="section-number">10.2.2. </span>데이터 다운로드<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<p>다양한 종류의 데이터 모델을 활용할 수 있는
<a class="reference external" href="https://www.kaggle.com">캐글<font size='2'>Kaggle</font></a>에서
훈련에 필요한 데이터셋을 다운로드하려면 다음 사항을 먼저 확인해야 한다.</p>
<ul class="simple">
<li><p>캐글 계정을 갖고 있어야 하며, 로그인된 상태에서 아래 두 과정을 먼저 해결해야 한다.</p></li>
<li><p>캐글에 로그인한 후 “Account” 페이지의 계정 설정 창에 있는 “API” 항목에서
“Create New API Token”을 생성하여 다운로드한다.</p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/c/dogs-vs-cats/rules">캐글: Dogs vs. Cats</a>를
방문해서 “I Understand and Accept” 버튼을 클릭해야 한다.</p></li>
</ul>
<p>다운로드된 데이터셋은 총 25,000장의 강아지와 고양이 사진으로 구성되었으며 570MB 정도로 꽤 크다.
강아지 사진 고양이 사진이 각각 12,500 장씩 포함되어 있으며, 사진들의 크기가 다음과 같이 일정하지 않다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/dog_and_cat_samples.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>훈련셋, 검증셋, 테스트셋 준비</strong></p>
<p>25,000 장의 사진 중에서 총 5,000 장의 사진만 사용해서 합성곱 신경망 모델을 훈련시키려 한다.</p>
<ul class="simple">
<li><p>훈련셋: 강아지와 고양이 각각 1,000 장</p></li>
<li><p>검증셋: 강아지와 고양이 각각 500 장</p></li>
<li><p>테스트셋: 강아지와 고양이 각각 1,000 장</p></li>
</ul>
<p>여기서는 5,000 장의 사진이 현재 디렉토리를 기준으로
다음과 같이 구성된 하위 디렉토리에 저장되어 있다고 가정한다.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cats_vs_dogs_small</span><span class="o">/</span>
<span class="o">...</span><span class="n">train</span><span class="o">/</span>
<span class="o">......</span><span class="n">cat</span><span class="o">/</span>
<span class="o">......</span><span class="n">dog</span><span class="o">/</span>
<span class="o">...</span><span class="n">validation</span><span class="o">/</span>
<span class="o">......</span><span class="n">cat</span><span class="o">/</span>
<span class="o">......</span><span class="n">dog</span><span class="o">/</span>
<span class="o">...</span><span class="n">test</span><span class="o">/</span>
<span class="o">......</span><span class="n">cat</span><span class="o">/</span>
<span class="o">......</span><span class="n">dog</span><span class="o">/</span>
</pre></div>
</div>
</section>
<section id="id8">
<h3><span class="section-number">10.2.3. </span>모델 구성<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<p>CNN 모델은 앞서 설명한대로 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>와 <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> 레이어를
연속에서 쌓는 방식을 사용한다.
앞서 소개한 모델 보다 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층과 <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> 층을 두 번 더 쌓는다.
이유는 보다 큰 이미지를 훈련 데이터로 사용하면서
동시에 보다 복잡한 문제를 해결해야 하기 때문이다.
합성곱 층과 맥스 풀링 층을 더 많이 쌓으면
모델의 정보 저장 능력을 키우면서 동시에 최종 맥스 풀링 층의 출력맵의 크기를 더 작게 만든다.</p>
<p><strong>모델 지정</strong></p>
<p>아래 모델의 경우
<code class="docutils literal notranslate"><span class="pre">Flatten</span></code> 층에 최종적으로 <code class="docutils literal notranslate"><span class="pre">7</span> <span class="pre">x</span> <span class="pre">7</span></code> 크기의 않은 특성맵으로 구성된 입력값이 전달되며,
특성맵 수는 32에서 256으로 점차 키워진다.
많은 합성곱 신경망이 이런 식으로 구성된다.</p>
<ul class="simple">
<li><p>입력층: 입력 샘플의 모양을 <code class="docutils literal notranslate"><span class="pre">(180,</span> <span class="pre">180,</span> <span class="pre">3)</span></code>으로 지정. 가로, 세로 픽셀 크기는 임의로 지정됨.
사진의 크기가 제 각각이기에 먼저 지정된 크기의 텐서로 변환을 해주는 전처리 과정이 필요함.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Rescaling(1./255)</span></code> 층: 0에서 255 사이의 값을 0에서 1 사이의 값으로 변환하는 용도로 사용</p></li>
<li><p>출력층: 이항 분류 모델이기에 한 개의 유닛과 시그모이드 활성화 함수 사용.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 입력층</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">180</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="c1"># 은닉층</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Rescaling</span><span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 출력층</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>모델 컴파일</strong></p>
<p>이진 분류 모델이기에 손실 함수는 <code class="docutils literal notranslate"><span class="pre">binary_crossentropy</span></code>로 정한다.
분류 모델의 평가지표는 일반적으로 정확도, 정밀도, 재현율 중에 하나를 선택한다.
훈련 데이터셋에 포함된 강아지와 고양이의 비율이 동일하게 지정되기에
여기서는 정확도를 평가지표로 사용한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="id9">
<h3><span class="section-number">10.2.4. </span>데이터 전처리와 모델 훈련<a class="headerlink" href="#id9" title="Link to this heading">#</a></h3>
<p><strong>데이터 불러오기와 전처리</strong></p>
<p>강아지-고양이 데이터셋에 포함된 사진들의 크기가 제 각각이기에
모든 입력 사진을 <code class="docutils literal notranslate"><span class="pre">(180,</span> <span class="pre">180,</span> <span class="pre">3)</span></code> 모양의 텐서로 변환하는
케라스의 <code class="docutils literal notranslate"><span class="pre">image_dataset_from_directory()</span></code> 함수를 이용하면 데이터 변환뿐만 아니라
지정된 크기의 배치로 구성된 훈련셋, 검증셋, 테스트셋을 쉽게 생성할 수 있다.</p>
<p>아래 코드는 <code class="docutils literal notranslate"><span class="pre">cats_vs_dogs_small</span></code>의 하위 디렉토리인 <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">validation</span></code>, <code class="docutils literal notranslate"><span class="pre">test</span></code> 디렉토리에 포함된
사진들을 무작위로 섞어 크기가 32인 배치들로 구성된
훈련셋, 검증셋, 테스트셋을 지정한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">image_dataset_from_directory</span>

<span class="n">new_base_dir</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="s2">&quot;cats_vs_dogs_small&quot;</span><span class="p">)</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">image_dataset_from_directory</span><span class="p">(</span>
    <span class="n">new_base_dir</span> <span class="o">/</span> <span class="s2">&quot;train&quot;</span><span class="p">,</span>
    <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">180</span><span class="p">,</span> <span class="mi">180</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">image_dataset_from_directory</span><span class="p">(</span>
    <span class="n">new_base_dir</span> <span class="o">/</span> <span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">180</span><span class="p">,</span> <span class="mi">180</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">image_dataset_from_directory</span><span class="p">(</span>
    <span class="n">new_base_dir</span> <span class="o">/</span> <span class="s2">&quot;test&quot;</span><span class="p">,</span>
    <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">180</span><span class="p">,</span> <span class="mi">180</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
<p>예를 들어 <code class="docutils literal notranslate"><span class="pre">train_dataset</span></code>에 포함된 각각의 배치는 <code class="docutils literal notranslate"><span class="pre">(32,</span> <span class="pre">180,</span> <span class="pre">180,</span> <span class="pre">3)</span></code> 모양의 4차원 입력 텐서와
<code class="docutils literal notranslate"><span class="pre">(32,)</span></code> 모양의 1차원 타깃으로 구성된다.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">data_batch</span><span class="p">,</span> <span class="n">labels_batch</span> <span class="ow">in</span> <span class="n">train_dataset</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;data batch shape:&quot;</span><span class="p">,</span> <span class="n">data_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;labels batch shape:&quot;</span><span class="p">,</span> <span class="n">labels_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">break</span>

<span class="go">data batch shape: (32, 180, 180, 3)</span>
<span class="go">labels batch shape: (32,)</span>
</pre></div>
</div>
<p><strong>모델 훈련</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> 콜백을 이용하여 검증셋에 대한 손실값(<code class="docutils literal notranslate"><span class="pre">&quot;val_loss&quot;</span></code>)을
기준으로 최고 성능의 모델을 저장한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
        <span class="n">filepath</span><span class="o">=</span><span class="s2">&quot;convnet_from_scratch&quot;</span><span class="p">,</span>
        <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">)</span>
    <span class="p">]</span>
</pre></div>
</div>
<p>크기가 32인 배치 단위로 이미 묶여 있기에 <code class="docutils literal notranslate"><span class="pre">fit()</span></code> 메서드를 호출할 때 배치 크기(<code class="docutils literal notranslate"><span class="pre">batch_size</span></code>)는 지정할 필요가 없다.
즉, 텐서플로우가 배치 단위의 입력 데이터셋을 처리할 수 있다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p>과대 적합이 10번 정도의 에포크 이후에 빠르게 발생한다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/08-09.png" style="width:800px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>훈련된 최고 성능의 모델에 대한 테스트셋에 대한 정확도가 70% 정도의 정확도로 그렇게 높지 않다.
과대적합이 매우 빠르게 발생했기 때문인데 이는 훈련셋의 크기가 2,000 정도로 매우 작기 때문이다.</p>
</section>
<section id="id10">
<h3><span class="section-number">10.2.5. </span>데이터 증식<a class="headerlink" href="#id10" title="Link to this heading">#</a></h3>
<p>데이터 증식 기법을 사용하여 훈련셋의 크기를 키우는 효과를 추가하면,
과대적합이 보다 늦게 발생하여 모델의 일반화 성능이 올라간다.
참고로 데이터 증식은 새로운 훈련셋을 추가하는 것이 아니다.
대신 그런 효과를 낼 뿐이다.</p>
<p>예를 들어 아래 코드의 <code class="docutils literal notranslate"><span class="pre">data_augmentation</span></code>는 Sequential 모델을 이용하여 간단하게
데이터 증식을 지원하는 층을 지정한다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">RandomFlip()</span></code>: 사진을 50%의 확률로 지정된 방향으로 반전.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RandomRotation()</span></code>: 사진을 지정된 범위 안에서 임의로 좌우로 회전</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RandomZoom()</span></code>: 사진을 지정된 범위 안에서 임의로 확대 및 축소</p></li>
</ul>
<p>하나의 사진이 입력되면 앞서 설명한 세 개의 층을 통과하면서
사진이 무작위적으로 반전/회전/확대/축소 된다.
그리고 에포크가 바뀔 때마다 동일한 사진이 변하는 방식은 매번 달라진다.
즉 하나의 사진이 매 에포크마다 다른 방식으로 무작위적으로 변환되어
훈련에 사용되어 훈련 샘플의 다양성이 커진다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data_augmentation</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span><span class="n">layers</span><span class="o">.</span><span class="n">RandomFlip</span><span class="p">(</span><span class="s2">&quot;horizontal&quot;</span><span class="p">),</span>
     <span class="n">layers</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
     <span class="n">layers</span><span class="o">.</span><span class="n">RandomZoom</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)]</span>
<span class="p">)</span>
</pre></div>
</div>
<p>훈련셋의 이미지 샘플 하나를 대상으로 데이터 증식 층을 아홉 번 적용한 결과를
다음고 같다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/08-10.png" style="width:800px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>데이터 증식 층을 이용하여 모델 구성을 다시 한다.
과대적합을 최대한 방지하기 위해 출력층 바로 이전에 드롭아웃(Dropout) 층도 추가한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">180</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">data_augmentation</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Rescaling</span><span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
<p>과대 적합이 보다 늦게 발생한다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/08-11.png" style="width:800px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>테스트셋에 대한 정확도가 83% 정도로 올라간다.
<code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>와 <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> 층을 더 쌓거나 층에 사용된 필터수를 늘리는 방식으로
모델의 성능을 90% 정도까지 끌어올릴 수는 있지만 그 이상은 어려울 것이다.</p>
</section>
</section>
<section id="id11">
<h2><span class="section-number">10.3. </span>모델 재활용<a class="headerlink" href="#id11" title="Link to this heading">#</a></h2>
<p>적은 양의 데이터셋을 대상으로 훈련하는 것보다 대용량의 데이터셋을 이용하여 훈련하면
보다 좋은 성능의 모델을 구현할 수 있다.
하지만 대용량의 데이터를 구하기는 매우 어렵거나 아예 불가능할 수 있다.
하지만 유사한 목적으로 대용량의 훈련 데이터셋을 이용하여 사전에 훈련된 모델을 재활용하면
높은 성능의 모델을 얻을 수 있다.</p>
<p>여기서는 좋은 성능으로 잘 알려진 모델인 VGG16을 재활용하여 높은 성능의
강아지와 고양이 분류 모델을 구현하는 두 가지 방식을 소개한다.</p>
<ul class="simple">
<li><p>전이 학습<font size='2'>transfer learning</font></p></li>
<li><p>모델 미세조정<font size='2'>model fine tuning</font></p></li>
</ul>
<p><strong>VGG16 모델</strong></p>
<p>VGG16 모델은 <a class="reference external" href="https://www.image-net.org/challenges/LSVRC/2014/">ILSVRC 2014</a>
경진대회에 참여해서 2등을 차지한 모델이다.
당시 훈련에 사용된 데이터셋은 120만 장의 이미지와 1,000개의 클래스로 구성되었으며
훈련은 여러 주(weeks)에 걸쳐서 진행되었다.</p>
<div align="center"><img src="https://www.image-net.org/static_files/figures/ILSVRC2012_val_00042692.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.image-net.org/challenges/LSVRC/2014/">ILSVRC 2014</a>&gt;</div></p><p>VGG16은 당시 1등을 차지한 모델인 GoogleNet 보다 인기가 높다.
이유는 VGG16가 최상위에 위치한 몇 개의 밀집층(<code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층)을  제외한 나머지 층을
합성곱 신경망의 기본인 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>와 <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> 두 종류의 층만으로
구성해서 모델의 구조가 매우 단순하기 때문이다.
보다 자세한 소개는 <a class="reference external" href="https://brunch.co.kr/&#64;hvnpoet/126">1등보다 빛나는 2등, VGG16</a>을
참고할 수 있다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-vgg16.png" style="width:800px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://datascientest.com/en/unveiling-the-secrets-of-the-vgg-model-a-deep-dive-with-daniel">Unveiling the Secrets of the VGG Model</a>&gt;</div></p><p><strong>유명 합성곱 신경망 모델</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">ketas.applications</span></code> 에 포함된 유명 합성곱 신경모델은 다음과 같다.</p>
<ul class="simple">
<li><p>VGG16</p></li>
<li><p>Xception</p></li>
<li><p>ResNet</p></li>
<li><p>MobileNet</p></li>
<li><p>EfficientNet</p></li>
<li><p>DenseNet</p></li>
<li><p>등등</p></li>
</ul>
<p><strong>이미지넷(ImagNet) 소개</strong></p>
<p><a class="reference external" href="https://www.image-net.org/index.php">이미지넷(Imagenet)</a>은
대용량의 이미지 데이터셋이며,
<a class="reference external" href="https://www.image-net.org/challenges/LSVRC/index.php">ILSVRC</a>
이미지 분류 경진대회에 사용된다.
이미지넷의 전체 데이터셋은 총 2만2천 개 정도의 클래스로 구분되는 동물, 사물 등의 객체를 담은
고화질 사진 1500만장 정도로 구성된다.
2017년까지 진행된 ILSVRC 경진대회는 보통 1000 개의 클래스로 구분되는
사물을 담은 1백만장 정도의 이미지를 이용한다.</p>
<div align="center"><img src="https://cs.stanford.edu/people/karpathy/cnnembed/cnn_embed_full_1k.jpg" style="width:100%;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://cs.stanford.edu/people/karpathy/cnnembed/">https://cs.stanford.edu/people/karpathy/cnnembed/</a>&gt;</div></p><section id="id12">
<h3><span class="section-number">10.3.1. </span>전이 학습<a class="headerlink" href="#id12" title="Link to this heading">#</a></h3>
<p><strong>전이 학습 기본 아이디어</strong></p>
<p>사전에 잘 훈련된 모델은 새롭게 구현하고자 하는 모델과 일반적으로 다른 목적으로 구현되었다.
하지만 예를 들어 강아지와 고양이를 포함한 동물 및 기타 여러 사물을
분류할 목적으로 훈련된 모델은 기본적으로 강아지와 고양이를
분류하는 능력을 갖고 있어야 한다.</p>
<p>반면에 이항 분류 모델과 다중클래스 분류 모델은 기본적으로 출력층에서 서로 다른
종류의 값을 출력한다.
고양이와 강아지를 포함해서 총 1000개의 사물 클래스로 이미지를 분류하는 모델의 출력층은
1000개의 유닛과 softmax 등과 같은 활성화 함수를 사용할 것이지만
고양이-강아지 분류 모델은 1개의 유닛과 sigmoid 등과 같은 활성화 함수를 사용해야 한다.</p>
<p>따라서 기존 모델의 출력층을 포함하여 분류값을 직접적으로 예측하는 마지막 몇 개의 층
(일반적으로 밀집층)을 제외시킨 나머지 합성곱 층으로 이루어진 기저(베이스, base)만을
가져와서 그 위에 원하는 목적에 맞는 층을 새롭게 구성한다(아래 그림 참조).</p>
<p>학습 관점에 보았을 때 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 합성곱층과 <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> 맥스풀링층으로 구성된 기저는
이미지의 일반적인 특성을 파악한 정보(가중치)를 포함하고 있기에
강아지/고양이 분류 모델의 기저로 사용될 수 있는 것이다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/08-12.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>VGG16 모델을 이용한 전이 학습</strong></p>
<p>VGG16 합성곱 모델에서 밀집층(dense 층)을 제외한 나머지 합성곱 층으로만 이루어진 모델을 가져온다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">conv_base</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">vgg16</span><span class="o">.</span><span class="n">VGG16</span><span class="p">(</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;imagenet&quot;</span><span class="p">,</span>
    <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">180</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
<p>모델을 가져올 때 사용된 옵션의 의미는 다음과 같다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">weights=&quot;imagenet&quot;</span></code>: Imagenet 데이터셋으로 훈련된 모델의 가중치 가져옴.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">include_top=False</span></code>: 출력값을 결정하는 밀집층은 제외함.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_shape=(180,</span> <span class="pre">180,</span> <span class="pre">3)</span></code>: 앞서 준비해 놓은 데이터셋을 활용할 수 있도록 지정함. 사용자가 직접 지정해야 함.
지정하지 않으면 임의의 크기의 이미지를 처리할 수 있음.
층 별 출력 텐서의 모양의 변화 과정을 확인하기 위해 특정 모양으로 지정함.</p></li>
</ul>
<p>가져온 모델을 요약하면 다음과 같다.
마지막 맥스풀링 층을 통과한 특성맵의 모양은 <code class="docutils literal notranslate"><span class="pre">(5,</span> <span class="pre">5,</span> <span class="pre">512)</span></code>이다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">conv_base</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="go">Model: &quot;vgg16&quot; </span>
<span class="go">_________________________________________________________________</span>
<span class="go">Layer (type)                 Output Shape              Param # </span>
<span class="go">=================================================================</span>
<span class="go">input_19 (InputLayer)        [(None, 180, 180, 3)]     0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block1_conv1 (Conv2D)        (None, 180, 180, 64)      1792 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block1_conv2 (Conv2D)        (None, 180, 180, 64)      36928 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block1_pool (MaxPooling2D)   (None, 90, 90, 64)        0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block2_conv1 (Conv2D)        (None, 90, 90, 128)       73856 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block2_conv2 (Conv2D)        (None, 90, 90, 128)       147584 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block2_pool (MaxPooling2D)   (None, 45, 45, 128)       0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block3_conv1 (Conv2D)        (None, 45, 45, 256)       295168 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block3_conv2 (Conv2D)        (None, 45, 45, 256)       590080 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block3_conv3 (Conv2D)        (None, 45, 45, 256)       590080 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block3_pool (MaxPooling2D)   (None, 22, 22, 256)       0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block4_conv1 (Conv2D)        (None, 22, 22, 512)       1180160 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block4_conv2 (Conv2D)        (None, 22, 22, 512)       2359808 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block4_conv3 (Conv2D)        (None, 22, 22, 512)       2359808 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block4_pool (MaxPooling2D)   (None, 11, 11, 512)       0 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block5_conv1 (Conv2D)        (None, 11, 11, 512)       2359808 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block5_conv2 (Conv2D)        (None, 11, 11, 512)       2359808 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block5_conv3 (Conv2D)        (None, 11, 11, 512)       2359808 </span>
<span class="go">_________________________________________________________________</span>
<span class="go">block5_pool (MaxPooling2D)   (None, 5, 5, 512)         0 </span>
<span class="go">=================================================================</span>
<span class="go">Total params: 14,714,688 </span>
<span class="go">Trainable params: 14,714,688 </span>
<span class="go">Non-trainable params: 0 </span>
</pre></div>
</div>
<p><strong>특성 추출</strong></p>
<p><strong>특성 추출</strong><font size='2'>feature extraction</font>은 전이 학습에 사용되는 모델을 이용한
데이터 변환 과정을 의미한다.
여기서는 <code class="docutils literal notranslate"><span class="pre">conv_base</span></code> 기저를 특성 추출에 활용하는 두 가지 방식을 소개한다.</p>
<p><strong>1) 단순 특성 추출</strong></p>
<p>아래 <code class="docutils literal notranslate"><span class="pre">get_features_and_labels()</span></code> 함수는
<code class="docutils literal notranslate"><span class="pre">conv_base</span></code> 모델의 <code class="docutils literal notranslate"><span class="pre">predict()</span></code> 메서드를 이용하여
준비된 훈련 데이터셋을 변환한다.
즉 모델 예측에 유용한 특성들로 구성된 데이터로 변환한다.
단, 레이블(타깃)은 그대로 둔다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">keras.applications.vgg16.preprocess_input()</span></code> 함수: <code class="docutils literal notranslate"><span class="pre">tf.float32</span></code> 자료형으로의 형변환 담당. 일종의 리스케일링 함수.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_features_and_labels</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="n">all_features</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_labels</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># 배치 단위로 VGG16 모델 적용</span>
    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
        <span class="n">preprocessed_images</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">vgg16</span><span class="o">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">conv_base</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">preprocessed_images</span><span class="p">)</span>
        <span class="n">all_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="n">all_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        
    <span class="c1"># 생성된 배치를 하나의 텐서로 묶어서 반환</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_features</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_labels</span><span class="p">)</span>
</pre></div>
</div>
<p>훈련셋, 검증셋, 테스트셋을 변환하면 다음과 같다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span> <span class="o">=</span>  <span class="n">get_features_and_labels</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
<span class="n">val_features</span><span class="p">,</span> <span class="n">val_labels</span> <span class="o">=</span>  <span class="n">get_features_and_labels</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span>
<span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span>  <span class="n">get_features_and_labels</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>
</pre></div>
</div>
<p>예를 들어, 변환된 강아지/고양이 이미지 샘플 2,000개는 이제 각각 <code class="docutils literal notranslate"><span class="pre">(5,</span> <span class="pre">5,</span> <span class="pre">512)</span></code> 모양을 갖는다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">train_features</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2000, 5, 5, 12)</span>
</pre></div>
</div>
<p>변환된 데이터셋을 훈련 데이터셋으로 사용하는
간단한 분류 모델을 구성하여 훈련만 하면 된다.
<code class="docutils literal notranslate"><span class="pre">Dropout</span></code> 층은 과대적합을 예방하기 위해 사용한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 입력층</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>

<span class="c1"># 은닉층</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 출력층</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 모델</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
<p>검증셋에 대한 정확도가 97% 정도까지 향상되지만 과대적합이 매우 빠르게 발생한다.
아무래도 훈련셋이 너무 작기 때문이다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/08-13.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>2) 데이터 증식과 특성 추출</strong></p>
<p>데이터 증식 기법을 활용하려면
VGG16 합성곱 기저(베이스)를 구성요소로 사용하는 모델을 직접 정의해야 한다.
다만 앞서 설명한 방식과는 달리 가져온 VGG16 기저에 포함된 파라미터가 새로운
모델의 훈련 과정동안 함께 훈련되지 않도록 <strong>동결</strong>(freezing)해야 한다.</p>
<ul class="simple">
<li><p>기저 동결하기: <code class="docutils literal notranslate"><span class="pre">trainable=False</span></code>로 지정.</p></li>
<li><p>입력 데이터의 모양도 미리 지정하지 않음에 주의할 것.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">conv_base</span>  <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">vgg16</span><span class="o">.</span><span class="n">VGG16</span><span class="p">(</span>
    <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;imagenet&quot;</span><span class="p">,</span>
    <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 기저 동결</span>
<span class="n">conv_base</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>동결 해제(<code class="docutils literal notranslate"><span class="pre">trainable=True</span></code>)로 설정하는 경우와 그렇지 않은 경우 학습되어야 하는
파라미터의 수가 달라짐을 다음처럼 확인할 수 있다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">conv_base</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;합성곱 기저의 학습을 허용하는 경우 학습 가능한 가중치 행렬 개수: &quot;</span><span class="p">,</span> 
<span class="go">          len(conv_base.trainable_weights))</span>
<span class="go">      </span>
<span class="go">합성곱 기저의 학습을 허용하는 경우 학습 가능한 파라미터 수: 26</span>
</pre></div>
</div>
<p>동결 설정(<code class="docutils literal notranslate"><span class="pre">trainable=False</span></code>)인 경우에 학습되는 파라미터 수가 0이 된다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">conv_base</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;합성곱 기저의 학습을 금지하는 경우 학습 가능한 가중치 행렬 개수: &quot;</span><span class="p">,</span> 
<span class="go">          len(conv_base.trainable_weights))</span>
<span class="go">      </span>
<span class="go">합성곱 기저의 학습을 허용하는 경우 학습 가능한 파라미터 수: 0</span>
</pre></div>
</div>
<p>아래 모델은 데이터 증식을 위한 층과 VGG16 기저를 함께 이용한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data_augmentation</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">RandomFlip</span><span class="p">(</span><span class="s2">&quot;horizontal&quot;</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">RandomZoom</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="c1"># 모델 구성</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">180</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">data_augmentation</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>                     <span class="c1"># 데이터 증식</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">vgg16</span><span class="o">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># VGG16용 전처리</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">conv_base</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>                                  <span class="c1"># VGG16 베이스</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 출력층</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
<p>이렇게 훈련하면 재활용된 합성곱 기저에 속한 층은 학습하지 않으며
두 개의 밀집층에서만 파라미터 학습이 이뤄진다.
과대적합이 보다 늦게 이루어지며 성능도 향상되었다.
테스트셋에 대한 정확도가 97.7%까지 향상된다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/08-14.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p></section>
<section id="id13">
<h3><span class="section-number">10.3.2. </span>모델 미세 조정<a class="headerlink" href="#id13" title="Link to this heading">#</a></h3>
<p>모델 <strong>미세 조정</strong>(파인 튜닝, fine-tuning)은 특성 추출 방식과는 달리
기존 합성곱 모델의 최상위 합성곱 층 몇 개를 동결 해제해서
새로운 모델에 맞추어 학습되도록 하는 모델 훈련기법이다.</p>
<p>여기서는 아래 그림에처럼 노락색 배경을 가진 상자 안에 포함된 합성곱 층을
동결 해제해서 함께 학습되도록 한다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/08-15.png" style="width:200px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>아래 코드는 모든 층에 대해 동결해제를 진행한 후에
마지막 4개 층을 제외한 나머지 층에 대해 다시 동결을 설정한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">conv_base</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">conv_base</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">]:</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>상위 4개 층만 동결 해제하는 이유는
합성곱 신경망의 하위층은 보다 일반적인 형태의 패턴을 학습하는 반면에
최상위층은 주어진 문제 해결에 특화된 패턴을 학습하기 때문이다.
따라서 이미지넷으로 훈련된 모델 전체를 대상으로 훈련하기 보다는
최상위층 몇 개만 훈련시키는 것이 보다 유용하다.</p>
<p>모델 컴파일과 훈련 과정은 이전과 동일하며,
정확도가 98%(<span class="math notranslate nohighlight">\(\pm\!\)</span> 1%)에 육박하는 모델을 얻게 된다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>

<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
        <span class="n">filepath</span><span class="o">=</span><span class="s2">&quot;fine_tuning&quot;</span><span class="p">,</span>
        <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">)</span>
<span class="p">]</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id14">
<h2><span class="section-number">10.4. </span>연습문제<a class="headerlink" href="#id14" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://colab.research.google.com/github/codingalzi/dlp2/blob/master/excs/exc-computer_vision_intro.ipynb">(실습) 컴퓨터 비전 기초: 합성곱 신경망</a></p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="working_with_keras.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">9. </span>케라스 신경망 모델 활용법</p>
      </div>
    </a>
    <a class="right-next"
       href="computer_vision_advanced.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">11. </span>고급 컴퓨터 비전</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">10.1. 합성곱 신경망</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mnist-cnn">10.1.1. MNIST 데이터셋 분류 CNN 모델</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">10.1.2. 합성곱 연산</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">10.1.3. 맥스 풀링</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">10.2. 합성곱 신경망 실전 활용 예제</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">10.2.1. 작은 데이터셋과 딥러닝 모델</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">10.2.2. 데이터 다운로드</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">10.2.3. 모델 구성</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">10.2.4. 데이터 전처리와 모델 훈련</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">10.2.5. 데이터 증식</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">10.3. 모델 재활용</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">10.3.1. 전이 학습</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">10.3.2. 모델 미세 조정</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">10.4. 연습문제</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By 코딩알지
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>