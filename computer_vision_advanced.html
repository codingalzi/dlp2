
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>10. 컴퓨터 비전 &#8212; Deep Learning with Python(2판)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'computer_vision_advanced';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="11. 시계열 분석" href="dl_for_timeseries.html" />
    <link rel="prev" title="9. 합성곱 신경망" href="computer_vision_intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Deep Learning with Python(2판)</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="what_is_deep_learning.html">1. 딥러닝 소개</a></li>
<li class="toctree-l1"><a class="reference internal" href="building_blocks_of_NN.html">2. 신경망 기본 구성 요소</a></li>
<li class="toctree-l1"><a class="reference internal" href="tf_tensor.html">3. 텐서</a></li>
<li class="toctree-l1"><a class="reference internal" href="training_loop_from_scratch.html">4. 훈련 루프 상세</a></li>
<li class="toctree-l1"><a class="reference internal" href="keras_and_tf.html">5. 케라스와 텐서플로우</a></li>
<li class="toctree-l1"><a class="reference internal" href="classification_regression.html">6. 분류와 회귀</a></li>
<li class="toctree-l1"><a class="reference internal" href="fundamentals_of_ml.html">7. 최적화와 일반화</a></li>
<li class="toctree-l1"><a class="reference internal" href="working_with_keras.html">8. 케라스 신경망 모델 구성법</a></li>
<li class="toctree-l1"><a class="reference internal" href="computer_vision_intro.html">9. 합성곱 신경망</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">10. 컴퓨터 비전</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl_for_timeseries.html">11. 시계열 분석</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl_for_text.html">12. 자연어 처리</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative_dl.html">13. 생성 모델</a></li>
<li class="toctree-l1"><a class="reference internal" href="best_practices.html">14. 딥러닝 실전 적용</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/codingalzi/dlp2" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/codingalzi/dlp2/issues/new?title=Issue%20on%20page%20%2Fcomputer_vision_advanced.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/computer_vision_advanced.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>컴퓨터 비전</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">10.1. 컴퓨터 비전 주요 과제</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">10.2. 이미지 분할</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cnn">10.3. CNN 아키텍처 주요 유형</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">10.3.1. 모듈(블록), 계층, 재활용</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">10.3.2. 잔차 연결</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">10.3.3. 배치 정규화</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">10.3.4. 채널 분리 합성곱</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kerascv">10.4. KerasCV 라이브러리</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">10.5. 연습 문제</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ch-computer-vision-advanced">
<span id="id1"></span><h1><span class="section-number">10. </span>컴퓨터 비전<a class="headerlink" href="#ch-computer-vision-advanced" title="Link to this heading">#</a></h1>
<p><strong>감사의 글</strong></p>
<p>아래 내용은 프랑소와 숄레의
<a class="reference external" href="https://github.com/fchollet/deep-learning-with-python-notebooks">Deep Learning with Python(2판)</a>의
소스코드 내용을 참고해서 작성되었습니다.
자료를 공개한 저자에게 진심어린 감사를 전합니다.</p>
<p><strong>소스코드</strong></p>
<p>여기서 언급되는 코드를
<a class="reference external" href="https://colab.research.google.com/github/codingalzi/dlp2/blob/master/notebooks/NB-computer_vision_advanced.ipynb">(구글 코랩) 컴퓨터 비전</a>에서
직접 실행할 수 있다.</p>
<p><strong>슬라이드</strong></p>
<p>본문 내용을 요약한 <a class="reference external" href="https://github.com/codingalzi/dlp2/raw/master/slides/slides-computer_vision_advanced.pdf">슬라이드</a>를 다운로드할 수 있다.</p>
<p><strong>주요 내용</strong></p>
<ul class="simple">
<li><p>합성곱 신경망의 주요 활용 분야(컴퓨터 비전)</p>
<ul>
<li><p>이미지 분류</p></li>
<li><p>이미지 분할</p></li>
<li><p>객체 탐지</p></li>
</ul>
</li>
<li><p>합성곱 신경망 기본 아키텍처</p>
<ul>
<li><p>잔차 연결</p></li>
<li><p>배치 정규화</p></li>
<li><p>채널 분리 합성곱</p></li>
</ul>
</li>
</ul>
<section id="id2">
<h2><span class="section-number">10.1. </span>컴퓨터 비전 주요 과제<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>컴퓨터 비전 분야에서 가장 주요한 연구 주제는 다음과 같다.</p>
<ul class="simple">
<li><p>이미지 분류(image classification): 이미지에 포함된 사물(들)의 클래스 분류</p>
<ul>
<li><p>단일 라벨 분류(single-label classification)</p>
<ul>
<li><p>예제: 한 장의 사진에서 고양이, 강아지, 사람, 자전거, 자동차 등 중에하 하나의 클래스 선택</p></li>
</ul>
</li>
<li><p>다중 라벨 분류(multi-label classification)</p>
<ul>
<li><p>예제: 한 장의 사진에 포함된 여러 종류의 객체를 모두 분류.
예를 들어 두 사람이 자전거를 타는 사진에서 두 사람과 자전거 등 사진에 포함된 모든 객체의 클래서 확인.</p></li>
</ul>
</li>
</ul>
</li>
<li><p>이미지 분할(image segmentation): 이미지를 특정 클래스를 포함하는 영역으로 분할</p>
<ul>
<li><p>예제: 줌(Zoom), 구글 미트(Google Meet) 등에서 사용되는 배경 블러처리 기능</p></li>
</ul>
</li>
<li><p>객체 탐지(object detection): 이미지에 포함된 객체 주의에 경계상자(bounding box) 그리기</p>
<ul>
<li><p>예제: 자율주행 자동차의 주변에 위치한 다른 자동차, 행인, 신호등 등 탐지 기능</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/computer_vision_tasks.png" style="width:100%;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>언급된 세 분야 이외에 아래 컴퓨터 비전 분야에서도 딥러닝이 중요하게 활용된다.</p>
<ul class="simple">
<li><p>이미지 유사도 측정(image similarity scoring)</p></li>
<li><p>키포인트 탐지(keypoint detection)</p></li>
<li><p>자세 추정(pose estimation)</p></li>
<li><p>3D 메쉬 추정(3D mesh estimation)</p></li>
</ul>
<div align="center"><img src="https://github.com/Jeff-sjtu/HybrIK/raw/main/assets/hybrik.png" style="width:100%;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://github.com/Jeff-sjtu/HybrIK">HybrIK</a>&gt;</div></p><p>여기서는 이미지 분할을 보다 자세히 살펴본다.
반면에 객체 탐지 등 다른 분야는 다루지 않는다.
다만 객체 탐지 관련해서 다음 논문을 참고할 것을 권유한다.</p>
<ul class="simple">
<li><p>작동원리 설명: 핸즈온 머신러닝 14장</p></li>
<li><p>기초 활용법: <a class="reference external" href="https://keras.io/examples/vision/retinanet/">RetinaNet 활용 객체 탐지</a></p></li>
<li><p>주요 활용 예제: <a class="reference external" href="https://github.com/ultralytics/yolov5">YOLOv5</a></p></li>
</ul>
</section>
<section id="id3">
<h2><span class="section-number">10.2. </span>이미지 분할<a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<p>이미지 분할은 크게 두 종류로 나뉜다.</p>
<ul class="simple">
<li><p>시맨틱 분할(semantic segmentation)</p>
<ul>
<li><p>객체가 속하는 클래스(범주)에 따라 분류</p></li>
<li><p>아래 사진 왼편: 배경과 구분된 고양이들을 cat 클래스로 하나로 묶어 배경과 구분</p></li>
</ul>
</li>
<li><p>인스턴스 분할(instance segmentation)</p>
<ul>
<li><p>클래스뿐만 아니라 객체 각각도 구분</p></li>
<li><p>아래 사진 오른편: 배경과 구분된 각각의 고양이를 cat1, cat2 등으로 구분</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/instance_segmentation.png" style="width:100%;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>Oxford-IIIT 애완동물 데이터셋</strong></p>
<p>시맨틱 분할을 보다 상세히 살펴보기 위해
<a class="reference external" href="https://www.robots.ox.ac.uk/~vgg/data/pets/">Oxford-IIIT 애완동물 데이터셋</a>을 이용하여
훈련을 진행한다.
데이터셋은 강아지와 고양이를 비롯해서 총 37 종의 애완동물이 찍힌
7,390장의 사진으로 구성된다.
사진의 크기는 제 각각이다.</p>
<ul class="simple">
<li><p>데이터셋 크기: 7,390</p></li>
<li><p>클래스(범주) 개수: 37</p></li>
<li><p>클래스별 사진 수: 약 200 장</p></li>
<li><p>사진별 라벨: 종과 품종, 머리 표시 경계상자, 트라이맵 분할<font size='2'>trimap segmentation</font> 마스크 등 4 종류로 구성</p></li>
</ul>
<p><strong>트라이맵 분할 마스크</strong>는 원본 사진과 동일한 크기의 흑백 사진이며
각각의 픽셀은 1, 2, 3 셋 중에 하나의 값을 갖는다.</p>
<ul class="simple">
<li><p>1: 동물의 몸에 해당하는 픽셀</p></li>
<li><p>2: 배경에 해당하는 픽셀</p></li>
<li><p>3: 동물과 배경을 구분하는 경계에 해당하는 픽셀</p></li>
</ul>
<p>아래에서 맨 왼쪽은 동물 사진을, 가운데 사진은 동물의 머리 영역을 표시하는 경계 상자를
맨 오른쪽 사진은 트라이맵 분할 마스크를 시각화하여 보여준다.</p>
<div align="center"><img src="https://www.robots.ox.ac.uk/~vgg/data/pets/pet_annotations.jpg" style="width:100%;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>이미지 분할 모델 구성</strong></p>
<p>이미지 분할 모델의 구성은 기본적으로 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층으로 구성된
<strong>다운샘플링 블록</strong><font size='2'>downsampling block</font>과
<code class="docutils literal notranslate"><span class="pre">Conv2DTranspose</span></code> 층으로 구성된
<strong>업샘플링 블록</strong><font size='2'>upsampling block</font>으로 이루어진다.</p>
<p>먼저 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층을 활용하는 다운샘플링 블록으로 시작한다.
이미지 분류를 위해 맥스풀링을 사용하는 대신 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층에서 보폭을 2로
설정하는 이유는 픽셀에 담긴 값(정보) 뿐만 아니라 각 픽셀의 위치도 중요하기 때문이다.
맥스풀링은 픽셀의 위치 정보를 무시하면서 동시에 위치와 독립적인 패턴을 알아내는 것이 중요할 때 사용된다.
실제로 맥스풀링은 여러 개의 픽셀 중에 가장 큰 값을 선택하는데 선택된 픽셀의 정보는 무시한다.</p>
<ul class="simple">
<li><p>이미지 분류 모델과 동일한 기능.</p></li>
<li><p>보폭(<code class="docutils literal notranslate"><span class="pre">strides=2</span></code>)을 사용하는 경우와 그렇지 않은 경우를 연속으로 적용하기에
별도의 <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code>은 사용하지 않음.</p></li>
<li><p>패딩(<code class="docutils literal notranslate"><span class="pre">padding=&quot;same&quot;</span></code>)을 사용하지만 보폭을 2로 두면 이미지 크기는 가로, 세로 모두 1/2로 줄어듦.</p></li>
<li><p>채널 수는 동일한 방식으로 두 배씩 증가시킴.</p></li>
</ul>
<p>다운샘플링 블록에 이어 <code class="docutils literal notranslate"><span class="pre">Conv2DTranspose</span></code> 층을 활용하는 업샘플링 블록을 추가한다.</p>
<ul class="simple">
<li><p>이미지 분할 모델의 최종 출력값은 입력 이미지의 동일한 크기의 트라이맵 분할 이미지임.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층을 통과하면서 크기가 작아진 텐서를 입력 이미지 크기로 되돌리는 기능 수행.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층이 적용된 역순으로 크기를 되돌려야 함.</p></li>
<li><p>모델 훈련과정에서 어떤 값들을 사용하여 모양을 되돌릴지 스스로 학습함.</p></li>
</ul>
<p>아래 그림이 업샘플링이 작동하는 과정을 보여준다.</p>
<ul class="simple">
<li><p>검정 테두리로 표시된 <code class="docutils literal notranslate"><span class="pre">2x2</span></code> 모양의 텐서에 포함된 하나의 항목에 초록색 바탕의 <code class="docutils literal notranslate"><span class="pre">3x3</span></code> 모양의 필터를 적용하면
왼편에 위치한 파랑색 바탕의 <code class="docutils literal notranslate"><span class="pre">3x3</span></code> 모양의 텐서가 생성된다.</p></li>
<li><p>이 과정을 <code class="docutils literal notranslate"><span class="pre">2x2</span></code> 텐서의 모든 항목에 대해 실행한다.
단, 생성되는 <code class="docutils literal notranslate"><span class="pre">3x3</span></code> 모양의 텐서는 지정된 보폭 크기만큼 오른쪽 또는 아래로 이동시키며 겹친다.</p></li>
<li><p>중첩되는 영역에 포함된 항목은 해당 항목에 대해 계산된 모든 값들의 합으로 지정한다.</p></li>
</ul>
<p><div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch09-conv2d_transpose01.png" style="width:600px;"></div></p>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://towardsdatascience.com/understand-transposed-convolutions-and-build-your-own-transposed-convolution-layer-from-scratch-4f5d97b2967">Understand Transposed Convolutions</a>&gt;</div></p><p>여기서 사용하는 다운/업 샘플링 블록은 다음과 같다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="n">img_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">img_size</span> <span class="o">+</span> <span class="p">(</span><span class="mi">3</span><span class="p">,))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Rescaling</span><span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2DTranspose</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2DTranspose</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2DTranspose</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2DTranspose</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2DTranspose</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2DTranspose</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<p>출력층으로 사용된 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층의 활성화 함수로 지정된 소프트맥스 함수는
출력 텐서의 마지막 축을 대상으로 작동한다.
즉, <code class="docutils literal notranslate"><span class="pre">num_classes</span></code> 개의 출력맵으로 구성된 3차원 텐서의 픽셀별로 소프트맥스 함수가 적용된다.
여기서는 <code class="docutils literal notranslate"><span class="pre">num_classes</span></code>가 3으로 지정된다.
이유는 최종적으로 픽셀별로 0, 1, 2 중에 하나의 값을 예측해야 하기 때문이다.</p>
<p>위 모델을 훈련시킬 때 손실함수로 <code class="docutils literal notranslate"><span class="pre">sparse_categorical_crossentropy</span></code>를 지정한다.
그러면 샘플의 타깃으로 사용되는 정수 0, 1, 2가
각각 <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">0,</span> <span class="pre">0)</span></code>, <code class="docutils literal notranslate"><span class="pre">(0,</span> <span class="pre">1,</span> <span class="pre">0)</span></code>, <code class="docutils literal notranslate"><span class="pre">(0,</span> <span class="pre">0,</span> <span class="pre">1)</span></code> 에 상응하도록 작동하여
타깃 샘플의 모양이 <code class="docutils literal notranslate"><span class="pre">(200,</span> <span class="pre">200,</span> <span class="pre">3)</span></code>인 것인양 작동하여
위 모델의 출력값의 모양과 동일해진다.</p>
<p><code class="docutils literal notranslate"><span class="pre">get_model(img_size=(200,200),</span> <span class="pre">num_classes=3)</span></code>을 호출해서 생성된 모델을 요약하면 다음과 같다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">img_size=(200,200)</span></code>: 크기가 제 각각인 사진을 모두 지정된 크기로 변환시켜서 훈련셋으로 활용</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">num_classes=3</span></code>: 최종적으로 3개의 채널을 갖는 텐서 생성. 소프트맥스 활성화 함수는 픽셀별로 적용됨.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Model</span><span class="p">:</span> <span class="s2">&quot;model&quot;</span>
<span class="n">_________________________________________________________________</span>
<span class="n">Layer</span> <span class="p">(</span><span class="nb">type</span><span class="p">)</span>                 <span class="n">Output</span> <span class="n">Shape</span>              <span class="n">Param</span> <span class="c1">#   </span>
<span class="o">=================================================================</span>
<span class="n">input_1</span> <span class="p">(</span><span class="n">InputLayer</span><span class="p">)</span>         <span class="p">[(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">3</span><span class="p">)]</span>     <span class="mi">0</span>         
<span class="n">_________________________________________________________________</span>
<span class="n">rescaling</span> <span class="p">(</span><span class="n">Rescaling</span><span class="p">)</span>        <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>       <span class="mi">0</span>         
<span class="n">_________________________________________________________________</span>
<span class="n">conv2d</span> <span class="p">(</span><span class="n">Conv2D</span><span class="p">)</span>              <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>      <span class="mi">1792</span>      
<span class="n">_________________________________________________________________</span>
<span class="n">conv2d_1</span> <span class="p">(</span><span class="n">Conv2D</span><span class="p">)</span>            <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>      <span class="mi">36928</span>     
<span class="n">_________________________________________________________________</span>
<span class="n">conv2d_2</span> <span class="p">(</span><span class="n">Conv2D</span><span class="p">)</span>            <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>       <span class="mi">73856</span>     
<span class="n">_________________________________________________________________</span>
<span class="n">conv2d_3</span> <span class="p">(</span><span class="n">Conv2D</span><span class="p">)</span>            <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>       <span class="mi">147584</span>    
<span class="n">_________________________________________________________________</span>
<span class="n">conv2d_4</span> <span class="p">(</span><span class="n">Conv2D</span><span class="p">)</span>            <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>       <span class="mi">295168</span>    
<span class="n">_________________________________________________________________</span>
<span class="n">conv2d_5</span> <span class="p">(</span><span class="n">Conv2D</span><span class="p">)</span>            <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>       <span class="mi">590080</span>    
<span class="n">_________________________________________________________________</span>
<span class="n">conv2d_transpose</span> <span class="p">(</span><span class="n">Conv2DTran</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>       <span class="mi">590080</span>    
<span class="n">_________________________________________________________________</span>
<span class="n">conv2d_transpose_1</span> <span class="p">(</span><span class="n">Conv2DTr</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>       <span class="mi">590080</span>    
<span class="n">_________________________________________________________________</span>
<span class="n">conv2d_transpose_2</span> <span class="p">(</span><span class="n">Conv2DTr</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>       <span class="mi">295040</span>    
<span class="n">_________________________________________________________________</span>
<span class="n">conv2d_transpose_3</span> <span class="p">(</span><span class="n">Conv2DTr</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>     <span class="mi">147584</span>    
<span class="n">_________________________________________________________________</span>
<span class="n">conv2d_transpose_4</span> <span class="p">(</span><span class="n">Conv2DTr</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>      <span class="mi">73792</span>     
<span class="n">_________________________________________________________________</span>
<span class="n">conv2d_transpose_5</span> <span class="p">(</span><span class="n">Conv2DTr</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>      <span class="mi">36928</span>     
<span class="n">_________________________________________________________________</span>
<span class="n">conv2d_6</span> <span class="p">(</span><span class="n">Conv2D</span><span class="p">)</span>            <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>       <span class="mi">1731</span>      
<span class="o">=================================================================</span>
<span class="n">Total</span> <span class="n">params</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span><span class="mi">880</span><span class="p">,</span><span class="mi">643</span>
<span class="n">Trainable</span> <span class="n">params</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span><span class="mi">880</span><span class="p">,</span><span class="mi">643</span>
<span class="n">Non</span><span class="o">-</span><span class="n">trainable</span> <span class="n">params</span><span class="p">:</span> <span class="mi">0</span>
<span class="n">_________________________________________________________________</span>
</pre></div>
</div>
<p>모델 컴파일과 훈련은 특별한 게 없다.
단, 앞서 설명한 대로 <code class="docutils literal notranslate"><span class="pre">sparse_categorical_crossentropy</span></code>를 손실함수로 지정한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span> 
              <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>GPU의 성능에 따라 아래 코드를 실행할 때
<code class="docutils literal notranslate"><span class="pre">ResourceExhaustedError:</span> <span class="pre">Graph</span> <span class="pre">execution</span> <span class="pre">error</span></code> 가 발생하거나
파이썬 서버가 다운될 수 있다.
이유는 입력 데이터 사진의 용량이 커서 GPU의 메모리가 부족해지는 현상이 발생할 수 있기 때문이다.
그런 경우 배치 크기를 16 정도로 줄여야 한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s2">&quot;oxford_segmentation&quot;</span><span class="p">,</span>
                                    <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_input_imgs</span><span class="p">,</span> <span class="n">train_targets</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
<span class="c1">#                    batch_size=64, # 고성능 GPU 활용</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>  <span class="c1"># 저성능 GPU 활용</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_input_imgs</span><span class="p">,</span> <span class="n">val_targets</span><span class="p">))</span>
</pre></div>
</div>
<p>훈련 결과를 그래프로 시각화해서 보면
과대적합이 20 에포크 정도 지나면서 발생함을 확인할 수 있다.</p>
<p><div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch09-training02.png" style="width:400px;"></div></p><p>참고로 배치 크기를 64로 할 경우 25 에포크 정도 지나면서 과대적합이 발생한다.</p>
<p><div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch09-training01.png" style="width:400px;"></div></p><p>훈련중 저장된 최고 성능의 모델을 불러와서 이미지 분할을
어떻게 진행했는지 하나의 이미지에 대해 테스트해보면
원본 이미지에 포함된 다른 사물이나 배경 때문에 약간의 잡음이 있지만
대략적으로 이미지 분할을 잘 적용함을 알 수 있다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/09-06.png" style="width:700px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p></section>
<section id="cnn">
<h2><span class="section-number">10.3. </span>CNN 아키텍처 주요 유형<a class="headerlink" href="#cnn" title="Link to this heading">#</a></h2>
<p><strong>모델 아키텍처</strong><font size='2'>model architecture</font>는 모델 설계방식을 의미하며
심층 신경망 모델을 구성할 때 매우 중요하다.
신경망 모델은 주어진 문제와 데이터셋에 따라 적절한 층을 적절하게 구성해야 한다.
적절한 모델 아키텍처를 사용할 수록 적은 양의 데이터로 보다 빠르게
좋은 성능의 모델을 얻을 가능성이 높아진다.
하지만 아쉽게도 좋은 모델 아키텍처와 관련되어 정해진 이론은 없다.
대신 많은 경험을 통한 직관이 모델 구성에 보다 중요하다.</p>
<section id="id4">
<h3><span class="section-number">10.3.1. </span>모듈(블록), 계층, 재활용<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<p>합성곱 신경망 모델을 포함하여 주요 신경망 모델의 아키텍처는 다음 두 가지 특징을 갖는다.</p>
<p>첫째, 깊게 쌓아 올린 합성곱 신경망 모델은 기본적으로 <strong>모듈</strong><font size='2'>module</font>을
<strong>계층</strong><font size='2'>hierarchy</font>으로 쌓아 올린 구조를 갖는다.
여기서 모듈은 여러 개의 층<font size='2'>layer</font>으로 구성되며 <strong>블록</strong><font size='2'>block</font>이라 불리기도 한다.
하나의 모듈(블록)이 여러 번 <strong>재활용</strong><font size='2'>reuse</font> 된다.
예를 들어, <a class="reference internal" href="computer_vision_intro.html#ch-computer-vision-intro"><span class="std std-numref">9장</span></a>에서 다룬 VGG16 모델은 “Conv2D, Conv2D, MaxPooling2D” 로 구성된 모듈(블록)을
재활용하여 계층으로 쌓아 올렸다.</p>
<p>둘째, 대부분의 합성곱 신경망 모델은 <strong>특성 피라미드</strong> 형식의 계층적 구조를 사용하는 점이다.
VGG16의 경우에 필터 수를 32, 64, 128 등으로 수를 늘리는 반면에 특성맵<font size='2'>feature maps</font>의
크기는 그에 상응하여 줄여 나간다(아래 그림 참고).</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch08-vgg16.png" style="width:800px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://datascientest.com/en/unveiling-the-secrets-of-the-vgg-model-a-deep-dive-with-daniel">Unveiling the Secrets of the VGG Model</a>&gt;</div></p><p>그런데 블록을 연결하는 계층을 높게 쌓으면 그레이디언트 소실 문제 등으로 인해
모델의 훈련이 잘 이뤄지지 않는다.
이를 해결하는 다양한 해결책이 개발되었으며
여기서는 합성곱 신경망 구성에 사용되는 세 개의 주요 아키텍처 유형을 살펴본다.</p>
<ul class="simple">
<li><p>잔차 연결<font size='2'>residual connections</font></p></li>
<li><p>배치 정규화<font size='2'>batch normalization</font></p></li>
<li><p>채널 분리 합성곱<font size='2'>depthwise separable convolutions</font></p></li>
</ul>
</section>
<section id="id5">
<h3><span class="section-number">10.3.2. </span>잔차 연결<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<p>일반적으로 많은 유닛이 포함된 층을 몇 개 쌓는 것보다
적은 유닛이 포함된 층을 높이 쌓을 때 모델의 성능이 좋아진다.
하지만 층을 높이 쌓을 수록
전달되어야 하는 손실값(오차)의 <strong>그레이디언트 소실 문제</strong><font size='2'>vanishing gradient problem</font>가
발생하여 역전파가 제대로 작동하지 못한다.
이 문제를 극복하기 위해 제시된 대표적인 아키텍처(설계방식)가 <strong>잔차 연결</strong><font size='2'>residual connections</font>이다.</p>
<p>아래 그림은 블록(모듈)의 입력값을 모델을 통과하여 생성된 출력값과 합쳐서 다음 모델으로 전달하는 아키텍처를 보여준다.
이 방식을 통해 모델의 입력값에 대한 정보가 보다 정확하게 상위 모델에 전달되어,
그레이디언트 소실 문제를 해결하는 데에 많은 도움을 준다.
실제로 잔차 연결을 이용하면 모델을 매우 높게 쌓아도 모델 훈련이 가능해질 수 있다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/09-09.png" style="width:30%;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><div class="info admonition">
<p class="admonition-title">ResNet 모델</p>
<p>잔차 연결 아키텍처는 2015년에 소개된 ResNet 계열의 모델에서 처음 사용되었으며,
2015년 ILSVRC 이미지 분류 경진대회에서 1등을 차지했다.</p>
</div>
<p><strong>잔차 연결 핵심: 모양 맞추기</strong></p>
<p>잔차 연결을 사용할 때 주의해야할 기본사항은 모듈의 입력텐서와 출력테서의 모양을 맞추는 일이다.
이때 맥스풀링 사용여부에 따라 보폭(<code class="docutils literal notranslate"><span class="pre">strides</span></code>)의 크기가 달라진다.</p>
<ul>
<li><p>맥스풀링을 사용하지 않는 경우: <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>에서 사용된 필터 수를 맞추는 데에만 주의하면 된다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층: <code class="docutils literal notranslate"><span class="pre">padding=&quot;same&quot;</span></code> 옵션을 사용하여 모양을 유지</p></li>
<li><p>필터 수가 변하는 경우: 잔차에 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층을 이용하여 필터 수를 맞춤. 필터 크기는 <code class="docutils literal notranslate"><span class="pre">1x1</span></code> 사용.
활성화 함수는 없음.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># padding 사용</span>
<span class="n">residual</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">)(</span><span class="n">residual</span><span class="p">)</span>                       <span class="c1"># 필터 수 맞추기</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">residual</span><span class="p">])</span>
</pre></div>
</div>
</li>
</ul>
<ul>
<li><p>맥스풀링을 사용하는 경우: 보폭을 활용해야 한다.</p>
<ul class="simple">
<li><p>잔차에 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층을 적용할 때 보폭 사용</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>                   <span class="c1"># 맥스풀링</span>
<span class="n">residual</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">residual</span><span class="p">)</span>            <span class="c1"># 보폭 사용</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">residual</span><span class="p">])</span>
</pre></div>
</div>
</li>
</ul>
<p><strong>예제</strong></p>
<p>아래 코드는 잔차 연결을 사용하는 활용법을 보여준다.
맥스풀링과 필터 수에 따른 구분을 사용함에 주의하라.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 입력층</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Rescaling</span><span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>

<span class="c1"># 은닉층</span>
<span class="k">def</span> <span class="nf">residual_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">pooling</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pooling</span><span class="p">:</span>                          <span class="c1"># 맥스풀링 사용하는 경우</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">residual</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">filters</span> <span class="o">!=</span> <span class="n">residual</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>  <span class="c1"># 필터 수가 변하는 경우</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="mi">1</span><span class="p">)(</span><span class="n">residual</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">residual</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">x</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">residual_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">pooling</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">residual_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">pooling</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">residual_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">pooling</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 채널 별로 하나의 값(채널 평균값) 선택</span>

<span class="c1"># 출력층</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 모델 설정</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id6">
<h3><span class="section-number">10.3.3. </span>배치 정규화<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<p><strong>정규화</strong><font size='2'>normalization</font>는
다양한 모양의 샘플을 정규화를 통해 보다 정규 분포를 따르도록 만든다.
이를 통해 모델의 학습을 도와주고 결국 훈련된 모델의 일반화 성능을 올려준다.
지금까지 살펴 본 정규화는 모델의 입력 데이터를 전처리 과정에서 평균을 0으로,
표준편차를 1로 만드는 방식이었다.
이는 데이터셋이 정규 분포를 따른다는 가정 하에 진행된 정규화였다.
아래 그림은 주택가격 예측 데이터의 특성 중에 주택가격과 건축년수를 정규화한 경우(오른편)와 그렇지 않는 경우(왼편)의
데이터 분포의 변화를 보여준다.</p>
<div align="center"><img src="https://miro.medium.com/max/770/1*4T4y3kI0R9Alk_2pe6B4Pg.png" style="width:70%;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://medium.com/@ilango100/batch-normalization-speed-up-neural-network-training-245e39a62f85">Batch Normalization — Speed up Neural Network Training</a>&gt;</div></p><div class="info admonition">
<p class="admonition-title">정규 분포와 머신러닝</p>
<p>정규 분포를 따르지 않는 데이터에 대한 분석은 기본적으로 머신러닝(딥러닝) 기법을 적용할 수 없다.</p>
</div>
<p>하지만 입력 데이터셋에 대한 정규화가 층을 통과한 출력값의 정규화를 보장하는 것은 아니다.
따라서 다음 층으로 넘겨주기 전에 정규화를 먼저 진행하면 보다 훈련이 잘 될 수 있다.
더 나아가 출력값을 먼저 정규화한 후에 활성화 함수를 적용할 때 보다 좋은 성능의 모델이 구현될 수 있음이
밝혀지기도 했다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp/master/notebooks/images/batchNormalization.jpg" style="width:70%;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://medium.com/@ilango100/batch-normalization-speed-up-neural-network-training-245e39a62f85">Batch Normalization — Speed up Neural Network Training</a>&gt;</div></p><p><strong>배치 정규화</strong><font size='2'>batch normalization</font>가 바로 앞서 설명한 기능을 대신 처리하며,
2015년에 발표된 한 논문에서 소개되었다.
케라스의 경우 <code class="docutils literal notranslate"><span class="pre">layers.BatchNormalization</span></code> 층이 배치 정규하를 지원한다.
배치 정규화를 실행하는 함수를 넘파이 어레이로 다음과 같이 구현할 수 있다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">batch_normalization</span><span class="p">(</span><span class="n">batch_of_images</span><span class="p">):</span> 
    <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">batch_of_images</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> 
    <span class="n">variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">batch_of_images</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> 
    <span class="k">return</span> <span class="p">(</span><span class="n">batch_of_images</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">variance</span>
</pre></div>
</div>
<p>아래 그림은 배치 정규화 층에서 입력 배치를 대상으로 정규화를 진행하는 과정을 시각화한다.
입력 텐서의 모양은 (N, H, W, C) 라고 가정한다.</p>
<ul class="simple">
<li><p>N: 배치 크기</p></li>
<li><p>H와 W: 높이와 너비</p></li>
<li><p>C: 채널 수</p></li>
</ul>
<p>즉, 배치 정규화는 배치에 포함된 모든 샘플을 대상으로 채널 단위로 계산된 평균값과 표준편차를
이용하여 각각의 샘플에 대해 정규화를 진행한다.
즉, 배치에 포함된 모든 샘플에 대해 동일한 평균값과 표준편차를 이용한다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp2/master/jupyter-book/imgs/ch09-batch_normalization.png" style="width:30%;"></div><p>배치 정규화로 인한 모델 성능 향상에 대한 구체적인 이론은 아직 존재하지 않는다.
다만 경험적으로 합성곱 신경망 모델의 성능에 많은 도움을 준다는 사실만 알려져 있다.
잔차 연결과 함께 배치 정규화 또한 모델 훈련과정에 그레이디언트 역전파에 도움을 주어
매우 깊은 심층 신경망 모델의 훈련에 도움을 준다.
예를 들어, ResNet50, EfficientNet, Xception 모델 등은 배치 정규화 없이는 제대로 훈련되지 않는다.</p>
<p><strong>배치 정규화 사용법</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code> 층을 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>, <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 등 임의의 층 다음에 사용할 수 있다.
주로 사용되는 형식은 다음과 같다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="o">...</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">use_bias=False</span></code> 옵션: 배치 정규화에 의해 어차피 데이터의 평균값을 0으로 만들기에 굳이 편향<font size='2'>bias</font> 파라미터를
훈련 과정 중에 따로 학습시킬 이유가 없다. 따라서 학습되어야 할 파라미터 수가 아주 조금 줄어들어
학습 속도가 그만큼 빨라진다.</p></li>
<li><p>활성화 함수 사용 위치: 배치 정규화 이후에 활성화 함수를 실행한다.
이를 통해 <code class="docutils literal notranslate"><span class="pre">relu()</span></code> 활성화 함수의 기능을 극대화할 수 있다(고 주장된다).</p></li>
</ul>
<p><strong>모델 미세조정과 배치 정규화</strong></p>
<p>배치 정규화 층이 포함된 모델을 미세조정할 때 배치 정규화 층도 함께 동결(freeze)할 것을 추천한다.
배치 정규화 층을 동결하면
재활용되는 모델이 기존 훈련과정에서 사용한 훈련 데이터셋 전체를 대상으로 계산된 평균값과 분산이 대신 활용된다.</p>
<p>이렇게 하는 이유는 미세조정의 경우 훈련셋의 데이터가 모델이 기존에 훈련했을 때의 훈련셋과 비슷하다고 전제하기 때문이다.
만약에 많이 다른 훈련셋으로 미세조정을 진행하면 동결해제된 모델의 파라미터가 급격하게 달라지게 되여
모델의 성능이 오히려 떨어질 수 있다(라고 추정된다).</p>
<p><strong>예제</strong></p>
<p>아래 그림은 2017년에 소개된 Xception 모델의 구조를 보여준다.
빨강색 사각형으로 표시된 부분에 <code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code> 층이 사용되었다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/dlp/master/notebooks/images/xception.jpg" style="width:100%;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://arxiv.org/abs/1610.02357">Xception: Deep Learning with Depthwise Separable Convolutions</a>&gt;</div></p></section>
<section id="id7">
<h3><span class="section-number">10.3.4. </span>채널 분리 합성곱<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<p>케라스의 <code class="docutils literal notranslate"><span class="pre">SeparableConv2D</span></code> 층은 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층보다
적은 수의 가중치 파라미터를 사용하여 보다 적은 양의 계산으로 성능이 좀 더 좋은 모델을 생성한다.
2017년 Xception 모델 논문에서 소개되었으며 당시 최고의 이미지 분류 성능을 보였다.</p>
<div class="note admonition">
<p class="admonition-title">Top 1 / Top 5 정확도</p>
<p>최신 이미지 분류 모델의 성능은
<a class="reference external" href="https://paperswithcode.com/sota/image-classification-on-imagenet">Image Classification on ImageNet</a>에서
확인할 수 있다.
2023년 기준으로 최고 성능 모델의 Top 1 정확도는 91.1%,
Top 5 정확도는 99.02% 정도이다.</p>
<ul class="simple">
<li><p>Top 1 정확도: 분류 모델이 모든 클래스에 대해 예측한 확률값 중에 가장 높은 확률값을 갖는 클래스가 실제 타깃과 일치할 확률</p></li>
<li><p>Top 5 정확도: 분류 모델이 모든 클래스에 대해 예측한 확률값 중에 가장 높은 5 개의 확률값을 갖는
5개의 클래스 중에 실제 타깃이 포함된 확률</p></li>
</ul>
</div>
<p><strong>SeparableConv2D 작동법</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">SeparableConv2D</span></code>는 필터를 채널 별로 적용한 후
나중에 채널 별 결과를 합친다.
이렇게 작동하는 층이 <strong>채널 분리 합성곱</strong>(depthwise separable convolution) 층이며
아래 그림처럼 채널 별로 생성된 결과를 합친 후 <code class="docutils literal notranslate"><span class="pre">1x1</span></code> 합성곱 신경망을 통과시킨다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/Figures/09-10.png" style="width:70%;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>SeparableConv2D 작동 원리</strong></p>
<p>이미지에 저장된 정보가 채널 별로 서로 독립적이라는 가정을 사용한다.
따라서 채널 별로 서로 다른 필터를 사용한 후 결과들을 <code class="docutils literal notranslate"><span class="pre">1x1</span></code> 모양의 필터를 사용하여 합친다.
이때 원하는 종류의 채널 수 만큼의 <code class="docutils literal notranslate"><span class="pre">1x1</span></code> 모양의 필터를 사용하여
다양한 정보를 추출한다.</p>
<p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>와 <code class="docutils literal notranslate"><span class="pre">SeparableConv2D</span></code>의 서로 다른 작동과정은 다음과 같이 설명된다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 작동 원리</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">padding=&quot;same&quot;</span></code> 옵션 사용한 경우</p></li>
<li><p>필터 1개 사용</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://miro.medium.com/max/428/1*sYpl-7LlrtlOKW8RvlyKOg.png" style="width:28%;"></div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">SeparableConv2D</span></code> 작동 원리</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">padding=&quot;same&quot;</span></code> 옵션 사용한 경우</p></li>
<li><p>필터 1개 사용</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://miro.medium.com/max/604/1*JwCJCgN2UreEn3U1nwVj8Q.png" style="width:60%;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://medium.com/@zurister/depth-wise-convolution-and-depth-wise-separable-convolution-37346565d4ec">Depth-wise Convolution and Depth-wise Separable Convolution</a>&gt;</div></p><p><strong>층의 파라미터 개수 비교</strong></p>
<p>채널 분리 합성곱 신경망이 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층을 사용하는 경우보다 몇 배 이상 적은 수의
파라미터를 사용한다.</p>
<p>경우 1(위 그림): <code class="docutils literal notranslate"><span class="pre">3x3</span></code> 모양의 필터 64개를 3개의 채널을 갖는 입력 데이터에 사용할 경우</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>의 경우: <code class="docutils literal notranslate"><span class="pre">3*3*3*64</span> <span class="pre">=</span> <span class="pre">1,728</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SeparableConv2D</span></code>의 경우: <code class="docutils literal notranslate"><span class="pre">3*3*3</span> <span class="pre">+</span> <span class="pre">3*64</span> <span class="pre">=</span> <span class="pre">219</span></code></p></li>
</ul>
<p>경우 2: <code class="docutils literal notranslate"><span class="pre">3x3</span></code> 모양의 필터 64개를 10개의 채널을 갖는 입력 데이터에 사용할 경우</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>의 경우: <code class="docutils literal notranslate"><span class="pre">3*3*10*64</span> <span class="pre">=</span> <span class="pre">5,760</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SeparableConv2D</span></code>의 경우: <code class="docutils literal notranslate"><span class="pre">3*3*10</span> <span class="pre">+</span> <span class="pre">10*64</span> <span class="pre">=</span> <span class="pre">730</span></code></p></li>
</ul>
<p><strong>채널 분리 합성곱의 약점</strong></p>
<p>채널 분리 합성곱의 연산이 CUDA에서 제대로 지원되지 않는다.
따라서 GPU를 사용하더라도 기존 <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> 층만을 사용한 모델에 비해
학습 속도에 별 차이가 없다.
즉 채널 분리 합성곱이 비록 훨씬 적은 수의 파라미터를 학습에 사용하지만
이로 인해 시간상의 이득은 주지 않는다.
하지만 적은 수의 파라미터를 사용하기에 일반화 성능이 보다 좋은 모델을
구현한다는 점이 매우 중요하다.</p>
<p><strong>참고</strong>: CUDA와 cuDNN</p>
<ul class="simple">
<li><p>CUDA(Compute Unified Device Architecture)</p>
<ul>
<li><p>CPU와 GPU를 동시에 활용하는 병렬 컴퓨팅을 지원하는 플랫폼</p></li>
<li><p>C, C++, Fortran 등의 저수준 언어 활용</p></li>
</ul>
</li>
<li><p>cuDNN(CUDA Deep Neural Network): CUDA를 활용하여 딥러닝 알고리즘의 실행을 지원하는 라이브러리</p>
<ul>
<li><p>Conv2D 등 특정 딥러닝 알고리즘에 대해서만 최적화됨.</p></li>
</ul>
</li>
</ul>
<p><strong>미니 Xception 모델</strong></p>
<p>미니 Xception 모델을 직접 구현하여 강아지-고양이 이항분류 작업을 실행해본다.
모델 구현에 사용되는 기법을 정리하면 다음과 같다.</p>
<ul class="simple">
<li><p>모듈을 쌓을 수록 필터 수는 증가시키고, 텐서 크기는 감소시킨다.</p></li>
<li><p>층의 파라미터 수는 가능한 적게 유지하고 모듈은 높게 쌓는다.</p></li>
<li><p>잔차 연결을 활용한다.</p></li>
<li><p>모든 합성곱 층 이후에는 배치 정규화를 적용한다.</p></li>
<li><p>채널 분리 합성곱 신경망을 활용한다.</p></li>
</ul>
<p>여기서는 비록 이미지 분류 모델을 예제로 활용하지만 앞서 언급된 기법은
컴퓨터 비전 프로젝트 일반에 적용될 수 있다.
예를 들어 <a class="reference external" href="https://arxiv.org/abs/1802.02611">DeepLabV3 모델</a>은
Xception 모델을 이용하는 2021년 기준 최고의 이미지 분할 모델이다.</p>
<p>사용하는 데이터셋은 <a class="reference internal" href="computer_vision_intro.html#ch-computer-vision-intro"><span class="std std-numref">9장</span></a>에서
사용한 캐글(kaggle)의 강아지-고양이 데이터셋이며,
데이터 증식층, 합성곱 층, 채널 분리 합성곱 층을 이용하여
아래와 같이 이진 분류 모델을 구성한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 데이터 증식 층</span>
<span class="n">data_augmentation</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="p">[</span><span class="n">layers</span><span class="o">.</span><span class="n">RandomFlip</span><span class="p">(</span><span class="s2">&quot;horizontal&quot;</span><span class="p">),</span>
 <span class="n">layers</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
 <span class="n">layers</span><span class="o">.</span><span class="n">RandomZoom</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)]</span>
<span class="p">)</span>

<span class="c1"># 입력층</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">180</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">data_augmentation</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Rescaling</span><span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 하나의 Conv2D 은닉층</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># SeparableConv2D, BatchNormalization, MaxPooling2D 층으로 구성된 모듈 쌓기</span>
<span class="c1"># 잔차 연결 활용</span>
<span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">]:</span>   <span class="c1"># 필터 수</span>
    <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SeparableConv2D</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SeparableConv2D</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># 잔차 연결</span>
    <span class="n">residual</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="n">residual</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">residual</span><span class="p">])</span>

<span class="c1"># 마지막 은닉층은 GlobalAveragePooling2D과 Dropout</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>    <span class="c1"># flatten 역할 수행(채널 별 평균값으로 구성)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 출력층</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 모델 지정</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
<p>이진 분류 모델의 훈련을 시작한 후 50번 정도의 에포크 실행 후에 과대적합이 발생한다.</p>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/HighResolutionFigures/figure_9-11.png" style="width:80%;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p>직접 구현한 모델이지만 테스트셋에 대한 정확도가 90% 정도 나오며,
<a class="reference internal" href="computer_vision_intro.html#ch-computer-vision-intro"><span class="std std-numref">9장</span></a>에서 직접 구현해서 훈련시킨 모델의 성능인 83% 정도보다 훨씬 높게 나온다.
보다 성능을 높이려면 하이퍼파라미터를 조정하거나 앙상블 학습을 적용한다 (<a class="reference internal" href="best_practices.html#ch-best-practices"><span class="std std-numref">14장</span></a> 참고).</p>
</section>
</section>
<section id="kerascv">
<h2><span class="section-number">10.4. </span>KerasCV 라이브러리<a class="headerlink" href="#kerascv" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://keras.io/guides/keras_cv/">KerasCV</a>는 컴퓨터 비전에서 활용될 수 있는 케라스 라이브러리 모음집이다.
<a class="reference external" href="https://www.youtube.com/watch?v=K2PKZS1fPlY&amp;amp;t=771s">유튜브: Applied ML with KerasCV and KerasNLP</a>에서 KerasCV에 대한 간략한 소개를 시청할 수 있다.</p>
</section>
<section id="id8">
<h2><span class="section-number">10.5. </span>연습 문제<a class="headerlink" href="#id8" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://colab.research.google.com/github/codingalzi/dlp2/blob/master/excs/exc-computer_vision_advanced.ipynb">(실습) 고급 컴퓨터 비전</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/code/aritrag/0-11-keras-starter-unet-tf-data-pipeline/notebook">ink detection with Keras</a> 내용 학습 후 깃허브 페이지에 블로그 작성하기</p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="computer_vision_intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">9. </span>합성곱 신경망</p>
      </div>
    </a>
    <a class="right-next"
       href="dl_for_timeseries.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">11. </span>시계열 분석</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">10.1. 컴퓨터 비전 주요 과제</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">10.2. 이미지 분할</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cnn">10.3. CNN 아키텍처 주요 유형</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">10.3.1. 모듈(블록), 계층, 재활용</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">10.3.2. 잔차 연결</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">10.3.3. 배치 정규화</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">10.3.4. 채널 분리 합성곱</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kerascv">10.4. KerasCV 라이브러리</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">10.5. 연습 문제</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By 코딩알지
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>