
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. 딥러닝이란? &#8212; Deep Learning with Python(2판)</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="2. 딥러닝의 수학적 구성요소" href="mathematical_building_blocks.html" />
    <link rel="prev" title="&lt;no title&gt;" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Deep Learning with Python(2판)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. 딥러닝이란?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mathematical_building_blocks.html">
   2. 딥러닝의 수학적 구성요소
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/what_is_deep_learning.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/codingalzi/dlp2"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/codingalzi/dlp2/issues/new?title=Issue%20on%20page%20%2Fwhat_is_deep_learning.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/codingalzi/dlp2/master?urlpath=tree/jupyter-book/what_is_deep_learning.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   1.1. 인공지능, 머신러닝, 딥러닝
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     1.1.1. 인공지능
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     1.1.2. 머신러닝
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     1.1.3. 데이터 표현법 학습
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       1.1.3.1. 머신러닝 모델
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       1.1.3.2. 예제: 선형 분류
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id8">
       1.1.3.3. 데이터 변환 수동화의 어려움
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id9">
       1.1.3.4. 데이터 변환 자동화
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       1.1.3.5. 가설 공간
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#deep">
     1.1.4. 딥러닝의 ‘딥’(deep)이란?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id11">
       1.1.4.1. 신경망
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     1.1.5. 딥러닝 작동 원리
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a">
       1.1.5.1. A. 가중치
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#b">
       1.1.5.2. B. 손실 함수
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#c">
       1.1.5.3. C. 역전파
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     1.1.6. 딥러닝의 지금까지 성과
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     1.1.7. 전망
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id15">
   1.2. 1.2 딥러닝 이전: 머신러닝의 역사
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id16">
     1.2.1. 확률적 모델링
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id17">
     1.2.2. 초창기 신경망
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id18">
     1.2.3. 커널 기법
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id19">
     1.2.4. 결정트리, 랜덤 포레스트, 그레이디언트 부스팅 머신
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id20">
     1.2.5. 딥러닝의 본격적 발전
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id21">
     1.2.6. 딥러닝의 특징
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id22">
       1.2.6.1. 최근 머신러닝 분야의 동향 1
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id23">
       1.2.6.2. 최근 머신러닝 분야의 동향 2
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id24">
   1.3. 1.3 딥러닝 발전 동력
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id25">
     1.3.1. 딥러닝 주요 요소
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id26">
     1.3.2. 하드웨어
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id27">
     1.3.3. 데이터
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id28">
     1.3.4. 알고리즘
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id29">
     1.3.5. 투자
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id30">
     1.3.6. 딥러닝의 대중화
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id31">
     1.3.7. 딥러닝의 미래
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>딥러닝이란?</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   1.1. 인공지능, 머신러닝, 딥러닝
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     1.1.1. 인공지능
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     1.1.2. 머신러닝
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     1.1.3. 데이터 표현법 학습
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       1.1.3.1. 머신러닝 모델
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       1.1.3.2. 예제: 선형 분류
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id8">
       1.1.3.3. 데이터 변환 수동화의 어려움
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id9">
       1.1.3.4. 데이터 변환 자동화
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       1.1.3.5. 가설 공간
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#deep">
     1.1.4. 딥러닝의 ‘딥’(deep)이란?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id11">
       1.1.4.1. 신경망
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     1.1.5. 딥러닝 작동 원리
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a">
       1.1.5.1. A. 가중치
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#b">
       1.1.5.2. B. 손실 함수
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#c">
       1.1.5.3. C. 역전파
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     1.1.6. 딥러닝의 지금까지 성과
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     1.1.7. 전망
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id15">
   1.2. 1.2 딥러닝 이전: 머신러닝의 역사
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id16">
     1.2.1. 확률적 모델링
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id17">
     1.2.2. 초창기 신경망
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id18">
     1.2.3. 커널 기법
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id19">
     1.2.4. 결정트리, 랜덤 포레스트, 그레이디언트 부스팅 머신
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id20">
     1.2.5. 딥러닝의 본격적 발전
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id21">
     1.2.6. 딥러닝의 특징
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id22">
       1.2.6.1. 최근 머신러닝 분야의 동향 1
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id23">
       1.2.6.2. 최근 머신러닝 분야의 동향 2
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id24">
   1.3. 1.3 딥러닝 발전 동력
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id25">
     1.3.1. 딥러닝 주요 요소
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id26">
     1.3.2. 하드웨어
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id27">
     1.3.3. 데이터
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id28">
     1.3.4. 알고리즘
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id29">
     1.3.5. 투자
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id30">
     1.3.6. 딥러닝의 대중화
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id31">
     1.3.7. 딥러닝의 미래
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="id1">
<h1><span class="section-number">1. </span>딥러닝이란?<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id2">
<h2><span class="section-number">1.1. </span>인공지능, 머신러닝, 딥러닝<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p><strong>관계 1: 연구 분야</strong></p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ai-ml-relation.png" style="width:600px;"></div>
<p>그림 출처: <a class="reference external" href="http://www.kyobobook.co.kr/readIT/readITColumnView.laf?thmId=00198&amp;sntnId=14142">교보문고(에이지 오브 머신러닝)</a></p>
<p><strong>관계 2: 역사</strong></p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ai-ml-relation2.png" style="width:600px;"></div>
<p>그림 출처: <a class="reference external" href="https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/">NVIDIA 블로그</a></p>
<div class="section" id="id3">
<h3><span class="section-number">1.1.1. </span>인공지능<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>인공지능: 인간의 지적 활동을 모방하여 컴퓨터로 자동화하려는 시도. 머신러닝과 딥러닝을 포괄함.</p></li>
<li><p>(1950년대) 컴퓨터가 생각할 수 있는가? 라는 질문에서 출발</p></li>
<li><p>(1956년) 존 맥카시(John McCarthy)</p>
<ul>
<li><p>컴퓨터로 인간의 모든 지적 활동 구현하는 것이 가능하다고 판단.</p></li>
</ul>
</li>
<li><p>(1980년대까지) <strong>학습</strong>(러닝)이 아닌 모든 가능성을 논리적으로 전개하는 기법 활용</p>
<ul>
<li><p>서양장기(체스) 등에서 우수한 성능 발휘</p></li>
<li><p>반면에 이미지 분류, 음석 인식, 자연어 번역 등 보다 복잡한 문제는 제대로 다루지 못함.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id4">
<h3><span class="section-number">1.1.2. </span>머신러닝<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>전통적 프로그래밍</p>
<ul>
<li><p>컴퓨터가 수행해야 할 규칙을 순서대로 적어 놓은 프로그램 작성</p></li>
<li><p>입력값이 지정되면 지정된 규칙을 수행하여 적절한 답을 생성함.</p></li>
</ul>
</li>
<li><p>머신러닝 시스템</p>
<ul>
<li><p>주어진 입력 데이터와 출력 데이터로부터 입력과 출력 사이에 존재하는
특정 통계적 구조를 스스로 알아내어
이를 이용하여 입력값으로부터 출력값을 생성하는 규칙을 생성함.</p></li>
<li><p>예제: 사진 태그 시스템. 태그 달린 사진 데이터셋을 학습한 후
자동으로 사진의 태그 작성.</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-a-new-programming-paradigm.png" style="width:400px;"></div>
<p>그림 출처: <a class="reference external" href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(Manning MEAP)</a></p>
<ul class="simple">
<li><p>1990년대 본격적으로 발전.</p></li>
<li><p>머신러닝은 통계학과 많이 관련되지만 다름.</p>
<ul>
<li><p>아주 큰 데이터(빅데이터)를 단순히 통계학적으로 다룰 수는 없음.</p></li>
<li><p>딥러닝의 경우 수학적, 통계적 이론 보다는 공학적 접근법이 보다 중요해짐.
소프트웨어와 하드웨어의 발전이 중요한 영향을 끼침.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id5">
<h3><span class="section-number">1.1.3. </span>데이터 표현법 학습<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>데이터 <strong>표현</strong>(data representation): 특정한 방식으로 구현된 데이터</p></li>
<li><p>예제: 컬러 이미지 표현법</p>
<ul>
<li><p>빨간색-초록색-파란색을 사용하는 RGB 방식 또는</p></li>
<li><p>색상-채도-명도를 사용하는 HSV 방식</p></li>
</ul>
</li>
<li><p>주어진 과제에 따라 적절한 표현법 선택해야 함</p>
<ul>
<li><p>컬러 사진에서 빨간색 픽셀만을 선택하고자 할 때: RGB 방식 활용</p></li>
<li><p>컬리 이미지의 채도를 낮추고자 할 때: HSV 방식 활용</p></li>
</ul>
</li>
</ul>
<div class="section" id="id6">
<h4><span class="section-number">1.1.3.1. </span>머신러닝 모델<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>필요 사항</p>
<ul>
<li><p><strong>입력 데이터셋</strong>: 음성 인식 모델을 위한 음성 파일, 이미지 태깅 모델을 위한 사진 등.</p></li>
<li><p><strong>기대 출력값</strong>: 음성 인식 작업의 경우 사람이 직접 작성한 글,
이미지 작업의 경우 ‘강아지’, ‘고양이’, 등의 사람이 직접 붙힌 태그.</p></li>
<li><p><strong>알고리즘 성능측정법</strong>: 출력 예상값과 기대 출력값 사이의 거리(차이) 측정법.
거리를 줄이는 방향으로 알고리즘에 사용되는 파라미터를 반복 수정하는
과정을 __학습__이라 부름.</p></li>
</ul>
</li>
<li><p>역할: 입력 데이터를 적절한 표현으로 변환한 후, 변환된 테이터셋으로부터
과제 해결을 위한 적절한 수학적, 통계적 규칙 찾기</p></li>
</ul>
</div>
<div class="section" id="id7">
<h4><span class="section-number">1.1.3.2. </span>예제: 선형 분류<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h4>
<ol class="simple">
<li><p>왼쪽 그림: 입력 데이터셋</p></li>
<li><p>가운데 그림: 부적절한 좌표 변환. 분류 과제 해결에 적합하지 않음.</p></li>
<li><p>오른쪽 그림: 적절한 좌표 변환. 분류 과제를 보다 효율적으로 해결할 수 있음.</p></li>
</ol>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-learning_representations.png" style="width:700px;"></div>
<p>그림 출처: <a class="reference external" href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(Manning MEAP)</a></p>
</div>
<div class="section" id="id8">
<h4><span class="section-number">1.1.3.3. </span>데이터 변환 수동화의 어려움<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>위 예제의 경우 수동으로 데이터 변환 방식을 어렵지 않게 알아낼 수 있음.</p></li>
<li><p>반면에 손글씨 숫자 인식(MNIST)의 경우 간단하지 않음(아래 그림 참조).</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ch03/homl03-10.png" width="300"/></div>
<p>그림 출처: <a class="reference external" href="https://www.hanbit.co.kr/store/books/look.php?p_code=B9267655530">핸즈온 머신러닝(2판)</a></p>
</div>
<div class="section" id="id9">
<h4><span class="section-number">1.1.3.4. </span>데이터 변환 자동화<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>머신러닝 모델 학습: 보다 유용한 데이터 표현으로 변환하는 과정을 자동으로 찾는 과정</p></li>
<li><p>__데이터 표현의 유용성__에 대한 기준: 주어진 과제 해결을 위한 보다 쉬운 규칙 제공</p></li>
<li><p>변환 방식 종류</p>
<ul>
<li><p>좌표 변환, 픽셀 개수, 닫힌 원의 개수, 선형/비선형 변환, 이동, …</p></li>
<li><p>기본적으로 주어진 문제에 따라 다른 변환 방식 활용</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id10">
<h4><span class="section-number">1.1.3.5. </span>가설 공간<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>주어진 문제에 가장 적절한 변환을 머신러닝 알고리즘 스스로 알아내기는 기본적으로 불가능.</p></li>
<li><p><strong>가설 공간</strong>: 프로그래머에 의해 지정된 함수들의 집합</p></li>
<li><p>머신러닝 알고리즘: 가설공간 내에서 적합한 변환 함수 탐색</p></li>
<li><p>예제: 위 2차원 좌표 변환 문제의 가설 공간은 ‘모든 가능한 좌표 변환 함수’들의 집합</p></li>
</ul>
</div>
</div>
<div class="section" id="deep">
<h3><span class="section-number">1.1.4. </span>딥러닝의 ‘딥’(deep)이란?<a class="headerlink" href="#deep" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>‘딥’(deep)이란?: __데이터 표현의 연속적 변환__을 지원하는 여러 개의 ‘층’(layer)을 활용한 학습</p></li>
<li><p>즉 __계층적 표현 학습__을 지원하는 머신러닝을 딥러닝이라 부름.</p></li>
<li><p>딥러닝 모델의 깊이 = 계층으로 쌓아 올린 층의 높이</p>
<ul>
<li><p>수 십개 또는 수 백개의 층으로 구성된 모델 존재</p></li>
<li><p>모든 층에서 데이터 표현의 변환이 __자동__으로 이루어지는 것이 핵심!</p></li>
</ul>
</li>
<li><p>섈로우 러닝(shallow learning): 한 두 개의 층만 사용하는 학습</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ch14/homl14-15b.png" width="700"/></div>
<p>&lt;그림 참조: <a class="reference external" href="https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html">ImageNet Classification with Deep Convolutional Neural Networks</a>&gt;</p>
<div class="section" id="id11">
<h4><span class="section-number">1.1.4.1. </span>신경망<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>유닛(unit): 층(layer)을 구성하는 요소. 몇 개에서 몇 십개로 이루어짐.</p></li>
<li><p>신경망(neural network): 계층적 표현 학습이 이루어지는 모델</p>
<ul>
<li><p><strong>계층적 ‘인풋-투-타깃’(input-to-target) 변환</strong> 학습 모델</p></li>
<li><p>예제: 숫자 이미지 <span class="math notranslate nohighlight">\(\Rightarrow \cdots \Rightarrow\)</span> 숫자</p></li>
</ul>
</li>
<li><p>단순하지만 매우 강력한 결과를 생산하는 아이디어! <strong>뇌 과학과 아무 상관 없음!</strong></p></li>
</ul>
<ul class="simple">
<li><p>예제: 손글씨 숫자 인식</p></li>
</ul>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-mnist_representations.png" style="width:550px;"></div>
<p>그림 출처: <a class="reference external" href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(Manning MEAP)</a></p>
</div>
</div>
<div class="section" id="id12">
<h3><span class="section-number">1.1.5. </span>딥러닝 작동 원리<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p>딥러닝 모델의 작동 원리를 이해하려면 다음 세 개념에 집중해야 함</p>
<ul class="simple">
<li><p>가중치(weight)</p></li>
<li><p>손실 함수(loss function)</p></li>
<li><p>역전파(backpropagation)</p></li>
</ul>
<div class="section" id="a">
<h4><span class="section-number">1.1.5.1. </span>A. 가중치<a class="headerlink" href="#a" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>데이터 표현의 변환에 사용되는 <strong>파라미터</strong>(parameter)</p></li>
<li><p>학습: 적절한 가중치를 모든 층에 대해 동시에(!) 찾는 과정</p>
<ul>
<li><p>하나의 가중치가 변하면 모든 다른 가중치도 변함!</p></li>
</ul>
</li>
<li><p>많게는 수 천만 개의 가중치를 학습해야 함.</p></li>
</ul>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-deep-learning-in-3-figures-1.png" style="width:500px;"></div>
<p>그림 출처: <a class="reference external" href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(Manning MEAP)</a></p>
</div>
<div class="section" id="b">
<h4><span class="section-number">1.1.5.2. </span>B. 손실 함수<a class="headerlink" href="#b" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>신경망의 출력값(output)과 타깃(target) 사이의 거리 측정. 가중치에 의존.</p></li>
<li><p><strong>목적 함수</strong>(objective function) 또는 <strong>비용 함수</strong>(cost function)라고도 불림</p></li>
<li><p>손실 함수의 반환값을 학습 과정에서 성능 평가용 피드백으로 활용.</p></li>
</ul>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-deep-learning-in-3-figures-2.png" style="width:500px;"></div>
<p>그림 출처: <a class="reference external" href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(Manning MEAP)</a></p>
</div>
<div class="section" id="c">
<h4><span class="section-number">1.1.5.3. </span>C. 역전파<a class="headerlink" href="#c" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>역전파(backpropagation) 알고리즘:
경사하강법에 기초하여 손실함수의 출력값과
타깃 사이의 거리를 좁혀주는 알고리즘</p></li>
<li><p>옵티마이저(optimizer): 역전파 알고리즘을 구현한 프로그램.</p>
<ul>
<li><p>모든 가중치 무작위 초기화: 결과적으로 손실값 매우 높음.</p></li>
<li><p>훈련 반복: 손실값이 낮아지도록 가중치 조절.</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-deep-learning-in-3-figures-3.png" style="width:500px;"></div>
<p>그림 출처: <a class="reference external" href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(Manning MEAP)</a></p>
</div>
</div>
<div class="section" id="id13">
<h3><span class="section-number">1.1.6. </span>딥러닝의 지금까지 성과<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>사람과 비슷한 수준의 이미지 분류, 음성 인식, 필기 인식, 자율 주행</p></li>
<li><p>상당한 성능의 기계 번역, TTS(text-to-speech) 변환</p></li>
<li><p>구글 어시스턴트, 아마존 알레사 등의 디지털 도우미</p></li>
<li><p>향상된 광고 타게팅, 웹 검색</p></li>
<li><p>자연어 질문 대처 능력</p></li>
<li><p>초인류 바둑 실력(2013 알파고)</p></li>
</ul>
</div>
<div class="section" id="id14">
<h3><span class="section-number">1.1.7. </span>전망<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>단기적으로 너무 높은 기대를 갖는 것은 위험함.</p>
<ul>
<li><p>실망할 경우 AI에 대한 투자가 급속도로 줄어들 수 있음.</p></li>
<li><p>1970년대와 1990년대 1차, 2차 AI 겨울(AI winter) 경험</p></li>
</ul>
</li>
<li><p>2020년대 초반 현재 중요한 문제에 본격적으로 딥러닝 적용되고 있지만 대중화는 아직.</p></li>
<li><p>1995년의 인터넷 처럼 앞으로 딥러닝의 가져올 영향에 대해 제대로 알 수 없음.</p></li>
</ul>
</div>
</div>
<div class="section" id="id15">
<h2><span class="section-number">1.2. </span>1.2 딥러닝 이전: 머신러닝의 역사<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>산업계에서 사용되는 머신러닝 알고리즘의 대부분은 딥러닝 알고리즘이 아님.</p></li>
<li><p>훈련 데이터가 너무 적거나, 딥러닝과 다른 알고리즘이 보다 좋은 성능 발휘 가능.</p></li>
</ul>
<div class="section" id="id16">
<h3><span class="section-number">1.2.1. </span>확률적 모델링<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>나이브 베이즈 알고리즘(Naive Bayes algorithm)을 활용하는 분석 기법이 대표적임.</p></li>
<li><p>베이즈 정리(Bayes theorem)에 기초하는 전통적인 기법</p></li>
<li><p>1950년대 부터 컴퓨터 없이 적용 시작</p></li>
<li><p>베이즈 정리 등 확률론의 기초는 18세기에 시작</p></li>
<li><p>예제: 로지스틱 회귀(logistic regression)</p></li>
</ul>
</div>
<div class="section" id="id17">
<h3><span class="section-number">1.2.2. </span>초창기 신경망<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>기본 아이디어: 1950년대부터 연구됨.</p></li>
<li><p>LeNet 합성곱 신경망: 손글씨 숫자 이미지 자동 분류 시스템</p>
<ul>
<li><p>1989년 벨 연구소(Bell Labs)의 얀 르쿤(Yann LeCun)</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ch14/homl14-16.gif" width="400"/></div>
<p>&lt; 그림 출처: <a class="reference external" href="http://yann.lecun.com/exdb/lenet/index.html">LeNet-T CNN</a> &gt;</p>
</div>
<div class="section" id="id18">
<h3><span class="section-number">1.2.3. </span>커널 기법<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>1990년대: 서포트 벡터 머신(SVM) + 커널 기법</p></li>
<li><p>초창기 신경망 성능을 뛰어 넘음.</p></li>
<li><p>한계</p>
<ul>
<li><p>대용량 데이터셋 처리에 부적합(매우 느림)</p></li>
<li><p>이미지 분류 등 지각 문제 해결 어려움</p></li>
</ul>
</li>
<li><p><strong>특성 공학</strong>(feature engineering)에 약함</p>
<ul>
<li><p>유용한 데이터 표현으로의 변환을 수동을 해결해야 함</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id19">
<h3><span class="section-number">1.2.4. </span>결정트리, 랜덤 포레스트, 그레이디언트 부스팅 머신<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>(2000년대) 결정트리: 입력값을 순서도 형식으로 특정 기준으로 분류하는 방식</p></li>
<li><p>랜덤 포레스트: 2010년 경까지 커널 기법보다 선호됨.</p></li>
<li><p>그레이디언트 부스팅 머신: 2014년 경 가장 선호되는 앙상블 학습 기법</p>
<ul>
<li><p>지각 문제 이외의 경우 여전히 가장 성능이 좋은 모델 중 하나임.</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-decision_tree.png" style="width:350px;"></div>
<p>그림 출처: <a class="reference external" href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(Manning MEAP)</a></p>
</div>
<div class="section" id="id20">
<h3><span class="section-number">1.2.5. </span>딥러닝의 본격적 발전<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>2011년: GPU를 활용한 딥 신경망 훈련 시작</p></li>
<li><p>2012년: ImageNet Challenge(이미지 분류 경진대회)의 획기적 성공</p>
<ul>
<li><p>2011년 최고 성능: 74.3%의 정확도</p></li>
<li><p>2012년 합성곱 신경망(convnet)의 최고 성능: 83.6%의 정확도</p></li>
<li><p>2015년 최고 성능: 96.4%의 정확도</p></li>
<li><p>ImageNet Challenge 대회 더 이상 진행되지 않음.</p></li>
</ul>
</li>
<li><p>2015년 이후: 많은 문제 영역에서 SVM, 결정트리 등을 딥러닝 모델로 대체함.</p></li>
</ul>
</div>
<div class="section" id="id21">
<h3><span class="section-number">1.2.6. </span>딥러닝의 특징<a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>자동화된 데이터 표현의 변환, 즉 특성 공학 자동화</p></li>
<li><p>층을 거치면서 점진적으로 더 복잡한 데이터 표현을 만들어 냄.</p></li>
<li><p>모든 과정의 데이터 표현의 변환, 즉 모든 층에 대한 특성 공학 스스로 해결</p></li>
</ul>
<div class="section" id="id22">
<h4><span class="section-number">1.2.6.1. </span>최근 머신러닝 분야의 동향 1<a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>2019년 캐글(Kaggle) 경진대회에서 상위팀이 사용한 도구 설문조사 결과</p></li>
</ul>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/kaggle_top_teams_tools.png" style="width:500px;"></div>
<p>그림 출처: <a class="reference external" href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(Manning MEAP)</a></p>
</div>
<div class="section" id="id23">
<h4><span class="section-number">1.2.6.2. </span>최근 머신러닝 분야의 동향 2<a class="headerlink" href="#id23" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>데이터과학 일반에서 가장 많이 사용되는 도구(캐글 설문조사 2020)</p></li>
</ul>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/kaggle_ds_survey_2020.png" style="width:500px;"></div>
<p>그림 출처: <a class="reference external" href="https://www.kaggle.com/kaggle-survey-2020">www.kaggle.com/kaggle-survey-2020(20쪽)</a></p>
</div>
</div>
</div>
<div class="section" id="id24">
<h2><span class="section-number">1.3. </span>1.3 딥러닝 발전 동력<a class="headerlink" href="#id24" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id25">
<h3><span class="section-number">1.3.1. </span>딥러닝 주요 요소<a class="headerlink" href="#id25" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>컴퓨터 비전, 자연어 인식 분야가 2012년 이후 획기적으로 발전하였음.</p></li>
<li><p>획기적 발전에 기여한 아래 기법은 하지만 1990년대에 제시됨</p>
<ul>
<li><p>1990년: 합성곱 신경망(convnet, convolutional neural network)과 역전파(backpropagation)</p></li>
<li><p>1997년: LSTM(Long Short-Term Memory)</p></li>
</ul>
</li>
<li><p>2010년대에 딥러닝의 급격한 발전에 기여한 세 가지 요소</p>
<ul>
<li><p>하드웨어</p></li>
<li><p>데이터셋과 벤치마크</p></li>
<li><p>알고리즘</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id26">
<h3><span class="section-number">1.3.2. </span>하드웨어<a class="headerlink" href="#id26" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>CPU: 1990년에 비해 5,000배 이상 빨라짐</p></li>
<li><p>GPU(Graphical Processing Unit):</p>
<ul>
<li><p>NVIDIA, AMD: 2000년대부터 게임용 그래픽 카드 개발에 천문학적으로 투자</p></li>
<li><p>2007년 NVIDIA의 CUDA 개발: GPU를 위한 프로그래밍 인터페이스. 다량의 행렬 계산을 병렬처리 가능해짐.</p></li>
<li><p>2011년: 신경망용 CUDA 개발.</p></li>
</ul>
</li>
<li><p>TPU(Tensor Processing Unit): 2016년 구글이 소개한 딥러닝 전용 칩.</p>
<ul>
<li><p>GPU보다 훨씬 빠르고 에너지 효율적임.</p></li>
<li><p>2020년에 3세대 TPU 카드 발표. 1990년의 최고 슈퍼컴퓨터보다 10,000배 이상 빠름.</p></li>
<li><p>2020년 최고의 슈퍼컴퓨터 = 27,000 개의 NVIDIA GPUs = 10개의 pod 성능
(1 pod = 1024개의 TPU 카드)</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id27">
<h3><span class="section-number">1.3.3. </span>데이터<a class="headerlink" href="#id27" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>인터넷과 저장장치의 발전으로 인한 엄청난 양의 데이터 축적</p>
<ul>
<li><p><strong>무어의 법칙</strong>(Moore’s law): 2년마다 반도체 집적회로의 성능이 2배로 향상됨.</p></li>
</ul>
</li>
<li><p>Flickr(이미지), YouTube(동영상), Wikipedia(문서) 등이 컴퓨터 비전과 자연어 처리(NLP)의
혁신적 발전의 기본 전제조건이었음.</p></li>
<li><p>벤치마크(성능비교)의 활성화</p>
<ul>
<li><p>ImageNet 데이터셋: 140만 개의 이미지와 손으로 작성된 1,000개의 클래스 태그</p></li>
<li><p>IamgeNet Challenge, Kaggle Competitions 등과 같은 경진대회</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id28">
<h3><span class="section-number">1.3.4. </span>알고리즘<a class="headerlink" href="#id28" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>2000년대 후반까지 딥러닝 네트워크를 효율적으로 훈련시킬 수 있는 알고리즘 부재(역전파 문제 미해결)</p></li>
<li><p>2009-2010: 주요 알고리즘 개선</p>
<ul>
<li><p>보다 좋은 신경망 층에 사용되는 활성화 함수</p></li>
<li><p>보다 좋은 가중치 초기화</p></li>
<li><p>보다 좋은 옵티마이저(RMSProp, Adam 등)</p></li>
</ul>
</li>
<li><p>2014-2016: 역전파에 도움되는 다양한 기법 개발</p>
<ul>
<li><p>배치 정규화(batch normalization), 잔차 연결(residual connection),
깊이별 분리 합성곱(depthwise separable convolution) 등</p></li>
</ul>
</li>
<li><p>현재: 수십 개의 층을 가지며 수천 만개의 가중치(파라미터)를 갖는
깊은 층으로 구성된 신경망 네트워크 훈련 가능</p></li>
</ul>
</div>
<div class="section" id="id29">
<h3><span class="section-number">1.3.5. </span>투자<a class="headerlink" href="#id29" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>2013년 이후 투자가 획기적으로 증가함</p></li>
</ul>
<div align="center"><img src="https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/startup_investment_oecd.png" style="width:500px;"></div>
<p>그림 출처: <a class="reference external" href="https://www.oecd-ilibrary.org/sites/3abc27f1-en/index.html?itemId=/content/component/3abc27f1-en&amp;mimeType=text/html">OECD estimate of total investments in AI startups</a></p>
</div>
<div class="section" id="id30">
<h3><span class="section-number">1.3.6. </span>딥러닝의 대중화<a class="headerlink" href="#id30" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>이전: C++, CUDA 등을 이용한 어려운 프로그램을 구현할 수 있었어야 함.</p></li>
<li><p>지금: 파이썬 기초 프로그래밍 수준에서 시작 가능</p>
<ul>
<li><p>Sci-kit Learn, Theano, Tensorflow, Keras 등의 라이브러리 활용</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id31">
<h3><span class="section-number">1.3.7. </span>딥러닝의 미래<a class="headerlink" href="#id31" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>여전히 딥러닝 혁신적 발전이 진행중임.</p>
<ul>
<li><p>최근의 가장 큰 혁신: 트랜스포머(transformer) 기법를 이용한 자연어 처리</p></li>
</ul>
</li>
<li><p>20년 뒤엔 알 수 없음. 하지만 딥러닝 발전의 토대를 이룬 아래 요소는 계속해서 활용될 것으로 기대함.</p>
<ul>
<li><p>단순함: 특성 공학의 자동화로 인해 모델 생성과 훈련이 단순화됨.</p></li>
<li><p>확장성: GPU 또는 TPU 등을 이용한 병렬화가 가능하기에 무어의 법칙을 최대한 활용할 수 있음.
작은 크기의 데이터 배치(묶음)로 나눈 후 훈련 반복을 병렬화하면 임의의 크기의 데이터셋을
이용한 훈련이 가능해짐.</p></li>
<li><p>다용도와 재사용성: 추가 입력된 데이터로 훈련을 이어갈 수 있음.
또한 잘 훈련된 모델을 다른 용도의 모델 훈련에 재활용할 수 있음.
이는 또한 아주 작은 데이터셋을 대상으로 딥러닝 모델을 적용할 수 있도록 해줌.</p></li>
</ul>
</li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">&lt;no title&gt;</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="mathematical_building_blocks.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2. </span>딥러닝의 수학적 구성요소</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By 코딩알지<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>