{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (실습) 자연어 처리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are the pros and cons of using a stateful RNN versus a stateless RNN?\n",
    "2. Why do people use encoder–decoder RNNs rather than plain sequence-to-sequence RNNs for automatic translation?\n",
    "3. How can you deal with variable-length input sequences? What about variable-length output sequences?\n",
    "4. What is beam search, and why would you use it? What tool can you use to implement it?\n",
    "5. What is an attention mechanism? How does it help?\n",
    "6. What is the most important layer in the transformer architecture? What is its purpose?\n",
    "7. When would you need to use sampled softmax?\n",
    "8. Embedded Reber grammars were used by Hochreiter and Schmidhuber in their paper about LSTMs. They are artificial grammars that produce strings such as “BPBTSXXVPSEPE”. Check outJenny Orr’s nice introduction to this topic, then choose a particular embedded Reber grammar (such as the one represented on Orr’s page), then train an RNN to identify whether a stringrespects that grammar or not. You will first need to write a function capable of generating a training batch containing about 50% strings that respect the grammar, and 50% that don’t.\n",
    "9. Train an encoder–decoder model that can convert a date string from one format to another (e.g., from “April 22, 2019” to “2019-04-22”).\n",
    "10. Go through the example on the Keras website for “Natural language image search with a Dual Encoder” . You will learn how to build a model capable of representing both images andtext within the same embedding space. This makes it possible to search for images using a text prompt, like in the CLIP model by OpenAI.\n",
    "11. Use the Hugging Face Transformers library to download a pretrained language model capable of generating text (e.g., GPT), and try generating more convincing Shakespearean text. Youwill need to use the model’s generate() method—see Hugging Face’s documentation for more details."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dlp08_intro_to_dl_for_computer_vision",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad0f3c8a064f687cbf898a0868fd45ba1c7e928ac8a0404f7c241d812ddc1e76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
