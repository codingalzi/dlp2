

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>2. 신경망 기본 구성 요소 &#8212; Deep Learning with Python(2판)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'building_blocks_of_NN';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="2.5. 부록: 텐서 소개" href="tensor_intro.html" />
    <link rel="prev" title="1. 딥러닝 소개" href="what_is_deep_learning.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    <p class="title logo__title">Deep Learning with Python(2판)</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="what_is_deep_learning.html">1. 딥러닝 소개</a></li>
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">2. 신경망 기본 구성 요소</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="tensor_intro.html">2.5. 부록: 텐서 소개</a></li>
<li class="toctree-l2"><a class="reference internal" href="tf_tensor.html">2.6. 부록: 텐서플로우 텐서</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="keras_and_tf.html">3. 케라스와 텐서플로우</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started_with_neural_networks.html">4. 신경망 활용 처음부터 끝까지: 분류와 회귀</a></li>
<li class="toctree-l1"><a class="reference internal" href="fundamentals_of_ml.html">5. 머신러닝 모델 훈련 기법</a></li>
<li class="toctree-l1"><a class="reference internal" href="unversal_workflow_of_ml.html">6. 머신러닝 작업 흐름 일반</a></li>
<li class="toctree-l1"><a class="reference internal" href="working_with_keras.html">7. 케라스 모델 고급 활용법</a></li>
<li class="toctree-l1"><a class="reference internal" href="computer_vision_intro.html">8. 컴퓨터 비전 기초: 합성곱 신경망</a></li>
<li class="toctree-l1"><a class="reference internal" href="computer_vision_advanced.html">9. 고급 컴퓨터 비전</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl_for_timeseries.html">10. 시계열 분석</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl_for_text.html">11. 자연어 처리</a></li>
<li class="toctree-l1"><a class="reference internal" href="generative_dl.html">12. 생성 모델</a></li>
<li class="toctree-l1"><a class="reference internal" href="best_practices.html">13. 딥러닝 실전 적용</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/codingalzi/dlp2" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/codingalzi/dlp2/issues/new?title=Issue%20on%20page%20%2Fbuilding_blocks_of_NN.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/building_blocks_of_NN.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>신경망 기본 구성 요소</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sec-nn-mnist">2.1. 신경망 모델 기초 훈련법</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">2.1.1. 훈련셋 준비</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">2.1.2. 신경망 모델 지정</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">2.1.3. 신경망 모델 컴파일</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">2.1.4. 데이터 전처리</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">2.1.5. 모델 훈련</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">2.2. 신경망 모델 훈련의 핵심 요소</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">2.3. 훈련된 모델 활용과 평가</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">2.4. 연습문제</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ch-building-blocks">
<span id="id1"></span><h1><span class="section-number">2. </span>신경망 기본 구성 요소<a class="headerlink" href="#ch-building-blocks" title="Permalink to this heading">#</a></h1>
<p><strong>감사의 글</strong></p>
<p>아래 내용은 프랑소와 숄레의
<a class="reference external" href="https://github.com/fchollet/deep-learning-with-python-notebooks">Deep Learning with Python(2판)</a>의
소스코드 내용을 참고해서 작성되었습니다.
자료를 공개한 저자에게 진심어린 감사를 전합니다.</p>
<p><strong>소스코드</strong></p>
<p>여기서 언급되는 코드를
<a class="reference external" href="https://colab.research.google.com/github/codingalzi/dlp2/blob/master/notebooks/NB-building_blocks_of_NN.ipynb">(구글 코랩) 신경망 구성 요소</a>에서
직접 실행할 수 있다.</p>
<p><strong>슬라이드</strong></p>
<p>본문 내용을 요약한 <a class="reference external" href="https://github.com/codingalzi/dlp2/raw/master/slides/slides-building_blocks_of_NN.pdf">슬라이드</a>를 다운로드할 수 있다.</p>
<p><strong>주요 내용</strong></p>
<p>아래 요소들을 직관적으로 살펴본다.</p>
<ul class="simple">
<li><p>신경망 모델 구성, 훈련, 활용</p></li>
<li><p>신경망 모델 훈련의 핵심 요소</p></li>
</ul>
<section id="sec-nn-mnist">
<span id="id2"></span><h2><span class="section-number">2.1. </span>신경망 모델 기초 훈련법<a class="headerlink" href="#sec-nn-mnist" title="Permalink to this heading">#</a></h2>
<p>케라스 라이브러리를 이용하여
MNIST 손글씨 데이터셋을 대상으로 분류를 학습하는
신경망 모델을 구성, 훈련, 활용하는 방법을 소개한다.</p>
<section id="id3">
<h3><span class="section-number">2.1.1. </span>훈련셋 준비<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<p>MNIST 데이터셋을 제공하는 많은 사이트가 있지만 여기서는
케라스 라이브러리가 자체로 제공하는 데이터셋을 활용한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p>손글씨 숫자 인식 용도 데이터셋. 28x28 픽셀 크기의 사진 70,000개의 샘플로 구성
라벨: 0부터 9까지 10개의 클래스 중 하나</p></li>
<li><p>훈련셋: 샘플 60,000개 (모델 훈련용)</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">train_images</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train_labels</span></code></p></li>
</ul>
</li>
<li><p>테스트셋: 샘플 10,000개 (훈련된 모델 성능 테스트용)</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">test_images</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">test_labels</span></code></p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch02-mnist-7.png?raw=true" style="width:600px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://towardsdatascience.com/exploring-how-neural-networks-work-and-making-them-interactive-ed67adbf9283">Towards data science: Mikkel Duif(2019)</a>&gt;</div></p><div class="info admonition">
<p class="admonition-title">샘플, 타깃, 라벨, 예측값, 클래스</p>
<p>머신러닝 모델의 훈련에 사용되는 데이터셋과 관련된 기본 용어는 다음과 같다.</p>
<ul class="simple">
<li><p>샘플<font size='2'>sample</font>: 개별 데이터를 가리킴.</p></li>
<li><p>타깃<font size='2'>target</font>과 라벨<font size='2'>label</font></p>
<ul>
<li><p>타깃: 개별 샘플과 연관된 값이며, 샘플이 주어지면 머신러닝 모델이 맞춰야 하는 값임.</p></li>
<li><p>라벨: 분류 과제의 경우 타깃 대신 라벨이라 부름.</p></li>
</ul>
</li>
<li><p>예측과 예측값: 개별 샘플에 대해 머신러닝 모델이 타깃에 가까운 값을 예측할 수록 좋은 성능의 모델임. 예측값은 모델이 입력 샘플들에 대해 예측한 값.</p></li>
<li><p>클래스<font size='2'>class</font>: 분류 모델의 에측값으로 사용될 수 있는 라벨(타깃)들의 집합. 범주<font size='2'>category</font>라고도 함.
객체지향 프로그래밍 언어의 클래스 개념과 다름에 주의할 것.</p></li>
</ul>
</div>
</section>
<section id="id4">
<h3><span class="section-number">2.1.2. </span>신경망 모델 지정<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<p>다음과 같이 구성된 신경망 모델을 MNIST 분류 모델로 사용한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    <span class="p">])</span>
</pre></div>
</div>
<p>위 신경망 모델의 구조에 사용된 요소들은 다음과 같다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Sequential</span></code> 클래스</p>
<ul>
<li><p>1개 이상의 층을 순차적으로 연결하여 모델 객체를 생성하는 (파이썬) 클래스.</p></li>
<li><p>앞으로 다른 방식으로 모델 객체를 생성하는 다양한 클래스를 접할 것임.</p></li>
</ul>
</li>
<li><p>층<font size='2'>layer</font></p>
<ul>
<li><p>데이터가 입력되면 적절한 방식으로 변환 후 이어지는 층으로 전달함.</p></li>
<li><p>여기서는 2개의 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층 사용.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층</p>
<ul>
<li><p>입력 샘플의 모든 특성을 이용하여 층의 출력값을 생성함.
이런 방식으로 연결된 층들을 <strong>조밀하게 연결된</strong><font size='2'>densely connected</font>
또는 <strong>완전하게 연결된</strong><font size='2'>fully-connected</font> 층이라고 함.
<code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층은 항상 조밀하게 다음 층과 연결됨.</p></li>
<li><p>첫째 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층</p>
<ul>
<li><p>512개의 유닛 사용. 784개의 픽셀값으로부터 512개의 값을 생성.
즉, 한 장의 MNIST 손글씨 숫자 사진에 해당하는 길이가 784인 1차원 어레이가 입력되면
길이가 512인 1차원 어레이를 생성함.</p></li>
<li><p>렐루<font size='2'>Relu</font> 함수: 활성화 함수로 사용됨.
생성된 512개의 값 중에서 음수는 모두 0으로 처리하는 함수.</p></li>
</ul>
</li>
<li><p>둘째 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층</p>
<ul>
<li><p>10개의 유닛 사용. 입력된 512개의 값으로부터 10개의 값을 생성.</p></li>
<li><p>소프트맥스<font size='2'>Softmax</font> 함수가 활성화 함수로 사용됨.</p></li>
<li><p>계산된 10개의 값을 이용하여 0부터 9까지 10개의 범주 각각에 속할 확률을 계산함. 모든 확률의 합은 1.</p></li>
</ul>
</li>
</ul>
</li>
<li><p>유닛<font size='2'>unit</font></p>
<ul>
<li><p>생성된 값을 저장하는 장치.</p></li>
<li><p>하나의 유닛에 하나의 값이 저장됨.</p></li>
</ul>
</li>
<li><p>활성화 함수<font size='2'>activation function</font></p>
<ul>
<li><p>생성되어 유닛에 저장된 값을 이용하여 새로운 개수의 다른 값을 생성하는 함수.</p></li>
<li><p>활성화 함수를 통과한 값이 다음 층으로 전달됨.</p></li>
</ul>
</li>
</ul>
</section>
<section id="id5">
<h3><span class="section-number">2.1.3. </span>신경망 모델 컴파일<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h3>
<p>지정된 신경망 모델을 훈련시키기 위해서 옵티마이저, 손실 함수, 성능 평가 지표를
설정하는 컴파일 과정을 실행해야 한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;rmsprop&quot;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>위 컴파일 과정에 사용된 요소들은 다음과 같다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">optimizer</span></code></p>
<ul>
<li><p>경사하강법(역전파) 업무를 처리하는 옵티마이저 지정.</p></li>
<li><p>여기서는 <code class="docutils literal notranslate"><span class="pre">rmsprop</span></code> 옵티마이저 사용.</p></li>
<li><p>앞으로 다양한 옵티마이저를 접할 것임.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">loss</span></code></p>
<ul>
<li><p>손실 함수<font size='2'>loss function</font> 지정.</p></li>
<li><p>손실 함수: 모델 훈련하는 동안 모델의 성능을 손실값으로 측정. 손실값이 작을 수록 좋음.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">metrics</span></code></p>
<ul>
<li><p>훈련과 테스트 과정을 모니터링 할 때 사용되는 한 개 이상의 평가 지표<font size='2'>metric</font>를 포함하는 리스트로 지정.</p></li>
<li><p>손실 함수값, 정확도 등 모델의 종류에 따라 다양한 평가 지표를 사용할 수 있음.</p></li>
<li><p>분류 모델의 경우 일반적으로 정확도<font size='2'>accuracy</font>를 평가지표로 포함시킴.</p></li>
</ul>
</li>
</ul>
</section>
<section id="id6">
<h3><span class="section-number">2.1.4. </span>데이터 전처리<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h3>
<p>머신러닝 모델에 따라 입력값이 적절한 형식을 갖춰야 한다.
앞서 두 개의 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층과 <code class="docutils literal notranslate"><span class="pre">Sequential</span></code> 클래스로 지정된 모델의
입력값은 1차원 어레이 형식을 갖춰야 한다.</p>
<p>그런데 MNIST 데이터 샘플의 경우
0부터 255 사이의 8비트 정수(<code class="docutils literal notranslate"><span class="pre">uint8</span></code>)로 이루어진 <code class="docutils literal notranslate"><span class="pre">(28,</span> <span class="pre">28)</span></code> 모양의 2차원 어레이로 표현되었다.
이를 1차원 어레이로 변환하기 위해 <code class="docutils literal notranslate"><span class="pre">(28*28,</span> <span class="pre">)</span></code> 모양의 1차원 어레이로 변환한다.
또한 어레이의 각 항목을 0부터 1 사이의 32비트 부동소수점(<code class="docutils literal notranslate"><span class="pre">float32</span></code>)으로 변환한다.
이는 머신러닝 모델이 일반적으로 정수가 아닌 부동소수점 계산을 사용하기 때문이다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">))</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>   <span class="c1"># 0과 1사이의 값</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">))</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>     <span class="c1"># 0과 1사이의 값</span>
</pre></div>
</div>
</section>
<section id="id7">
<h3><span class="section-number">2.1.5. </span>모델 훈련<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h3>
<p>모델 훈련은 컴파일된 모델의 <code class="docutils literal notranslate"><span class="pre">fit()</span></code> 메소드를 호출하면 된다.
MNIST 모델의 경우 지도 학습 모델이기에 입력 데이터셋과 타깃 데이터셋을 각각 첫째와 둘째 인자로 사용한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>첫째 인자: 훈련 데이터셋</p></li>
<li><p>둘째 인자: 훈련 라벨셋</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">epoths</span></code>: 에포크. 전체 훈련 세트 대상 반복 훈련 횟수.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batch_size</span></code>: 배치 크기. 배치 크기만큼의 훈련 데이터셋로 훈련할 때 마다 가중치 업데이트.</p></li>
</ul>
<p>모델의 훈련 과정 동안 에포크가 끝날 때마다
평균 손실값과 평균 정확도를 계산하여 다음과 같이 출력한다.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">1</span><span class="o">/</span><span class="mi">5</span>
<span class="mi">469</span><span class="o">/</span><span class="mi">469</span> <span class="p">[</span><span class="o">==============================</span><span class="p">]</span> <span class="o">-</span> <span class="mi">5</span><span class="n">s</span> <span class="mi">4</span><span class="n">ms</span><span class="o">/</span><span class="n">step</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.2551</span> <span class="o">-</span> <span class="n">accuracy</span><span class="p">:</span> <span class="mf">0.9263</span>
<span class="n">Epoch</span> <span class="mi">2</span><span class="o">/</span><span class="mi">5</span>
<span class="mi">469</span><span class="o">/</span><span class="mi">469</span> <span class="p">[</span><span class="o">==============================</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="n">s</span> <span class="mi">4</span><span class="n">ms</span><span class="o">/</span><span class="n">step</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.1044</span> <span class="o">-</span> <span class="n">accuracy</span><span class="p">:</span> <span class="mf">0.9693</span>
<span class="n">Epoch</span> <span class="mi">3</span><span class="o">/</span><span class="mi">5</span>
<span class="mi">469</span><span class="o">/</span><span class="mi">469</span> <span class="p">[</span><span class="o">==============================</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="n">s</span> <span class="mi">3</span><span class="n">ms</span><span class="o">/</span><span class="n">step</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.0683</span> <span class="o">-</span> <span class="n">accuracy</span><span class="p">:</span> <span class="mf">0.9793</span>
<span class="n">Epoch</span> <span class="mi">4</span><span class="o">/</span><span class="mi">5</span>
<span class="mi">469</span><span class="o">/</span><span class="mi">469</span> <span class="p">[</span><span class="o">==============================</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="n">s</span> <span class="mi">4</span><span class="n">ms</span><span class="o">/</span><span class="n">step</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.0504</span> <span class="o">-</span> <span class="n">accuracy</span><span class="p">:</span> <span class="mf">0.9847</span>
<span class="n">Epoch</span> <span class="mi">5</span><span class="o">/</span><span class="mi">5</span>
<span class="mi">469</span><span class="o">/</span><span class="mi">469</span> <span class="p">[</span><span class="o">==============================</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="n">s</span> <span class="mi">3</span><span class="n">ms</span><span class="o">/</span><span class="n">step</span> <span class="o">-</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.0378</span> <span class="o">-</span> <span class="n">accuracy</span><span class="p">:</span> <span class="mf">0.9885</span>
</pre></div>
</div>
<p><strong>배치 크기, 스텝, 에포크</strong></p>
<p><strong>스텝</strong><font size='2'>step</font>은 하나의 배치(묶음)에 대해 훈련하는 과정을 가리킨다.
위 코드에서 <strong>배치 크기</strong>(<code class="docutils literal notranslate"><span class="pre">batch_size</span></code>)가 128이기에 총 6만개의 훈련 샘플을 128개씩 묶는다.
따라서 469(60,000/128 = 468.75)개의 배치가 생성되며,
하나의 <strong>에포크</strong><font size='2'>epoch</font> 동안 총 469번의 스텝이 실행된다.</p>
<p>스텝이 끝날 때마다 사용된 배치 묶음에 대한 손실값과 정확도가 계산되어
에포크 단위로 평균값이 훈련 과정중에 보여지게 된다.
위 훈련은 총 5번의 훈련 에포크가 진행되며 최종적으로 훈련셋에 대한 정확도는 98.85%로 계산되었다.</p>
<p><strong>모델 예측값 계산 과정</strong></p>
<p>전처리된 데이터가 신경망 모델에 전달되어 출력값으로 변환되는 과정을 묘사하면 다음과 같다.</p>
<div align="center"><img src="https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch02-mnist_2layers_arch.png?raw=true" style="width:600px;"></div><ul class="simple">
<li><p>손글씨 데이터 샘플 입력</p>
<ul>
<li><p>위 사진에서는 8을 가리키는 사진 샘플이 입력값으로 사용됨.</p></li>
<li><p>784 개의 픽셀값으로 구성된 1차원 어레이로 변환</p></li>
</ul>
</li>
<li><p>첫째 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층</p>
<ul>
<li><p>입력된 784개의 픽셀값을 이용하여 512개의 값 생성.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">relu()</span></code> 활성화 함수로 인해 음수는 모두 0으로 처리됨.</p></li>
</ul>
</li>
<li><p>둘째 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층</p>
<ul>
<li><p>첫째 <code class="docutils literal notranslate"><span class="pre">Dense</span></code> 층에서 생성된 512개의 값을 이용하여 10개의 값 생성.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">softmax()</span></code> 활성화 함수로 인해 모두 0과 1사이의 값으로 변환됨.
모든 값의 합이 1이 되며, 각각의 범주에 속할 확률을 가리킴.</p></li>
</ul>
</li>
</ul>
<p><strong>가중치 행렬과 출력값 계산</strong></p>
<p>아래 그림은 위 모델을 단순화 시켜서 첫째 층과 둘째 층 모두 3개의 유닛으로 구성되었을 때
둘째 층에서 첫째 층에서 넘어온 특성들을 변환시키는 과정을 한눈에 보여준다.</p>
<div align="center"><img src="https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch02-mnist01.png?raw=true" style="width:500px;"></div>
<p>하나의 샘플에 대한 데이터 변환의 구체적인 계산은 다음과 같다.</p>
<div align="center"><img src="https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch02-mnist02.png?raw=true" style="width:500px;"></div>
<p>위 변환식을 행렬 연산으로 표현하면 다음과 같다.</p>
<div align="center"><img src="https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch02-mnist03a.png?raw=true" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://datascienceplus.com/mnist-for-machine-learning-beginners-with-softmax-regression/">MNIST For Machine Learning Beginners With Softmax Regression</a>&gt;</div></p><div class="note admonition">
<p class="admonition-title">선형 회귀 모델의 예측값 계산</p>
<p>아래 식은 선형회귀 모델이 가중치 벡터와 편향을 이용하여 예측값을 계산하는 방식을 보여주는데,
신경망 모델에 포함된 하나의 유닛에 저장될 하나의 값을 계산하는 것과 동일하다.
단, 신경망 모델에 사용되는 사용되는 유닛마다 다른 가중치 벡터와 편향을 학습해야 한다는 점이 다르다.</p>
<div class="math notranslate nohighlight">
\[
\hat y = w_1 \cdot x_1 + \cdots + w_n \cdot x_n + b
\]</div>
</div>
<p><strong>스텝과 훈련</strong></p>
<p>이전 그림들은 모두 하나의 입력 샘플이 변환되는 과정을 보여준다.
하지만 입력 데이터의 변환은 실제로는 배치 단위로 이루어진다.
즉, 배치에 포함된 모든 샘플에 대해 동시에 데이터 변환을 실행한다.
예를 들어, 배치 크기가 128이면, 위 MNist 손글씨 이미지를 분류하는
모델은 <code class="docutils literal notranslate"><span class="pre">128x784</span></code> 모양의 2차원 어레이를 입력값으로 사용하며,
각각의 층에서 이뤄지는 데이터 변환은 다음과 같은 행렬 연산으로 계산된다.
아래 식에서 <code class="docutils literal notranslate"><span class="pre">W</span></code>는 가중치 행렬을, <code class="docutils literal notranslate"><span class="pre">X</span></code> 는 배치 데이터셋, <code class="docutils literal notranslate"><span class="pre">b</span></code>는 편향 벡터를 가리킨다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">softmax</span><span class="p">(</span><span class="n">W</span> <span class="n">X</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
<p>가중치 행렬과 편향 벡터는 모델의 훈련이 시작될 때 무작위로 초기화된다.
그런 다음 스텝을 반복하면서 타깃에 보다 가까운 예측값을 계산하는 가중치 행렬과 편향 벡터를
경사하강법을 활용하여 학습한다.</p>
<p>정리하면, 스텝은 다음 과정으로 이루어진다.</p>
<ul class="simple">
<li><p>입력된 배치 데이터셋을 변환하여 모델의 예측값 생성</p></li>
<li><p>예측값의 오차 정보를 이용하여 보다 정확한 예측값을 생성할 수 있도록 가중치 행렬과 편향 벡터를 조정</p></li>
</ul>
<p>이러한 스텝이 하나의 에포크 동안 여러 번 실행된다.
예를 들어, 앞서 배치 크기가 128이고, 훈련 데이터셋의 크기가 6만이었기에 하나의 에포크 동안
총 469번의 스텝이 실행된다.
이유는 <code class="docutils literal notranslate"><span class="pre">60000</span> <span class="pre">=</span> <span class="pre">28</span> <span class="pre">*</span> <span class="pre">468</span> <span class="pre">+</span> <span class="pre">96</span></code> 이기에 128개로 묶인 468개의 묶음 각각에 대해 스텝이 진행되고
나머지 96개를 묶은 배치에 대한 스텝이 한 번 더 진행되기 때문이다.</p>
<p><strong>아핀 변환과 데이터 변환</strong></p>
<p>데이터셋 <code class="docutils literal notranslate"><span class="pre">X</span></code>에 대해 행렬 연산 <code class="docutils literal notranslate"><span class="pre">W</span> <span class="pre">X</span> <span class="pre">+</span> <span class="pre">b</span></code>를 이용한 데이터 변환을
<strong>아핀 변환</strong><font size='2'>Affine transformation</font>이라 부른다.
따라서 신경망 모델에서 층과 층 사이의 데이터 변환은
기본적으로 아핀 변환 이후에
활성화 함수를 적용한 결과로 얻어진다.</p>
</section>
</section>
<section id="id8">
<h2><span class="section-number">2.2. </span>신경망 모델 훈련의 핵심 요소<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h2>
<p>딥러닝 모델이 사용하는 신경망의 훈련은
입력 데이터를 배치 단위로 여러 층을 통과시키면서 변환시키는 과정을
최적의 예측값을 만들 때까지 여러 에포크를 거치면서 진행한다.
이런 신경망 훈련의 핵심 요소는 다음과 같다.</p>
<ul class="simple">
<li><p>가중치</p></li>
<li><p>순전파</p></li>
<li><p>손실 함수</p></li>
<li><p>역전파</p></li>
<li><p>경사하강법</p></li>
<li><p>옵티마이저</p></li>
<li><p>훈련 루프</p></li>
</ul>
<p><strong>가중치와 순전파</strong></p>
<p>신경망의 각 층에 사용되는 데이터 변환 알고리즘 알고리즘은
<strong>가중치</strong><font size='2'>weight</font>라 불리는
<strong>파라미터</strong><font size='2'>parameter</font>에 의해 결정된다.</p>
<p>층에 데이터가 입력되면 변환 알고리즘에 의해 변환된 데이터가 다음 층으로 전달된다 (아래 그림 참고).
이와 같이 입력값을 가중치와 조합하는 과정을 여러 층에서 수행하여
최종 결과물인 예측값<font size='2'>prediction</font>을
생성하는 과정을 <strong>순전파</strong><font size='2'>forward pass</font>라고 한다.</p>
<p><strong>머신러닝 모델의 훈련은 바로 각 층에서 필요한 적절한 가중치를 찾는 과정을 가리킨다.</strong>
경우에 따라서 수 십만 수 백만, 수 천만 개 까지의 매우 많은 수의 적절한 가중치와 편향 파라미터를 학습해야 하는
훈련 과정이 매우 어렵거나 심지어 불가능한 과제로 판명되기도 한다.</p>
<div align="center"><img src="https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch01-deep-learning-in-3-figures-3-a3.png?raw=true" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><div class="note admonition">
<p class="admonition-title">신경망 모델의 가중치 파라미터</p>
<p>신경망 모델의 가중치 파라미터는 가중치 행렬과 편향 벡터를 모두 포함하는 것으로 이해해야 한다.</p>
</div>
<p><strong>손실 함수</strong></p>
<p>모델의 <strong>손실 함수</strong><font size='2'>loss function</font>는
모델의 최종 출력결과인 예측값과 실제 타깃<font size='2'>target</font>이
얼마나 다른지를 측정한다.
손실 함수를 <strong>목적 함수</strong><font size='2'>objective function</font> 또는
<strong>비용 함수</strong><font size='2'>cost function</font>라고도 부른다.
훈련된 모델에 대한 손실 함수의 값인 <strong>손실 점수</strong><font size='2'>loss score</font>는
낮을 수록 훈련이 잘되었다고 평가한다.</p>
<div align="center"><img src="https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch01-deep-learning-in-3-figures-3-a2.png?raw=true" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>역전파, 경사하강법, 옵티마이저</strong></p>
<p><strong>역전파</strong><font size='2'>backpropagation</font>는
<strong>경사하강법</strong><font size='2'>gradient descent</font>에 기초하여
훈련 중인 모델의 손실값을 최대한 낮추는 방향으로
각 층의 가중치를 조절하는 과정을 가리킨다.
역전파는 <strong>옵티마이저</strong><font size='2'>optimizer</font>에 의해 실행되며
딥러닝 모델 훈련 알고리즘의 핵심이다.</p>
<p>모델 훈련이 시작될 때 가중치는 임의로 초기화된다.
이후 손실 점수가 보다 작아지는 방향으로 조금씩 업데이트하는
<strong>역전파를 반복 실행</strong>하면서 손실값이 점차 낮아져서 최종적으로 최소 손실값을 갖도록 하는
가중치를 학습해 간다.</p>
<div align="center"><img src="https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch01-deep-learning-in-3-figures-3-d.png?raw=true" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p><p><strong>훈련 루프</strong></p>
<p>신경망 모델의 <strong>훈련 루프</strong><font size='2'>training loop</font>는
“순전파-손실값 계산-역전파”로 구성된 순환과정을 가리키며,
모델의 훈련은 최소 손실값을 갖도록 하는 가중치를 찾을 때까지 훈련 루프를 반복하는 방식으로 진행된다.</p>
<div align="center"><img src="https://github.com/codingalzi/dlp2/blob/master/jupyter-book/imgs/ch01-deep-learning-in-3-figures-3-a1.png?raw=true" style="width:500px;"></div>
<p><div style="text-align: center">&lt;그림 출처: <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python(2판)</a>&gt;</div></p></section>
<section id="id9">
<h2><span class="section-number">2.3. </span>훈련된 모델 활용과 평가<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h2>
<p><strong>모델 활용</strong></p>
<p>훈련된 모델을 이용하여 훈련에 사용되지 않은 손글씨 숫자 사진 10장에 대한 예측값을
<code class="docutils literal notranslate"><span class="pre">predict()</span></code> 메서드로 확인하는 방식은 다음과 같다.
<code class="docutils literal notranslate"><span class="pre">predict()</span></code> 메서드의 입력값이 하나의 샘플이 아닌 여러 개의 샘플에 대해 동시에 계산될 수 있음에 주의한다.
즉, 하나의 샘플에 대한 예측값을 계산하고자 하더라도 무조건 하나의 샘플 데이터로 구성된 2차원 어레이가 입력값으로 사용된다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">test_digits</span> <span class="o">=</span> <span class="n">test_images</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_digits</span><span class="p">)</span>
</pre></div>
</div>
<p>출력값으로 각 사진에 대한 예측값으로 구성된 2차원 어레이가 계산된다.
각 항목은 각 입력값으로 사용된 손글씨 사진이 각 범주에 속할 확률을 갖는
길이가 10인 1차원 어레이가 된다.
예를 들어 첫째 사진에 대한 예측값은 다음과 같다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">array([5.6115879e-10, 6.5201892e-11, 3.8620074e-06, 2.0421362e-04,</span>
<span class="go">       2.3715735e-13, 1.0822280e-08, 3.6126845e-15, 9.9979085e-01,</span>
<span class="go">       2.0998414e-08, 1.0214288e-06], dtype=float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span> 
<span class="go">7 </span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">7</span><span class="p">]</span> 
<span class="go">0.99999106</span>
</pre></div>
</div>
<p>위 예측값의 7번 인덱스의 값이 0.998 정도로 가장 높으며, 이는
0번 사진 입력 샘플이 숫자 7을 담고 있을 확률이 거의 100% 라고 예측했음을 의미한다.
실제로도 0번 사진은 숫자 7을 담고 있어서 이 경우는 정확하게 예측되었다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">test_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> 
<span class="go">7</span>
</pre></div>
</div>
<p><strong>모델 성능 평가</strong></p>
<p>훈련에 사용되지 않은 테스트셋 전체에 대한 성능 평가를 위해
<code class="docutils literal notranslate"><span class="pre">evaluate()</span></code> 메서드를 테스트셋과 테스트셋의 라벨셋을 인자로 해서 호출한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
<span class="go">313/313 [==============================] - 1s 3ms/step - loss: 0.0635 - accuracy: 0.9811</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;test_acc: </span><span class="si">{</span><span class="n">test_acc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">test_acc: 0.9811000227928162</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">evaluate()</span></code> 메서드의 반환값 계산은 훈련 과정과 동일하게 배치 단위로 손실값과 앞서 모델을 컴파일할 때 지정한 정확도를
계산한 다음에 최종적으로 손실값과 정확도의 평균값을 반환한다.
배치 크기는 32가 기본값으로 사용되기에 총 313(10,000/32=312.5)번의 스텝이 진행되었다.</p>
<p>테스트 세트에 대한 정확도는 98.11% 이며 훈련 세트에 대한 정확도인 98.85% 보다 조금 낮다.
이는 모델이 훈련 세트에 대해 약간의 <strong>과대 적합</strong><font size='2'>overfitting</font>이 발생했음을 의미한다.
과대적합과 과대적합을 해결하는 다양한 방법에 대해서는 나중에 보다 자세히 다룬다.</p>
</section>
<section id="id10">
<h2><span class="section-number">2.4. </span>연습문제<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://colab.research.google.com/github/codingalzi/dlp2/blob/master/excs/exc-building_blocks_of_NN.ipynb">(실습) 신경망 기본 구성 요소</a></p></li>
</ol>
</section>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="what_is_deep_learning.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1. </span>딥러닝 소개</p>
      </div>
    </a>
    <a class="right-next"
       href="tensor_intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2.5. </span>부록: 텐서 소개</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sec-nn-mnist">2.1. 신경망 모델 기초 훈련법</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">2.1.1. 훈련셋 준비</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">2.1.2. 신경망 모델 지정</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">2.1.3. 신경망 모델 컴파일</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">2.1.4. 데이터 전처리</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">2.1.5. 모델 훈련</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">2.2. 신경망 모델 훈련의 핵심 요소</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">2.3. 훈련된 모델 활용과 평가</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">2.4. 연습문제</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By 코딩알지
</p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>